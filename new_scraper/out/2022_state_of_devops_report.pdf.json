[{"source": "sources/2022_state_of_devops_report.pdf", "content": "2022 Accelerate\nState of DevOps Report\nSponsored by"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Table of contents\n2 Contents05  Surprises 55\n06   Demographics and  \nFirmographics 59\n07  Final thoughts 67\n08  Acknowledgements 68\n09  Authors 69\n10  Methodology 73\n11  Further reading 7601  Executive summary 03\n02   How do  \nyou compare?\n\n08\n03   How do  \nyou improve?\n\nIntroduction 19\n Cloud  21\n SRE and DevOps  26\n Technical DevOps Capabilities 29\n Culture  37\n04   Why supply chain  \nsecurity matters 42\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "3For the last eight years, we have produced the \nAccelerate State of DevOps report, hearing from \n33,000 professionals along the way.\n\nOur research \nfocuses on examining how capabilities and  \npractices predict the outcomes that we consider \ncentral to DevOps:\n\u2022 Software delivery performance \u2013 The Four Key \nMetrics of software delivery performance: \ndeployment frequency, lead time for changes, \nchange failure rate, and time to restore service.\n\n\u2022 Operational performance \u2013 The Fifth Key  \nMetric, reliability.\n\n\u2022 Organizational performance \u2013 How well \nyour organization meets performance and \nprofitability goals.\n\nWe also focus on the factors that underlie  \nother outcomes like burnout and the  \nlikelihood that employees will recommend  \ntheir teams.\n\nExecutive summaryExecutive summary01\nAccelerate  State of DevOps 2022\nDerek DeBellis Claire Peters"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Securing the  \nsoftware supply chain \n4 Executive summaryAdoption of good application development security \npractices was correlated with additional benefits.\n\nWe found that teams that focus on establishing \nthese security practices have reduced developer \nburnout; teams with low levels of security practices \nhave 1.4x greater odds of having high levels of \nburnout than teams with high levels of security.1  \nThe teams that focus on establishing security \npractices are significantly more likely to  \nrecommend their team to someone else.\n\nFurther, \nSLSA-related security practices positively predict \nboth organizational performance and software \ndelivery performance, but this effect needs  \nstrong continuous integration capabilities  \nin place to fully emerge.\n\n1 We conceptualize high in this stat as >= 1 standard deviation on the score (e.g.\n\nsecurity) and low as <= -1 standard deviation on the score."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "1 We conceptualize high in this stat as >= 1 standard deviation on the score (e.g.\n\nsecurity) and low as <= -1 standard deviation on the score.\n\nAccelerate  State of DevOps 2022In 2021, we found that securing the software  \nsupply chain is essential to reaching many  \nimportant outcomes.\n\nThis year we dug deeper on software supply chain \nsecurity, making it a primary theme of our survey \nand report.\n\nWe leveraged the Supply Chain Levels for \nSecure Artifacts (SLSA) framework to explore technical \npractices that support the development of software \nsupply chain security.\n\nWe also used the National \nInstitute for Standards and Technology\u2019s Secure \nSoftware Development Framework (NIST SSDF) \nto explore attitudes, processes, and non-technical \npractices related to securing the software supply chain."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "We found that the biggest predictor of an \norganization\u2019s application-development security \npractices was cultural, not technical: high-trust, \nlow-blame cultures focused on performance were \n1.6x more likely to have above average adoption of \nemerging security practices than low trust, high-\nblame cultures focused on power or rules.\n\nWe also \nfound early evidence suggesting that pre-deployment \nsecurity scanning is effective at finding vulnerable \ndependencies, resulting in fewer vulnerabilities in \nproduction code."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Besides the security practices mentioned above,  \nthe key variables that impact organizational \nperformance tend to fall in the following categories: \nOrganizational and team culture\nHigh-trust and low-blame cultures, as defined by \nWestrum, tend to have higher organizational \nperformance.\n\nSimilarly, organizations with teams that feel \nsupported through funding and leadership sponsorships \ntend to have higher organizational performance.\n\nTeam \nstability and positive perceptions about one\u2019s team \n(likelihood to recommend team) also tend to lead to \nhigher levels of organizational performance.\n\nLastly, \ncompanies that offer flexible work arrangements tend  \nto see high levels of organizational performance.\n\nReliability\nBoth the practices we associate with reliability \nengineering (e.g., clear reliability goals, salient reliability \nmetrics, etc.)\n\nand the extent to which people report \nmeeting their reliability expectations are powerful \npredictors of high levels of organizational performance."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "and the extent to which people report \nmeeting their reliability expectations are powerful \npredictors of high levels of organizational performance.\n\n5 Executive summary Accelerate  State of DevOps 20222Jung, Sun Jae.\n\n\u201cIntroduction to Mediation Analysis and Examples of Its Application to Real-world Data.\u201d Journal of preventive medicine and \npublic health = Yebang Uihakhoe chi vol.\n\n54,3 (2021): 166-172. doi:10.3961/jpmph.21.069\n3 Carri\u00f3n, Gabriel Cepeda, Christian Nitzl, and Jos\u00e9 L. Rold\u00e1n.\n\n\u201cMediation analyses in partial least squares structural equation modeling: \nGuidelines and empirical examples.\u201d Partial least squares path modeling.\n\nSpringer, Cham, 2017.\n\n173-195.Drivers of organizational \nperformance\nCloud\nWe found that cloud usage is predictive of  \norganizational performance.\n\nCompanies with software \ninitially built on and for the cloud tend to have higher \norganizational performance."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Companies with software \ninitially built on and for the cloud tend to have higher \norganizational performance.\n\nUsing private clouds,  \npublic clouds, hybrid clouds, or a mixture of clouds, \ncorresponds with higher organizational performance  \nthan the use of on-premises servers alone.\n\nThose who  \nuse multiple public clouds are 1.4x more likely to have \nabove average organizational performance than those \nwho don\u2019t.\n\nCloud usage also seems to impact organizational \nperformance through other factors in our dataset.\n\nOne example is supply chain security, where we found \nthat organizations using public clouds were also more \nlikely to implement SLSA practices\u2013 perhaps because \ncloud providers encourage and provide building blocks \nfor many SLSA practices, such as automating builds and \ndeployments.2,3 The broader point is that using cloud \nplatforms opens a team up to inherit many capabilities  \nand practices that eventually flow into higher \norganizational performance.\u201d"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "6 Executive summaryContext matters\n\u2022 High software delivery performance is only \nbeneficial to organizational performance when \noperational performance is also high.\n\nDelivering \nquickly might not matter if your service is unable to \nmeet users' reliability expectations.\n\n\u2022 Implementing software supply chain security \ncontrols, like those recommended by the SLSA \nframework, has a positive effect on software \ndelivery performance when continuous integration \nis firmly established.\n\nWithout continuous \nintegration capabilities in place, software  \ndelivery performance and security controls  \nmight be in conflict.\n\n\u2022 The impact of Site Reliability Engineering (SRE) \npractices on a team\u2019s ability to reach reliability \ntargets is non-linear.\n\nPracticing SRE doesn\u2019t \npositively affect reliability until a team achieves \na certain level of SRE maturity.\n\nBefore a team reaches this level of SRE maturity, we don\u2019t detect \na relationship between SRE and reaching reliability \ntargets."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Before a team reaches this level of SRE maturity, we don\u2019t detect \na relationship between SRE and reaching reliability \ntargets.\n\nAs a team\u2019s SRE adoption grows, however, \nit reaches an inflection point where the use of SRE \nstarts to strongly predict reliability.\n\nThe improved \nreliability then impacts organizational performance.\n\n\u2022 Technical capabilities build upon one another.\n\nContinuous delivery and version control amplify \neach other\u2019s ability to promote high levels of \nsoftware delivery performance.\n\nCombining \ncontinuous delivery, loosely-coupled architecture, \nversion control, and continuous integration fosters \nsoftware delivery performance that is greater than \nthe sum of its parts.\n\nAccelerate  State of DevOps 2022For a long time, DORA has taken into consideration that effects depend on broader team context.\n\nWe believe \nit\u2019s important to understand a team\u2019s characteristics (processes, strengths, constraints, and goals), and the \nenvironment in which the work takes place."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "We believe \nit\u2019s important to understand a team\u2019s characteristics (processes, strengths, constraints, and goals), and the \nenvironment in which the work takes place.\n\nFor example, a technical capability that is advantageous in one \ncontext could be deleterious in another.\n\nThis year we focused on explicitly modeling these hypothesized \nconditions in the form of interactions; many of these hypotheses are supported by this year\u2019s data:"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "7 Executive summaryThe conditions upon which delivery depends, and  \nthe need to understand a team\u2019s broader context,  \nleads us to a conclusion that is similar to this  \ninsight from 2021: \n\u201cTo make meaningful improvements, teams must  \nadopt a philosophy of continuous improvement.\n\nUse the benchmarks to measure your current \nstate, identify constraints based on the capabilities \ninvestigated by the research, and experiment \nwith improvements to relieve those constraints.\n\nExperimentation will involve a mix of victories and \nfailures, but in both scenarios teams can take \nmeaningful actions as a result of lessons learned.\u201d\nIndeed, we found an effect this year that is deeply \naligned with this overarching philosophy: teams that \nrecognize the need to continuously improve tend to have \nhigher organizational performance than those that don\u2019t.\n\nIn short, teams need to continuously adapt, and  \nto experiment with software development practices."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "In short, teams need to continuously adapt, and  \nto experiment with software development practices.\n\nTeams that recognize  \nthe need to continuously \nimprove tend to have higher \norganizational performance \nthan those that don\u2019t.\n\nAccelerate  State of DevOps 2022We know this because, overall, teams that do this  \nhave higher organizational performance.\n\nNot always \n(what works for one organization does not necessarily \nwork for another), but most of the time.\n\nAs you engage  \nin your own experiments with DevOps practices,  \nbe prepared for the occasional failure as you hone  \nin on what works for your team.\n\nThis year we also uncovered a number of surprises  \nin the data but you\u2019ll have to read on to find out  \nwhat those are."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "8 How do you compare?Are you curious about how your team compares to \nothers in the industry?\n\nThis section includes the latest \nbenchmark assessment of DevOps performance.\n\nWe examine how teams develop, deliver, and operate \nsoftware systems, and then segment respondents into \nclusters that capture the most common combinations \nof DevOps performance.\n\nThis year we include two different clustering approaches.\n\nThe first is based on historical precedent.\n\nThis clustering \napproach focuses on creating clusters based on four \nmetrics that capture software delivery performance: lead \ntime, deployment frequency, time to restore service, and \nchange failure rate.\n\nWe summarize each of these below.\n\nThe goal of this approach is to help you quantify your \nteam\u2019s current performance so that you can compare \nyour performance to other teams.\n\nHow do you compare?02\nThe second clustering approach includes a fifth metric, \nreliability, which we use to understand operational \nperformance."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "How do you compare?02\nThe second clustering approach includes a fifth metric, \nreliability, which we use to understand operational \nperformance.\n\nWhy add a new metric to the cluster \nanalysis?\n\nBecause we have consistently seen the \nimportance of this metric.\n\nIndeed, we have evidence \nthat suggests that delivery performance can be \ndetrimental to organizational performance if not \npaired with strong operational performance.\n\nUnlike \nour traditional clustering approach, this is a descriptive \nexercise that attempts to paint a picture of common \nways teams perform across delivery and operational \nperformance.\n\nHence, it isn\u2019t always obvious which \ncluster is better.\n\nFirst, let\u2019s look at a brief overview of the five  \nmeasures we\u2019re using to understand software  \ndelivery and operational performance.\n\nAccelerate  State of DevOps 2022Derek DeBellis"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "9Software delivery and  \noperational performance\nTo meet the demands of their ever-changing \nindustries, organizations must deliver and operate \nsoftware quickly and reliably.\n\nThe faster your teams \ncan make changes to your software, the sooner you \ncan deliver value to your customers, run experiments, \nand receive valuable feedback.\n\nWith eight years of \ndata collection and research, we have developed and \nvalidated four metrics that measure software delivery \nperformance.\n\nSince 2018, we\u2019ve included a fifth metric \nHow do you compare?\n\nAccelerate  State of DevOps 2022\nto capture operational capabilities.\n\nTeams that excel \nin all five measures exhibit exceptional organizational \nperformance.\n\nWe call these five measures software \ndelivery and operational (SDO) performance."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Teams that excel \nin all five measures exhibit exceptional organizational \nperformance.\n\nWe call these five measures software \ndelivery and operational (SDO) performance.\n\nNote \nthat these metrics focus on system-level outcomes, \nwhich helps avoid the common pitfalls of tracking \nsoftware metrics, that may result in pitting functions \nagainst each other and making local optimizations  \nat the cost of overall outcomes."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "10Five metrics of delivery  \nand operational performance\nThe four metrics of software delivery performance  \ncan be considered in terms of throughput and stability.\n\nWe measure throughput using lead time for code \nchanges  (that is, time from code commit to release  \nin production), and deployment frequency.\n\nWe measure stability using time to restore a service \nafter an incident and change failure rate.\n\nA fifth metric represents operational performance  \nand is a measure of modern operational practices.\n\nWe base operational performance on reliability, \nwhich is how well your services meet user expectations, \nsuch as availability and performance.\n\nHistorically we \nmeasured availability rather than reliability, but because \navailability is a specific focus of reliability engineering, \nwe expanded to measure reliability in 2021 so that \navailability, latency, performance, and scalability would \nbe more broadly represented."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Specifically, we asked \nrespondents to rate their ability to meet or exceed  \ntheir reliability targets.\n\nWe found that teams with \nvarying degrees of delivery performance see better \noutcomes (e.g., less burnout) when they also prioritize \noperational performance.\n\nHow do you compare?Lead time \nfor changesMTTR\nDeployment  \nfrequencyChange  \nfailure  rate\nOpera tional\nReliabilit y\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "11Historical clustering approach: \nclustering delivery performance\nThis year, when evaluating the four-cluster solution \nwe\u2019ve used since 2018, we noticed that the data \nshowed a clear low performance cluster and a clear \nhigh performance cluster.\n\nHowever, the two clusters \nthat we would traditionally use to demarcate medium \nperformance and high performance were not \ndifferentiated enough to warrant a split."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Furthermore, \nthe various indices that we use to pick the right cluster \nHow do you compare?Software delivery performance metric Low Medium High\nDeployment frequency\nFor the primary application or service you work on, how often does your \norganization deploy code to production or release it to end users?Between once per \nmonth and once \nevery 6 monthsBetween once \nper week and \nonce per monthOn-demand\n(multiple \ndeploys per \nday)\nLead time for changes\nFor the primary application or service you work on, what is your lead time \nfor changes (i.e., how long does it take to go from code committed to code\nsuccessfully running in production)?Between one \nmonth and six \nmonthsBetween one \nweek and one \nmonthBetween one \nday and one \nweek\nTime to restore service\nFor the primary application or service you work on, how long does it generally \ntake to restore service when a service incident or a defect that impacts users \noccurs (e.g., unplanned outage or service impairment)?Between one \nweek and one \nmonthBetween one day \nand one weekLess than \none day\nChange failure rate\nFor the primary application or service you work on, what percentage of \nchanges to production or released to users result in degraded service (e.g., \nlead to service impairment or service outage) and subsequently require \nremediation (e.g., require a hotfix, rollback, fix forward, patch)?46%-60% 16%-30% 0%-15%solution invariably suggested that three clusters \nbest captured the data, regardless of the clustering \ntechniques applied."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "The table below describes the \ndelivery performance characteristics for each cluster.\n\nThe striking difference from last year is that we don\u2019t \nconsider any cluster to be elite this year.\n\nThis year\u2019s \nhigh cluster is a blend of last year\u2019s high and elite \nclusters.\n\nWe decided to omit an elite cluster because \nthe highest performing cluster simply isn\u2019t indicating \nenough of the characteristics of last year\u2019s elite cluster.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "12 How do you compare?7% \nElite\n48% \nHigh\n37% \nMedium\n15% \nLow201820% \nElite\n23% \nHigh\n44% \nMedium\n12% \nLow201926% \nElite\n40% \nHigh\n28% \nMedium\n7% \nLow2021N/A\nElite\n11%\nHigh\n69% \nMedium\n19% \nLow2022It suggests that this sample doesn\u2019t represent teams \nor organizations with employees who feel they have \nforged ahead.\n\nOne possible hypothesis, which we \ncurrently lack the data to support, is that software \ndevelopment has seen reduced innovation in terms of \npractices, tooling, and information sharing.\n\nThis could \nbe the result of the ongoing pandemic hampering \nthe ability to share knowledge and practices across \nteams and organizations.\n\nThere might have been fewer \nopportunities to gather and learn from one another, \nwhich, in turn, might have slowed innovation."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "There might have been fewer \nopportunities to gather and learn from one another, \nwhich, in turn, might have slowed innovation.\n\nWe are \nhopeful to do a deeper dive to explore what underpins \nthis finding.All that said, if you compare this year\u2019s low, medium \nand high clusters with last year\u2019s, you\u2019ll see that there \nis a shift toward slightly higher delivery performance.\n\nIt appears that this year\u2019s clusters are between two of \nlast year\u2019s.\n\n2022\u2019s high cluster is between 2021\u2019s high \nand elite.\n\n2022\u2019s low cluster seems to be between \n2021\u2019s low and medium.\n\nThe shift upwards for the low \nperformance cluster suggests that while the ceiling  \nfor delivery performance has been lowered, the floor \nhas been raised.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "13 How do you compare?The percentage breakdowns in the table above, \nshow that the percentage of high performers is at a \n4-year low, while the percentage of low performers \nrose dramatically, from 7% in 2021 to 19% this year.\n\nOver two-thirds of this year\u2019s respondents fall into \nthe medium cluster.\n\nThe clear drop in high and elite \nperformers might suggest that many of this year\u2019s \nrespondents are in organizations or on teams that \neither haven\u2019t established, or are in the process of \nestablishing, a DevOps culture that we\u2019re seeing \nemerge across many modern teams.\n\nWe might be focusing too much on the differences \nbetween 2021 and 2022, rather than highlighting the \nsimilarities.\n\nThe clusters from 2021 and 2022 share \nmany characteristics, including a huge separation \nbetween high performers from low performers.\n\nFor \nexample, high performers are estimated1 to have  \n417x more deployments than low performers."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "For \nexample, high performers are estimated1 to have  \n417x more deployments than low performers.\n\nAccelerate  State of DevOps 20221 See \u201cMethodology\u201d section to \nunderstand what is behind this estimate"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "14 How do you compare?Clustering delivery performance  \nand operational performance\nWe decided to do a cluster analysis on the three \ncategories the five metrics are designed to represent: \nthroughput  (a composite of lead time of code changes \nand deployment frequency), stability  (a composite of \ntime to restore a service and change failure rate) and \noperational performance (reliability).\n\nThe reason for \nthis was the pivotal role operational performance plays in our models.\n\nFor organizations that do not show  \nsolid operational performance, throughput and  \nstability have less of an impact on organizational \nperformance.\n\nWe feel that describing the landscape \nof DevOps performance without accounting for \noperational performance leaves out a crucial part  \nof the picture.\n\nExploring the data led us to a four cluster solution."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Exploring the data led us to a four cluster solution.\n\nHere \nis a breakdown of the four clusters and their names:\nClusterStabilityOperational \nPerformanceThroughput\n% respondents\nTime to restore \nserviceChange failure rate Reliability Lead timeDeployment \nfrequency\nStartingBetween one day and \none week31%-45%Sometimes meet \nexpectationsBetween one \nweek and one \nmonthBetween once per \nweek and once per \nmonth28%\nFlowing Less than one hour 0%-15%Usually meet \nexpectationsLess than one dayOn demand \n(multiple deploys \nper day)17%\nSlowing Less than one day 0%-15%Usually meet \nexpectationsBetween one \nweek and one \nmonthBetween once per \nweek and once per \nmonth34%\nRetiringBetween one month \nand six months46%-60% Usually meet \nexpectationsBetween one \nmonth and six \nmonthsBetween once per \nmonth and once \nevery 6 months21%\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "15 How do you compare?Each cluster has unique characteristics  \nand accounts for a substantial proportion \nof the responses.\n\nAnd finally, the Retiring cluster looks like a team  \nthat is working on a service or application that is still \nvaluable to them and their customers, but no longer \nunder active development.\n\nRespondents in the Slowing cluster do not deploy  \ntoo often, but when they do, they are likely to succeed.\n\nOver a third of responses fall into this cluster, making it \nthe largest and most representative of our sample.\n\nThis \npattern is likely typical (though far from exclusive) to a \nteam that is incrementally improving, but they and their \ncustomers are mostly happy with the current state  \nof their application or product.The Flowing cluster performs well across all \ncharacteristics: high reliability, high stability,  \nhigh throughput.\n\nOnly 17% of respondents are  \nin this flow state.The Starting cluster performs neither well nor  \npoorly across any of our dimensions."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Only 17% of respondents are  \nin this flow state.The Starting cluster performs neither well nor  \npoorly across any of our dimensions.\n\nThis cluster \nmight be in the early stages of their product, feature, \nor service\u2019s development.\n\nThey might be less focused \non reliability because they\u2019re focusing on getting \nfeedback, understanding their product-market fit,  \nand more generally, exploring.\n\nIf you visited two teams in the same cluster,  \nhowever, they\u2019d likely come across as very different, \nand our story might not capture what you see.\n\nThe story we provide for each cluster above is an \nattempt to use our experience working with many \nteams to make these patterns in the data intelligible.\n\nFurther, if you visited the same team at two different \npoints in time, it is possible that they would not have \nstayed in the same cluster."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Further, if you visited the same team at two different \npoints in time, it is possible that they would not have \nstayed in the same cluster.\n\nOne possible reason for  \nthis could be that the team has either improved or \ndegraded; another possibility is that the team has \nmoved into a deployment pattern more appropriate  \nfor the current state of its application or service.\n\nFor example, at an earlier point in an application  \nor service\u2019s development, a team might have been \nfocused on exploring (Starting cluster), but as they  \nstart to find their niche, they may shift their focus  \nto reliability (Flowing cluster or Slowing cluster).\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "16 How do you compare?\n\nAccelerate  State of DevOps 2022These clusters differ notably in their practices and \ntechnical capabilities.\n\nGiven the high levels of  \nsoftware delivery and operational performance \ndemonstrated by the Flowing cluster, we decided  \nto look into how they differ from the other clusters  \nin their practices and technical capabilities.\n\nWe found \nthat relative to other clusters, the Flowing cluster \nfocuses more on:\n\u2022 Loosely-coupled architectures: the extent  \nteams can make large-scale changes to the  \ndesign of their system without depending on  \nother teams to make changes in their systems\n\u2022 Providing flexibility: how flexible a company is with \nregard to employee work arrangements\n\u2022 Version control: how changes to application  \ncode, system configuration, application \nconfiguration, etc."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "are managed\n\u2022 Continuous integration (CI): how frequently \nbranches are integrated into the trunk\n\u2022 Continuous delivery (CD): capabilities focused  \non getting changes into production safely, \nsustainably and efficientlyCuriously, the Flowing cluster tends to focus less on \ndocumentation.\n\nLast year, we found that documentation \npractices are central to both delivery performance and \noperational performance (SDO).\n\nHow does the Flowing  \ncluster have strong SDO performance without a heavy \nfocus on documentation?\n\nFor one, there are many routes \nto strong SDO performance outside of documentation.\n\nFurther, perhaps the Flowing cluster is continuously \nrefactoring its code to create a more self-documenting \nprocess and, thereby, have less of a need for documents  \nas we describe them in the survey.\n\nThe Slowing cluster, which makes up the highest \nproportion of our respondents, tends to be made up of \nrespondents from larger organizations that tend to be less \ncloud-native than other clusters."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "The Slowing cluster, which makes up the highest \nproportion of our respondents, tends to be made up of \nrespondents from larger organizations that tend to be less \ncloud-native than other clusters.\n\nPicture a very mature \ncompany with some calcified processes that, at the end  \nof the day, still provides end-users with stable and \nreliable (and valuable) experiences.\n\nThis cluster exhibits \na performance oriented, generative culture.2  One of the \nSlowing cluster\u2019s most interesting characteristics is that \nit has low throughput and high positive-work-culture (a \n\u201cgenerative\u201d work culture, according to Westrum); this \nis an uncommon combination.\n\nIt\u2019s more common to see \nproportional throughput and work culture (high/high or \nlow/low).\n\nWe hope to conduct future research to better \nunderstand the relationship between throughput and culture.\n\n2 (Westrum)"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "17 How do you compare?\n\nAccelerate  State of DevOps 2022We also looked at how these different clusters \ncompare on three outcomes: burnout, organizational \nperformance, and unplanned work.\n\nWhat we found broke \nour expectations.\n\nThe Retiring cluster outperformed the \nother clusters in organizational performance.\n\nLooking \nat the characteristics of this cluster (poor stability and \npoor throughput) this is seemingly at odds with most \nof DORA\u2019s previous findings.\n\nBut instead of blaming \nrandomness for creating an anomaly (highly possible),  \nwe want to explore some possible explanations.\n\nWhen trying to unpack these findings, there is an \nimportant complementary finding to keep in mind.\n\nThe Retiring cluster achieves high organizational \nperformance at a great cost: its teams have the highest \nburnout rates, feel the most susceptible to errors, \nand are burdened with the most unplanned work."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "In \ntandem, these results suggest that reliability might be \nenough to achieve high organizational performance, \nbut without speed and stability, your team will pay the \ncost of burnout and unplanned work.\n\nWe have other hypotheses to explain why the Retiring \ncluster has higher organizational performance than the \nother clusters, particularly the Flowing cluster.\n\nHere is \na quick list.\u2022 There are features that underlie these  \nfour clusters that may not be in our data.\n\nFor example, organization size may be a decent \nproxy for maturity.\n\nThe Flowing cluster tends to \nbe from smaller companies, which may indicate \ntheir products are in more formative stages.\n\n\u2022 The members of the Flowing cluster tend to \nbe from smaller companies, which may be less \nbound by historical processes and infrastructure \nand, as a consequence, have more sophisticated \nDevOps processes in place."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "That said, the  \ndata show that an organization\u2019s size is  \npositively correlated with organizational \nperformance for reasons that may be largely \nunrelated to technology.\n\n\u2022 The Flowing cluster tended to disregard the \nprinciples described in Westrum\u2019s generative \nculture.\n\nWe have seen that this is often to the \ndetriment of organizational performance.\n\n\u2022 Organizations in each cluster may differ on what \nthey mean by reliability expectations and how \nthey monitor them.\n\nThe same goes for how they \ndefine their organizational performance goals."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "18 How do you compare?\u2022 The Retiring cluster may have high short-term \norganizational performance, but we wonder how \nthey would perform long-term.\n\nWill the burnout \nresult in turnover?\n\nWill they be able to scale  \ntheir processes?\n\n\u2022 We are asking the questions at varying levels.\n\nThe technical capabilities (for example, loosely-\ncoupled architecture) are asked at the level of the \nteam; the organizational performance questions \nare asked at the level of the organization.\n\nOrganizations often have many teams, and  \nit is possible for the respondent to recognize  \nthat while their organization is functioning well,  \nthe team they\u2019re working on isn\u2019t.\n\nFurther, the Flowing cluster scores second highest \non organizational performance behind the Retiring \ncluster, and has some of the lowest levels of burnout \nand unplanned work."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Further, the Flowing cluster scores second highest \non organizational performance behind the Retiring \ncluster, and has some of the lowest levels of burnout \nand unplanned work.\n\nAs demonstrated by both the \nFlowing and Slowing clusters, a DevOps philosophy  \nis most effective when reliability is in place.We\u2019re excited to continue exploring new ways \nto describe variations within the industry.\n\nGoing \nforward, we want to continue to include operational \nperformance as a relevant dimension in our \nunderstanding of these variations.\n\nWe also want \nto avoid highly prescriptive and evaluative clusters \n(e.g., Elite),  and instead concentrate on the simply \ndescriptive exercise of identifying common \nconstellations of SDO performance.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "19 How do you improve?How do you improve?03\nHow do you improve across  \na multitude of outcomes?\n\nThe State of DevOps report is designed to provide \nevidence-based guidance to help your team focus \non the DevOps practices and capabilities that get to \nthe outcomes you care about.\n\nThis year we expanded \nour investigation into both security and the set of \noutcomes teams desire.\n\nIn the past, we focused on \nsoftware delivery and operational performance (SDO) \nand organizational performance outcomes.\n\nWe still \ndo, but we also wanted to explore burnout, likelihood \nto recommend the team, unplanned work, and error \nproneness, not only as a means to improve SDO \nand organizational performance, but also as ends in \nthemselves.\n\nConsequently, this year, we made sure  \nto call out practices and capabilities that seem to  \nexert an influence on these outcomes.\n\nAccelerate  State of DevOps 2022Derek DeBellis"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Beyond the four keys \nHow do DORA metrics \nimprove the performance of \ndevelopment and operations?\n\nA cross-functional team of \nsoftware engineers at Liberty \nMutual Insurance regularly \nreviews performance using \nDORA\u2019s \u201cfour keys\u201d metrics.\n\nFor example, Jenna Dailey, Sr. \nScrum Master at Liberty Mutual, \nshared that a squad leveraged \nDORA\u2019s research to help the \nteam identify a bottleneck, \nmove towards a test-driven \ndevelopment approach, and \nrealize improvements in their \noverall performance.\n\nLearn more about Liberty \nMutual\u2019s approach to leveraging \ndata and DORA metrics to \nimprove the quality and delivery \nof software in their recent \nTomorrow Talks.\n\n20 How do you improve?The research model shifted this year to better reflect \na theory underlying DORA: there isn\u2019t a one-size-fits-\nall approach to DevOps.\n\nIn practice, we\u2019ve found that \nmaking recommendations involves understanding a \nteam\u2019s broader context."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "In practice, we\u2019ve found that \nmaking recommendations involves understanding a \nteam\u2019s broader context.\n\nA practice that is beneficial to \none team might be detrimental to another team.\n\nFor \nexample, we have long hypothesized that technical \ncapabilities (such as loosely-coupled architecture, \ntrunk based development, version control, and \ncontinuous integration) have a more pronounced \npositive impact on software delivery performance \nwhen continuous delivery is in place.\n\nThis year we \nexplicitly modeled this and other interactions.\n\nThe \ngoal is to enhance our understanding from simply \n\u201cwhat has an effect on what?\u201d to include \u201cunder what \nconditions do these effects exist, get amplified, or \nget attenuated?\u201d Understanding all this conditionality \nhas proven to be a complicated and mind-bending \nendeavor, but we\u2019re excited to share with you some of \nthese early findings.\n\nYou can find this year\u2019s and previous years\u2019 research \nmodels online on our website .\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Eric Maxwell\n21 How do you improve?Cloud \nBuilding on the momentum we have seen over the \npast several years, the use of cloud computing \ncontinues to accelerate.\n\nIn fact, the percentage of \npeople reporting the use of public cloud, including \nmultiple clouds, is now 76%, up from 56% in 2021.\n\nThe number of people reporting no cloud usage at \nall, including those that do not use private cloud, \ndropped to just 10.5%, down from 21% last year.\n\nThe \nuse of multiple public clouds rose from 21% to 26%, \nand hybrid cloud usage is up 25% to 42.5%.\n\nWe also \nsaw a small increase in the use of private cloud to \n32.5%, up from last year\u2019s reporting of 29%.36%\nincrease in the use  \nof public cloud25%\nincrease in hybrid \ncloud usage\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "22 How do you improve?2022% change\nover 2021\nHybrid cloud 42.47% 25%\nPublic and/or Multiple public 76.08% 36%\nPrivate Cloud 32.55% 12%\nNo Cloud 10.55% -50%Cloud usage continues to accelerate YoYAs we have shown in previous years, and continue to \nvalidate in this report, the use of cloud computing has a \npositive impact on overall organizational performance.\n\nRespondents that used cloud were 14% more likely  \nto exceed  in organizational performance goals than \ntheir non-cloud using peers.\n\nOur research shows that \ncloud computing enables teams to excel at things  \nlike software supply chain security and reliability and \nthose things lead to organizational performance.\n\nSurprisingly, users of all types of cloud \u2013 public, private, \nhybrid, and multi \u2013 showed a negative association \nwith change failure rate, meaning an increased change failure rate.\n\nThis warrants further investigation.\n\nInstead \nof speculating on the reasons for this, we\u2019ll investigate \nfurther in future research."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "This warrants further investigation.\n\nInstead \nof speculating on the reasons for this, we\u2019ll investigate \nfurther in future research.\n\nBut with few exceptions, the \nuse of cloud-native applications (applications that were \noriginally designed and architected for the cloud) stood \nout with positive signals on everything we surveyed.\n\nUse of any cloud computing platform, public or  \nprivate, positively contributes to culture and work \nenvironment outcomes (for example, generative \nculture, lower burnout, more stability, and higher \nemployee satisfaction).\n\nCloud users scored 16%  \nhigher on these cultural outcomes.The use of cloud computing has a positive impact on overall \norganizational performance.\n\nRespondents that used cloud  \nwere 14% more likely to exceed in organizational \nperformance goals than their non-cloud using peers.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "23 How do you improve?Hybrid and multi-cloud  \ndrive organizational performance\nWe continue to see strong signals that the use of \nhybrid cloud and multiple public clouds has a positive \nimpact on organizations.\n\nPractitioners who used \nmultiple clouds showed a 1.4x higher organizational \nperformance compared to non-cloud users.\n\nHowever, \nuse of hybrid and multi-cloud (as well as private cloud) \nseem to have a negative impact on several software \ndelivery performance indicators (MTTR, lead-time, and \ndeployment frequency) unless respondents also have \nhigh levels of reliability.\n\nThis finding further speaks to  \nthe importance of a robust SRE practice and  \nthe role reliability plays in software delivery.\n\nIn 2021 we asked respondents to tell us their primary \nreason for utilizing multiple public clouds, whereas in \n2022 we asked participants to tell us all the benefits  \nthey realize from utilizing multiple cloud providers."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Availability was the number one most reported  \nbenefit, which coincides with the attention and focus  \nwe have seen in the industry around reliability \u2014 you  \ncan not have reliable services unless they are available.\n\nOver 50% of practitioners reported leveraging the \nunique benefits of different cloud providers.\n\nBenefits realized by adopting multiple cloud providersThe use of hybrid and multi-cloud (and private) seems to  \nhave a negative impact on software delivery  performance \nindicators \u2013 MTTR, lead-time, and deployment frequency \u2013  \nunless respondents had high levels of reliability.\n\n50%\nof respondents reported  \nusing multiple cloud providers.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "24 How do you improve?The five characteristics  \nof cloud computing\nIn keeping with our previous research approach,  \nwe sought not simply to learn if participants were  \nusing cloud computing technologies, but how they\u2019re \nusing cloud computing technologies.\n\nWe achieved  \nthis by asking about the five essential characteristics  \nof cloud computing, as defined by the National  \nInstitute of Standards and Technology (NIST).\n\nOn-demand self-service \u2013 Consumers can provision \ncomputing resources as needed, automatically,  \nwithout any human interaction required on the  \npart of the provider.\n\nBroad network access \u2013 Capabilities are widely \navailable and consumers can access them through \nmultiple clients such as mobile phones, tablets,  \nlaptops, and workstations.\n\nResource pooling \u2013 Provider resources are pooled in  \na multi-tenant model, with physical and virtual resources \ndynamically assigned and reassigned on demand."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Resource pooling \u2013 Provider resources are pooled in  \na multi-tenant model, with physical and virtual resources \ndynamically assigned and reassigned on demand.\n\nThe customer generally has no direct control over  \nthe exact location of the provided resources, but  \ncan specify a location at a higher level of abstraction,  \nsuch as country, state, or data center.\n\nRapid elasticity  \u2013 Capabilities can be elastically \nprovisioned and released to rapidly scale outward or \ninward with demand.\n\nConsumer capabilities available \nfor provisioning appear to be unlimited and can be \nappropriated in any quantity at any time.\n\nMeasured service \u2013 Cloud systems automatically \ncontrol and optimize resource use by leveraging \na metering capability at a level of abstraction \nappropriate to the type of service, such as storage, \nprocessing, bandwidth, and active user accounts.\n\nResource usage can be monitored, controlled, and \nreported for transparency."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Resource usage can be monitored, controlled, and \nreported for transparency.\n\nThis report validates the previous three years of  \nDORA research, concluding that the presence of  \nthese five characteristics in an organization \npositively affects software delivery and operations \nperformance.\n\nWe also found that these characteristics The use of the five characteristics of \ncloud computing is a crucial beginning \nto a long causal chain that leads to \norganizational performance.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "25 How do you improve?lead to better organizational performance by setting \nprocesses in motion that affect the organization in \npositive ways.\n\nExhibiting the five characteristics of \ncloud computing is the first step in a long journey that \nleads to higher organizational performance.\n\nIn 2022 we see that teams are increasingly taking \nadvantage of cloud computing differentiators.\n\nFor the \n4th year in a row, we are seeing growing adoption of \nthe five characteristics of cloud computing.\n\nResourcer \nPooling saw the largest increase of 14% and Rapid \nElasticity, which was the second most used feature  \nlast year, saw the smallest rise of 5%.\n\n14%\nincrease in  \nresource pooling\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "26 How do you improve?SRE and DevOps\nA successful technology team contributes more to \ntheir organization than shipping code \u2014 more, even, \nthan shipping quality code.\n\nThey also ensure that the \nservices they deliver remain available, performant, and \notherwise consistent with users\u2019 expectations over \ntime.\n\nReliability is a multi-faceted measure of how well \na team upholds these commitments, and this year we \ncontinued our explorations into reliability as a factor in \nsoftware delivery and operations.\n\nSite Reliability Engineering (SRE) is an influential  \napproach to operations which originated at Google  \nand is now practiced in many organizations.\n\nSRE \nprioritizes empirical learning, cross-functional \ncollaboration, extensive reliance on automation, and \nthe use of measurement techniques including Service \nLevel Objectives (SLOs).\n\nOther modern operations \npractices employ similar methods but apply different \nnaming conventions."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Other modern operations \npractices employ similar methods but apply different \nnaming conventions.\n\nTherefore, to assess the extent of \nthese practices as objectively as possible, our survey \ntakes care to use neutral, descriptive language in the \ntext that we present to respondents.\n\nWe also collect data \non the outcomes of reliability engineering: the extent to Without reliability, software \ndelivery performance doesn\u2019t \npredict organizational success.\n\nwhich teams are able to achieve their reliability targets.\n\nBoth inputs and outputs \u2014 SRE practices and reliability \noutcomes \u2014 are reflected in our predictive model \nalongside other DevOps capabilities.\n\nReliability is essential\nSRE adoption is widespread among the teams we surveyed: \na majority of respondents use one or more of the practices \nwe asked about."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Reliability is essential\nSRE adoption is widespread among the teams we surveyed: \na majority of respondents use one or more of the practices \nwe asked about.\n\nAcross this breadth of teams, the data \nreveal a nuanced relationship between reliability, software \ndelivery, and outcomes: when reliability is poor, software \ndelivery performance does not predict organizational \nsuccess.\n\nHowever, with better reliability, we begin to see the \npositive influence of software delivery on business success.\n\nAccelerate  State of DevOps 2022\nDave Stanke"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "27 How do you improve?This phenomenon is consistent with the use of the SRE \n\u201cerror budget\u201d framework: when a service is unreliable, \nusers won\u2019t benefit from pushing code faster into that \nfragile context.\n\nAs Site Reliability Engineers have long asserted, reliability \nis the most important \u201cfeature\u201d of any product.\n\nOur \nresearch supports the observation that keeping promises \nto users is a necessary condition in order for improved \nsoftware delivery to benefit the organization.\n\nAcknowledge the J-Curve\nWhat challenges await you on the path to achieving \nreliability?"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Acknowledge the J-Curve\nWhat challenges await you on the path to achieving \nreliability?\n\nIn their O\u2019Reilly publication \u201cEnterprise \nRoadmap to SRE,\u201d1  DORA survey contributors James \nBrookbank and Steve McGhee reflect on their \nexperiences of implementing SRE in established \norganizations, and recommend \u201cacknowledging the J \nCurve of change.\u201d Previously described in the 2018 State \nof DevOps Report, the \u201cJ Curve,\u201d is a phenomenon in \nwhich organizational transformations tend to exhibit \nearly success, followed by periods of diminished returns, \n1 https://sre.google/resources/practices-and-processes/\nenterprise-roadmap-to-sre/ \nAccelerate  State of DevOps 2022\nInvestment in SRE yields \nimprovements to reliability, \nbut only once a threshold of \nadoption has been reached.\n\nor even regressions.\n\nThose who persist through these \nchallenges, however, often experience renewed and \nsustained levels of elevated achievement."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "or even regressions.\n\nThose who persist through these \nchallenges, however, often experience renewed and \nsustained levels of elevated achievement.\n\nOur research this year reveals a J Curve pattern across \nthe technology teams we studied: when teams engage \nin fewer reliability engineering practices \u2014 suggesting \nthey are earlier in their journey of adopting SRE \u2014 these \npractices don\u2019t predict better reliability outcomes.\n\nHowever, as teams adopt more SRE, they reach an \ninflection point where the use of SRE starts to strongly \npredict reliability, and in turn, organizational performance."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "28 How do you improve?Investing in people,  \nprocess, and tooling\nReliability is a human endeavor, and in many ways \nthe SRE approach exemplifies this.\n\nOne of SRE\u2019s \ncore principles is that user perception, as opposed \nto internal monitoring data, is the true measure \nof reliability.\n\nSo it\u2019s perhaps unsurprising that \nreliability is driven by positive team dynamics.\n\nWe \nfound that teams with a \u201cgenerative\u201d culture, one \nthat exhibits trust and collaboration, are more \nlikely to practice SRE, and more likely to achieve \ngood reliability outcomes.\n\nStable teams, whose \nmembership is consistent across time, also deliver \ngreater reliability for user-facing services.\n\nAnd, \nas with DevOps as a whole, reliability engineering \nefforts benefit from augmenting human efforts \nwith process and tooling.\n\nPractices such as the use \nof cloud computing and continuous integration are \npredictive of better reliability outcomes."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Practices such as the use \nof cloud computing and continuous integration are \npredictive of better reliability outcomes.\n\nTeams that persist beyond initial steps of SRE adoption \nsee increasing improvement in reliability outcomesTeams that are in the early stages of a journey \ntoward an SRE practice should be prepared for \nsetbacks along the way.\n\nIt can be a long road  \nas culture, process, and tooling all realign to  \nnew guiding principles.\n\nBut they can be assured  \nthat, with time and continued investment,  \nsuccess is likely.Dependable teams make \ndependable services: \ngenerative team culture \npredicts better reliability."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "But they can be assured  \nthat, with time and continued investment,  \nsuccess is likely.Dependable teams make \ndependable services: \ngenerative team culture \npredicts better reliability.\n\nAccelerate  State of DevOps 2022Reliability outcomesHigh\nLow\nAdoption of SRE practices Low HighReliability outcomesHigh\nLow\nAdoption of SRE practices Low HighReliability outcomesHigh\nLow\nAdoption of SRE practices Low HighReliability outcomesHigh\nLow\nAdoption of SRE practices Low HighReliability outcomesHigh\nLow\nAdoption of SRE practices Low HighReliability outcomesHigh\nLow\nAdoption of SRE practices Low HighReliability outcomesHigh\nLow\nAdoption of SRE practices Low High"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "29 How do you improve?Technical DevOps Capabilities\nHow do we improve?\n\nBack to table of contents State of DevOps 2022: Sponsor briefing\nInner Loop Outer LoopCode\nTest Build\nReleaseTestIntegrate\nDeployPushThis year, we looked at a variety of technical capabilities to understand the \noutcomes that are driven by different technical practices.\n\nWe considered two \nbroad phases of software development: the \u201cinner loop,\u201d and the \u201couter loopTechnical DevOps capabilities\nOur research shows that companies \nthat excel in inner and outer loop \ndevelopment are able to ship code \nfaster and with higher levels of \nreliabilityThis year, we looked at a variety of technical capabilities \nto understand the outcomes that are driven by different \ntechnical practices."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "We considered two broad phases of \nsoftware development: the \u201cinner loop,\u201d which comprises \ndeveloper tasks such as coding, testing, and pushing \nto version control, and the \u201couter loop,\u201d which includes \nactivities such as code merge, automated code review, \ntest execution, deployment, and release.\n\nAccelerate  State of DevOps 2022Eric Maxwell"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "30 How do you improve?Our research shows that companies that excel in  \ninner and outer loop development are able to ship  \ncode faster and with higher levels of reliability.\n\nThe capabilities that contribute most to high \nperformance are version control, continuous  \nintegration, continuous delivery, and loosely- \ncoupled architecture.\n\nHigh performers who  \nmeet reliability targets are:In fact, respondents who make higher-than-average \nuse of all of the above capabilities have 3.8x higher \norganizational performance than those who do not \nuse these technical capabilities.\n\nContinuous integration\nContinuous Integration, often referred to as CI, is a part of \nthe outer loop development process that automatically \nbuilds an artifact and runs a series of automated tests for \nevery code commit in an effort to assess whether code \nis ready to be deployed.\n\nThis process provides quick, \nautomated feedback to the developer, allowing them to \noperate with higher levels of confidence."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "This process provides quick, \nautomated feedback to the developer, allowing them to \noperate with higher levels of confidence.\n\nCI is a key part of \ntaking code from a developer\u2019s workstation to production.\n\nAs in previous years, CI is shown to drive delivery \nperformance.\n\nHigh performers who meet reliability \ntargets are 1.4x more likely to use CI than others.\n\nThis year we dove a bit deeper into the other part \nof the outer loop development process: continuous \ndelivery, which we will describe in a later chapter.\n\nBut \nfirst, let\u2019s take a look at a complementary component to \ncontinuous integration: trunk-based development.33%\n39%\n46%\n40%more likely to  \nuse version control\nmore likely to practice \ncontinuous integration\nmore likely to practice \ncontinuous delivery\nmore likely to have  \nsystems based on a loosely-\ncoupled architectureHigh performers who  \nmeet reliability targets are  \n1.4x more likely to use Cl.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "31 How do you improve?Individuals with 16+ years of experience that use  \ntrunk-based development realize the benefits of  \nthe practice and see:\n\uf070 Increased  overall software delivery performance \n\uf071 Decreased  amounts of unplanned work\n\uf071 Decreased  error-proneness\n\uf071 Decreased  change failure rate\nThis is likely due to the additional practices required \nto successfully implement Trunk-based development.\n\nTeams that do not have rigorously enforced rules \naround never walking away from a broken trunk or that \ndo not use gated code branches and auto-roll back \ncode that breaks the trunk will certainly experience \npain when trying to develop on the trunk.\n\nHowever, the presence of trunk-based  \ndevelopment shows a positive impact on overall \norganizational performance.\n\nTrunk-based development\nTrunk-based development is the practice of  \ncontinuously merging code into the trunk and avoiding \nlong-lived feature branches."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Trunk-based development\nTrunk-based development is the practice of  \ncontinuously merging code into the trunk and avoiding \nlong-lived feature branches.\n\nThis practice is considered \na complement to continuous integration and has been \nshown for years to accelerate software delivery velocity.\n\nDue to the shift in demographics this year around \nyears of experience on the job, we are able to see that \nexperience matters when implementing trunk-based \ndevelopment.\n\nLast year we had 40% of respondents \nstate they had 16+yrs on the job and this year that \ncategory represented just 13%.\n\nContinuing to validate \nour \u201cDelivery Depends\u201d theme, we see that folks with \nless experience overall have less positive results around \ntrunk-based development and see:\n\uf071 Decreased  overall software delivery performance \n\uf070 Increased  amounts of unplanned work\n\uf070 Increased  error-proneness\n\uf070 Increased  change failure rate\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "32 How do you improve?Last year, we examined the technical DevOps \ncapabilities that predict the likelihood that a team \npractices CD, and discovered that factors such as \nloosely-coupled architecture and continuous testing / \nintegration were among the strongest predictors.\n\nThis \nyear, in addition to examining the factors driving the \nuse of CD, we analyzed and identified the effects of \nCD alone as well as its interactions with other DevOps \ncapabilities on development outcomes.\n\nCD drives software delivery \nperformance\nSimilar to previous years\u2019 findings, the use of CD is a \npredictor of higher software delivery performance, both \nalone and in combination with other DevOps capabilities.\n\nTeams that rated higher on CD are more likely to have \nhigher frequency of deploying code to production, and \nshorter lead time for changes and service restoration.\n\nContinuous Delivery \nContinuous delivery (CD) is a software  \ndevelopment practice that:\n \n1."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Continuous Delivery \nContinuous delivery (CD) is a software  \ndevelopment practice that:\n \n1.\n\nEnables the team to deploy software to  \nproduction or end users at any time\n2.\n\nEnsures the software is in a deployable  \nstate throughout its lifecycle, including  \nwhen working on new features\n3.\n\nEstablishes a fast feedback loop that enables  \nthe team to check the quality and deployability  \nof the system, and prioritizes fixing issues  \nblocking deployment.\n\nNote that continuous delivery does not necessarily \nimply continuous deployment, the practice in which \nevery software build is automatically deployed.\n\nContinuous delivery requires only that a software  \nbuild can be deployed at any time.\n\nAccelerate  State of DevOps 2022Frank Xu"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "33 How do you improve?Technical practices and CD\nOur research has regularly shown that a broad  \nset of technical capabilities support CD.\n\nThis year,  \nwe explored what happens when some of these \nindividual capabilities are used in conjunction with  \nCD.\n\nWe found that trunk-based development and \nloosely-coupled architecture, together with CD,  \nmay have a negative impact on a team\u2019s performance.\n\nFor example, we see evidence that teams who are \nadopting loosely-coupled architectures and CD \ntogether are 43% more likely to anticipate more than \naverage error proneness (i.e., product outages, security \nvulnerabilities and significant performance degradation \nto happen to their services), compared to teams \nthat only adopted CD.\n\nThese effects require further \ninvestigation and point to some potential friction for \nteams who are improving."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "These effects require further \ninvestigation and point to some potential friction for \nteams who are improving.\n\nThis friction may be related \nto the J-curve of transformation wherein teams realize \nearly improvements but then falter as they move beyond \nthe low-hanging fruit.\n\nCommitment to improvement is \nrequired to realize its full potential.\n\nWhen improving any \ncapability, such as CD, be sure to watch after the effects \non the team and overall performance.\n\nIn addition, respondents are 2.5x more likely to report \nhigher software delivery performance when their team \nalso adopts version control practices.\n\nCD can increase unplanned work\nThe data suggested that continuous delivery leads to \ndevelopers spending more time on rework or unplanned \nwork.\n\nA hypothesis for this finding is that developers are \nmore likely to build applications iteratively when there are \ntighter feedback loops.\n\nAs a result they may view some \niterative changes as unplanned work on the same part of \nthe system."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "As a result they may view some \niterative changes as unplanned work on the same part of \nthe system.\n\nThis work may be simultaneously unplanned \nand driven by feedback from a previous deployment.\n\nAccelerate  State of DevOps 2022Teams that combine version \ncontrol and continuous \ndelivery are 2.5x more likely to \nhave high software delivery \nperformance than teams that \nonly focus on one."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "34 How do you improve?Loosely-coupled Architecture\nLoosely-coupled systems are important to the \neffectiveness of teams and organizations.\n\nThis doesn\u2019t \njust apply to cloud- or microservice-based systems \n\u2014 it has to do with an organization\u2019s ability to make \nchange.\n\nThe ease with which an organization can safely \nand confidently change its software is a marker of the \nsoftware\u2019s quality.\n\nWith a loosely-coupled architecture teams can:\n\u2022 Make large-scale changes to the design of their  \nsystem without having to depending on other  \nteams to make changes in their systems\n\u2022 Get faster feedback through independent,  \non-demand testing with lower coordination costs\n\u2022 Deploy code with negligible downtime\nIn this year\u2019s report, we asked respondents to  \ndescribe whether or not the software they build  \nis based on a loosely-coupled architecture."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "The results were intriguing, and showed a  \nvariety of mostly positive associations between  \nthe presence of loosely-coupled architecture and  \nteams\u2019 performance across multiple dimensions.\n\nAccelerate  State of DevOps 2022\nDavid Farley"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "35 How do you improve?The benefits of a  \nloosely-coupled architecture\nTeams that focus on building software with loosely-\ncoupled architectures are in a better position to \nperform strongly across stability, reliability, and \nthroughput.\n\nThese teams are also more likely to \nrecommend their workplace to a friend or colleague.\n\nIt\u2019s common to see software that uses a loosely-coupled \narchitecture from teams that are deploying to the cloud \nand adopting a microservices architectural approach, managing hundreds of services.\n\nHowever, loose coupling \nis more than a simple measure of the count of services in \na system.\n\nComponents in a loosely-coupled architecture \ncan be deployed independently.\n\nThis independence allows \nteams to develop, test, and deploy their services without \nexpensive coordination overhead between teams."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "This independence allows \nteams to develop, test, and deploy their services without \nexpensive coordination overhead between teams.\n\nIn the real world, loose coupling is not restricted to one \narchitectural style; fundamentally, it\u2019s the ability to make \na change in one part of the system, without that change \nimpacting other parts.\n\nThis allows organizations to divide \nup their work, so that individual teams can make progress \nwithout having to coordinate with other teams.\n\nIn our experience, teams that require deep integration \ntesting with other services as a way to build confidence \nin their software before it\u2019s deployed have not yet \nachieved loose coupling; to do so, these teams would \nbenefit from improving the interfaces and isolation \nbetween systems.\n\nOne effective way to improve \ninterfaces and isolation is by improving the \u2018testability\u2019 \nof services and components.\n\nIf your design allows you \nto test your service in isolation, then its interface is,  \nby definition, loosely-coupled."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "If your design allows you \nto test your service in isolation, then its interface is,  \nby definition, loosely-coupled.\n\nTeams that focus on building \nsoftware with loosely-\ncoupled architectures are in \na better position to perform \nstrongly across stability, \nreliability, and throughput.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "36 How do you improve?We also found that cohesive, stable teams that use \nloosely-coupled architecture are more likely to use \nsoftware development practices that encourage and \nsupport continuous improvement.\n\nFor example, SRE \npractices such as setting reliability goals to prioritize \nwork or performing regular reviews to revise reliability \ntargets based on evidence, both support loosely-\ncoupled architecture.\n\nLoosely-coupled architectures also allow the \norganization to more easily add employees, as \nindependent teams that don\u2019t need to coordinate  \nwith other teams are freer to increase the size of  \ntheir teams independently.\n\nIn short, loose coupling of software services  \nimpacts more than just technical impact.\n\nIt also  \naffects the socio-technical aspects of software \ndevelopment.\n\nCoupling is at the root of Conway\u2019s Law \u2014 \nthe idea that an organization\u2019s design systems mirror their \nown communication structure."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Coupling is at the root of Conway\u2019s Law \u2014 \nthe idea that an organization\u2019s design systems mirror their \nown communication structure.\n\nMore loosely-coupled \nsystems mean more loosely-coupled organizations with  \na more distributed, scaleable, approach to development.Surprising findings\nThis year\u2019s research revealed that loosely-coupled \narchitecture might contribute to burnout on teams.\n\nThis is a surprising finding that contradicts findings  \nfrom previous years.\n\nOur analysis shows that stable \nteams where information flows freely have lower levels of \nburnout.\n\nWestrum\u2019s generative culture and team stability \nboth support loosely-coupled architecture and decrease \nburnout, so this is clearly contradictory.\n\nMore research is \nrequired before we can draw definitive conclusions.\n\nAt the same time, when security requirements are defined \nand controlled by a consolidated security organization, \nit may be more difficult for teams to decouple their \nsoftware from other teams."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "At the same time, when security requirements are defined \nand controlled by a consolidated security organization, \nit may be more difficult for teams to decouple their \nsoftware from other teams.\n\nThis further demonstrates \nthe benefit of shifting security concerns to the team that \nis most responsible for the application (see also: Why \nsupply chain security matters).\n\nThis is one of the more \nsubtle forms of coupling in organizations, and though \nwe have collected the data on security, this is likely to \nbe equally true of other centralized functions.\n\nAllowing \nteams to make their own decisions on security, and other \nfrequently centralized functions, is one way to make \nprogress toward reaping the benefits that using loosely-\ncoupled architecture can impart to your organization.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "37 How do you improve?Culture \n\u201cWell, this is how things are done around here.\u201d \nPeople have likely uttered this phrase countless  \ntimes and across a wide range of industries to \ndescribe their organization\u2019s approach to  \nchallenges and opportunities.\n\nEvery organization has its own unique culture,  \nand our research has consistently shown that  \nculture is foundational to an organization\u2019s success \nand the well-being of its employees.\n\nCulture is also a necessary aspect of DevOps  \nsince, at the most basic level, DevOps is about  \ntools, practices, and how people work together  \nto develop and deliver software quickly, reliably,  \nand safely.\n\nUnderstanding the factors that impact  \nan organization\u2019s culture can help leadership tackle \nculture-related challenges head-on.\n\nTherefore, \nfostering a healthy culture should be a priority for \norganizations.\n\nIf left unaddressed, these culture-\nrelated challenges may hinder DevOps practices  \nfrom taking hold."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Therefore, \nfostering a healthy culture should be a priority for \norganizations.\n\nIf left unaddressed, these culture-\nrelated challenges may hinder DevOps practices  \nfrom taking hold.\n\nAccelerate  State of DevOps 2022\nDaniella Villalba"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "38 How do you improve?This year we continued to use Westrum\u2019s organizational \ntypology to measure the health of an organization\u2019s \nculture.\n\nIn addition, we expanded our understanding  \nof culture by measuring team churn, flexible work \narrangements, perceived organizational buy-in,  \nand burnout.\n\nData from this year\u2019s research support previous findings \nthat organizational performance is impacted by the \ntype of culture that exists within an organization.\n\nSpecifically, a generative culture is associated with \nhigher levels of organizational performance compared  \nto organizations characterized by a bureaucratic or pathological culture.\n\nEmployees at organizations with  \na generative culture are more likely to belong to stable \nteams,  produce higher-quality documentation, and \nspend most of their time engaged in meaningful work."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Employees at organizations with  \na generative culture are more likely to belong to stable \nteams,  produce higher-quality documentation, and \nspend most of their time engaged in meaningful work.\n\nTeam Churn\nWe investigated team churn and found that stable \nteams  \u2014 teams whose composition hadn\u2019t changed \nmuch over the last 12 months, were more likely to exist \nwithin high-performing organizations.\n\nConstant churn \ncan impact productivity and morale as new team \nmembers need time to onboard."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Constant churn \ncan impact productivity and morale as new team \nmembers need time to onboard.\n\nAnd those who stay \nPathological\nPower orientedBureaucratic\nRule orientedGenerative\nPerformance oriented\nLow cooperation Modest cooperation High cooperation\nMessengers are \u201cshot\u201d Messengers are neglected Messengers are trained\nResponsibilities shirked Narrow responsibilities Responsibilities are shared\nBridging discouraged Bridging tolerated Bridging encouraged\nFailure leads to scapegoating Failure leads to justice Failure leads to inquiry\nNovelty crushed Novelty leads to problems Novelty implementedWestrum Organizational culture\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "39 How do you improve?might need to adapt to changes in their workload and \nteam dynamics.\n\nIn addition, our research showed that \nstable teams were more likely to report producing \nquality documentation compared to teams that \nexperienced more churn.\n\nA team that is constantly \ndealing with change may have a harder time keeping  \nup with practices that lead to quality documentation.\n\nFlexible work arrangements \nGiven the shift to flexible work arrangements that many \norganizations have adopted since the outbreak of the \nCOVID-19 pandemic, we investigated whether giving \nemployees the freedom to choose between remote, in-person, or hybrid options was associated with higher \norganizational performance.\n\nFindings showed that \norganizations with higher levels of employee flexibility  \nhave higher organizational performance compared to \norganizations with more rigid work arrangements."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Findings showed that \norganizations with higher levels of employee flexibility  \nhave higher organizational performance compared to \norganizations with more rigid work arrangements.\n\nThese \nfindings provide evidence that giving employees the \nfreedom to modify their work arrangements as needed \nhas tangible and direct benefits for an organization.\n\nBurnout\nBurnout is a feeling of dread, apathy, and cynicism \nsurrounding work.\n\nWhen people experience burnout,  \nthey are not just unmotivated and exhausted, they are \nalso more likely to have lower job satisfaction, which can \nincrease employee turnover.\n\nBurnout has been linked to  \na wide range of poor psychological and physical health \noutcomes such as increased risk for depression and \nanxiety, heart disease, and suicidal thoughts1 .\n\nLast year we measured burnout in the context of the \nCOVID-19 pandemic and found that a generative culture \nwas associated with lower rates of employee burnout."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Last year we measured burnout in the context of the \nCOVID-19 pandemic and found that a generative culture \nwas associated with lower rates of employee burnout.\n\nHigh performing \norganizations are more  \nlikely to have flexible  \nwork arrangements.\n\n1 Maslach C, Leiter MP .\n\nUnderstanding the burnout experience: recent research and its implications for psychiatry.\n\nWorld Psychiatry.\n\n2016 Jun;15(2):103-11. doi: 10.1002/wps.20311.\n\nPMID: 27265691; PMCID: PMC4911781.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "40 How do you improve?This year we replicated this finding and expanded our \nunderstanding of burnout by showing that stable teams \nand flexible work arrangements are also associated with \nless burnout.\n\nIn addition, this year we measured team Net \nPromoter Score (NPS), which indicates whether people \nwould recommend their team to a friend or colleague.\n\nWe found that team NPS was associated with perceived \nleadership buy-in.\n\nAnd mirroring the burnout findings,  \nwe found that a generative culture, a stable team, and  \na flexible work arrangement are associated with people \nbeing more likely to recommend their team to others.\n\nHow employees perceive  \ntheir organization\nLastly, we investigated perceived leadership buy-in  \nby asking people to predict how much support  \nthey expected their team to receive over the next  \n12 months."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Results showed that higher perceived \nleadership buy-in (for example more financial support, \nmore allocation of resources, sponsorships) was \nassociated with high performing organizations.\n\nWe also asked people to predict the likelihood that  \na security breach or a complete outage would occur  \nover the next 12 months.\n\nResults showed that people \nworking at high performing organizations were  \nless likely to expect a major error to occur -  \nthey had a more positive outlook on their  \norganization.\n\nSimilarly, we found that  \npeople working in organizations with  \nhigh software and delivery  \nperformance were less likely to  \nfeel that their current practices  \nneeded to be changed to  \nimprove business outcomes.\n\nFlexible work models \nare associated with \ndecreases in employee \nburnout and increases in \nemployees\u2019 likelihood of \nrecommending their team \nas a good place to work.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "41 How do you improve?A few words on representation  \nOur findings showed that employees from \nunderrepresented groups were more likely to report \nspending more time on unplanned work regardless  \nof whether they belong to high or low performing \norganizations.\n\nWe also found that employees from \nunderrepresented groups reported higher levels of \nburnout compared to employees who do not belong  \nto underrepresented groups.\n\nTeam leads should be  \naware of the risk for workload imbalance and ensure  \nwork is allocated fairly among team members.\n\nTaken together, these findings underscore the importance \nof creating a healthy and inclusive environment for \nemployees both at the organizational and team level.\n\nWhile we continue to emphasize the importance  \nof culture, we acknowledge that changing or even \nimproving an organization\u2019s culture is no easy task."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "While we continue to emphasize the importance  \nof culture, we acknowledge that changing or even \nimproving an organization\u2019s culture is no easy task.\n\nWe recommend that organizations seek to first \nunderstand their employees\u2019 experiences and \nsubsequently invest resources in addressing  \nculture-related issues as part of DevOps \ntransformation efforts.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "42 Supply chain securityWhy supply chain \nsecurity matters04\nIn November 2020, relatively few technology \nprofessionals suspected that a software supply  \nchain security crisis was brewing.\n\nThe Open Source \nSecurity Foundation, a successor to past efforts, had \nbeen founded to focus on open source software \nsecurity, and while there were a few bright spots  towards \naddressing this problem, the topic was not on the front \npage of major newspapers.\n\nA major attack, SolarWinds, \nAccelerate  State of DevOps 2022\nJohn Speed Meyers Todd Kulesza\nchanged all of that.\n\nWhen attackers can silently  \npenetrate thousands of major companies and \ngovernment networks on the back of trojan  \nsoftware updates, the times change fast.\n\nToday, the topic of software supply chain security  \nhas become widely recognized as urgent \u2014 if not  \nover family dinner, certainly in the boardroom."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "43 Supply chain securityThere are numerous initiatives, and large parts of the \nsoftware industry have committed to reforming their \nown software supply chain security practices and \nimproving the security of the open source commons.\n\nIn this chapter, we focus on two initiatives: \nSupply Chain Levels for Software Artifacts (SLSA, \npronounced \u201csalsa\u201d), and the NIST Secure Software \nDevelopment Framework (SSDF).\n\nEach offers a range \nof defensive measures to make sure that attackers \ncan\u2019t tamper with software production processes \nand sail past network defenders via malicious \nsoftware updates.\n\nBut how widely used are the software supply chain \nsecurity practices associated with SLSA and SSDF?\n\nWhich practices need help driving adoption, and \nwhich are already in widespread use?\n\nTo date, there \nwere no systematic answers to these questions.\n\nBy surveying hundreds of software professionals \nabout their use of practices associated with supply \nchain security, we provide some early answers."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "By surveying hundreds of software professionals \nabout their use of practices associated with supply \nchain security, we provide some early answers.\n\nIn particular, four main findings stand out:01 Adoption has already begun: Software \nsupply chain security practices embodied \nin SLSA and SSDF already see modest \nadoption, but there is ample room for more.\n\n02 Healthier cultures have a head start: \nOrganizational culture is a primary \ndriver of software development security \npractices, with higher trust, \u201cblameless\u201d cultures are \nmore likely to establish SLSA and SSDF practices  \nthan lower-trust organizational cultures.\n\n03 There\u2019s a key integration point: \nAdoption of the technical aspects of \nsoftware supply chain security appears  \nto hinge on the use of CI/CD, which often provides \nthe integration platform for many supply chain \nsecurity practices."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "04 It provides unexpected benefits: \nBesides a reduction in security risks, \nbetter security practices carry additional \nadvantages, such as reduced burnout.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "44 Supply chain securityWhat companies do today to \navoid security vulnerabilities\nTo better understand what organizations are doing \ntoday to identify and resolve security vulnerabilities \nin the software they build, we added over two dozen \nquestions to this year\u2019s survey.\n\nThese questions  \nbroadly fell into two categories: \n\u2022 Questions that asked respondents to agree \nor disagree with a statement (for example, \n\u201cMy organization has an effective method for \naddressing security threats\u201d or \u201cI have access to \nthe necessary tooling to execute security tests\u201d).\n\n\u2022 Questions that asked respondents how \nestablished or not established security practices \nare at their organization (for example, \u201cBuilds \nare defined through build scripts and nothing \nelse\u201d or \u201cProduction releases are built by using a \ncentralized CI/CD system, never on a developer\u2019s \nworkstation\u201d)."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "We used the \u201cestablished/not \nestablished\u201d scale because early tests found that \nrespondents were biased towards agreeing with \nsome security-related questions.\n\nThe questions \nabout SSDF, however, were more naturally phrased \nwith the agree/disagree response scale.The SLSA framework, at v0.1 at the time of \nwriting, describes a series of software supply chain \nintegrity practices associated with SLSA \u201clevels,\u201d \nwith higher levels corresponding to higher levels of \nsoftware supply chain security assurance.\n\nWe asked \nrespondents about many of the particular practices \nassociated with SLSA.\n\nIn particular, the survey asked, \n\u201cHow established are the following practices for  \nthe primary application or service you work on?\u201d  \nTable 1 lists the wording of the SLSA-related  \npractices covered in the survey.\n\nThe SSDF, currently at v1.1, focuses on practices  \nto help organizations ship software with fewer \nvulnerabilities, and to minimize the potential  \nimpact of remaining vulnerabilities."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "The SSDF, currently at v1.1, focuses on practices  \nto help organizations ship software with fewer \nvulnerabilities, and to minimize the potential  \nimpact of remaining vulnerabilities.\n\nInstead of  \nSLSA\u2019s \u201clevels,\u201d SSDF practices are grouped into  \nfour categories: preparing the organization, \nprotecting the software being developed,  \nproducing well-secured software, and responding \neffectively to discovered vulnerabilities.\n\nThe survey \nasked respondents how much they agree (or \ndisagree) with statements describing several SSDF \npractices; these questions are summarized in Table 2.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "45 Supply chain securitySLSA Practice Survey Definition\nCentralized CI/CDProduction releases are built by using a centralized CI/CD system,  \nnever on a developer\u2019s workstation\nHistory Preserved Revisions and their change history are preserved indefinitely\nBuild Script Builds are fully defined through the build script and nothing else\nIsolated Builds are isolated; they cannot interfere with concurrent or subsequent builds\nBuild Text FilesBuild definitions and configurations are defined in text files stored in a version  \ncontrol system\nParameters MetadataBuild metadata (e.g.\n\ndependencies, build process, build environment)  \nabout an artifact includes all build parameters\nDependencies Meta-\ndataBuild metadata (e.g.\n\ndependencies, build process, build environment)  \nabout an artifact documents all dependencies\nMetadata  \nGeneratedBuild metadata (e.g."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "dependencies, build process, build environment)  \nabout an artifact documents all dependencies\nMetadata  \nGeneratedBuild metadata (e.g.\n\ndependencies, build process, build environment) is either generated  \nby the build service, or by a build-metadata generator that reads the build service\nPrevent InputsWhen running builds, build steps are prevented from loading any build inputs  \ndynamically (i.e.\n\nall required sources and dependencies are fetched upfront)\nUsers No EditBuild metadata (e.g.\n\ndependencies, build process, build environment)  \nabout an artifact cannot be edited by build services users\nMetadata AvailableBuild metadata (e.g.\n\ndependencies, build process, build environment)  \nis available to the people who need it (e.g.\n\nvia a central database), and is  \ndelivered in a format that they accept\nTwo Person ReviewEvery change in a revision\u2019s history must be individually reviewed and  \napproved by two trusted persons prior to submission\nMetadata SignedThe build metadata (e.g."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "dependencies, build process, build environment)  \nabout how an artifact was produced is signed by my build service\nTable 1.\n\nSLSA-Related Survey Questions\nNote: Respondents had five possible responses to each question: not established at all,  \nslightly established, moderately established, very established, and completely established.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "46 Supply chain securitySSDF Practice Survey Definition\nSecurity reviews A security review is conducted for all major features on the applications I work on\nContinuous code \nanalysis / testingWe continuously engage in automated or manual code analysis and testing for all supported re-\nleases, in order to identify or confirm the presence of previously undetected vulnerabilities\nEarly security testing Security tests are run early in the software development process, either by me or by another team\nEffectively address \nthreatsMy organization has an effective method for addressing security threats\nIntegrated with de-\nvelopment teamSecurity roles are integrated into our software development team\nDocuments require-\nmentsOur org has processes in place to identify and document all security requirements for the software \nour organization develops or acquires (including third-party and open source)\nRegularly reviews \nrequirementsSecurity requirements are reviewed at regular intervals (annually, or sooner if required)\nMetadata  \nGeneratedBuild metadata (e.g."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "dependencies, build process, build environment) is either generated by the \nbuild service, or by a build-metadata generator that reads the build service\nIntegrated with de-\nvelopment cycleAt my company, the software-security protocol is seamlessly built into our development process\nStandard process \nacross projectsAt my company, we have a standardized process for addressing software security across projects\nMonitor security \nreportsWe have ongoing efforts to monitor information coming from public sources regarding possible \nvulnerabilities in the software we use and its third-party components\nHave necessary tools I have access to the necessary tooling to execute security tests\nTable 2.\n\nSSDF-Related Survey Questions\nNote: Respondents had seven possible responses to each question: strongly disagree, disagree,  \nsomewhat disagree, neither agree nor disagree, somewhat agree, agree, and strongly agree.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "47 Supply chain securityan organization was a predictor of the maturity of its \nsecurity practices.\n\nThus, we believe that without this \ncritical piece of infrastructure, it is very difficult for an \norganization to ensure a consistent set of scanners, \nlinters, and tests are run against the software artifacts \nthey create.\n\nIn addition to CI/CD, other commonly established \npractices included indefinite preservation of code \nhistory (60%), builds that are solely defined via scripts \n(58%), keeping builds isolated from one another (57%), \nand storing build definitions in source control (56%).\n\nOn the lower end, the two least commonly established \npractices were requiring two or more reviewers to \napprove each code change (45%) and signing build \nmetadata to prevent/detect tampering (41%).Overall, we found relatively broad adoption of  \nemerging industry practices, though with plenty  \nof room for these to become more established."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "For example, while 66% of respondents agreed  \nwith the statement, \u201cAt my company, the software-\nsecurity protocol is seamlessly built into our \ndevelopment process,\u201d only 18% strongly agreed.\n\nFigures 1 and 2 summarize participant responses  \nto our security questions.\n\nWe found that using continuous integration/continuous \ndelivery (CI/CD) systems for production releases was \nthe most commonly established practice, with 63% \nof respondents saying this was \u201cvery\u201d or \u201ccompletely\u201d \nestablished.\n\nThat CI/CD tops this list aligns with prior \nsecurity research, which found that most organizations \nimplement application-level security scanning as part \nof their CI/CD process.\n\nIn addition, a separate set of \nsecurity-focused qualitative interviews suggested that \nmost developers were unable to run such tooling locally \nduring development.\n\nThe SLSA framework similarly \nbuilds upon CI systems as a central integration point for \nsupply chain security."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "The SLSA framework similarly \nbuilds upon CI systems as a central integration point for \nsupply chain security.\n\nOur model analysis, described \nin the next section, found that the presence of CI in \nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "48 Supply chain securityAlongside questions about established practices, we \nalso asked participants to agree or disagree with a \nset of statements about security at their organization.\n\nThe statement with the highest level of agreement \nwas, \u201cWe have ongoing efforts to monitor information \ncoming from public sources regarding possible \nvulnerabilities in the software we use and its third-\nparty components,\u201d with 81% of respondents agreeing."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "On the opposite side, the statement with the lowest \nproportion of agreement regarded negative impacts \nof security practices on software development \u2013 56% \nof respondents agreed that, \u201cThe software security \nprocesses that exist at my company slow down the \ndevelopment process for the applications I work on.\u201d \nAccelerate  State of DevOps 2022While it\u2019s encouraging that this had the lowest level  \nof respondent agreement, the fact that a majority  \nof respondents said current security processes  \nslow down development suggests a great deal  \nof room for improvement in security tooling and \napproaches.\n\nOur model analysis also supports  \nthis interpretation, showing mixed (though  \nminor) effects on software delivery performance."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "49 Supply chain security0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%Completely or \nvery establishedModerately  \nestablishedNot or slightly \nestablished\nPercentage of respondentsCentralized CICD\nHistory preserved\nBuild script\nIsolated\nBuild text fields\nParameters metadata\nDependencies metadata\nMetadata generated\nPrevents inputs\nUsers no edit\nMetadata available\nTwo person review\nMetadata signed\nFigure 1.\n\nEstablishment of SLSA practices\nSurvey responses about the establishment of SLSA practices.\n\nA majority of respondents indicated some  \nestablishment of all of these practices, but relatively few said they were \u201ccompletely\u201d established yet.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "50 Supply chain securitySecurity reviews\nContinuous code analysis/ testing\nEarly security testing\nEffectively address threats\nEffectively identify threats\nIntegrated with development\nDocuments requirements\nRegularly review requirements\nintegrated with development cycle\nStandard process across projects\nMonitor security reports\nHave necessary tools\n0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%Agree Neither agree nor disagree Disagree\nPercentage of respondents\nFigure 2.\n\nEstablishment of SSDF practices\nSurvey responses about the establishment of SSDF practices.\n\nSimilar to SLSA, a majority  \nof respondents agreed that their organization followed all of these practices.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "51 Supply chain securityOur survey data suggest that there are several  \nfactors which make it easier for developers to,  \n\u201cdo the secure thing.\u201d\nThe biggest factor we found was not technical at all, but \nrather cultural: organizations closest to the \u201cgenerative\u201d \nWestrum culture group were significantly more likely \nto say they had broadly established security practices, \nas defined by the SLSA framework1 .\n\nAspects of generative \ncultures include being highly cooperative, sharing risks and \nresponsibilities, and learning from past mistakes.\n\nWe \nhypothesize these traits manifest in healthier security \npractices in numerous ways, such as encouraging \nsoftware engineers to be more proactive about supply \nchain security, rewarding people for their efforts around \nsecurity regardless of their job role, or reducing perceived \nrisks of reporting potential security issues.\n\nTechnologically, three of the most important factors \ndriving security relate to infrastructure."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Technologically, three of the most important factors \ndriving security relate to infrastructure.\n\nIntuitively this \nmakes sense: if your infrastructure makes tasks like \nvulnerability scanning or manual code reviews easier to \nconduct, then it becomes more likely your engineers will \nuse them.\n\nSpecifically, we found that having systems \nfor source control, continuous integration, and What helps companies follow \ngood security practices?\n\nApplication security is just one aspect of software \ndevelopment, and thus one of many competing \ndemands on developers\u2019 time and attention.\n\nHigh-\nfriction approaches to security can be frustrating for \ndevelopers and ineffective overall, as people try  \nto avoid the friction points.\n\nFor example, a set of \nresearch interviews with professional software \nengineers found that their touchpoints with security \nteams were limited to either the start or end of a \nproject, and the teams could be difficult to engage \nwith."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "In the words of one participant, \u201cWe have an \napplication security team, but I have never had my \ncode reviewed by them\u2026 I am like most engineers,  \nI avoid them usually.\u201d \nOne approach to improving software security is to \nreduce barriers to following security practices.\n\nThe \ndevelopers we spoke with wanted  to do the right thing, \nand often discussed frustration that shipping features \nor fixes consistently took priority over potential security \nissues.\n\nFor example, one respondent to a separate \nsecurity-related survey described their biggest \nsecurity challenge as, \u201cmaking it a priority  \nin the first place.\n\nIt\u2019s not sexy, it doesn\u2019t sell more \nproduct, [and] it\u2019s not a problem until it becomes one.\u201d \n1 Interestingly, these same respondents were not more likely to agree with the NIST SSDF questions.\n\nWhile SLSA and SSDF discuss different \naspects of application development security, we expected to find overlap between these sets of questions."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "While SLSA and SSDF discuss different \naspects of application development security, we expected to find overlap between these sets of questions.\n\nAs mentioned earlier, it\u2019s possible \nthat the response scale for SSDF was biased towards \u201cagreement\u201d responses, which would explain this difference.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "52 Supply chain securitysecurity tools locally would help them work faster  \nand more efficiently.\n\nThe cultural and technological factors discussed above \nwere the biggest drivers of security, but not the only \nones.\n\nOther notable factors included:\n\u2022 Flexibility in work arrangements (for example, does \nthe organization support working from home?)\n\n\u2022 Cloud use (either public or private)\n\u2022 Working on a \u201ccloud-native\u201d application or service\n\u2022 Feeling that the business values and  \ninvests in your team\n\u2022 Low turnover on team\n\u2022 Organization size, with larger organizations \nreporting higher security scores\nThese factors, however, mostly seem to correlate with \neither the generative Westrum culture (for example, \nflexible work arrangements, feeling valued by your \norganization, or having low team turnover), or with CI/\nCD usage (for example, working on a cloud-native \napplication, or working at a large organization)."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "This data \nleads us to believe organizational culture and modern \ndevelopment processes (such as continuous integration) \nare the biggest drivers of an organization\u2019s application \ndevelopment security, and the best place to start for \norganizations looking to increase their security posture.continuous delivery were all linked with also having \nmore firmly established SLSA practices.\n\nA key part of \nthis is likely when security issues get developer attention, \nwhich a separate survey found was primarily during CI.\n\nTypically CI directly precedes code reviews, and is when \nvulnerability scanners and other code analysis tools are \nrun, as it guarantees that all code commits are subject to \nthe same security requirements.\n\nThe lack of a centralized \nbuild system makes such consistent scanning far more \nchallenging, and the lack of source control in turn makes \nit challenging to have a centralized build system in  \nthe first place."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Security scanning as part of CI/CD, however, may not \nbe early enough for software engineers.\n\nIn a set of \nsecurity-related interviews with application developers, \nthey consistently told us security scanning on their \ndevelopment workstation would help to save time  \nand effort.\n\nTwo situations were commonly cited:  \n1) wanting to know in advance if they were building \nupon a dependency with known vulnerabilities, so \nthey could re-evaluate using that dependency before \nbuilding on top of it, and 2) avoiding long CI wait times, \nsometimes measured in hours, just to confirm whether \ntheir current changes resolved a security issue.\n\nIn \nboth cases, software engineers said that while a CI \n\u201cbackstop\u201d was necessary, the ability to run the same \nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "53 Supply chain securityWhat outcomes do good \nsecurity practices lead to?\n\ncan eliminate security threats, but our evidence suggests \nthey do reduce an organization\u2019s security risk.\n\nSecurity practices can also positively impact performance-\nbased outcomes, but there is a twist: CI plays a pivotal \nrole.\n\nWhen CI isn\u2019t implemented, security practices show \nno effect on software delivery performance.\n\nBut when \nCI is implemented, security practices have a strong \npositive effect on software delivery performance.\n\nThis \nessentially means that CI is necessary for security practices \nto positively impact software delivery performance.\n\nFurther, security practices generally have a positive effect \non organizational performance, and when CI is firmly \nestablished, this effect is amplified.\n\nThe graph below \nattempts to visualize this effect.As organizations improve their security practices around \nsoftware development, what benefits might they expect \nto see?"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "The graph below \nattempts to visualize this effect.As organizations improve their security practices around \nsoftware development, what benefits might they expect \nto see?\n\nOur survey data confirms that participants \nanticipate a lower chance of security breaches, \nservice outages, and performance degradation as \ncompanies increase establishment of supply chain \nsecurity practices .\n\nSimilarly, we conducted separate \nresearch in the first half of 2022, finding that running \ntools like vulnerability scanners during CI significantly \nincreased the probability of identifying vulnerabilities  \nin software dependencies: respondents who used such \ntools were nearly twice as likely to report identifying  \na security vulnerability in their own code or in one of  \nits dependencies.\n\nIn short: SLSA and SSDF practices \nappear to work as intended."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "In short: SLSA and SSDF practices \nappear to work as intended.\n\nWe don\u2019t claim that they  \nAbove average CI\nBelow average CI\nBelow average security practices\n0.4 0.5 0.6Security Practices (SLSA-related)\nproportion with above average organizational performanceAbove average security practices0.45% 0.66%\n0.33% 0.46%\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "54 Supply chain securityAlong with a reduction in perceived security risks, \nrespondents also reported less burnout among team \nmembers and an increased willingness to recommend \ntheir organization as a great place to work.\n\nBoth of \nthese findings speak to the \u201cyes, and\u2019\u2019 nature of security \nfor software engineers: it\u2019s one more task on their \nalready crowded plates.\n\nTools and processes that help \nthem incorporate secure practices into their existing \ndevelopment workflow, as opposed to unplanned  \nwork or \u201cfire drills\u201d when a threat is discovered,  \nprovide a mechanism for reducing security risks and \nincreasing developer joy.\n\nTaken together, our evidence suggests that healthy, \nhigh-performing teams also  tend to have good \nsecurity practices  broadly established (though, \nas noted earlier, there continues to be room for \nimprovement)."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Following approaches such as the  \nSLSA or SSDF frameworks might not single-handedly \nimprove all the culture and performance metrics that  \nwe measure, but it\u2019s clear that security need not come  \nat the expense of other development priorities.Tools and processes that \nhelp them incorporate \nsecure practices into their \nexisting development \nworkflow, as opposed to \nunplanned work or \u201cfire \ndrills\u201d when a threat is \ndiscovered, provide a \nmechanism for reducing \nsecurity risks and \nincreasing developer joy.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "55 SurprisesAlthough each year\u2019s report focuses on the \ncorresponding year\u2019s survey responses, we do our  \nbest to understand these findings in the context of  \nthe entire catalog of State of DevOps Reports and \nadjacent research (for example, research on burnout \nand culture).\n\nTesting the reliability of these effects \nthrough replication efforts is a core tenet of the \nresearch program.\n\nThis gives us an opportunity to \nadjust our beliefs to fit the data and understand \nevolving or emerging trends.\n\nThis year we ran into a few surprises.\n\nThere are a \nmyriad of potential reasons for this.\n\nFor one, the sample \nshifted this year to include more people earlier in their \ncareers than in previous reports.\n\nOne interpretation \nis that we\u2019re hearing more from the people who are \ndirectly responsible for implementing the technical \npractices and capabilities, as opposed to people who Surprises05\nmight be responsible for overseeing or directing the \nimplementation of these practices."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Another possibility \nis that something has shifted in the industry or the \nworld; what worked yesterday isn\u2019t guaranteed to work \ntomorrow.\n\nMacroeconomic forces, and another year \nlargely in the shadow of the COVID-19  pandemic, for \nexample, may have changed the physics of DevOps.\n\nLastly, subtle changes to what is included in our  \nmodel may have changed the relationships  \nbetween variables.1 \n1 Judea Pearl\u2019s \u201cBook of Why\u201d and Robert McElreath\u2019s \n\u201cStatistical Rethinking\u201d present us with incredible \nexamples of how what you do and don\u2019t include in your \nstatistical models can impact the model\u2019s output.\n\nAccelerate  State of DevOps 2022Derek DeBellis"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "56 SurprisesAn unexpected or unhypothesized finding puts \nresearchers in a tough spot when it\u2019s time to write the \nreport.\n\nGiven the risk that the finding is spurious or, at the \nvery least, has yet to establish (or even contradicts) the \nempirical evidence of multiple studies, the responsible \nmove is to do follow-up research to attempt to replicate \nthe results and understand their cause.2  By focusing on the \nsurprises, a researcher also runs the risk of deemphasizing \nhow many effects have reliably emerged across years \nof research.\n\nWe statistically explore over one hundred \npathways for each State of DevOps report.\n\nIn doing so, \nwe invite the risk of spurious findings simply by chance.\n\nWe try to counteract that with yearly replication efforts.\n\nOn the other hand, not reporting the finding risks \ncreating a file drawer effect3 , which effectively results \nin the expected or palatable becoming well-known, \nand the unexpected or difficult to stomach being \nhidden away."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "We seek to strike a balance: we don\u2019t \nwant to sensationalize nascent findings, but we also \nfeel it is crucial to share them.\n\nHere are the things that \nsurprised us the most, and what we think they mean:01 We have consistently observed that trunk-\nbased development practices have a positive \nimpact on software delivery performance.\n\nIn fact, this has been observed in every year of \nthe study since 2014.\n\nTrunk-based development \ncapabilities were behaving out of character this year.\n\nFor one, trunk capabilities had a negative impact on \nsoftware delivery performance.\n\nThe opposite was \ntrue in previous research reports.\n\nGiven how aberrant \nthis finding is, we are eager to see if it is replicated in \nupcoming research and hear if the community has  \nany explanations.\n\n02 We only found that software delivery \nperformance is beneficial to organizational \nperformance when operational \nperformance is also high, and many respondents \ndid not have high operational performance."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "This \ncontradicts previous iterations of our research \nwhere the connection between software delivery \nperformance and organizational performance was \nmuch clearer.\n\n2 Kerr, N. L. (1998).\n\nHARKing: Hypothesizing after the results are known.\n\nPersonality and social psychology review, 2(3), 196-217.\n\n3 Rosenthal, R. (1979).\n\nThe file drawer problem and tolerance for null results.\n\nPsychological bulletin, 86(3), 638.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "57 Surprises03 Documentation practices negatively \nimpacted software delivery performance.\n\nThis is at odds with previous reports.\n\nOne \nhypothesis is that documentation is becoming an \nincreasingly automated practice, especially among \nhigh-performing teams.\n\nUntil we collect additional  \ndata, we have little evidence to either support or  \nrefute this belief.\n\n04 Some tech capabilities (i.e., trunk based \ndevelopment, loosely-coupled architecture, \nCI, CD) seemed to predict burnout.\n\nAs \nmentioned above, many respondents in this sample \nwere notably earlier in their careers than participants \nin previous years\u2019 samples.\n\nHence, we might have been \ntalking to people responsible for implementing the \ncapability as opposed to those responsible for creating \nor overseeing the initiative.\n\nThe implementation \nprocess may be notably more challenging than its \noversight."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "The implementation \nprocess may be notably more challenging than its \noversight.\n\nWe want to do further research to better \nunderstand this finding.05 Reliability engineering practices had a \nnegative impact on software delivery \nperformance.\n\nOne explanation is that these \nare not necessarily causally intertwined.\n\nThis year \nwe noticed in a new clustering analysis (see \u201cHow do \nyou compare\u201d) that a subset of clusters seemed to \nfocus on reliability while ignoring software delivery \nperformance.\n\nWe believe that these are decoupled, in \nthe sense that you can do one without doing the other, \nbut ultimately, to make software delivery performance \ncount in terms of organizational performance, \nreliability needs to be in place.\n\n06 We added SLSA-related practices to \nunderstand whether teams are adopting \nthese approaches to maintaining a secure \nsoftware supply chain."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "06 We added SLSA-related practices to \nunderstand whether teams are adopting \nthese approaches to maintaining a secure \nsoftware supply chain.\n\nWhile we expected there to be \nsome association between implementation of security \npractices and performance (e.g., use of technical \ncapabilities, better software delivery performance, and \nbetter organizational performance), we were surprised to \nsee that security practices were actually the mechanism \nthrough which technical capabilities impacted software \ndelivery performance and organizational performance.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "58 SurprisesThe inclusion of SLSA-related practices seems to  \naccount for much of the effect of continuous integration, \nversion control and continuous delivery on both software \ndelivery performance and organizational performance.\n\nPut differently, there is a causal chain that is being \ndetected in the data where many technical capabilities \nhave a positive impact on SLSA-related practices and \nthrough this positive impact on SLSA-related practices \nhave a positive impact on both software delivery \nperformance and organizational performance.\n\nWe used mediation analyses to detect this result.4 5   \nThis is pushing us to explore whether our measure of \nSLSA-related practices is tracking other features of the \nteam (e.g., general performance) and in what way security \npractices lead to better software delivery performance \nand organizational performance."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "We look forward to studying these effects again  \nnext year, to see whether we can reproduce and \nexplain these new patterns, or whether we should  \nlean toward dismissing them as outliers (that we  \nshould also try to explain).\n\nAs always, we welcome \nfeedback from the community.\n\n4 Jung, Sun Jae.\n\n\u201cIntroduction to Mediation Analysis and Examples of Its Application to Real-world Data.\u201d Journal of preventive medicine and public \nhealth = Yebang Uihakhoe chi vol.\n\n54,3 (2021): 166-172. doi:10.3961/jpmph.21.069\n5 Carri\u00f3n, Gabriel Cepeda, Christian Nitzl, and Jos\u00e9 L. Rold\u00e1n.\n\n\u201cMediation analyses in partial least squares structural equation modeling: Guidelines \nand empirical examples.\u201d Partial least squares path modeling.\n\nSpringer, Cham, 2017.\n\n173-195.Join the DORA Community \n(http:/ /dora.community) to \ncontinue the discussion about \nthese surprises and other \nfindings in this year\u2019s report!\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "59 Who took the survey?Who took the survey?\n\nWith eight years of research and more than 33,000 \nsurvey responses from industry professionals, the \nState of DevOps Report showcases the software \ndevelopment and DevOps practices that make teams \nand organizations most successful.\n\nThis year, over \n1350 working professionals from a variety of industries \naround the globe shared their experiences to help \ngrow our understanding of the factors that drive higher \nperformance.\n\nThank you for your contributions to our \nresearch and our industry!\n\nIn summary, representation \nacross demographic and firmographic measures has \nremained remarkably consistent.Demographics  \nand Firmographics06\nSimilar to previous years, we collected demographic \ninformation from each survey respondent.\n\nCategories \ninclude gender, disability, and underrepresented groups.\n\nThis year we saw representation that was consistent with \nprevious reports across firmographic categories including \ncompany size, industry, and region."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "This year we saw representation that was consistent with \nprevious reports across firmographic categories including \ncompany size, industry, and region.\n\nAgain, over 60% of \nrespondents work as engineers or managers and a third \nwork in the technology industry.\n\nAdditionally, we see \nindustry representation from financial services, retail,  \nand industrial/manufacturing companies.\n\nThank you for your \ncontributions to our  \nresearch and our industry!\n\nAccelerate  State of DevOps 2022Derek DeBellis"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "60 Who took the survey?Demographics\nGender\nRelative to 2021, this year\u2019s sample had a higher \nproportion of female respondents (18% vs. 12%).\n\nThe proportion of male respondents (76%) was \nlower than 2021 (83%).\n\nRespondents stated that \nwomen make up 25% of their teams, which is \nidentical to 2021 (25%).\n\nDisability\nWe identified disability along six dimensions that \nfollow guidance from the Washington Group \nShort Set.\n\nThis is the fourth year we have asked \nabout disability.\n\nThe percentage of people  \nwith disabilities was consistent with our 2021 \nreport at 11%.\n\nUnderrepresented\nIdentifying as a member of an underrepresented \ngroup can refer to race, gender, or another \ncharacteristic.\n\nThis is the fifth year we have asked \nabout underrepresentation."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Underrepresented\nIdentifying as a member of an underrepresented \ngroup can refer to race, gender, or another \ncharacteristic.\n\nThis is the fifth year we have asked \nabout underrepresentation.\n\nThe percentage  \nof people who identify as underrepresented  \nhas increased slightly from 17% in 2021 to  \n19% in 2022.19% \nYes\n10% \nPrefer  \nnot to say\n71%\nNoUnderrepresented11% \nYes\n7% \nPrefer  \nnot to say\n82%\nNoDisability1% \nNon-binary6% \nPrefer not \nto respond\n76% \nMale18%\nFemale\nPercent women: 25% MedianGender\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "61 Who took the survey?0-23%8%\n3-511%27%\n6-1020%33%\n11-1525%\n18%\n>1641%\n13%\nYears of Experience2021 2022Years of experience\nNotably more respondents this year had five years  \nor less of experience (35%) than in 2021 (14%).\n\nPerhaps unsurprisingly then, the proportion of \nrespondents with more than 16 years of experience \n(13%) was a fraction of 2021 (41%).\n\nThis shift may explain some patterns that emerged  \nin the data, and we believe is important to keep this in \nmind when interpreting the results, especially when \ncomparing to last year.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "62 Who took the survey?\n\nAccelerate  State of DevOps 2022\nFirmographics\nRole\n85% of respondents consist of \nindividuals who either work on \ndevelopment or engineering teams \n(26%), work on DevOps or SRE teams \n(23%), work on IT ops or infrastructure \nteams (19%), or are managers (17%).\n\nThe proportion of respondents who \nwork on IT ops or infrastructure teams \n(19%) more than doubled last year\u2019s \nproportion (9%).\n\nC-level executives \n(9% in 2021 to 4%), and Professional \nServices (4% in 2021 to 1%) are two \nof the more pronounced decreases \nrelative to last year.\n\nIndustry\nAs in previous State of DevOps \nreports, we see that most \nrespondents work in the technology \nindustry, followed by financial \nservices, other, and retail."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "63 Who took the survey?\n\nRegion\nThis year we asked respondents to select the country \nthey were from instead of the region.\n\nRegion, which was \nfrequently represented by a continent, seemed a bit too \ncoarse to understand the makeup of our respondents.\n\nWe received responses from participants in over 70 \ncountries; 89% of respondents came from 22 countries.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "64 Who took the survey?\n\nNumber of employees\nConsistent with previous State of DevOps surveys, \nrespondents come from organizations of a variety of \nsizes.\n\n22% of respondents are at companies with more \nthan 10,000 employees and 7% are at companies with \n5,000\u20139,999 employees.\n\nAnother 15% of respondents are at organizations with 2,000\u20134,999 employees.\n\nWe \nalso saw a fair representation of respondents (13%) from \norganizations with 500\u20131,999 employees , 15% with 100\u2013\n499 employees, and finally 15% with 20\u201399 employees .\n\nThis year, we also allowed respondents to select \u201cI don\u2019t \nknow\u201d about their organization\u2019s size; 15% of respondents \neither reported not knowing or skipped the question.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "65 Who took the survey?\n\nTeam size\nThis year we had participants indicate the approximate \nnumber of people on their team.\n\n25% of respondents \nworked on teams with 5 people or fewer.\n\n50% of \nrespondents worked on teams with 8 people or fewer.\n\n75% of respondents worked on teams with 12 people  \nor fewer.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "66 Who took the survey?\n\nDeployment target \n2021 was the first year we decided to look at where \nrespondents deployed the primary service or application \nthey work on.\n\nTo our surprise, the number one deployment target was containers.\n\nThis year was no different, although \nat a lower proportion (54%) than last year (64%).\n\nWe also added more options in the hope of giving \nrespondents more ways to reflect where they deploy.\n\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "67 Final thoughtsEach year that we produce this report, we strive to \nprovide a rigorous account of how practices and \ncapabilities lead to business-critical outcomes such \nas organizational performance.\n\nWe evaluate the \nreplicability of many effects in previous reports,  \nand extend the scope of our work to account for \nemerging priorities in the DevOps space.\n\nThis year  \nwe shaped our survey and analyses to do a deep \ndive on security practices and altered our statistical \nmodeling approach to explore the conditionality or \ndependencies of certain effects.\n\nWe also explored  \nnew ways to describe the landscape of software \ndelivery and operational performance."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "We also explored  \nnew ways to describe the landscape of software \ndelivery and operational performance.\n\nIn many ways, the narrative that materialized this year \nis an echo of previous years: technical capabilities \nbuild upon each other to create better performance; \nthere are many benefits inherent in the use of cloud; \nworkplace culture and flexibility lead to better \norganizational performance; and employee  \nburnout prevents organizations from reaching  \ntheir goals.\n\nThe analysis of interactions that  \nwe explicitly added to the model helped us  \nunderstand the conditions under which certain Final thoughts07\neffects can take place.\n\nFor example, software delivery \nperformance only seems to have a positive impact \non organizational performance when operational \nperformance (reliability) is high, which leads to \nthe conclusion that you need both to thrive as an \norganization.\n\nThere were also a few surprises, which \nwe highlighted in a dedicated section."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "There were also a few surprises, which \nwe highlighted in a dedicated section.\n\nWe thank everyone who contributed to this year\u2019s \nsurvey.\n\nWe hope our research helps you and your \norganization build better teams and better software \u2014 \nwhile also maintaining work-life balance.\n\nAccelerate  State of DevOps 2022Derek DeBellis"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "68 AcknowledgementsA large family of passionate contributors made this \nyear\u2019s report possible.\n\nSurvey question design, analysis, \nwriting, editing, and report design are just a few of the \nways that our colleagues helped to realize this large \neffort.\n\nThe authors would like to thank all of these  \npeople for their input and guidance on the report this \nyear.\n\nAll acknowledgements are listed alphabetically.Acknowledgements08\nScott Aucoin\nAlex Barrett\nJames Brookbank\nKim Castillo\nLolly Chessie\nJenna Dailey\nDerek DeBellis\nRob Edwards\nDave Farley\nChristopher Grant\nMahshad Haeri\nNathen Harvey\nDamith Karunaratne\nTodd Kulesza\nAmanda Lewis\nIan LewisEric Maxwell\nJohn Speed Meyers\nSteve McGhee\nJacinda Mein\nAlison Milligan\nPablo P\u00e9rez Villanueva\nClaire Peters\nConnor Poske\nDave Stanke\nDustin Smith\nSeth Vargo\nDaniella Villalba\nBrenna Washington\nKaiyuan \u201cFrank\u201d Xu\nNicola Yap\nAccelerate  State of DevOps 2022"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "69 AuthorsAuthors09\nAccelerate  State of DevOps 2022Claire Peters\nClaire Peters is a User Experience Researcher at Google.\n\nHer research comprises \nvarious aspects and expressions of DORA in applied settings.\n\nShe studies Google\u2019s \nCloud Application Modernization Program (CAMP), DORA-driven customer \nengagements, and Four-Keys-related tooling, with the goal of helping teams and \nindividuals more effectively apply DORA principles in their day-to-day work.\n\nClaire \nis also a member of DORA\u2019s core research team, and constructs the annual DORA \nsurvey and the State of DevOps report.\n\nShe holds an MA in Applied Cultural Analysis \nfrom the University of Copenhagen.\n\nDave Farley\nDave Farley, is the managing director and founder of Continuous Delivery Ltd and \nCreator of the Continuous Delivery YouTube Channel.\n\nDave is co-author of the \nbest-selling Continuous Delivery book.\n\nHis also the best selling author of Modern \nSoftware Engineering: Doing What Works to Build Better Software Faster."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "Dave is co-author of the \nbest-selling Continuous Delivery book.\n\nHis also the best selling author of Modern \nSoftware Engineering: Doing What Works to Build Better Software Faster.\n\nHe is \nco-author of the Reactive Manifesto and a winner of the Duke Award for the open \nsource LMAX Disruptor project.\n\nDave is a pioneer of Continuous Delivery, thought-\nleader and expert practitioner in CD, DevOps, TDD and software design, and has \na long track record in creating high-performance teams, shaping organisations \nfor success, and creating outstanding software.\n\nFind more of Dave on his Twitter , \nYouTube, blog , and website ."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "70 Authors Accelerate  State of DevOps 2022Daniella Villalba\nDaniella Villalba is a user experience researcher dedicated to the DORA  \nproject.\n\nShe focuses on understanding the factors that make developers  \nhappy and productive.\n\nBefore Google, Daniella studied the benefits of \nmeditation training, the psycho-social factors that affect the experiences  \nof college students, eyewitness memory, and false confessions.\n\nShe received \nher PhD in Experimental Psychology from Florida International University.\n\nDave Stanke\nDave Stanke is a Developer Relations Engineer at Google, where he advises \ncustomers on best practices for adopting DevOps and SRE.\n\nThroughout his \ncareer, he has worn all the hats, including startup CTO, product manager, \ncustomer support, software developer, sysadmin, and graphic designer.\n\nHe holds an MS in Technology Management from Columbia University.\n\nDerek DeBellis\nDerek DeBellis is a Quantitative User Experience Researcher at Google."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "He holds an MS in Technology Management from Columbia University.\n\nDerek DeBellis\nDerek DeBellis is a Quantitative User Experience Researcher at Google.\n\nAt Google, Derek focuses on survey research, logs analysis, and figuring out \nways to measure concepts central to product development.\n\nDerek has recently \npublished on Human-AI interaction, the impact of Covid-19\u2019s onset on smoking \ncessation, designing for NLP errors and the role of UX in privacy discussions."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "71 Authors Accelerate  State of DevOps 2022Eric Maxwell\nEric Maxwell leads Google\u2019s DevOps Digital Transformation practice where he \nadvises the world\u2019s best companies on how to be even better \u2013 a little bit at a \ntime, continuously.\n\nEric spent the first half of his career as an engineer, in the \ntrenches, automating all the things and building empathy for other practitioners.\n\nEric co-created Google\u2019s Cloud Application Modernization Program (CAMP), \nis a member of the DORA Core Team, and author of the DevOps Enterprise \nGuidebook.\n\nBefore Google, Eric spent time whipping up awesome with other \npunny folks at Chef Software.\n\nJohn Speed Meyers\nJohn Speed Meyers is a security data scientist at Chainguard, a software \nsupply chain security startup.\n\nJohn\u2019s research projects have included topics \nsuch as software supply chain security, open source software security, and the \nworld\u2019s response to growing Chinese military power."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "John\u2019s research projects have included topics \nsuch as software supply chain security, open source software security, and the \nworld\u2019s response to growing Chinese military power.\n\nPreviously, John worked \nat In-Q-Tel, the RAND Corporation, and the Center for Strategic and Budgetary \nAssessments.\n\nJohn has a PhD in policy analysis from the Pardee RAND Graduate \nSchool, a masters in public affairs (MPA) from Princeton\u2019s School of Public and \nInternational Affairs, and a BA in international relations from Tufts University.\n\nKaiyuan \u201cFrank\u201d Xu \nKaiyuan \u201cFrank\u201d Xu is a Quantitative User Experience Researcher at Google.\n\nHe \nanalyzes log and survey data to understand usage patterns and user feedback \nfor Google Cloud products,  improving product excellence for developers.\n\nBefore Google, Kaiyuan conducted years of qualitative and quantitative user \nresearch at Microsoft for Azure and Power Platform products.\n\nHe received his \nMS in Human Centered Design and Engineering from University of Washington."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "72 Authors Accelerate  State of DevOps 2022Nathen Harvey\nNathen Harvey is a Developer Relations Engineer at Google who has built  \na career on helping teams realize their potential while aligning technology  \nto business outcomes.\n\nNathen has had the privilege of working with some  \nof the best teams and open source communities, helping them apply the \nprinciples and practices of DevOps and SRE.\n\nNathen co-edited and  \ncontributed to 97 Things Every Cloud Engineer Should Know, O\u2019Reilly 2020.\n\nTodd Kulesza \nTodd Kulesza is a User Experience Researcher at Google, where he studies  \nhow software engineers work today, and how they might be able to work better \ntomorrow.\n\nHe holds a PhD in Computer Science from Oregon State University."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "73 MethodologyResearch design\nThis study employs a cross-sectional, theory-based \ndesign known as inferential predictive, one of the \nmost common types of designs conducted in business \nand technology research today.\n\nInferential predictive \ndesign is used when purely experimental design is not \npractical or impossible.\n\nTarget population and sampling\nThe target population for this survey was practitioners \nand leaders working in, or closely with, technology and \ntransformations, especially those familiar with DevOps.\n\nWe \npromoted the survey via email lists, online promotions, an \nonline panel, social media, and by asking people to share \nthe survey with their networks (that is, snowball sampling).\n\nCreating latent constructs \nWe formulated our hypotheses and constructs using \npreviously validated constructs wherever possible.\n\nWe \ndeveloped new constructs based on theory, definitions, \nand expert input."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "We \ndeveloped new constructs based on theory, definitions, \nand expert input.\n\nWe then took additional steps to \nclarify intent to ensure that data collected from the \nsurvey had a high likelihood of being reliable and valid.1Methodology10\nCalculating the differences between \nlow performers and high performers\nIn the \u201cHow do you compare\u201d section we compare  \nlow performers and high performers on the four \nmetrics of delivery performance.\n\nThe method is a \nsimple one.\n\nLet\u2019s take deployment frequency as an \nexample.\n\nThe high cluster deploys on demand (i.e., \nmultiple times per day).\n\nIf they perform an average  \nof four deployments per day, that ends up being  \n1460 deployments a year (4 * 365).\n\nThe low  \nperformers, by contrast, deploy between once \nevery month, to once every six months, for a mean \ndeployment frequency of once every 3.5 months,  \nand an average deployment frequency of about  \n3.4 deployments a year (12/3.5)."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "We take the ratio \n(1,460 deployments high / 3.4 deployments low)  \nand get 417x.\n\nThis approach is generalized for the  \nother development performance metrics.\n\nAccelerate  State of DevOps 20221  Churchill Jr, G. A.\n\n\u201cA paradigm for developing better measures of marketing constructs,\u201d Journal of Marketing Research 16:1, (1979), 64\u201373."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "74 Methodology Accelerate  State of DevOps 2022Statistical analysis methods\nCluster analysis \nFor both of the clustering solutions portrayed in the \n\u201cHow do you compare\u201d section, we used hierarchical \nclustering with a version of Ward\u2019s agglomerative \nmethod2  to evaluate how well varying cluster solutions \nfit the data.\n\nFor the first clustering results we presented, we  \nlooked for clusters of responses across deployment \nfrequency, lead time, time to restore a service, and \nchange failure rate.\n\nThis year we found three clusters \nafter evaluating 14 different hierarchical clustering \nsolutions using 30 different indices for determining  \nthe number of clusters.3\nThe second cluster analysis we presented was \nmethodologically identical to the first, but was deployed \nover different dimensions in the data."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "We wanted to  \nlook for common response patterns (i.e., clusters) \nacross throughput (a composite of deployment frequency and lead time), operational performance \n(reliability) and stability (a composite of time to restore \nservice and change failure rate).\n\nWe also explored \ndifferent clustering algorithms to see how sensitive our  \nresults were to our approach.\n\nThough there isn\u2019t an \nestablished way to quantify that sensitivity (that we \nknow of), the clusters that emerged tended to have \nsimilar characteristics.\n\nMeasurement model \nBefore conducting our analysis, we identified \nconstructs using exploratory factor analysis with \nprincipal component analysis using varimax rotation.4 \nWe confirmed statistical tests for convergent and \ndivergent validity and reliability using average variance \nextracted (AVE), correlation, Cronbach\u2019s alpha5 , rhoA 6A, \nheterotrait-monotrait ratio5 7, and composite reliability.\n\n2 Murtagh, Fionn, and Pierre Legendre."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "2 Murtagh, Fionn, and Pierre Legendre.\n\n\u201cWard\u2019s hierarchical agglomerative clustering method: which algorithms implement Ward\u2019s criterion?.\u201d \nJournal of classification  31.3 (2014): 274-295.\n\n3 Charrad M., Ghazzali N., Boiteau V., Niknafs A.\n\n(2014).\n\n\u201cNbClust: An R Package for Determining the Relevant Number of Clusters in a Data Set.\u201d, \n\u201cJournal of Statistical Software, 61(6), 1-36.\u201d, \u201cURL http://www.jstatsoft.org/v61/i06/\u201d\n4 Straub, D., Boudreau, M. C., & Gefen, D. (2004).\n\nValidation guidelines for IS positivist research.\n\nCommunications of the Association for Informa -\ntion systems, 13(1), 24.\n\n5 Nunnally, J.C. Psychometric Theory.\n\nNew York: McGraw-Hill, 1978\n6 Hair Jr, Joseph F., et al.\n\n\u201cPartial least squares structural equation modeling (PLS-SEM) using R: A workbook.\u201d (2021): 197.\n\n7 Brown, Timothy A., and Michael T. Moore.\n\n\u201cConfirmatory factor analysis.\u201d Handbook of structural equation modeling 361 (2012): 379."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "75 Methodology Accelerate  State of DevOps 2022Structural equation modeling \nWe tested the structural equation models (SEM)  \nusing Partial Least Squares (PLS) analysis8 , which  \nis a correlation-based structural equation modeling.\n\nAnalysis of the  \nsecond cluster model\nTo understand what predicts cluster membership,  \nwe employed multinomial logistic regression.9  \nWe used this approach because we were trying  \nto predict cluster membership, which, in this  \ncase, is unordered categorical data with more  \nthan two levels.\n\nTo understand the outcomes that \ncluster memberships predicted, we used a linear \nregression for each outcome (burnout, unplanned \nwork, and organizational performance.\n\n8 Hair Jr, J. F., Hult, G. T. M., Ringle, C. M., & Sarstedt, M. (2021).\n\n\u201cA primer on partial least squares structural equation modeling (PLS-SEM).\u201d \nSage publications.\n\n9 Ripley, Brian, William Venables, and Maintainer Brian Ripley.\n\n\u201cPackage \u2018nnet\u2019.\u201d R package version 7.3-12 (2016): 700."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "76 Further readingJoin the DORA Community to discuss, learn,  \nand collaborate on improving software delivery  \nand operations performance.\n\nhttp:/ /dora.community\nLearn more about the Four Keys metrics\nhttps:/ /goo.gle/four-keys\nFind more information on DevOps capabilities.\n\nhttps:/ /goo.gle/devops-capabilities\nLearn more about how you can implement  \nDORA practices in your organization, from  \nour Enterprise Guidebook\nhttps:/ /goo.gle/enterprise-guidebook\nFind resources on Site Reliability Engineering (SRE)\nhttps:/ /sre.google\nhttps:/ /goo.gle/enterprise-roadmap-sre\nTake the DevOps Quick Check\nhttps:/ /goo.gle/devops-quickcheckFurther reading11\nAccelerate  State of DevOps 2022Explore the DevOps research program\nhttps:/ /goo.gle/devops-research\nLearn from other companies who have  \nimplemented DORA practices by reading  \nout Google Cloud DevOps Award winner ebook\nhttps:/ /goo.gle/devops-awards\nFind out about the Google Cloud Application \nModernization Program or CAMP."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "https:/ /goo.gle/3daLa9s\nLeveraging data and DORA metrics  \nto transform tech processes\nhttps:/ /goo.gle/3Doh8Km\nRead the whitepaper: \u201cThe ROI of DevOps \nTransformation: How to quantify the impact of  \nyour modernization initiatives\u201d by Forsgren, N.,  \nHumble, J., & Kim, G. (2018).\n\nhttps:/ /goo.gle/3qEClIh"}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "77 Further readingRead the book: Accelerate: The science behind  \ndevops: Building and scaling high performing \ntechnology organizations.\n\nIT Revolution."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "IT Revolution.\n\nhttps:/ /itrevolution.com/book/accelerate\nLearn more about the Supply chain Levels for  \nSecure Artifacts (SLSA) framework\nhttps:/ /slsa.dev\nLearn more about Secure Software  \nDevelopment Framework (NIST SSDF)\nhttps:/ /goo.gle/3qBXLWk  \nLearn more about DevOps culture: Westrum \norganizational culture\nhttps:/ /goo.gle/3xq7KBV\nLearn more about Open Source Security Foundation\nhttps:/ /openssf.org/\nLearn more about in-toto\nhttps:/ /in-toto.io/\nAccelerate  State of DevOps 2022Learn more about NTIA.gov\u2019s Software Bill of Materials\nhttps:/ /www.ntia.gov/SBOM\nCybersecurity: Federal Response to SolarWinds  \nand Microsoft Exchange Incidents\nhttps:/ /www.gao.gov/products/gao-22-104746\nLearn more about application-level security  \nscanning as part of CI/CD\nhttps:/ /go.dev/blog/survey2022-q2-results#security  \nLast but not least, see prior State of DevOps Reports."}, {"source": "sources/2022_state_of_devops_report.pdf", "content": "All are listed at https:/ /goo.gle/dora-sodrs:  \n2014 Accelerate State of DevOps Report\n2015 Accelerate State of DevOps Report\n2016 Accelerate State of DevOps Report\n2017 Accelerate State of DevOps Report\n2018 Accelerate State of DevOps Report\n2019 Accelerate State of DevOps Report\n2021 Accelerate State of DevOps Report"}]