[{"source": "sources/todo/state-of-devops-2019.pdf", "content": "2019 \nACCELERATE  \nState of DevOps\nSponsored by"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "ContentS\nEXeCUTIVE SUMMARY  3\n      KEY FINDINGS   5 \n \nWHO TOOK THE SURVEY?\n\n7\n    DEMOGRAPHICS & FIRMoGRAPHICS 8\nHOW DO WE COMPARE?\n\n14\n   HOW To USETHE RESEARCH MODELS 26\nHOW DO WE IMPROVe?\n\n29\n   SDO & Organizational performance 30\n   Productivity  55\nHOw DO WE TRANSFORM: What really works?\n\n69FINAL THOUGHTS 76 \nMETHODOLOGY  77\nACKNOWLEDGEMENTS  79\nAUTHORS 80\nAPPENDIX A:  \nVisual presentation of  \nThe Four Key Metrics                         81 \nAPPENDIX B:  \nStrategies for Scaling DevOps            82 \nTABLE OF CONTENTS"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "3\nAccelerate: State of DevOps 2019    |     Executive Summary  EXECUTIVE SUMMARY\nThe Accelerate State of DevOps Report \nrepresents six years of research and \ndata from over 31,000 professionals  \nworldwide.\n\nIt is the largest and longest-\nrunning research of its kind, providing  \nan independent view into the practices \nand capabilities that drive high \nperformance.\n\nThe results let us understand  \nthe practices that lead to excellence  \nin technology delivery and powerful \nbusiness outcomes.\n\nOur research employs rigorous \nstatistical methods to present \ndata-driven insights about the most \neffective and efficient ways to develop and deliver technology.\n\nCluster analysis \nallows teams to benchmark against the \nindustry, identifying themselves as \nlow, medium, high, or elite performers \nat a glance."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Cluster analysis \nallows teams to benchmark against the \nindustry, identifying themselves as \nlow, medium, high, or elite performers \nat a glance.\n\nTeams can then leverage the findings  \nof our predictive analysis to identify  \nthe specific capabilities they can use  \nto improve their software delivery \nperformance and ultimately become  \nan elite performer.\n\nThis year, we also investigate the ways  \nin which organizations can support \nengineering productivity through"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "4\nAccelerate: State of DevOps 2019    |     Executive Summary  initiatives such as supporting \ninformation search, more usable \ndeployment toolchains, and reducing \ntechnical debt through flexible \narchitecture, code maintainability,  \nand viewable systems.\n\nOur research continues to show that \nthe industry-standard  Four Key Metrics1 \nof software development and delivery \ndrive organizational performance in \ntechnology transformations.\n\nThis year\u2019s \nreport revalidates previous findings \nthat it is possible to optimize for \nstability without sacrificing speed.\n\nWe also the identify the capabilities  \nthat drive improvement in the Four Key \nMetrics, including technical practices,  \ncloud adoption, organizational practices \n(including change approval processes),  \nand culture."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "For organizations seeking guidance on  \nhow to improve, we point to the only real path \nforward: Start with foundations, and then \nadopt a continuous improvement mindset  \nby identifying your unique constraint (or set  \nof constraints).\n\nOnce those constraints no \nlonger hold you back, repeat the process.\n\nWe also provide guidance on the most \neffective strategies for enacting these changes.\n\n1  https://www.thoughtworks.com/radar/techniques/four-key-metrics"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Accelerate: State of DevOps 2019    |     Executive Summary  5\nKEY  \nFINDINGS  \nThe industry continues to improve,  \nparticularly among the elite performers.\n\nThe proportion of our highest performers \nhas almost tripled, now comprising 20% of all \nteams.\n\nThis shows that excellence is possible\u2014\nthose that execute on key capabilities see  \nthe benefits.\n\nDelivering software quickly,  \nreliably, and safely is at the heart  \nof technology transformation and \norganizational performance.\n\nWe see continued evidence that software \nspeed, stability, and availability contribute \nto organizational performance (including \nprofitability, productivity, and customer \nsatisfaction).\n\nOur highest performers are  \ntwice as likely to meet or exceed their \norganizational performance goals.\n\n1\n2"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Accelerate: State of DevOps 2019    |     Executive Summary  6The best strategies for scaling \nDevOps in organizations focus  \non structural solutions that  \nbuild community.\n\nHigh performers favor strategies that \ncreate community structures at both \nlow and high levels in the organization, \nincluding Communities of Practice and \nsupported Proofs of Concept, likely \nmaking them more sustainable and \nresilient to reorgs and product changes.\n\nCloud continues to be a differentiator \nfor elite performers and drives high \nperformance.\n\nThe use of cloud\u2014as defined by \nNIST Special Publication 800-145\u2014\nis predictive of software delivery \nperformance and availability.\n\nThe \nhighest performing teams were 24 \ntimes more likely than low performers \nto execute on all five capabilities of \ncloud computing.Productivity can drive \nimprovements in work/life balance \nand reductions in burnout, and \norganizations can make smart \ninvestments to support it."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "To support productivity, organizations \ncan foster a culture of psychological \nsafety and make smart investments  \nin tooling, information search,  \nand reducing technical debt  \nthrough flexible, extensible, and \nviewable systems.\n\nThere\u2019s a right way to handle the \nchange approval process, and it \nleads to improvements in speed and \nstability and reductions in burnout.\n\nHeavyweight change approval \nprocesses, such as change approval \nboards, negatively impact speed and \nstability.\n\nIn contrast, having a clearly \nunderstood process for changes \ndrives speed and stability, as well  \nas reductions in burnout.3\n45\n6"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "W H O  \nTOOK\nTHE SURVEY?\n\nDORA\u2019s research provides insight into \nsoftware development and DevOps \npractices applied in industry, backed \nby scientific studies spanning six years \nwith over 31,000 survey responses \nfrom working professionals.\n\nThis year, \nalmost 1,000 \u00b2 individuals from a range \nof industries around the world added \ntheir voices to the 2019 Report.\n\nOverall, \nwe see similar representation across \nkey demographic and firmographic \nmeasures when compared to last year, \nother than a noticeable drop in the \nreported percentage of women on teams.\n\n2   With almost 1,000 respondents, our analyses have a 3% margin of error assuming 23 million \nsoftware professionals worldwide and a 95% confidence interval."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "8\nAccelerate: State of DevOps 2019    |     Who Took the Survey?\n\n8\nCompared to last year, we see consistent \nrepresentation of respondents across key \ndemographic categories that include gender, \ndisability, and underrepresented groups.\n\nWhile \nwe see similar gender makeup among our survey \nrespondents overall, the reported percentage of \nwomen on teams fell compared to last year.\n\nWe also saw consistent representation across key \nfirmographic categories including company size, \nindustry, and region.\n\nThe majority of respondents \nwork as engineers or managers within the technology \nindustry.\n\nWe continue to have diverse representation \nacross departments from consultants, coaches, and \nsales/marketing roles.\n\nAdditionally, we continue to \nsee industry representation from highly regulated \norganizations in financial services, government, \nhealthcare, and retail companies.DEMOGRAPHICS  \n& FIRMOGRAPHICS"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "9\nAccelerate: State of DevOps 2019    |     Who Took the Survey?\n\n3   This is similar to proportions reported by the Stack Overflow Developer Survey 2019, which includes 90% men and 10% women.\n\nThey do not include non-binary and \u201cdid not specify.\n\n\u201d https://insights.stackoverflow.com/survey/2019\n4    This is consistent with proportions seen elsewhere in industry; e.g., the Stack Overflow Developer Survey 2019,  \nwhich reports 6% of total respondents identify as having a disability.\n\nhttps://insights.stackoverflow.com/survey/2019DEMOGRAPHICS GENDER \nDISABILITY  Male Non-Binary Female Did not specify\nYes No Did not specify\n10+82+1+7+L83%  \n10%  \n7% \n1% 6+85+9+L85%  \n6% \n9% Gender breakouts from this year\u2019s survey responses remain \nconsistent with 83% male in 2019 (vs. 83% last year), 10% female  \n(vs 12% last year), and <1% non-binary (vs <1% last year).3\nDisability is identified along six dimensions that follow \nguidance from the Washington Group Short Set."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This is the second year we have asked about disability  \nand it has stayed consistent at 6% in 2018 and 2019.4Respondents this year stated that only 16% of teams \ninclude women (median), representing a dip from \n25% reported last year."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "DEMOGRAPHICS \n10\nAccelerate: State of DevOps 2019    |     Who Took the Survey?\n\n*   > 100% due to rounding\n48%  \n3% 9% 16%  20% \n4% \nMore \nthan 160-2 3-5 6-10 11-15 Prefer not \nto respondUNDERREPRESENTED GROUPS \nIdentifying as a member of an underrepresented group  \ncan refer to race, gender, or another characteristic.\n\nThis is  \nthe third year we have captured this data and it has stayed \nrelatively consistent from 13% in 2018 to 14% in 2019.\n\n*\n14+75+11+L76%  \n14%  \n11%  \nYes No Did not specify\nYEARS OF EXPERIENCE\nSimilar to last year, a large portion of respondents have \nmore than 16 years of experience (50% last year), followed \nby 11-15 years of experience (also 20% last year).\n\nOverall demographic breakouts in 2019 remain consistent with \n2018, with slight percentage variances year to year that fall \nwithin the margin of error."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "11\nAccelerate: State of DevOps 2019    |     Who Took the Survey?"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "30%\n       26%\n         16%\n         5%\n        4% \n        4%\n       3%\n      2%\n      2%\n      2%\n    1%\n    1%\n    1%\n    1%Development or Engineering\nDevOps or SRE\nManager\nIT Operations or Infrastructure\nConsultant, Coach, or Trainer\nC-level Executive\nProduct Management\nPrefer Not to Answer\nNA\nOther\nProfessional Services\nQuality Engineering or Assurance\nInformation Security\nRelease Engineering\n                                  38%\n         12%\n  9%\n  9%\n          5%\n          5%\n       4%\n       4%\n       4%\n     3%\n     3%\n     3%\n   1%Technology\nFinancial Services\nRetail/Consumer/e-Commerce\nOther\nHealthcare & Pharmaceuticals\nGovernment\nMedia/Entertainment  \nInsurance\nEducation\nIndustrials & Manufacturing\nTelecommunications\nEnergy\nNon-profitFIRMOGRAPHICSDEPARTMENTS \nParticipants who work in DevOps teams have increased  \nsince we began our study, reporting 16% in 2014, 19%  \nin 2015, 22% in 2016, and holding steady around 27%  \nfor the past three years."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "(Note this is within the margin of error.)\n\nINDUSTRY  \nSimilar to last year, most respondents work within the \ntechnology industry, followed by financial services, retail, \nand other."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "12\nAccelerate: State of DevOps 2019    |     Who Took the Survey?\n\n50%\n2% 4%1%1%29%\n9%\n1%\n1%FIRMOGRAPHICSREGION\nConsistent with last year, North America accounts for \nroughly half of all respondents , followed by EU/ UK \nat 29%.\n\nWe see a drop in responses from Asia, falling  \nfrom 18% last year to 9% this year."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "13\nAccelerate: State of DevOps 2019    |     Who Took the Survey?\n\nEMPLOYEES\nOne out of four respondents work at very large companies \n(10,000+) employees, accounting for 26% of all responses, and \nanother two out of four respondents work at companies ranging \nbetween 20-1,999 employees.\n\nThese distributions are similar \nto the 2018 Report, though there was a drop in responses from \nemployees working in companies with 500-1,999 employees \n(down 12% vs 2018) and more responses from people working \nin company sizes of 100-499 employees (up 7% vs 2018).\n\nOPERATING SYSTEMS\nThe distribution of operating systems  \nwas fairly consistent compared to  \nlast year as well."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "3%\n  1%\n     3%\n                       13%\n                  21%\n             15%\n 8%\n             7%\n               26%\n   2%\n 1-4 \n5-9 \n10-19 \n20-99 \n100-499 \n500-1,999 \n2,000-4,999 \n5,000-9,999 \n10,000+\nI  don\u2019t know/NA FIRMOGRAPHICS 12%  \n            6%          \n                    33%  \n            26%          \n              56% \n           52%          \n         22%  \n            25%          \n                              36%  \n                            43%          \n                              48%  \n                       49%          \n                               5%  \n                      4%          \n                             8% \n                  5%          \n                         4% \n                 4%          \n2% \n2%          \n3% \n3%              13% \n  11%          \n    10%  \n7%          \n                    12%  \n 5%          \n       12%  \n 8%                8% \n4%          Windows 2003/2003R2\nWindows 2008/2008R2\nWindows 2012/2012R2\nOther Windows \nLinux Debian/Ubuntu variants  \nLinux Enterprise variants (RHEL, Oracle, CentOS) \nLinux Fedora\nSUSE Linux Enterprise Server\nLinux OpenSUSE\nLinux Arch\nOther Linux    \nOther UNIX\nFreeBSD/NetBSD/OpenBSD\nAIX\nSolaris\nOS Other \n2018\n2019"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "HOW DO WE  \nCOMPARE?\n\nThis section functions as your DevOps \nbenchmark assessment.\n\nWe use rigorous \nstatistical methods to examine how teams \nare developing, delivering, and operating \nsoftware systems.\n\nBenchmarks for elite, \nhigh, medium, and low performers show \nwhere you are in the context of multiple \nimportant analyses throughout the report.\n\nWe also identify trends year over year."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "15\nAccelerate: State of DevOps 2019    |     How Do We Compare?15\nOrganizations increasingly rely on their ability to deliver \nand operate software systems to achieve their goals.\n\nTo compare performance on this key outcome metric, \nthe industry needs a way to measure the effectiveness \nof their development and delivery practices.\n\nOver the \nlast six years we have developed and validated four \nmetrics that provide a high-level systems view of \nsoftware delivery and performance and predict an \norganization\u2019s ability to achieve its goals.\n\nLast year,  \nwe added an additional metric focused on operational \ncapabilities, and found that this measure helps \norganizations deliver superior outcomes.\n\nWe call  \nthese five measures software delivery and \noperational (SDO) performance, which focus  \non system-level outcomes."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "We call  \nthese five measures software delivery and \noperational (SDO) performance, which focus  \non system-level outcomes.\n\nThis helps avoid the \ncommon pitfalls of software metrics, which often pit \ndifferent functions against each other and result in \nlocal optimizations at the cost of overall outcomes.SOFTWARE \nDELIVERY AND  \nOPERATIONAL \nPERFORMANCE"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "16\nAccelerate: State of DevOps 2019    |     How Do We Compare?SOFTWARE DEVELOPMENT SOFTWARE DEPLOYMENT SERVICE OPERATION\nLead Time Change Fail Availability\nDeployment Frequency Time to Restore\nFOUR KEY METRICSThe first four metrics that capture the \neffectiveness of the development and  \ndelivery process can be summarized in terms \nof throughput and stability.\n\nWe measure the \nthroughput of the software delivery process \nusing lead time of code changes from check-in to release along with deployment frequency.\n\nStability is measured using time to restore\u2014\nthe time it takes from detecting a user-\nimpacting incident to having it remediated\u2014\nand change fail rate, a measure of the quality \nof the release process.\n\nPERFORMANCE METRICS"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "17\nAccelerate: State of DevOps 2019    |     How Do We Compare?5   Availability is not included in our cluster analysis because availability measures do not apply the same way for software solutions that are not provided \nin the form of services, such as packaged software or firmware.\n\n6   Teams can define their availability goals using Service Level Agreements (SLAs) and Service Level Objectives (SLOs) and measure their performance using \nService Level Indicators (SLIs).\n\nFor more information on developing SLAs, SLOs, and SLIs, you can check out Site Reliability Engineering: How Google \nRuns Production Systems (2016) by Beyer et al.\n\nMany professionals approach these metrics as \nrepresenting a set of trade-offs, believing that \nincreasing throughput will negatively impact \nthe reliability of the software delivery process \nand the availability of services.\n\nFor six years in \na row, however, our research has consistently \nshown that speed and stability are outcomes \nthat enable each other."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "For six years in \na row, however, our research has consistently \nshown that speed and stability are outcomes \nthat enable each other.\n\nCluster analysis of the \nfour software delivery measures in the 2019 \ndata reveals four distinct performance profiles, \nwith statistically significant differences in \nthroughput and stability measures among \nthem.5 As in previous years, our highest \nperformers do significantly better on all four \nmeasures, and low performers do significantly \nworse in all areas.\n\nIn addition to speed and stability, availability \nis important for operational performance.\n\nAt a high level, availability represents an  \nability for technology teams and organizations \nto keep promises and assertions about \nthe software they are operating."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "At a high level, availability represents an  \nability for technology teams and organizations \nto keep promises and assertions about \nthe software they are operating.\n\nNotably, \navailability is about ensuring a product or \nservice is available to and can be accessed  \nby your end users.6\nAvailability reflects how well teams define \ntheir availability targets, track their current \navailability, and learn from any outages, \nmaking sure their feedback loops are \ncomplete.\n\nThe items used to measure \navailability form a valid and reliable \nmeasurement construct."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "18\nAccelerate: State of DevOps 2019    |     How Do We Compare?Aspect of Software Delivery Performance* Elite High Medium Low\nDeployment frequency\nFor the primary application or service you work on, how  \noften does your organization deploy code to production  \nor release it to end users?"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "On-demand  \n(multiple  \ndeploys per day) \nBetween once \nper day and \nonce per week \nBetween once  \nper week and  \nonce per month \nBetween once \nper month and \nonce every six \nmonths\nLead time for changes\nFor the primary application or service you work on, what is your  \nlead time for changes (i.e., how long does it take to go from code  \ncommitted to code successfully running in production)?Less than  \none dayBetween one \nday and  \none weekBetween one \nweek and  \none monthBetween one \nmonth and  \nsix months\nTime to restore service\nFor the primary application or service you work on, how long  \ndoes it generally take to restore service when a service incident  \nor a defect that impacts users occurs (e.g., unplanned outage or  \nservice impairment)?Less than  \none hour \nLess than  \none daya \nLess than  \none dayaBetween one \nweek and  \none month\nChange failure rate\nFor the primary application or service you work on, what percentage \nof changes to production or released to users result in degraded \nservice (e.g., lead to service impairment or service outage) and \nsubsequently require remediation (e.g., require a hotfix, rollback,  \nfix forward, patch)?0-15%b,c \n0-15%b,d \n0-15%c,d \n46-60%\nMedians reported because distributions are not normal."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "All differences are significantly different based on Tukey\u2019s post hoc analysis except where otherwise noted.\n\na,b,c  Means are significantly different based on Tukey\u2019s post hoc analysis; medians do not exhibit differences because of underlying distributions.\n\nd Means are not significantly different based on Tukey\u2019s post hoc analysis.\n\n*For a visual presentation of the Four Metrics, please see Appendix A."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "19\nAccelerate: State of DevOps 2019    |     How Do We Compare?7    It should also be noted that none of these practices apply solely to the cloud.We also confirmed last year\u2019s finding that better \nsoftware delivery goes hand-in-hand with higher \navailability.\n\nAnalysis shows that availability \nmeasures are significantly correlated with software \ndelivery performance profiles, and elite and high \nperformers consistently reported superior \navailability, with elite performers being 1.7 times \nmore likely to have strong availability practices.7\nIndustry velocity is increasing\nMany analysts are reporting the industry has \n\u201ccrossed the chasm\u201d with regards to DevOps and \ntechnology transformation, and our analysis this \nyear confirms these observations.\n\nIndustry velocity \nis increasing and speed and stability are both \npossible, with shifts to cloud technologies fueling \nthis acceleration."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Industry velocity \nis increasing and speed and stability are both \npossible, with shifts to cloud technologies fueling \nthis acceleration.\n\nThis reaffirms the importance  \nof technology that enables organization to deliver \nvalue to their stakeholders.We ran additional analyses (e.g., using control variables)  \nto see if industry and organization size had a significant \neffect on SDO performance.\n\nWe found no evidence that \nindustry has an impact with the exception of retail, \nsuggesting that organizations of all types and sizes, \nincluding highly regulated industries such as financial \nservices and government, can achieve high levels of \nperformance.\n\nOur results for the retail industry suggest  \nthat those in retail see some benefits in speed and stability.\n\nWe found evidence that enterprise organizations  \n(those with more than 5,000 employees) are lower \nperformers when compared to those with fewer than  \n5,000 employees."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "We found evidence that enterprise organizations  \n(those with more than 5,000 employees) are lower \nperformers when compared to those with fewer than  \n5,000 employees.\n\nThis is likely due to several factors  \nseen in large organizations, most notably heavyweight \nprocess and controls as well as tightly coupled \narchitectures that introduce delay and associated \ninstability.\n\nWe urge enterprises not to take these  \nfindings as an excuse to  suffer poor performance,  \nbut recognize that excellence is possible, embark on a \nprogram of continuous improvement, and look to other \nenterprise organizations that have achieved elite \nperformance for inspiration and guidance.\n\nINDUSTRY AND  \nORGANIZATION IMPACTS  \nON SDO PERFORMANCE"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "20\nAccelerate: State of DevOps 2019    |     How Do We Compare?We compared the proportions of each \nperformance cluster in 2018 and 2019:\n2018 2019*\nELITE7%\n48%\n23%\n37%\n44%\n15%\n12%HIGH PERFORMERS\nHIGH PERFORMERS\nMEDIUM PERFORMERS\nMEDIUM PERFORMERS\nLOW PERFORMERS\nLOW  \nPERFORMERSPERFORMANCE CLUSTERS\nWe identified elite performers in last year\u2019s report \nfor the first time, but this group was a subset of \nour high performers.\n\nThis year, we see four distinct \ngroups in our analysis.\n\nWe use the same name \nbecause the elite performers exhibit the same \nspeed and stability characteristics this year as last \nyear, showing that these two groups are similar.\n\n20%\nELITE  \nPERFORMERS\n*   < 100% due to roundingThis comparison shows us that: \n\u2022  The proportion of our elite performers has almost tripled, \nshowing that excellence is possible\u2014it just requires execution.\n\n\u2022  The proportion of low performers is down."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "\u2022  The proportion of low performers is down.\n\nThis reflects  \na continued shift in the industry, as organizations continue  \nto transform their technology.\n\n\u2022  The proportion of medium performers is up.\n\nSome are likely \nimproved low performers, while others may be high performers \nwho dropped as they struggled with increased complexity."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "21\nAccelerate: State of DevOps 2019    |     How Do We Compare?ELITE PERFORMERS\nComparing the elite group against the low \nperformers, we find that elite performers have\u2026\nfrequent code deployments208\nTIMES MORE  \n time to recover from incidents2,604\nTIMES FASTER  lead time from  \ncommit to deploy106\nTIMES FASTER  \nchange failure rate  \n(changes are  1/7  as likely to fail)7\nTIMES  LOWER   \nThroughput Stability"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "22\nAccelerate: State of DevOps 2019    |     How Do We Compare?8   In 2017: https://www.informationweek.com/devops/capital-one-devops-at-its-core/d/d-id/1330515THROUGHPUT\nDeployment frequency\nThe elite group reported that it routinely deploys on-demand and \nperforms multiple deployments per day, consistent with the last \nseveral years.\n\nBy comparison, low performers reported deploying \nbetween once per month (12 per year) and once per six months  \n(two per year), which is a decrease in performance from last year.\n\nThe normalized annual deployment numbers range from 1,460 \ndeploys per year (calculated as four deploys per day x 365 days) for \nthe highest performers to seven deploys per year for low performers \n(average of 12 deploys and two deploys).\n\nExtending this analysis \nshows that elite performers deploy code 208 times more frequently \nthan low performers."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Extending this analysis \nshows that elite performers deploy code 208 times more frequently \nthan low performers.\n\nIt's worth noting that four deploys per day  \nis a conservative estimate when comparing against companies  \nsuch as CapitalOne that report deploying up to 50 times per day  \nfor a product,8 or companies such as Amazon, Google, and Netflix \nthat deploy thousands of times per day (aggregated over the \nhundreds of services that comprise their production environments)."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "23\nAccelerate: State of DevOps 2019    |     How Do We Compare?\n\nChange lead time\nSimilarly, elite performers report change \nlead times of less than one day, with change \nlead time measured as the time from code \ncommitted to having that code successfully \ndeployed in production.\n\nThis is a small \ndecrease in performance from last year, when \nour highest performers reported change lead \ntimes of less than one hour.\n\nIn contrast to our \nelite performers, low performers required lead \ntimes between one month and six months.\n\nWith lead times of 24 hours for elite performers \n(a conservative estimate at the high end of \n\u201cless than one day\u201d) and 2,555 hours for low \nperformers (the mean of 730 hours per month \nand 4,380 hours over six months), the elite \ngroup has 106 times faster change lead times \nthan low performers."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "24\nAccelerate: State of DevOps 2019    |     How Do We Compare?STABILITY\nTime to restore service\nThe elite group reported time to restore service of less than one hour,  \nwhile low performers reported between one week and one month.\n\nFor this calculation, we chose conservative time ranges: one hour for high \nperformers and the mean of one week (168 hours) and one month (5,040 \nhours) for low performers.\n\nBased on these numbers, elites have 2,604 times \nfaster time to restore service than low performers.\n\nAs previously noted, \ntime to restore service performance stayed the same for both elite and  \nlow performers when compared to the previous year.\n\nChange failure rate\nElite performers reported a change failure rate between zero and 15%, \nwhile low performers reported change failure rates of 46% to 60%.\n\nThe mean between these two ranges shows a 7.5% change failure rate  \nfor elite performers and 53% for low performers."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "The mean between these two ranges shows a 7.5% change failure rate  \nfor elite performers and 53% for low performers.\n\nThis represents change \nfailure rates for elite performers that are seven times better than low \nperformers.\n\nAs noted earlier, change failure rates stayed the same  \nfor both elite and low performers when compared to the previous year."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "25\nAccelerate: State of DevOps 2019    |     How Do We Compare?SOFTWARE DELIVERY  \nPERFORMANCE All of the measures shown are relative; that \nis, they compare the highest and the lowest \nperformers each year.\n\nFrom 2018 to 2019, the \ngap for all performance metrics between \nthe lowest and highest performers increased \nor stayed the same, with the exception of lead \ntime for changes.\n\nThe increased gap in deploy \nfrequency indicates a decrease in performance \namong low performers, which may be due \nto growing complexity in environments and \ntherefore difficulty in delivering software.\n\nThe reduced ratio of the lowest to the highest \nperformers in lead time represents a reduction \nin the performance of the highest performing \ngroup, which is seeing lead times increase  \nfrom less than an hour to between an hour  \nand a day."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This may reflect the trend in more \nheavyweight code review and approval \nprocesses that have become popular  \nin recent years.2019\n208x\nMore Frequent\nDeploy Frequency 2604x\nFaster Time to \nRestore Service106x\nFaster  \nLead TIme 7x  \nLower Change  \nFail Rate \n2018\n46x\nMore Frequent\nDeploy Frequency 2604x\nFaster Time to \nRestore Service  2555x\nFaster   \nLead TIme7x  \nLower Change  \nFail Rate  Comparing highest to lowest performers."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "26\nAccelerate: State of DevOps 2019    |     How to Use the Research Models\nHOW TO  \nUSE THE  \nRESEARCH MODELS  \nThis year\u2019s Report is designed to help drive \nimprovement in both performance and \nproductivity using two research models.\n\nYou  \nmay wonder, why are there two research models?\n\nHow are they different?\n\nHow are they similar?\n\nAnd most importantly, how can I use them to  \nhelp me make decisions and guide my own work?\n\nStart by identifying your goal...\nPRODUCTIVITYSDO & ORGANIZATIONAL \nPERFORMANCE\nCUL TURE OF PSYCHOLOGICAL SAFETY\nCLOUD INTERNAL SEARCH\nEXTERNAL SEARCH\nDISASTER RECOVERY TESTING TECHNICAL DEBTCHANGE MANAGEMENT USEFUL, EASY-TO-USE TOOLS\nTECHNICAL PRACTICESSTART"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "27\nAccelerate: State of DevOps 2019    |     How to Use the Research Models\nIf you want to improve SDO performance or organizational \nperformance, look at the model with those constructs,  \nand head to that section of the report for guidance on which \ncapabilities you should focus on.\n\nIf you want to improve productivity, look at the model with \nproductivity as a construct, and head to that section of the \nreport for guidance on which capabilities you should focus on.\n\nHow to use the models  \nto guide your transformation\n\u2022 Identify the capabilities that will improve your goal (that \nis, those with arrows that point to the construct you want \nto improve).\n\nAs we\u2019ve identified in this report, these are \nyour candidate capabilities for improvement.\n\n(For SDO \nand organizational performance, we have also identified \nadditional capabilities in our previous five years of research."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "(For SDO \nand organizational performance, we have also identified \nadditional capabilities in our previous five years of research.\n\n)9\n\u2022 Remember to accelerate your transformation by starting \nwith a solid foundation and then focusing on the \ncapabilities that are constraints: What capabilities cause \nthe biggest delays?\n\nWhat are the biggest headaches?\n\nWhere are the biggest problems?\n\nPick three to five and \ndedicate resources to solving these first.\n\nDon\u2019t worry \nif you still have problems; by focusing on the biggest \nproblems now, you remove bottlenecks, discover \nsynergies, and avoid unnecessary work.\n\n\u2022 There are other important outcomes from this work.\n\nBenefits from pursuing improvements in SDO and \norganizational performance include reducing burnout  \nand deployment pain (which we researched in  \n2016 and 2017), and improving security outcomes  \n(which we researched in 2017 and 2018), and culture \n(researched in years 2014 through 2019)."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Additional \nbenefits from improving productivity include improving \nwork/life balance and reducing burnout.\n\nHow to read the research models \nWe use a structural equation model (SEM), which is a predictive \nmodel used to test relationships.\n\nEach box represents  \na construct we measured in our research, and each arrow \nrepresents relationships between the constructs.\n\nA larger  \nbox that contains boxes (constructs) is a second-order  \nconstruct.\n\nA light blue box with a dotted line to another construct \nindicates a control variable.\n\n(See pages 31 and 57 for full models.)\n\nConstructs in bold represent those that we investigate for the \nfirst time this year.\n\nConstructs with a dark bold outline are \ncommon team and organizational goals: SDO performance  \nand organizational performance or productivity.\n\nKeep these  \nin mind as you identify your goals and read the models.\n\n9  You can find all of our State of DevOps Reports at cloud.google.com/devops"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "28\nAccelerate: State of DevOps 2019    |     How to Use the Research Models\nTo interpret the models, all lines with arrows can be read \nusing the words \u201cpredicts, \u201d \u201caffects, \u201d \u201cdrives, \u201d or \u201cimpacts.\n\n\u201d \nFor example, the second-order construct SDO performance is \ncomprised of the constructs software delivery performance \nand availability, and these together drive organizational \nperformance.\n\nThe construct disaster recovery testing drives \navailability.\n\nWe indicate that disaster recovery testing is a  \nnewly investigated construct this year by marking it in bold.\n\nAn arrowed line with a (-) next to it indicates a negative impact \nbetween two constructs; for example, technical debt negatively \nimpacts (or reduces) productivity.\n\nYou may notice there\u2019s some overlap  \nin the two research models.\n\nThis is because the goals\u2014SDO performance and productivity\u2014\nare related in many ways."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "You may notice there\u2019s some overlap  \nin the two research models.\n\nThis is because the goals\u2014SDO performance and productivity\u2014\nare related in many ways.\n\nThe outcomes are about making  \nand delivering technology in superior ways, and in ways  \nthat deliver value to organizations and to individuals.\n\nIt makes sense that some of the things we do to support  \nthe work of software delivery will also benefit the productivity  \nof those who develop and deliver software.\n\nYet while they  \nare similar, they still measure different outcomes and so we \nconduct our analysis separately.\n\nThus, they are in two different \nresearch models.\n\nWhat the overlap in the two research \nmodels tells us\n\u2022 Making smart investments in the pursuit of SDO \nperformance can reduce burnout, and better productivity \ncan lead to reductions in burnout as well.\n\nThis should  \nbe encouraging to organizations and technologists  \nalike, as the demands of work continue to grow."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This should  \nbe encouraging to organizations and technologists  \nalike, as the demands of work continue to grow.\n\nWe note that having a good work/life balance is  \nkey to reducing burnout.\n\n\u2022 A culture of psychological safety contributes to  \nSDO performance, organizational performance,  \nand productivity, showing that growing and fostering  \na healthy culture reaps benefits for organizations  \nand individuals.\n\n\u2022 Investments in code maintainability, loosely coupled \narchitecture, and monitoring help support SDO \nperformance (via continuous delivery) and productivity \n(via reductions in technical debt), highlighting the \nimportance of good tooling and systems."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "HOW DO WE  \nIMPROVE SDO &  \nORGANIZATIONAL  \nPERFORMANCE?\n\nA key goal in digital transformation is \noptimizing software delivery performance: \nleveraging technology to deliver value  \nto customers and stakeholders.\n\nOur \nresearch provides evidence-based \nguidance so you can focus on the \ncapabilities and practices that matter  \nto accelerate your transformation.\n\nThis \nyear, we also outline implementation \nstrategies so you can set your path \nforward for maximum impact."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "30\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?30\nBegin by focusing on the capabilities outlined in our \nresearch; they provide predictive guidelines to improve \nyour technology delivery and deliver value.\n\nStart with \nfoundations: Basic automation (such as version control \nand automated testing), monitoring, clear change \napproval processes, and a healthy culture.\n\nThen \nidentify your constraints to plan your path forward.\n\nThis strategy works for those just beginning \ntransformations as well as those who have been \noptimizing for years.\n\nFocus resources on what is \ncurrently holding you back, then iterate: Identify \nconstraints and choose the next target.\n\nUse the model on page 31 to locate the goal you  \nwant to improve and identify the capabilities that \nimpact it.\n\nFor example, if your goal is to improve \nsoftware delivery performance, these capabilities  \nare culture, clear change process, continuous  \ndelivery, and cloud."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "For example, if your goal is to improve \nsoftware delivery performance, these capabilities  \nare culture, clear change process, continuous  \ndelivery, and cloud.\n\nThen focus on those that  \nare your biggest constraints.IMPROVING  \nSDO AND  \nORGANIZATIONAL  \nPERFORMANCE"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "31\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?SOFTWARE DELIVERY & OPERATIONAL PERFORMANCE\nSDO P erformance\nOrganizational  \nperformanceIndustry (control)\nEnterprise (control)CUL TURE OF PSYCHOLOGICAL SAFETY\nBurnoutConstruct\nControl variableSecond-order construct\n  Common goal  \nfor team or organization\nPredictive relationship\nMixed results\nNegative predictive relationshipContinuous  \ndeliveryLoosely coupled architecture\nMonitoring  \nDeployment automationHEAVYWEIGHT CHANGE PROCESS\nCODE MAINTAINABILITY\nTrunk-based developmentCLEAR CHANGE PROCESS\nContinuous  \nintegrationAutomated\ntestingCloud-\nDISASTER RECOVERY TESTING\n--\n-AvailabilitySoftware  \ndelivery  \nperformance\nBOLD   Newly investigated this year"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "EXCEL OR DIE\n\u2022 Retailers often have some of the slimmest \nmargins, requiring efficiency and automation  \nto scale and respond to changes quickly.\n\n\u2022 Retailers must be able to cope with huge swings \nin demand or risk going out of business\u2014Black \nFriday can make or break a retailer\u2019s entire year.\n\nBy leveraging the cloud, retailers can burst \ncapacity easily and they aren\u2019t stuck having \ndiscussions about \u201cif\u201d or \u201cwhen\u201d they should use \nthe cloud.\n\nThey\u2019re already there.\n\n\u2022 Retailers have figured out how to be nimble in \nhighly regulated environments because they \nhave to.\n\nWhile other industries had the luxury \nof blaming regulation for delayed adoption, the \ncompetitive environment forced retailers to figure \nout how to operate in regulated environments \nquickly and securely.\n\nAnd they\u2019re doing it.\n\nAfter \nall, you can\u2019t sell goods without processing the \noccasional credit card transaction."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "And they\u2019re doing it.\n\nAfter \nall, you can\u2019t sell goods without processing the \noccasional credit card transaction.\n\nOur analysis found no evidence that industry made an \nimpact in the speed and stability of software delivery, except \nfor retail, which saw significantly better SDO performance.\n\nWhen we consider the crushing competitive environment of \nthe retail industry\u2014termed the retail apocalypse following a \ndecade of steady closures\u2014this should come as no surprise.\n\nThose who excel at delivering profitability, productivity, and \ncustomer satisfaction survive.\n\nAnything less than excellence \nleads to failure.\n\nWhile retailers may be at the forefront of \nthis highly competitive shift, we see other industries such as \nfinancial services following quickly behind."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Anything less than excellence \nleads to failure.\n\nWhile retailers may be at the forefront of \nthis highly competitive shift, we see other industries such as \nfinancial services following quickly behind.\n\nKeeping up with the rate of technological change is essential \nfor organizations in these competitive environments who \nmust keep demanding customers happy and satisfied while \ndelivering consistent revenues to keep stakeholders satisfied.\n\nRetail may be the perfect example of technology delivering \nvalue, and those in other industries should learn from their \nexperience: \n\u2022 Retailers were among the first to embrace A/B testing to \nunderstand customers\u2019 buying habits, preferences, and \ninteractions in websites and apps so they could optimize \npurchases.\n\nThis technical ability requires more robust \ntechnical solutions and provides a powerful feedback \nloop to product development and marketing."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "33\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?CLOUD\nWith the evolving nature of business, more and \nmore organizations are choosing multi-cloud \nand hybrid cloud solutions.\n\nThis is because these \nsolutions offer flexibility, control, and availability \nin addition to performance gains.10 In our survey, \nrespondents indicated increased use of multi-\ncloud and hybrid cloud compared to last year.\n\nWe also asked respondents to indicate where \ntheir primary application work was hosted, \nand again saw responses that indicate there is \nno clear consensus on what it means to work \nin a hybrid or multi-cloud environment.\n\nAs we \nstated in last year\u2019s report, hybrid is often self-\ndefined.\n\nIf respondents say they are working in \na hybrid environment, then they are.\n\nThis often \ncreates frustration (and widely varying reports \n10    Transform Your Business with a Hybrid and Multicloud Strategy , Tilak, March 2019."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This often \ncreates frustration (and widely varying reports \n10    Transform Your Business with a Hybrid and Multicloud Strategy , Tilak, March 2019.\n\nHOSTING FOR PRIMARY SERVICE \nOR APPLICATIONamong industry analysts) when experts try to \ndiscuss terms and the state of the industry:  \nWe can\u2019t compare things that we can\u2019t define \nand measure.\n\n44%  \n27%  \n23%  \n5% 50% \n3% \nPrivate Other Public No Cloud Hybrid Personal \nServer"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "34\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?HOW YOU IMPLEMENT  \nCLOUD INFRASTRUCTURE MATTERS\nIf everyone has a different understanding of what it means to be  \n\u201cin the cloud,\u201d how can we actually measure its benefits?\n\nWe address  \nthis limitation by focusing on the essential characteristics of cloud \ncomputing*\u2014as defined by the National Institute of Standards and \nTechnology (NIST)\u2014and use that as our guide.\n\nIn our survey, 80% of respondents11  said the primary application or \nservice they supported was hosted on some kind of cloud platform.\n\nUsing the NIST framework, we investigated the impact of essential \npractices on SDO performance and, for the second year in a row, \nfound that what really matters is how teams implement their cloud \nservices, not just that they are using a cloud technology.\n\n* Terms in bold throughout this report match constructs that can be found in the research models on page 31 and 57."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "* Terms in bold throughout this report match constructs that can be found in the research models on page 31 and 57.\n\n11   Refer to the previous chart that shows where respondents\u2019 primary service or application is hosted.\n\nNote that more than one option could be selected, so 80% of respondents selected an option that included the cloud."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "35 AGREED OR STRONGL Y AGREED%Elite performers were 24 times more likely to \nhave met all essential cloud characteristics \nthan low performers.12 This may explain why \nteams and executives who claim to have \nadopted cloud computing technologies also \nfeel frustration at not reaping the promised \nbenefits of speed and stability: Many of our \nsurvey respondents who claim to be using \ncloud computing haven\u2019t actually adopted  \nthe essential patterns that matter.\n\nOnly 29%  \nof respondents who said they were using cloud \ninfrastructure agreed or strongly agreed that \nthey met all five of the characteristics of \nessential cloud computing defined by NIST .On-demand self-service  \n+11% from 2018\nConsumers can automatically provision computing resources  \nas needed, without human interaction from the provider.\n\nBroad network access  \n+14% from 2018\nCapabilities can be accessed through heterogeneous platforms  \nsuch as mobile phones, tablets, laptops, and workstations."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Broad network access  \n+14% from 2018\nCapabilities can be accessed through heterogeneous platforms  \nsuch as mobile phones, tablets, laptops, and workstations.\n\nResource pooling  \n+15% from 2018\nProvider resources are pooled in a multi-tenant model, with physical \nand virtual resources dynamically assigned on-demand.\n\nThe customer \nmay specify location at a higher level of abstraction such as country, \nstate, or datacenter.\n\nRapid elasticity  \n+13% from 2018\nCapabilities can be elastically provisioned and released to rapidly scale \noutward or inward on demand, appearing to be unlimited and able to \nbe appropriated in any quantity at any time.\n\nMeasured service  \n+14% from 2018\nCloud systems automatically control, optimize, and report resource use \nbased on the type of service such as storage, processing, bandwidth, \nand active user accounts."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "FIVE ESSENTIAL  \nCHARACTERISTICS  \nOF CLOUD COMPUTING\n12   This is consistent with last year\u2019s findings, that elite performers were 23 times more likely than low \nperformers to agree or strongly agree with all essential cloud characteristics.\n\n11+46+43+L\n14+46+40+L\n15+43+42+L\n13+45+42+L\n14+48+18+L57% \n58% \n58% \n62% 60%"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "36\nSCALING \nTHE CLOUD\n Last year we found that elite performing teams \nwere more likely to be executing on all five \nessential cloud characteristics, and those \nfindings were revalidated this year.\n\nThese \ncharacteristics matter when defining what it \nmeans to adopt cloud computing because they \nenable an actionable strategy for success: Our \nresearch shows they impact SDO performance.\n\nBy focusing on execution in the cloud\u2014whether \npublic, private, or hybrid\u2014any team or \norganization is capable of reaping the benefits \nof speed, stability, and availability.\n\nA clear win from using the cloud is on-demand scaling.\n\nTeams  \nthat take advantage of dynamic scaling are able to make the \ninfrastructure behind their service elastically react to demand from \nusers.\n\nTeams can monitor their services and automatically scale \ntheir infrastructure as needed.\n\nThe abstractions used in the cloud have changed the ways we think \nabout and visualize our infrastructure."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Teams can monitor their services and automatically scale \ntheir infrastructure as needed.\n\nThe abstractions used in the cloud have changed the ways we think \nabout and visualize our infrastructure.\n\nFor someone using a \ncontainer orchestrator such as Kubernetes or Mesos, the package \nbeing shipped is a container image plus the config for deployment.\n\nTypical platform-as-service (PaaS) offerings are leaning more \ntowards a deployment model centered around container images as \nthe packaging method and container runtimes for execution.\n\nWe see \nthis in products such as Heroku, Google App Engine, Azure Container \nInstances, Cloud Foundry, and Amazon\u2019s Fargate.\n\nServerless (also \nknown as function-as-a-service, or FaaS)13 has taken this one step \nfurther, simplifying deployment and allowing consumers to only \nworry about the execution of the application code itself and \nabstracting scaling, capacity planning, and maintenance away  \nfrom developers and operators."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Examples include AWS Lambda, \nAzure Functions, GCP Cloud Functions, and Zeit.\n\nOver time, the abstractions used in the cloud have become universal \nstandards for deployment across cloud and platform providers.\n\nNetwork, virtual machines, identity and access management (IAM), \nstorage, and databases have all become the de-facto products  \nof every cloud service provider, in addition to machine learning, \nInternet of Things (IoT), container solutions, language runtime \nsolutions, and security products.\n\nWe continue to see the state  \nof products converge on the paradigms around containers,  \nruntime languages, and application packages.\n\n13  The term serverless is also used to describe \u201crich-client\u201d applications.\n\nHere, we limit our description to function-as-a-service.\n\nPlease see this post  \nby Mike Roberts for more information:  \nhttps://martinfowler.com/articles/serverless.html#WhatIsServerless"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "37\nCLOUD COST\nThe cloud is also changing how we think about \ncosts for our infrastructure and deployments.\n\nNo longer is the unit of measurement an entire \ndatacenter or even a full rack of servers.\n\nCustomers of cloud providers can focus on \npaying only for what they use while having the \nagility to scale when necessary.\n\nIn addition to positively impacting SDO \nperformance, adopting cloud best practices \nimproves organizations\u2019 visibility into the cost \nof running their technologies.\n\nRespondents \nwho meet all essential cloud characteristics are \n2.6 times more likely to be able to accurately \nestimate the cost to operate software.\n\nThey are \nalso twice as likely to be able to easily identify \ntheir most operationally expensive \napplications, and 1.65 times as likely  \nto stay under their software operation budget.\n\nWhy can teams on the cloud better estimate and manage their costs?"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Why can teams on the cloud better estimate and manage their costs?\n\nIt \nis likely because the cloud provides better visibility into infrastructure \nusage and spend to developers and IT operations professionals.\n\nThis \nincreased visibility and awareness make it possible to change the way \nwe architect and build our systems while also aligning incentives.\n\nWhile this variability can be initially confusing and overwhelming for \nthose unused to this new financial model, teams can reap the benefits \nof efficient design by only paying for the compute resources they use.\n\nIn contrast, the data center in traditional environments is often a \n\u201cblack box, \u201d where information about processing and cycle cost is \ndifficult or impossible to get.\n\nAdditionally, the nature of capital \nexpenses means that once infrastructure is purchased, there are no \nbenefits for being aggressively efficient with design."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Additionally, the nature of capital \nexpenses means that once infrastructure is purchased, there are no \nbenefits for being aggressively efficient with design.\n\nIn this regard, the \ncapital expenses are a fixed cost\u2014predictable and understood up-front, \nbut rarely visible to the engineering team and impossible to avoid even \nif more efficient designs are deployed.\n\nSome in finance may say that the cloud has not led to cost savings  \nin the short-run, yet we know that it provides greater information \ntransparency.\n\nHow can this be?\n\nWhile the cloud provides transparent \ninformation about costs to the system owners, users do not pay for \nthese costs unless there is a chargeback model or similar mechanism.\n\nThis can lead to wildly variable costs that go unchecked, making cloud \ncosts unpredictable.\n\nIn these scenarios, teams that pay for infrastructure \nmay prefer data centers because they are predictable, even though \ntheir visibility disincentivizes system users to build more efficient \nsystems."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "We suggest organizations better align incentives so that \nsystem owners have both visibility to build more efficient systems, and \nthe incentives to do so, by using chargeback or similar mechanisms.\n\nWhile some workloads are better suited to on-prem environments (such \nas those that are steady or predictable), there are other benefits to using \ncloud infrastructure, such as the ability to leverage infrastructure-as-code.BLACK BOX  \nVS. TRANSPARENCY"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "38\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?TECHNICAL PRACTICES \nExecuting for maximum effect\nMany organizations wanting to adopt DevOps look for a set of prescriptive \nsteps or best practices to guide their journey.\n\nHowever, every organization \nis different and which practices to adopt depends on the current state  \nof the organization\u2014including the state of its technology, culture, and \nprocesses\u2014and its short- and long-term goals.\n\nThe solution is to take a holistic approach, where you first work to \nunderstand the constraints in your current software delivery process  \nwith an eye to your short- and long-term outcomes in measurable terms."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Then empower teams to decide how best to accomplish those outcomes\u2014\nafter all, they are the experts in their work and context.14 Those who adopt \nthis approach see more scalable and flexible solutions, and by not having \nto micromanage detailed execution plans, management can focus on \nhigh-level outcomes, allowing their organizations to grow.\n\nBy focusing on \ndesigning and executing short-term outcomes that support the long-term \nstrategy, teams are able to adjust to emergent and unanticipated \n14   This approach derives from the work of Mike Rother based on his study of Toyota, which is described in detail at  \nhttp://www-personal.umich.edu/~mrother/Homepage.html."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "39\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?problems, outperforming their peers whose three- \nand five-year plans cannot be flexible and nimble \nenough to keep up with changes in customer \ndemands, the technology landscape, or emergent \nsecurity threats.15\nWhile there is no \u201cone size fits all\u201d approach to \nimprovement, we have observed some themes  \nin our work helping organizations adopt DevOps.\n\nThese themes are particularly relevant for companies \nlooking to accelerate their transformation in the \nface of seemingly difficult and complex constraints.\n\nConcurrent efforts at team  \nand organization levels \nSome capabilities are typically developed  \nat the team level, while others\u2014particularly  \nin large organizations or organizations with \nstrong hierarchical structures\u2014often require \norganization-level efforts.\n\nThese two streams\u2014team-level and organization-level\u2014can and \nshould proceed concurrently, as they often \nsupport each other."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "These two streams\u2014team-level and organization-level\u2014can and \nshould proceed concurrently, as they often \nsupport each other.\n\n15   Providing teams with the capacity and resources on an ongoing basis is essential to the success of this approach."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "15   Providing teams with the capacity and resources on an ongoing basis is essential to the success of this approach.\n\n16  For an exhaustive list of capabilities that drive improvements in SDO performance, we point the reader to Appendix A  in Accelerate: The Science of Lean Software and DevOps (which summarizes the 2014 - 2017 State of DevOps \nReports), the 2018 Accelerate State of DevOps Report, and this Report.CAPABILITIES RESEARCHED IN 201916\nOrganization level\u2022 Loosely coupled architecture\n\u2022 Clear change process\n\u2022 Code maintainability \nTeam level\u2022 Continuous integration\n\u2022 Automated testing\n\u2022 Deployment automation\n\u2022 Monitoring\n\u2022 Trunk-based development\nBoth team and  \norganizational level\u2022 Use of cloud services\n\u2022 Disaster recovery testing\nFor example, creating a continuous integration \nplatform that makes it easy for teams to get  \nfast feedback on their automated tests can be  \na significant force-multiplier when used across \nseveral teams in an organization."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "40\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?Similarly, deployment automation at the team \nlevel will have little impact if the team\u2019s code  \ncan only be deployed together with that of other \nteams.\n\nThis points to an architectural obstacle \nthat must be resolved at the organizational level \n(which, in turn, is likely to require work from \nindividual teams).\n\nWe will look at these capabilities in more detail, \ninvestigating them through the lens of team-level \nand organization-level capabilities.\n\nRemember that our goal is improving our ability  \nto deliver software, which we accomplish through \ntechnical practices in delivery and deployment  \nwe call continuous delivery (CD).\n\nCD reduces  \nthe risk and cost of performing releases.\n\nContinuous delivery for the sake of continuous \ndelivery is not enough if you want your organization  \nto succeed, however."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "CD reduces  \nthe risk and cost of performing releases.\n\nContinuous delivery for the sake of continuous \ndelivery is not enough if you want your organization  \nto succeed, however.\n\nIt must be done with an eye to \norganizational goals such as profitability, \nproductivity, and customer satisfaction.Teams can deploy on-demand to production  \nor to end users throughout the software  \ndelivery lifecycle.\n\nFast feedback on the quality and \ndeployability of the system is available  \nto everyone on the team and acting on this \nfeedback is team members\u2019 highest priority.HOW WE MEASURED CONTINUOUS DELIVERY"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "41\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?Team-level technical capabilities \nIn previous years we found that test automation  \nhad a significant impact on CD.\n\nThis year, we  \nbuilt upon prior years\u2019 research and found that \nautomated testing positively impacts continuous \nintegration (CI).\n\nWith automated testing, developers \ngain confidence that a failure in a test suite denotes \nan actual failure just as much as a test suite passing \nsuccessfully means it can be successfully deployed.\n\nThe ability to reproduce and fix failures, gather \nfeedback from tests, improve test quality and iterate \ntest runs quickly also ties into automated testing.\n\nWe revalidated that CI improves CD.\n\nFor CI  \nto be impactful, each code commit should \nresult in a successful build of the software \nand a set of test suites being run.\n\nAutomated \nbuilds and tests for a project should be run \nsuccessfully every day."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Automated \nbuilds and tests for a project should be run \nsuccessfully every day.\n\nWe revalidated that deployment automation, \ntrunk-based development17, and monitoring \nimpact CD.\n\nThese capabilities may have \ndependencies on organization-level work,  \nas we described for deployment automation.\n\nFor example, teams can monitor their own code, \nbut will not see full benefits if both application \nand infrastructure are not monitored and used  \nto make decisions.How is this different from previous research \nand what does it mean for you?\n\nIn previous years, we simply tested the \nimportance of automated testing and CI, but \ndidn\u2019t look at the relationship between the two.\n\nThis year, we found that automated testing \ndrives improvements in CI."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This year, we found that automated testing \ndrives improvements in CI.\n\nIt means that smart \ninvestments in building up automated test \nsuites will help make CI better.17   Our research shows that effective trunk-based development is characterized by fewer than three active \nbranches and branches and forks having lifetimes of less than a day before being merged to master."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "42\nOPEN SOURCE  \nSOFTWARE DEVELOPMENT\n Organization-level technical capabilities \nIn contrast to capabilities that can be implemented \nand executed at the team level for quick impact, \nsome capabilities benefit from organization-level \ncoordination and sponsorship.\n\nExamples of these \nkinds of capabilities are those that involve decisions \nor design that span several teams, such as \narchitecture or policy (e.g., change management).\n\nThis year\u2019s research revalidated the positive  \nimpact of loosely coupled architecture on CD.\n\nA loosely coupled architecture is when delivery \nteams can independently test, deploy, and change  \ntheir systems on demand without depending  \non other teams for additional support, services, \nresources, or approvals, and with less back-and-\nforth communication."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This allows teams to quickly \ndeliver value, but it requires orchestration at a \nhigher level.Our research has focused on software development and delivery in \nan organizational context, where a team\u2019s full-time job is developing \nand delivering software, allowing members to coordinate their \ndevelopment and releases around a much tighter check-in and \nrelease cadence.\n\nWe have found that trunk-based development with \nfrequent check-in to trunk and deployment to production is \npredictive of performance outcomes.\n\nBut what about open source software development?\n\nOpen source projects have a different set of timelines and \nexpectations since they are largely community-driven, with \ncommunity members from around the world sending patches to \nprojects when their schedule allows."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Because open source projects \nmust support collaboration with people around the world and \nacross many organizations (including freelancers, hobbyists,  \nand developers at all levels), open source project releases are  \ncut in a different style than a continuous delivery software practice.\n\nThey are typically cut from a branch at a specific point in time after \nsignificant testing.\n\nOur research findings extend to open source development in some \nareas: \n\u2022 Committing code sooner is better: In open source projects, \nmany have observed that merging patches faster to prevent \nrebases helps developers move faster.\n\n\u2022 Working in small batches is better: Large \u201cpatch bombs\u201d are \nharder and slower to merge into a project than smaller, more \nreadable patchsets since maintainers need more time to review \nthe changes."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "\u2022 Working in small batches is better: Large \u201cpatch bombs\u201d are \nharder and slower to merge into a project than smaller, more \nreadable patchsets since maintainers need more time to review \nthe changes.\n\nWhether you are working on a closed-source code base or an open \nsource project, short-lived branches; small, readable patches; and \nautomatic testing of changes make everyone more productive."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "43\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?Architectural approaches that enable this strategy \ninclude the use of bounded contexts and APIs  \nas a way to decouple large domains, resulting  \nin smaller, more loosely coupled units.\n\nService-\noriented architectures are supposed to enable \nthese outcomes, as should any true microservices \narchitecture.18 Architecture designs that permit \ntesting and deploying services independently  \nhelp teams achieve higher performance.\n\nIt takes a lot of code to run our systems: Facebook \nruns on 62 million lines of code (excluding backend \ncode), the Android operating system runs on 12 to \n15 million lines of code, and a typical iPhone app \nhas 50,000 lines of code.19 With the huge amount  \nof code it takes to run our organizations, we wanted \nto investigate which code-related practices really \nhelp drive performance (or if they do at all),  \na construct we called code maintainability."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Our analysis found that code maintainability \npositively contributes to successful CD.\n\nTeams \nthat manage code maintainability well have \nsystems and tools that make it easy for \ndevelopers to change code maintained by \nother teams, find examples in the codebase, \nreuse other people\u2019s code, as well as add, \nupgrade, and migrate to new versions of \ndependencies without breaking their code.\n\nHaving these systems and tools in place not \nonly contributes to CD, but also helps decrease \ntechnical debt, which in turn improves productivity, \nsomething you\u2019ll see in a later section.\n\nOrganizations that elevate code maintainability \nprovide real advantages to their engineers.\n\nFor example, managing dependencies is hard.\n\nUpdating a dependency could open a rabbit \nhole to issues such as breaking API changes, \n18   It's important to avoid premature decomposition of new systems into services, or overly fine-grained services, both of which can inhibit delivery performance."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Martin Fowler covers this in MonolithFirst https://martinfowler.com/bliki/MonolithFirst.html.\n\n19    https://www.businessinsider.com/how-many-lines-of-code-it-takes-to-run-different-software-2017-2"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "44updating a transitive dependency, creating \nincompatible dependencies (for example,  \nthe diamond dependency issue), and breaking \nfunctionality.\n\nTooling that can help avoid  \nthese errors or illuminate the consequences  \nof code changes can improve design decisions  \nand code quality for all engineers.\n\nDebates about  tools or code organization  \nare easy to fall into.\n\nIt\u2019s important to focus on \noutcomes: Are we enabling or preventing  \nsoftware performance and productivity?\n\nAdvanced users such as developers, testers, and sysadmins were \npreviously neglected when considering the usability of their tooling.\n\nSometimes management assumed that\u2014as relative technology \nexperts\u2014the technologists could figure out any tool they were given.\n\nThis isn\u2019t an uncommon mindset.\n\nIn World War II, pilots were \nselected and trained based on their ability to operate overly \ncomplex cockpits.\n\nThen usability experts realized that complex work \nlike piloting an aircraft was difficult enough."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Then usability experts realized that complex work \nlike piloting an aircraft was difficult enough.\n\nIt was better to design a \ncockpit to be easy-to-use and understandable, and let pilots spend \ntheir attention safely piloting the aircraft.\n\nOther times, usability needs are ignored because management \nassumes that technologists\u2019 needs are like those of regular end \nusers.\n\nToday, we know that power users (such as engineers) often \nhave special use cases, with unique design needs.\n\nTechnologists \nalso include broader skill sets and backgrounds\u2014such as UX, infosec, \nand database engineers\u2014as well as diverse abilities.\n\nMaking tools \nthat are accessible and easy-to-use is an important consideration for \ntool vendors.\n\nWith this in mind, in this year's research we studied the usability  \nof the tools used to deploy software because technical practices that \nsupport software development and deployment are important to \nspeed and stability."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "The usefulness and ease-of-use of this deployment tooling is highly \ncorrelated with CI and CD.\n\nThis makes sense, because the better  \nour tools are suited to our work, the better we are able to do it.\n\nWe also find this drives productivity, which you can read about  \non page 55.USEFUL, EASY-TO-USE  \nTOOLS FOR  \nDEPLOYING SOFTWARE"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "45\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?DISASTER RECOVERY TESTING \nEvery organization that runs mission-critical software systems should have a disaster \nrecovery plan.\n\nBut creating plans without testing them is like creating backups without \nalso practicing restoring from backup regularly\u2014that is to say, useless.\n\nWe asked \nrespondents which kinds of disaster recovery testing their organizations perform.\n\nLow Medium High Elite OVERALL\nTable-top exercises that are not carried out on \nreal systems 35% 26% 27% 30% 28%\nInfrastructure (including datacenter) failover 27% 43% 34% 38% 38%\nApplication failover 25% 46% 41% 49% 43%\nSimulations that disrupt production-like test sys -\ntems (including failure injection such as degrad -\ning network links, turning off routers, etc.\n\n)18% 22% 23% 29% 23%\nSimulations that disrupt production systems \n(including failure injection such as degrading \nnetwork links, turning off routers, etc."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": ")18% 22% 23% 29% 23%\nSimulations that disrupt production systems \n(including failure injection such as degrading \nnetwork links, turning off routers, etc.\n\n)18% 11% 12% 13% 12%\nCreating automation and systems that disrupt \nproduction systems on a regular, ongoing basis 9% 8% 7% 9% 8%DISASTER RECOVERY TEST TYPES \nBY PERFORMANCE PROFILE"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "46\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?Not all tests are performed using production \nsystems, which is a concern for two reasons.\n\nFirst, it\u2019s difficult (and often prohibitively expensive) \nto create comprehensive reproductions of \nproduction systems.\n\nSecond, the types of incidents \nthat bring down production systems are often \ncaused by interactions between components  \nthat are operating within apparently normal \nparameters, which might not be encountered  \nin test environments.\n\nAs systems become more \ncomplex, these factors become more significant.\n\nWe asked how frequently organizations  \nperform disaster recovery tests on  \nproduction infrastructure:\n\u2022 Simulations that disrupt production systems \n(including failure injection such as degrading \nnetwork links, turning off routers, etc.)"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "\u2022 Infrastructure (including datacenter) failover\n\u2022 Application failoverOnly 40% of respondents perform disaster \nrecovery testing at least annually using one  \nor more of the methods listed.\n\nOrganizations \nthat conduct disaster recovery tests are  \nmore likely to have higher levels of service \navailability\u2014that is, the ability for technology \nteams and organizations to make and keep \npromises and assertions about the software \nproduct or service they are operating.\n\nMike Garcia, Vice President of Stability & \nSRE at Capital One, says, \u201cIt's not enough to \ndemonstrate you can deliver quickly on modern \ncloud technology.\n\nEspecially in a heavily regulated \nindustry like banking, we have obligations that \nrequire us to prove our level of resiliency in our \nresponsibility to meet the needs of our customers.\n\n..."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Especially in a heavily regulated \nindustry like banking, we have obligations that \nrequire us to prove our level of resiliency in our \nresponsibility to meet the needs of our customers.\n\n...\n\nIn order to do that, we have had to advance \nbeyond just demonstrating that we can failover  \nen masse\u2026 The idea is to progressively show  \nmore advanced capabilities and automatic \nresiliency through more sophisticated  \nchaos-testing techniques.\u201d"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "47\nLEARNING FROM DISASTER  \nRECOVERY EXERCISES Organizations that work together cross-\nfunctionally and cross-organizationally  \nto conduct disaster recovery exercises see \nimprovements in more than just their systems.\n\nBecause these tests pull together so many \nteams, they surface connections that many \nforget or don\u2019t realize exist, the exercises  \nalso improve and strengthen the processes \nand communication surrounding the systems \nbeing tested, making them more efficient  \nand effective.\n\nWe also looked at whether organizations act on \nwhat they discover in disaster recovery testing \nexercises.\n\nAnalysis shows that organizations \nthat create and implement action items based \non what they learn from disaster recovery \nexercises are 1.4 times more likely to be in  \nthe elite performing group.\n\nBlameless post-mortems are an important aspect to \nsupport growth and learning from failure."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Blameless post-mortems are an important aspect to \nsupport growth and learning from failure.\n\nThis is well-\ndocumented in the literature and supported in our \nprevious research, which showed that conducting \nblameless post-mortems contributes to a learning \nculture and an organizational culture that optimizes  \nfor software and organizational performance outcomes.\n\nFor a great read on disaster recovery exercises\u2014from \nboth the viewpoint of their benefits even in light of their \nexpense, as well as a play-by-play from an SRE in the \nmiddle of an exercise\u2014check out Weathering the \nUnexpected by Kripa Krishnan with Tom Limoncelli.\n\n20 \nIn this ACM Queue article, Kripa Krishnan, a director at \nGoogle previously in charge of disaster recovery testing \n(DiRT) exercises, makes the following observation:  \n\u201cFor DiRT-style events to be successful, an organization \nfirst needs to accept system and process failures as a \nmeans of learning.\n\nThings will go wrong."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Things will go wrong.\n\nWhen they  \ndo, the focus needs to be on fixing the error instead of \nreprimanding an individual or team for a failure  \nof complex systems.\n\n\u201d\n20   https://queue.acm.org/detail.cfm?id=2371516"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "48\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?CHANGE MANAGEMENT\nMaking changes to software and production systems is often \ncomplex and bureaucratic.\n\nTwo factors are responsible for much  \nof this complexity: the need for coordination between teams,  \nand requirements of regulatory control, particularly in financial \nservices, healthcare, and government.\n\nWhile the complexities \ninvolved in implementing regulatory control requirements are \nbeyond the influence of leadership and practitioners, we can \ninfluence the role that team coordination plays in change \nmanagement\u2014and that role is changing."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "For example, segregation of duties, which  states that changes \nmust be approved by someone other than the author, is often \nrequired by regulatory frameworks.21 While we agree that no \nindividual should have end-to-end control over a process  \n(the intent of this control), there are lightweight, secure ways  \nto achieve this objective that don\u2019t suffer the same coordination  \ncosts as heavyweight approaches.\n\n21   Examples include the Payment Card Industry Data Security Standard (PCI-DSS) and the NIST Risk \nManagement Framework used by US Federal Government agencies."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "49One approach is to require every change be \napproved by someone else on the team as part  \nof code review, either prior to commit to version \ncontrol (as part of pair programming) or prior  \nto merge into master.\n\nThis can be combined with automated thresholds \nthat bound changes.\n\nFor example, you may \nimplement checks to not allow developers to push \na change (even with peer review) that will increase \ncompute or storage costs over a certain threshold.\n\nThis lightweight, straightforward-to-implement \nprocess presents a clear opportunity for \npractitioners to improve change management.\n\nSome proponents, supported by IT service \nmanagement (ITSM) frameworks, claim that formal \nchange approval processes lead to more stability, \nand point out that these have been the norm in \nindustry for decades."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Using code review to implement segregation of duties \nrequires that all changes to production systems should \nbe recorded in a change management system that lists \nthe change along with the person or people who \nauthored it, and logs authenticated approval events.\n\nIf you\u2019re using version control as the source of truth  \nfor all changes to your systems (a technique from the \nparadigm known as \u201cinfrastructure as code\u201d or \u201cgitops\u201d), \nyou simply need to be able to record who approved each \nchange.\n\nThis has the added benefit of making the review \nand submit process highly auditable.\n\nOur previous \nresearch also shows that comprehensive use of version \ncontrol, including for system configuration and scripting, \ndrives performance.IMPLEMENTING  \nSEGREGATION  \nOF DUTIES"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "50\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?Others, backed by lean and agile philosophies, \nargue that more streamlined change approvals \nlead to faster feedback, better information flow, \nand better outcomes.\n\nTo investigate these \nhypotheses, we created two new constructs\u2014  \none that captures a lightweight, clearly understood \nchange approval process, and another that \ncaptures a more formal, heavyweight change \napproval process\u2014and tested their impact on \nsoftware delivery performance.\n\nHeavyweight change process  \nWe found that formal change management \nprocesses that require the approval of an external \nbody such as a change advisory board (CAB)  \nor a senior manager for significant changes  \nhave a negative impact on software delivery \nperformance.\n\nSurvey respondents were 2.6 times \nmore likely to be low performers if their organization had this kind of formal approval process in place."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Survey respondents were 2.6 times \nmore likely to be low performers if their organization had this kind of formal approval process in place.\n\nThis expands on our previous research, which \nfound that heavyweight change approvals \nprocess were negatively correlated with change \nfailure rates.22\nThe motivation behind the heavyweight change \nmanagement processes proposed by ITSM \nframeworks is reducing the risk of releases.\n\nTo examine this, we investigated whether a  \nmore formal approval process was associated \nwith lower change fail rates and we found no \nevidence to support this hypothesis, consistent \nwith earlier research.23 We also examined whether \nintroducing more approvals results in a slower \nprocess and the release of larger batches less \nfrequently, with an accompanying higher impact \non the production system that is likely to be \nassociated with higher levels of risk and thus \n22,23 Velasquez, N., Kim, G., Kersten, N., & Humble, J.\n\n(2014).\n\nState of DevOps Report: 2014.\n\nPuppet Labs."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "51higher change fail rates.\n\nOur hypothesis was \nsupported in the data.\n\nThis has important \nimplications for organizations working to reduce risk \nin their release process: Organizations often respond \nto problems with software releases by introducing \nadditional process and more heavyweight approvals.\n\nAnalysis suggests this approach will make things worse.\n\nWe recommend that organizations move away from \nexternal change approval because of the negative \neffects on performance.\n\nInstead, organizations \nshould \u201cshift left\u201d to peer review-based approval \nduring the development process.\n\nIn addition to peer \nreview, automation can be leveraged to detect, \nprevent, and correct bad changes much earlier in  \nthe delivery lifecycle.\n\nTechniques such as continuous \ntesting, continuous integration, and comprehensive \nmonitoring and observability provide early and \nautomated detection, visibility, and fast feedback."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Techniques such as continuous \ntesting, continuous integration, and comprehensive \nmonitoring and observability provide early and \nautomated detection, visibility, and fast feedback.\n\nIn this way, errors can be corrected sooner than \nwould be possible if waiting for a formal review.\n\nContinuous delivery offers a superior risk management \napproach compared to traditional change management \nprocesses, but there is still an important role for the CAB.\n\nAs organizations become more complex, facilitating \nnotification and coordination among teams is \nincreasingly critical.\n\nOur previous research has \nestablished that fostering information flow is essential to \ndeveloping a high-performance, mission-driven culture.\n\nSince approving each individual change is impossible in \npractice in the continuous paradigm, the CAB should \nfocus instead on helping teams with process-\nimprovement work to increase the performance of \nsoftware delivery."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This can take the form of helping \nteams implement the capabilities that drive \nperformance by providing guidance and resources.\n\nCABs can also weigh in on important business decisions \nthat require a trade-off and sign-off at higher levels of \nthe business, such as the decision between time-to-\nmarket and business risk.\n\nYou\u2019ll note the new role of the CAB is strategic.\n\nBy shifting \ndetailed code review to practitioners and automated \nmethods, time and attention of those in leadership and \nmanagement positions is freed up to focus on more \nstrategic work.\n\nThis transition, from gatekeeper to \nprocess architect and information beacon, is where we \nsee internal change management bodies headed, and is \nconsistent with the practices of organizations that excel \nat software delivery performance.WHAT HAPPENS TO  \nTHE CAB IN THE CONTINUOUS  \nDELIVERY PARADIGM?"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "52\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?Clear change process  \nWhile moving away from traditional, formal change \nmanagement processes is the ultimate goal, simply \ndoing a better job of communicating the existing \nprocess and helping teams navigate it efficiently has \na positive impact on software delivery performance.\n\nWhen team members have a clear understanding  \nof the process to get changes approved for \nimplementation, this drives high performance.\n\nThis means they are confident they can get changes \nthrough the approval process in a timely manner \nand know the steps it takes to go from \u201csubmitted\u201d \nto \u201caccepted\u201d every time for all the types of changes \nthey typically make.\n\nSurvey respondents with a \nclear change process were 1.8 times more likely  \nto be in elite performers\nIn our work with large organizations, change \nmanagement is consistently one of the biggest \nconstraints.\n\nRemoving it requires work at multiple levels."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Removing it requires work at multiple levels.\n\nTeams can implement continuous integr ation, \ncontinuous testing, and peer review to find  \nbad changes as quickly as possible while also \nsatisfying segregation of duties.\n\nAnd only our \ntechnical practitioners have the power to  \nbuild and automate the change management \nsolutions we design, making them fast, reliable, \nrepeatable, and auditable.\n\nLeaders at every level should move away from a \nformal approval process where external boards \nact as gatekeepers approving changes, and \ninstead move to a governance and capability \ndevelopment role.\n\nAfter all, only managers have \nthe power to influence and change certain levels \nof organizational policy.\n\nWe have seen \nexponential improvements in performance\u2014  \nthroughput, stability, and availability\u2014in just \nmonths as a result of technical practitioners  \nand organizational leaders working together."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "53\nAccelerate: State of DevOps 2019    |     How Do We Improve SDO & Organizational Performance?CUL TURE OF PSYCHOLOGICAL SAFETY\nCulture is often lauded as the key to DevOps and technology \ntransformations by practitioners and champions who lead efforts  \nin organizations.\n\nIndeed, Davis and Daniels cite culture as a key  \nfactor in successful and scalable technology efforts in their book  \nEffective DevOps.24 Our own research has found that an organizational \nculture that optimizes for information flow, trust, innovation, and  \nrisk-sharing is predictive of SDO performance.25\nResearch from a large two-year study at Google found similar results:26  \nthat high-performing teams need a culture of trust and psychological \nsafety, meaningful work, and clarity.\n\nThis team environment allows \nmembers to take calculated and moderate risks, speak up, and be more \ncreative.\n\nSome have wondered if these results can also be true outside  \nof Google."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This team environment allows \nmembers to take calculated and moderate risks, speak up, and be more \ncreative.\n\nSome have wondered if these results can also be true outside  \nof Google.\n\nIs this kind of culture beneficial to the wide mix of enterprises, \ntools, and engineering skills we see in other organizations?\n\nOr does it  \nonly hold true for the engineers that pass Google\u2019s notoriously rigorous \ninterviews, in a large enterprise, supported by huge infrastructure  \nand only a certain type of code base?\n\n24   Davis, J., & Daniels, R. (2016).\n\nEffective DevOps: building a culture of collaboration, affinity, and tooling at scale.\n\nO'Reilly Media, Inc.\n25   This research was based on an organizational culture framework originally proposed by the sociologist Dr. Ron Westrum.\n\nThis model is outlined in the 2018 Accelerate State of DevOps Report .\n\n26  https://rework.withgoogle.com/blog/five-keys-to-a-successful-google-team/"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "54\nTECHNOLOGY\u2019S IMPACT  \nON ORGANIZATIONAL  \nPERFORMANCE To answer that question, we shifted our measure of \nculture to the questions that the Project Aristotle team \nincluded in its research.27 Our analysis found that this \nculture of psychological safety  is predictive of \nsoftware delivery performance, organizational \nperformance, and productivity.\n\nAlthough Project \nAristotle measured different outcomes, these results \nindicate that teams with a culture of trust and \npsychological safety, with meaningful work and \nclarity, see significant benefits outside of Google.The ability to deliver software rapidly and reliably and provide high \nlevels of availability is a powerful tool.\n\nIt enables organizations to \neasily and quickly prototype new products and features and test \nthe impact on users without impacting existing users."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "It enables organizations to \neasily and quickly prototype new products and features and test \nthe impact on users without impacting existing users.\n\nIt also allows \norganizations to keep up with compliance and regulatory changes, \nand deliver critical software patches and updates necessary for \nsecurity quickly and reliably.\n\nIf leveraged effectively, organizations \nthat can achieve high levels of SDO performance should be able to \nbetter respond to technological change and shifts in the market \nand create superior products and services.\n\nThis, in turn, helps \norganizations better achieve their desired organizational \noutcomes, both commercial and non-commercial.\n\nOur analysis \nthis year shows elite performers are twice as likely to meet  \nor exceed their organizational performance goals."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Our analysis \nthis year shows elite performers are twice as likely to meet  \nor exceed their organizational performance goals.\n\nThe organizational performance measures we use are derived  \nfrom academic literature and capture both commercial28 and \nnon-commercial29 goals, including:\n\u2022 Profitability\n\u2022 Productivity\n\u2022 Market share\n\u2022 Number of customers\n\u2022 Quality of products or services\n \nAs with last year, our second-order construct of SDO performance \npredicts organizational performance, and does so better than \nsoftware delivery performance or availability do alone.\u2022 Operating efficiency\n\u2022 Customer satisfaction\n\u2022 Quality of products  \nor services provided\n\u2022 Achieving organizational  \nor mission goals\n28   Widener, S. K. (2007).\n\nAn empirical analysis of the levers of control framework.\n\nAccounting, Organizations and Society, 32(7-8), 757-788.\n\n29   Cavalluzzo, K. S., & Ittner, C. D. (2004).\n\nImplementing performance measurement innovations: \nevidence from government."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Accounting, Organizations and Society, 32(7-8), 757-788.\n\n29   Cavalluzzo, K. S., & Ittner, C. D. (2004).\n\nImplementing performance measurement innovations: \nevidence from government.\n\nAccounting, Organizations and Society, 29(3-4), 243-267.\n\n27   Many thanks to the Project Aristotle team for sharing their research instrument.STRUCTURE AND CLARITY  \nTeam members have clear roles, plans, and goals\nMEANING  \nWork is personally important to team members\nIMPACT  \nTeam members think their work matters  \nand creates changePSYCHOLOGICAL SAFETY  \nTeam members feel safe to take risks and  \nbe vulnerable in front of each other\nDEPENDABILITY  \nTeam members get things done on time and meet  \nGoogle's high bar for excellence\n1\n2\n3\n4\n5"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Another important goal in teams and \norganizations is improving productivity \nto get more value out of your transformation \nand your employees.\n\nThis marks the first \nyear we investigate productivity: how \norganizations can support it with smart \ninvestments in tools and information, \nhow technical debt interrupts it,  \nand how it affects employee work/life \nbalance and burnout.\n\nHOW DO WE  \nIMPROVE  \nPRODUCTIVITY?"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "56\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?56\nMost agree that productivity is important: Productive \nengineers are able to do their work more efficiently, \ngiving them more time to re-invest into other work,30 \nsuch as documentation, refactoring, or doing more  \nof their core function to deliver additional features  \nor build out additional infrastructure.31 \nBut what is productivity, and how should we measure \nit?\n\nProductivity cannot be captured with a simple \nmetric such as lines of code, story points, or  \nbugs closed; doing so results in unintended \nconsequences that sacrifice the overall goals  \nof the team.32 For example, teams may refuse to  \nhelp others because it would negatively impact  \ntheir velocity,  even if their help is important to  \nachieve organizational goals."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "IMPROVING  \nPRODUCTIVITY\n30   We point the reader to a discussion of productivity by noted economist Hal Varian  \nhttps://www.wsj.com/articles/silicon-valley-doesnt-believe-u-s-productivity-is-down-1437100700\n31   We discuss the benefits of reinvesting the time savings from productivity gains (vs. seeing them as cost savings to be \neliminated) in our 2017 ROI white paper \u201cForecasting the Value of DevOps Transformations.\n\n\u201d This is not a new idea; \neconomists have investigated this and Dr Varian addresses it in his WSJ article cited above.\n\ncloud.google.com/devops\n32   This can also be summarized by Goodhart\u2019s Law, which states that \"When a measure becomes a target, it ceases to \nbe a good measure.\"\n\nBy focusing only on easy-to-measure, local metrics, teams often set those as their targets, at the \nexpense of global goals that truly further organizational outcomes.\n\nSee Chapter 2 of Accelerate: The Science of Lean \nSoftware and DevOps for more detail."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "57\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?Researchers have discussed this topic at length, \nand most have come to the same conclusion: \nProductivity is the ability to get complex, \ntime-consuming tasks completed with \nminimal distractions and interruptions.\n\nMany of us describe this as getting into a good \nwork flow or rhythm.To use this model, locate the goal you want \nto improve in the figure, and then identify \nthe capabilities that impact it.\n\nFor example, \nif your goal is to reduce technical debt, these \ncapabilities are code maintainability, having  \na loosely coupled architecture, and monitoring.\n\nn.s.\n\nPRODUCTIVITYYears of experience  \n(control)CUL TURE OF PSYCHOLOGICAL SAFETY\nBurnout\nLoosely coupled architecture Monitoring INTERNAL SEARCH\nCODE MAINTAINABILITYUSEFUL, EASY-TO-USE TOOLS\nEXTERNAL SEARCH -\n- - --\nTECHNICAL DEBTWORK RECOVERY\nConstruct\nControl variable\nn.s."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": ":     Not significant\nBOLD  Newly investigated this year  Common goal  \nfor team or organizationPredictive relationship\nNegative predictive relationship -"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "58\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?USEFUL, EASY-TO-USE TOOLS\nUseful and easy-to-use tools are now considered a must-have for \nconsumer technologies, but these obvious characteristics are often \noverlooked among technology professionals who assume they are \nexperts and can make any tool or technology work.\n\n(Or because those \npurchasing tools for these groups assume usability is less important  \nfor technologists, or are optimizing for other factors such as cost, \nlicensing terms, or vendor management.)\n\nIn fact, the opposite is true:  \nWhen building complex systems and managing business-critical \ninfrastructure, tools are even more important because the work  \nis more difficult.\n\nWe focused on tools used in deploying software through  \nthe CI/CD and test automation toolchain because they are  \nat the heart of DevOps."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "We focused on tools used in deploying software through  \nthe CI/CD and test automation toolchain because they are  \nat the heart of DevOps.\n\nWe found that these two attributes  \ndrive productivity:\n\u2022 How easy it is to use the toolchain (including  \nstraightforward and easy interactions and operation) \n\u2022 How useful the toolchain is in accomplishing  \njob-related goalslikely to have  \neasy-to-use tools1.5\nTIMES MORE  HIGHEST PERFORMING \nENGINEERS"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "59\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?Low Medium High Elite\nA mix of proprietary \ntools, open source, and \ncommercial off-the-shelf \n(COTS) software30% 34% 32% 33%\nMainly open source and \nCOTS, heavily customized 17% 8% 7% 10%\nMainly open source  \nand COTS, with little  \ncustomization14% 21% 18% 20%\nPrimarily COTS  \npackaged software 8% 12% 8% 4%\nPrimarily developed  \nin-house and proprietary \nto my organization20% 6% 5% 6%\nPrimarily open source,  \nheavily customized 6% 7% 5% 12%\nPrimarily open source,  \nwith little customization 5% 12% 24% 15%TOOL USAGE BY  \nPERFORMANCE PROFILEAnd what do those tools look like?\n\nWe dug into \nthe data by performance profile and saw some \ninteresting patterns: \n\u2022 The strongest concentration of fully \nproprietary software is seen in low \nperformers, while the lowest concentration  \nis seen among high and elite performers.\n\nProprietary software may be valuable, but it \ncomes at great cost to maintain and support."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Proprietary software may be valuable, but it \ncomes at great cost to maintain and support.\n\nIt\u2019s no surprise that the highest performers \nhave moved away from this model.\n\n\u2022 There is a relatively equal concentration of \ncommercial off-the-shelf (COTS) software with \nlittle customization.\n\nSome may wonder why \nhigh performers can use COTS and still be high \nperformers, especially if the message continues \nto be that \u201csoftware is eating the world\u201d and \nwe must be creating our own software."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "60\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?As Martin Fowler outlines,33 companies  \nshould be thoughtful about which software  \nis strategic and which is merely utility.\n\nBy \naddressing their utility needs with COTS \nsolutions and minimizing customization,  \nhigh performers save their resources for \nstrategic software development efforts.\n\nWe also see that elite performers automate and \nintegrate tools more frequently into their toolchains \non almost all dimensions.\n\nAlthough automation \nmay be seen as too expensive to implement (we \noften hear, \u201cI don\u2019t have time or budget to automate\u2014  \nit\u2019s not a feature!\u201d), automation is truly a sound \ninvestment.34 It allows engineers to spend less  \ntime on manual work, thereby freeing up time  \nto  spend on other important activities such as  \nnew development, refactoring, design work, and \ndocumentation."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "It also gives engineers more \nconfidence in the toolchain, reducing stress  \nin pushing changes.33   Martin Fowler, MartinFowler.com, UtilityVsStrategicDichotomy.\n\nhttps://martinfowler.com/bliki/UtilityVsStrategicDichotomy.html\n34 This is a site reliability engineering (SRE)  best practice: reduce toil, which is work without productivity.\n\nLow Medium High Elite\nAutomated build 64% 81% 91% 92%\nAutomated unit tests 57% 66% 84% 87%\nAutomated acceptance tests 28% 38% 48% 58%\nAutomated performance tests 18% 23% 18% 28%\nAutomated security tests 15% 28% 25% 31%\nAutomated provisioning  \nand deployment to  \ntesting environments39% 54% 68% 72%\nAutomated deployment  \nto production 17% 38% 60% 69%\nIntegration with  \nchatbots / Slack 29% 33% 24% 69%\nIntegration with production  \nmonitoring and observability \ntools13% 23% 41% 57%\nNone of the above 9% 14% 5% 4% AUTOMATION AND INTEGRATION  \nBY PERFORMANCE PROFILE"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "61\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?\n\nWe wondered if the amount of juggling work would be \nsignificantly different among our highest and lowest \nperformers\u2014after all, productivity is the ability to get \nwork done and feel like you are in \u201ca flow.\n\n\u201d \nTo capture this, we asked respondents a few questions: \n\u2022 How many roles they juggle or different types of \nwork do they do regardless of their official job title  \n\u2022 How many projects they switched between in a day\n\u2022 How many projects they were working on overall\n \nSurprisingly, we did not detect significant differences \nbetween low, medium, high, and elite performers.\n\nTherefore, we cannot conclude that how well teams \ndevelop and deliver software affects the number of \nroles and projects that respondents juggle.\n\nThere is  \nno such thing as \u201cpush through this phase and it will \nget significantly better.\n\n\u201d Instead, we should take steps \nto make our work sustainable."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "There is  \nno such thing as \u201cpush through this phase and it will \nget significantly better.\n\n\u201d Instead, we should take steps \nto make our work sustainable.\n\nThat is done through \nprocess improvement work and automation, which  \nwill reduce toil and make the work repeatable, \nconsistent, fast, scalable, and auditable.\n\nIt will  \nalso free us up to do new, creative work.PRODUCTIVITY ,  \nBURNOUT, AND  \nJUGGLING WORKTechnical professionals and tools  \nOur work in 2017 found that empowered teams \nwho make their own decisions about tools and \nimplementations contribute to better software \ndelivery performance.\n\nIn this year\u2019s research, we \nsee that given the opportunity, high performers \nchoose useful and usable tools, and these kinds \nof tools improve productivity.\n\nThis has important implications for product \ndesign.\n\nProducts that have both utility and \nusability are more likely to be adopted by \ntechnology professionals, and when they are \nused, have better outcomes."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Products that have both utility and \nusability are more likely to be adopted by \ntechnology professionals, and when they are \nused, have better outcomes.\n\nThese kinds of \ntools should be prioritized by industry leaders.\n\nIt's not enough to deliver products that are \nfeature complete; they also need to be usable \nto be adopted and deliver value during a \nDevOps transformation."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "62\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?INTERNAL AND EXTERNAL SEARCH\nFinding the right information to help solve a problem, debug an \nerror, or find a similar solution quickly and easily can be a key \nfactor in getting work done and maintaining the flow of work.\n\nThis \nis especially true in today\u2019s tech environment, which is comprised \nof increasingly complex systems.\n\nWe found that having access to \ninformation sources supports productivity.\n\nThese information \nsources come in two categories: internal and external search.\n\n\u2022 Internal search: Investments that support document and code \ncreation as well as effective search for company knowledge \nbases, code repositories, ticketing systems, and other docs \ncontribute to engineering productivity.\n\nThose who used internal \nknowledge sources were 1.73 times more likely to be productive."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Those who used internal \nknowledge sources were 1.73 times more likely to be productive.\n\nProviding developers, sysadmins, and support staff with the \nability to search internal resources allows them to find answers \nthat are uniquely suited to the work context (for example, using \n\u201cfind similar\u201d functions) and apply solutions faster.\n\nIn addition, \ninternal knowledge bases that are adequately supported and \nfostered create opportunities for additional information sharing \nand knowledge capture.\n\nlikely to be productive1.73\nTIMES MORE  \nlikely to be productive1.67\nTIMES MORE  USE OF  \nINTERNAL SEARCH\nUSE OF  \nEXTERNAL SEARCH"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "63\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?For example, people may pose questions when \nthey find solutions that almost fit, prompting \nanswers and discussion from the internal \ncommunity, which feeds additional information \ninto the knowledge base.\n\nIf the organization has \ninvested in systems that can easily search across \nall types of information and data, the culture can \ncontribute to a \u201cvirtuous cycle\u201d of knowledge \nsharing.\n\nSome organizations are leveraging \nmachine learning technologies to identify and \nsuggest candidate solutions to internal search  \nas well.\n\n\u2022 External search: These include external sources \nsuch as search engines and Stack Overflow.\n\nOur \nanalysis found that those who used external search \nin their work were 1.67 times more likely to report \nfeeling productive in their work."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Our \nanalysis found that those who used external search \nin their work were 1.67 times more likely to report \nfeeling productive in their work.\n\nExternal search is \nimportant because these technologies provide \nstrong communities for learning and growing (and recruiting, an important side benefit) and \nprovide support for the use and adoption of \npublic cloud and open source tooling.\n\nThat is, \nleveraging commonly used external tools and \nsystems with a strong user community and \ngood ecosystem allows tech professionals to \ntroubleshoot with the world, while proprietary \nand home-grown implementations only allow \nexperts within an organization to weigh in on \npossible solutions.\n\nWe see support for this in \nthe data.\n\nIn our 2018 research, elite performers \nleveraged and planned to expand their use  \nof open source."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "We see support for this in \nthe data.\n\nIn our 2018 research, elite performers \nleveraged and planned to expand their use  \nof open source.\n\nIn this year\u2019s research, we see \nthat eite performers use more open source \ntooling and low performers have the highest \nuse of proprietary data (see page 59); these \ntechnology choices are bound to have an \nimpact on productivity."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "64\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?TECHNICAL DEBT\nTechnical debt was introduced in 1992 by Ward Cunningham35 to describe what \nhappens when we fail to adequately maintain what he calls \u201cimmature\u201d code.\n\n35  http://c2.com/doc/oopsla92.html      Although immature code may work fine and be completely acceptable to the \ncustomer, excess quantities will make a program unmasterable, leading to extreme \nspecialization of programmers and finally an inflexible product.\n\nShipping first-time \ncode is like going into debt.\n\nA little debt speeds development so long as it is paid \nback promptly with a rewrite...\n\nThe danger occurs when the debt is not repaid.\n\nEvery minute spent on not-quite-right code counts as interest on that debt."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "The danger occurs when the debt is not repaid.\n\nEvery minute spent on not-quite-right code counts as interest on that debt.\n\nEntire \nengineering organizations can be brought to a standstill under the debt load of an \nunconsolidated implementation.\u201d\nIn today\u2019s complex systems, technical debt can occur in scripts, configuration \nfiles, and infrastructure as well as application code.\n\nTechnical debt includes \ncode or systems with:\n\u2022 Known bugs that go unfixed in favor of new features\n\u2022 Insufficient test coverage \n\u2022 Problems related to low code quality  \nor poor design \n\u2022 Code or artifacts that aren\u2019t cleaned up  \nwhen no longer used \u2022 Implementations that the current team doesn\u2019t have expertise in,  \nand therefore can\u2019t effectively debug or maintain\n\u2022 Incomplete migration\n\u2022 Obsolete technology\n\u2022 Incomplete or outdated documentation or missing comments\u201c"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "65\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?We found that technical debt negatively impacts \nproductivity, that respondents with high technical \ndebt were 1.6 times less productive, and that the \nhighest performers were 1.4 times more likely to \nhave low technical debt.\n\nCoping with technical debt  \nWard Cunningham states that \u201cthe best antidote [to \nchanging systems] is more complete familiarity with  \nthe product and its implementation.\u201d When engineers  \ncan understand changes, they can accept them.\n\nToday\u2019s complex infrastructures and distributed \nsystems make it impossible for engineers to maintain \na mental model of the complete state of the system.\n\nIn addition, supporting these complex systems has \nled to more specialized professionals who cannot \nhave complete familiarity with the entire system.36\nWe can help engineers build mental models by \narchitecting for flexible, extensible, and visible \nsystems to reduce technical debt."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "36   In order to have complete visibility into the system, one would have to be a full stack developer.\n\nAside from the obvious definitional challenge\u2014What is full stack?\n\nChips to CSS?\u2014many in the \nindustry agree that a full stack developer isn\u2019t possible or desirable.\n\nHow can we actually reduce technical debt and not \njust cope with it?\n\nOne approach is refactoring.\n\nRefactoring is a \u201cdisciplined technique for \nrestructuring an existing body of code, altering its \ninternal structure without changing its external \nbehavior, \u201d and Martin Fowler points out that \nrefactoring should be part of daily work.\n\nBetter tooling \nwith robust refactoring support built in are also \nimportant.\n\nIn fact, many large organizations have \ninvested in tools for doing code refactors across their \ncode base; for example, Facebook open sourced its \ntool fastmod and Google has open sourced ClangMR.\n\nACTIVELY  \nREDUCING  \nTECHNICAL DEBT"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "66\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?\n\nCUL TURE OF  \nPSYCHOLOGICAL SAFETY\nA culture that values psychological safety, \ntrust, and respect contributes to productivity  \nby letting employees focus on solving problems \nand getting their work done rather than  \npolitics and fighting.\n\nThis echoes work by other \nresearchers; as we discuss in the section earlier, \na study by Google found that this same kind  \nof culture leads to more effective teams.The findings on productivity can also apply to open \nsource projects.\n\nContributors can go from zero to \nproductive on open source projects faster if the \ndocumentation for how to contribute is up-to-date, \nsimple, and consistent with other open source  \nprojects.\n\nA large project with a custom and outdated \ncontribution process will have a hard time getting  \nnew contributors since the path to entry is too complex."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "A large project with a custom and outdated \ncontribution process will have a hard time getting  \nnew contributors since the path to entry is too complex.\n\nPair a complicated contribution process with technical \ndebt and your would-be contributors will view your \nproject as \u201cread-only.\n\n\u201d Applying all the same best \npractices mentioned here to your open source project \nwill get new contributors into the flow much faster  \nand grow your community in the most productive way.PRODUCTIVITY AND  \nOPEN SOURCE PROJECTS"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "67\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?ADDITIONAL BENEFITS OF IMPROVED PRODUCTIVITY\nThe benefits to the team and organization from higher productivity  \nare usually obvious: more work gets done, so we deliver more value.\n\nBut what about benefits to the people doing the work?\n\nWork Recovery\nResearch shows that productivity has a positive impact on work recovery , \nand we find support for that in our data as well.\n\nWork recovery is the ability  \nto cope with work stress and detach from work when we are not working.\n\nSome call this \u201cleaving work at work,\u201d and research shows that people who \ncan detach from work have better well-being and handle work-related \nstress better."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Some call this \u201cleaving work at work,\u201d and research shows that people who \ncan detach from work have better well-being and handle work-related \nstress better.\n\nThe reverse of this is also important: Feeling overworked leads \nto difficulty detaching, which leads to burnout and lower life satisfaction.37 \nBurnout  \nBurnout  has been recognized by the World Health Organization as a \ncondition that results from unmanaged chronic workplace stress,38 \nand it is more than just being tired.\n\nBurnout is a combination of  exhaustion, \n37     Sonnentag, S., & Fritz, C. (2015).\n\nRecovery from job stress: The stressor-detachment model as an integrative framework.\n\nJournal of Organizational Behavior, 36(S1), S72-S103.\n\nhttps://onlinelibrary.wiley.com/doi/abs/10.1002/job.1924\n38  World Health Organization, Burn-out an \"occupational phenomenon\": International Classification of Diseases.\n\nhttps://www.who.int/mental_health/evidence/burn-out/en/"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "68\nAccelerate: State of DevOps 2019    |     How Do We Improve Productivity?cynicism, and inefficacy at work.\n\nIt is often seen  \nin complex, high-risk work in hospitals, air traffic \ncontrol, and technology,39 and research shows \nthat stressful jobs can be as bad for physical \nhealth as secondhand smoke40 and obesity.41  \nIn extreme cases, burnout can lead to family \nissues, clinical depression, and even suicide.\n\nIn this year\u2019s research, we found that work \nrecovery can reduce burnout, which confirms \nother research.\n\nWe also revalidated previous \nyears\u2019 research and found that good technical \npractices and improved process (in the form of \nclear change management) can reduce burnout.\n\nWe see that the highest performers are half as \nlikely to report feeling burned out.\n\nSaid another \nway, low performers are twice as likely to report \nfeeling burned out.\n\nProductivity has a positive impact on work recovery.\n\nSince this can \nbe a key to reducing stress and burnout, how can we support it?"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Productivity has a positive impact on work recovery.\n\nSince this can \nbe a key to reducing stress and burnout, how can we support it?\n\nResearch shows that there are five keys to promote work recovery:\nPsychological detachment is the ability to stop thinking of work \noutside of work.\n\nTo promote this, consider electronic barriers that \nhelp keep work stress at work.\n\nRelaxation is not a luxury that we indulge on vacation; it\u2019s a key \ncomponent of productivity.\n\nMake a routine out of giving yourself \ntime to recover.\n\nMastery of a skill outside work promotes a positive outlook, \nreduces stress, and promotes healthy relationships.\n\nPractice  \nskills outside of work that bring you joy.\n\nA lack of control causes stress.\n\nBalance a lack of control over  \nwork demands with active pursuits outside of work, which  \nyou can control.\n\nFoster a culture that encourages stepping away from work.\n\nManagement in particular can set the tone that people are \nexpected to go home and not work on evenings and weekends."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Foster a culture that encourages stepping away from work.\n\nManagement in particular can set the tone that people are \nexpected to go home and not work on evenings and weekends.\n\nPractitioners can support this culture by disconnecting when \nthey\u2019re not at work, and encouraging colleagues to do the same.\n\n*\n*  A culture of psychological safety is strongly correlated with work recovery,  \nand can help support it.\n\nThis is true because team members can feel safe to talk \nabout stress, workloads, and taking time off when they head home."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This is true because team members can feel safe to talk \nabout stress, workloads, and taking time off when they head home.\n\nWe didn\u2019t test  \na predictive relationship because our measure of culture didn\u2019t specifically ask \nabout \u201csupporting and encouraging taking time away from work, \u201d and those kinds \nof cultures have been shown to increase work recovery.HOW TO SUPPORT  \nWORK RECOVERY\n39   While some claim technology is not high-risk work, the stresses of pushing the wrong code can be very real: \nErrors that have the potential to be very public or have life-changing implications (such as writing software \nthat supports hospitals or healthcare systems) is the reality for many in technology.\n\n40   Goh, J., Pfeffer, J., Zenios, S. A., & Rajpal, S. (2015).\n\nWorkplace stressors & health outcomes: Health policy  \nfor the workplace.\n\nBehavioral Science & Policy, 1(1), 43-52.\n\n41   Chandola, T ., Brunner, E., & Marmot, M. (2006).\n\nChronic stress at work and the metabolic syndrome: \nprospective study."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Behavioral Science & Policy, 1(1), 43-52.\n\n41   Chandola, T ., Brunner, E., & Marmot, M. (2006).\n\nChronic stress at work and the metabolic syndrome: \nprospective study.\n\nBMJ, 332(7540), 521-525.1\n2\n3\n4\n5"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "HOW DO WE   \nT R A N S F O R M :  \nWHAT REALLY   \nWORKS\nWe are often asked how companies \nspread new ways of work throughout \ntheir organization.\n\nConstant restructuring \nand reorganizing isn\u2019t sustainable due \nto its short-term negative impact on \nproductivity, and we know of several \norganizations who have executed major \ntransformations that haven\u2019t undergone  \na reorg.\n\nWhile there isn\u2019t a golden  \npath to success, one thing is clear:  \nA DevOps transformation is not a  \npassive phenomenon.\n\nThis year we  \nsought to identify the most common \napproaches for spreading DevOps best \npractices throughout an organization."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "70\nAccelerate: State of DevOps 2019    |     How Do We Transform?70\nWe asked respondents to share how their teams and \norganizations spread DevOps and Agile methods.\n\nRespondents could select one or more of  \nthe following approaches:*\n\u2022 Training Center  \n(sometimes referred to as a DOJO) \n\u2022 Center of Excellence\n\u2022 Proof of Concept but Stall\n\u2022 Proof of Concept as a Template \n\u2022 Proof of Concept as a Seed TRANSFORM:  \nWHAT REALLY  \nWORKS\n* Refer to Appendix B  for detailed descriptions of each approach\u2022 Communities of \nPractice  \n\u2022 Big Bang \n\u2022 Bottom-up or \nGrassroots \n\u2022 Mashup\nThese items were created based on commonly \nused approaches that we have observed across \nthe industry.\n\nOnce generated, we asked a \nrepresentative team of subject matter experts \nto review the list.\n\nThey gave us feedback and \nhelped us refine the options for clarity and \ncomprehensiveness."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "71\nAccelerate: State of DevOps 2019    |     How Do We Transform?We examined the data across our SDO performance \nclusters to examine the effectiveness of each \nstrategy.\n\nIt is not a perfect proxy, but it does  \nprovide a glimpse into what the highest and  \nlowest performers are doing to scale their \ntechnology transformations.\n\nMashups are commonly reported in this sample  \nat 40%, but they lack sufficient funding and \nresources in any particular investment.\n\nWe  \ncaution that without a strategy to guide a \ntechnology transformation, organizations will often \nmake the mistake of hedging their bets and suffer \nfrom \u201cdeath by initiative\u201d: identifying initiatives in \ntoo many areas, which ultimately leads to under-\nresourcing important work and dooming them  \nall to failure."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Instead, it is best to select a few \ninitiatives and dedicate resources to ensure their \nsuccess (time, money, and executive and champion  \npractitioner sponsorship).42High performers favor strategies that create \ncommunity structures at both low and high \nlevels in the organization, likely making them \nmore sustainable and resilient to reorgs and \nproduct changes.\n\nThe top two strategies \nemployed are Communities of Practice and \nGrassroots, followed by Proof of Concept (PoC) \nas a Template (a pattern where the PoC copies) \nand PoC as a Seed.\n\nLow performers tend to favor Training Centers \n(also known as DOJOs) and Centers of Excellence \n(CoE)\u2014strategies that create more silos and \nisolated expertise.\n\nThey also attempt PoCs,  \nbut these generally stall and don\u2019t see success.\n\nSome strategies see common patterns among \nall performance profiles: All profiles report \nadopting and supporting a mix of strategies."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Some strategies see common patterns among \nall performance profiles: All profiles report \nadopting and supporting a mix of strategies.\n\n42   This is much like the constraints model of continuous improvement we outline earlier: Set  \nshort- and long-term goals, identify the key areas that need the most improvement to achieve \nthose goals, and allocate resources accordingly."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "72\nAccelerate: State of DevOps 2019    |     How Do We Transform?No profiles report strong use of a Big Bang \nstrategy\u2014though low performers use this the most \noften (19% of the time)\u2014and that\u2019s probably for the \nbest.\n\nIn our experience, this is an incredibly difficult \nmodel to execute and should only be attempted in \nthe most dire of situations, when a \u201cfull reset\u201d  \nis needed.\n\nIn the Big Bang, everyone needs to  \nbe on board for the long-haul, with resources \ndedicated for a multi-year journey.\n\nThis may \nexplain why this method is seen most often  \namong our low performers.\n\nWhy aren\u2019t CoEs and  \nTraining Centers recommended?\n\nIn general, Centers of Excellence (CoEs) are not \nrecommended because they centralize expertise  \nin one group.\n\nThis creates several problems.\n\nFirst, \nthe CoE is now a bottleneck for the relevant \nexpertise for the organization and this cannot scale as demand for expertise in the organization \ngrows."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This creates several problems.\n\nFirst, \nthe CoE is now a bottleneck for the relevant \nexpertise for the organization and this cannot scale as demand for expertise in the organization \ngrows.\n\nSecond, it establishes an exclusive group \nof \u201cexperts\u201d in the organization, in contrast to \nan inclusive group of peers who can continue  \nto learn and grow together.\n\nThis exclusivity \nfosters bad norms and behaviors and can chip \naway at healthy organizational cultures.\n\nFinally, \nthe experts are removed from doing the work.\n\nThey are able to make recommendations  \nor establish generic \u201cbest practices\u201d but  \nthe path from the generic learning to the \nimplementation of real work is left up to  \nthe learners.\n\nFor example, experts will build  \na workshop on how to containerize an \napplication, but they rarely or never actually \ncontainerize applications.\n\nThis disconnect \nbetween theory and hands-on practice will \neventually threaten their expertise."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "73\nAccelerate: State of DevOps 2019    |     How Do We Transform?While some see success in Training Centers, \nthey require dedicated resources and programs \nto execute both the original program and \nsustained learning.\n\nMany companies have set \naside incredible resources to make their \nTraining Programs effective: They have entire \nbuildings dedicated to a separate, creative \nenvironment, and staff devoted to create \ntraining materials and assess progress.\n\nAdditional resources are then needed to assure \nthat the learning is sustained and propagated \nthroughout the organization.\n\nThe organization \nhas to provide support for the teams that \nattended the Training Center, to help ensure \ntheir skills and habits are continued back  \nin their regular work environments, and that old \nwork patterns aren\u2019t resumed.\n\nIf these resources \naren\u2019t in place, organizations risk all of their \ninvestments going to waste."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "If these resources \naren\u2019t in place, organizations risk all of their \ninvestments going to waste.\n\nInstead of a Center \nwhere teams go to learn new technologies and processes to spread to the rest of the \norganization, new habits stay in the Center, \ncreating another silo, albeit a temporary one.\n\nThere are also similar limitations as in the CoE:  \nIf only the Training Center staff (or other, \ndetached \u201cexperts\u201d) are creating workshops \nand training materials, what happens if they \nnever actually do the work?"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "74\nAccelerate: State of DevOps 2019    |     How Do We Transform?Low Medium High Elite\nTraining Center 27% 21% 18% 14%\nCenter of Excellence 34% 34% 20% 24%\nProof of Concept but Stall 41% 32% 20% 16%\nProof of Concept as a Template 16% 29% 29% 30%\nProof of Concept as a Seed 21% 24% 29% 30%\nCommunities of Practice 24% 51% 47% 57%\nBig Bang 19% 19% 11% 9%\nBottom-up or Grassroots 29% 39% 46% 46%\nMashup 46% 42% 34% 38%HEATMAP OF DEVOPS TRANSFORMATION \nSTRATEGIES BY PERFORMANCE PROFILE"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "75\nAccelerate: State of DevOps 2019    |     How Do We Transform?Scaling strategies that work  \nWe conducted an additional cluster analysis to \nunderstand the strategies used most often by  \nhigh and elite performers, and identify four model \npatterns that emerge.\n\n\u2022 Community Builders: This group focuses on \nCommunities of Practice, Grassroots, and PoCs  \n(as a Template and as a Seed, as described earlier).\n\nThis occurs 46% of the time.\n\n\u2022 University: This group focuses on education and \ntraining, with the majority of their efforts going into \nCenters of Excellence, Communities of Practice, \nand Training Centers.\n\nWe see this pattern only 9% \nof the time, suggesting that while this strategy \ncan be successful, it is not common and requires \nsignificant investment and planning to ensure that \nlearnings are scaled throughout the organization.\u2022 Emergent: This group has focused on \nGrassroots efforts and Communities of \nPractice."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This appears to be the most hands-\noff group and appears in 23% of cases.\n\n\u2022 Experimenters: Experimenters appeared in \n22% of cases.\n\nThis group has high levels of \nactivity in all strategies except Big Bang and \nDOJOs\u2014that is, all activities that focus on \ncommunity and creation.\n\nThey also include \nhigh levels in PoC but Stall, and because they \nare able to leverage this activity and remain \nhigh performers suggests they use this strategy \nto experiment and test out ideas quickly.\n\nWith these four patterns in mind, we can \nbegin to strategize how to organize a DevOps \ntransformation.\n\nHigh and elite performers have \nstarted to develop strategies for scaling that \norganizations can choose from to mirror those \nefforts and improve their own performance."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "FINAL  \nTHOUGHTS\nEvery decade has its own trendy software \nmethodology.\n\nWhile they all seem to feel better, \nhistory proves them to be ineffective.\n\nHowever, we \nsee continued evidence that DevOps delivers value, \nand for six consecutive years, we have statistically \nverified key capabilities and practices that help \norganizations improve their software development \nand delivery using DevOps methods.\n\nDevOps is not a trend, and will eventually be  \nthe standard way of software development and \noperations, offering everyone a better quality of life.\n\nWe thank everyone who contributed to this \nyear\u2019s survey, and hope our research helps you \nand your organization build better teams and \nbetter software\u2014while also leaving work at work."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "77\nAccelerate: State of DevOps 2019    |     Methodology\nMETHODOLOGY\nOur rigorous methodology goes beyond reporting raw numbers \nand looks at the predictive relationships between SDO \nperformance, organizational performance, technical practices, \ncultural norms, and productivity.\n\nIn this section, we describe our \nanalysis methods, as well as how we enlisted survey respondents \nand how we designed our questions, models, and constructs.\n\nFor \nmore detail,  we point you to Part II of our book Accelerate: The \nScience of Lean Software and DevOps .\n\nWe welcome questions about our survey methodology  \nat dora-data@google.com.\n\nResearch design\nThis study employs a cross-sectional, theory-based design.\n\nThis theory-based design is known as inferential, or inferential \npredictive, and is one of the most common types conducted  \nin business and technology research today."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This theory-based design is known as inferential, or inferential \npredictive, and is one of the most common types conducted  \nin business and technology research today.\n\nInferential design is \nused when purely experimental design is not possible and field \nexperiments are preferred\u2014for example, in business, when data \ncollection happens in complex organizations, not in sterile lab \nenvironments\u2014and companies won\u2019t sacrifice profits to fit into \ncontrol groups defined by the research team.\n\nTarget population and sampling method\nOur target population for this survey was practitioners and leaders \nworking in, or closely with, technology work and transformations \nand especially those familiar with DevOps.\n\nBecause we don\u2019t have  \na master list of these people\u2014we can describe them, but we don\u2019t \nknow exactly where they are, how to find them, or how many of them exist\u2014we used snowball sampling to obtain respondents."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "This means we promoted the survey via email lists, online promotions, \nand social media, and also asked people to share the survey with their \nnetworks, growing the sample like a snowball rolling down a hill \ncollects additional snow.\n\nOur sample is likely limited to organizations \nand teams that are familiar with DevOps, and as such, may be doing \nsome of it.\n\nA key to overcoming limitations in snowball sampling is to \nhave a diverse initial sample.\n\nWe accomplished this by leveraging our \nown contact lists as well as those of our sponsors for our initial \nsample, resulting in demographics and firmographics that largely \nmatch industry trends.\n\nCreating latent constructs\nWe formulated our hypotheses and constructs using previously \nvalidated constructs wherever possible.\n\nWhen we needed to create \nnew constructs, we wrote them based on theory, definitions, and \nexpert input."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "When we needed to create \nnew constructs, we wrote them based on theory, definitions, and \nexpert input.\n\nWe then took additional steps to clarify intent and \nwording to ensure that data collected from the final survey would \nhave a high likelihood of being reliable and valid.43 We used \nLikert-type44 questions for construct measurement, which  \nmake it possible to perform more advanced analyses.\n\n7743   We used Churchill\u2019s methodology: Churchill Jr, G. A.\n\n\u201cA paradigm for developing better measures  \nof marketing constructs, \u201d Journal of Marketing Research 16:1, (1979), 64\u201373.\n\n44   McLeod, S. A.\n\n(2008).\n\nLikert scale.\n\nRetrieved from www.simplypsychology.org/likert-scale.html"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "78\nAccelerate: State of DevOps 2019    |     Methodology\nStatistical analysis methods\n\u2022 Cluster analysis.\n\nWe use cluster analysis to identify our \nsoftware delivery performance profiles and scaling approaches \nused by high performers.\n\nIn this approach, those in one group \nare statistically similar to each other and dissimilar from those \nin other groups, based on our performance behaviors of \nthroughput and stability: deployment frequency, lead time, \ntime to restore service, and change fail rate."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "A solution using \nWard\u2019s method45 was selected based on (a) change in fusion \ncoefficients, (b) number of individuals in each cluster (solutions \nincluding clusters with few individuals were excluded), and (c) \nunivariate F-statistics.46 We used a hierarchical cluster-analysis \nmethod because it has strong explanatory power (letting us \nunderstand parent-child relationships in the clusters) and \nbecause we did not have any industry or theoretical reasons to \nhave a predetermined number of clusters.\n\nThat is, we wanted \nthe data to determine the number of clusters we should have.\n\nFinally, our dataset was not too big (hierarchical clustering is \nnot suitable for extremely large datasets).\u2022 Measurement model."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Finally, our dataset was not too big (hierarchical clustering is \nnot suitable for extremely large datasets).\u2022 Measurement model.\n\nPrior to conducting analysis, constructs \nwere identified using exploratory factor analysis with principal \ncomponent analysis using varimax rotation.47 Statistical tests \nfor convergent and divergent validity48 and reliability49 were \nconfirmed using average variance extracted (AVE), correlation, \ncronbach\u2019s alpha,50 and composite reliability.51 The constructs \npassed these tests, therefore exhibiting good psychometric  \nproperties .\n\n\u2022 Structural equation modeling .\n\nThe structural equation models \n(SEM)52 were tested using Partial Least Squares (PLS) analysis, \nwhich is a correlation-based SEM."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "\u2022 Structural equation modeling .\n\nThe structural equation models \n(SEM)52 were tested using Partial Least Squares (PLS) analysis, \nwhich is a correlation-based SEM.\n\nWe utilize PLS for our analysis \nfor several reasons: It does not require assumptions of \nnormality in the data, it is well suited to exploratory and \nincremental research, and the analysis optimizes for prediction \nof the dependent variable (vs testing for model fit of the data).53 \nSmartPLS 3.2.8 was used.\n\nWhen controlling for industry,54 no \nsignificant effect was found except for retail (at p < 0.05 level), \nas noted in the text.\n\nWhen controlling for enterprise \n(organizations with 5,000 or more employees), a significant \neffect was found (where p < 0.001).\n\nWhen controlling for years of \nexperience, no significant effect was found."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "When controlling for years of \nexperience, no significant effect was found.\n\nAll paths shown in \nthe SEM figures are p < .001, except the following, which are p < \n0.05: Continuous delivery \u2192 Burnout, Change approvals \u2192 \nSoftware delivery performance, Continuous integration \u2192 \nContinuous delivery, Culture \u2192 Software delivery performance \n(in the main model), and External search \u2192 Productivity, \nMonitoring \u2192 Technical debt, and Code maintainability \u2192 \nTechnical debt (in the productivity model).\n\n7845  Ward, J.H.\n\n\u201cHierarchical Grouping to Optimize an Objective Function.\n\n\u201d Journal of the American Statistical \nAssociation 58(1963): 236\u2013244.\n\n46  Urich,D., and B. McKelvey.\n\n\u201cGeneral Organizational Classification: An Empirical Test Using the United States and \nJapanese Electronic Industry.\n\n\u201d Organization Science 1, no.\n\n1 (1990): 99\u2013118.\n\n47  Straub, D., Boudreau, M. C., & Gefen, D. (2004).\n\nValidation guidelines for IS positivist research."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "\u201d Organization Science 1, no.\n\n1 (1990): 99\u2013118.\n\n47  Straub, D., Boudreau, M. C., & Gefen, D. (2004).\n\nValidation guidelines for IS positivist research.\n\nCommunications \nof the Association for Information systems, 13(1), 24.\n\n48 http://www.socialresearchmethods.net/kb/convdisc.htm\n49 http://www.socialresearchmethods.net/kb/reliable.php\n50 Nunnally, J.C. PsychometricTheory.\n\nNewYork: McGraw-Hill, 1978.\n\n51  Chin, W. W. (2010).\n\nHow to write up and report PLS analyses.\n\nIn Handbook of partial least squares (pp.\n\n655-690).\n\nSpringer, Berlin, Heidelberg.\n\n52 http://www.statisticssolutions.com/structural-equation-modeling/\n53  These methodology considerations are supported by: Chin, W.W. (1998).\n\nIssues and opinions on structural \nequation modeling.\n\nMIS Quarterly, 22(2), vii-xvi; Gefen, D., Straub, D. W., & Rigdon, E. E. (2011).\n\nAn update and"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "equation modeling.\n\nMIS Quarterly, 22(2), vii-xvi; Gefen, D., Straub, D. W., & Rigdon, E. E. (2011).\n\nAn update and \nextension to SEM guidelines for administrative and social science research.\n\nMIS Quarterly, 35(2), iii-xiv.\n\n; and \nHulland (1999).\n\nHulland, J.\n\n(1999).\n\nUse of partial east squares (PLS) in strategic management research: A review \nof four recent studies.\n\nStrategic Management Journal, 20(2), 195-204.\n\n54  http://methods.sagepub.com/reference/encyc-of-research-design/n77.xml"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "79\nAccelerate: State of DevOps 2019    |     Acknowledgements79ACKNOWLEDGEMENTS\nOur research is informed by our work and conversations with \nthe DevOps, Agile, and broader technical community; many \nthanks to all of our peers and colleagues who so openly share \ntheir experiences, stories, success, challenges, and failures.\n\nWe \nuse these to guide our literature review and shape our research \nquestions each year.\n\nThe authors would like to thank several people for their input \nand guidance on the report this year.\n\nAll acknowledgements \nare listed alphabetically by type of contribution.\n\nThanks to Adrian  Cockroft , Sam  Guckenheimer , Gene  Kim , \nand Kelsey  Hightower  for overall guidance on the report;  \nyour input as advisors helped highlight key research ideas  \nand direction."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Thanks to Adrian  Cockroft , Sam  Guckenheimer , Gene  Kim , \nand Kelsey  Hightower  for overall guidance on the report;  \nyour input as advisors helped highlight key research ideas  \nand direction.\n\nFor research advice, topic review, and input on measurement \nitems, we thank the Engineering  Productivity  Research  team \nat Google and in particular Collin  Green , Ciera  Jaspan , \nAndrea Knight-Dolan , and Emerson  Murphy -Hill .\n\nSpecial \nthanks to the Project  Aristotle  team for their insights on \npsychological safety and for sharing their research instrument.\n\nOur work is not possible without the careful review of subject \nmatter experts; for their time on supplementary topic review \nand input on measurement items, we are extremely grateful.\n\nMany thanks to Angie  Jones , Ashley  McNamara , Betsy  Beyer , \nBridget Kromhout , Courtney  Kissler , J. Paul  Reed , Mike  McGarr , \nNathen  Harvey , Seth  Vargo , and Xavier Velasquez ."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Many thanks to Angie  Jones , Ashley  McNamara , Betsy  Beyer , \nBridget Kromhout , Courtney  Kissler , J. Paul  Reed , Mike  McGarr , \nNathen  Harvey , Seth  Vargo , and Xavier Velasquez .\n\nSpecial thanks to David Huh  for providing analysis support for this \nyear\u2019s survey and report.\n\nWe thank our detailed technical readers who offered feedback and \nhelped us refine the report: Nathen Harvey , Tom Limoncelli , Caitie  \nMcCaffrey , Rachel Potvin , Corey Quinn , and Xavier Velasquez .\n\nThe authors would like to thank Cheryl Coup\u00e9  for her careful eye  \nand meticulous work editing this year\u2019s report.\n\nReport layout and design by Siobh \u00e1n Doyle."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "80\nAccelerate: State of DevOps 2019    |     Authors80AUTHORS\nDr. Nicole Forsgren leads the DORA team, now with Google Cloud.\n\nShe has led the \nlargest studies of DevOps to date, as the principal investigator on the State of DevOps \nReports for the past six years and lead author on the Shingo Publication Award-winning \nbook Accelerate: The Science of Lean Software and DevOps.\n\nShe has been a professor, \nsysadmin, and performance engineer.\n\nNicole\u2019s work  has been published in several \npeer-reviewed journals.\n\nNicole earned her PhD in Management Information Systems  \nfrom the University of Arizona.\n\nJez Humble Jez Humble is co-author of several books on software including Shingo \nPublication Award winner Accelerate, The DevOps Handbook, Lean Enterprise ,  \nand the Jolt Award-winning Continuous Delivery.\n\nHe has spent his career tinkering  \nwith code, infrastructure, and product development in companies of varying sizes  \nacross three continents."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "He has spent his career tinkering  \nwith code, infrastructure, and product development in companies of varying sizes  \nacross three continents.\n\nHe works for Google Cloud as a technology advocate, and \nteaches at UC Berkeley .Dr.\n\nDustin Smith is a human factors psychologist and senior user experience researcher \nat Google.\n\nHe has studied how people are affected by the systems  and environments \naround them in a variety of contexts: software engineering, free-to-play gaming, \nhealthcare, and military.\n\nHis research at Google has emphasized identifying areas where \nsoftware developers can feel happier and more productive during development.\n\nDustin \nreceived his PhD in Human Factors Psychology from Wichita State University.\n\nJessie Frazelle is an independent consultant.\n\nShe\u2019s been an engineer at various \nstartups as well as Google, Microsoft, and GitHub."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "Jessie Frazelle is an independent consultant.\n\nShe\u2019s been an engineer at various \nstartups as well as Google, Microsoft, and GitHub.\n\nShe\u2019s observed a lot of different \ndevelopment and infrastructure practices by working on the tools themselves, including \nDocker and Kubernetes, and by also being an end user of various PaaS.\n\nShe likes to see \nthings from all perspectives, jumping back and forth from developing tools to using them \nin production."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "81\nAccelerate: State of DevOps 2019    |     Appendix A81APPENDIX A\n  DEPLOY FREQUENCY\nTIME TO RESTORE SERVICELEAD TIME FOR CHANGES\n2 \u2013 2 \u2013\n2 \u2013 2 \u20134 \u2013 4 \u2013\n4 \u2013 4 \u20136 \u2013 6 \u2013\n6 \u2013 6 \u2013LOW       MED      HIGH      ELITEMTTR\nCHANGE FAIL USERDEPLOY OFTEN\nLEAD TIME\nLOW       MED      HIGH       ELITELOW       MED      HIGH      ELITE\nLOW       MED      HIGH      ELITECHANGE FAIL RATEDEPLOY FREQUENCY:\n1 = Fewer than once per six months\n2 =  Between once per month  \nand once every 6 months\n3 = Between once per week and once per month\n4 = Between once per day and once per week\n5 = Between once per hour and once per day\n6 = On demand (multiple deploys per day)\nLEAD TIME FOR CHANGES\n1 = More than six months\n2 = Between one month and six months\n3 = Between one week and one month\n4 = Between one day and one week\n5 = Less than one day\n6 = Less than one hour\nTIME TO RESTORE SERVICE\n1 = More than six months\n2 = Between one month and six months\n3 = Between one week and one month\n4 = Between one day and one week\n5 = Less than one day\n6 = Less than one hour\nCHANGE FAIL RATE\n1 = 76%-100%\n2 = 61%-75%\n3 = 46%-60%\n4 = 31%-45%\n5 = 16%-30%\n6 = 0%-15%"}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "82\nAccelerate: State of DevOps 2019    |     Appendix B82APPENDIX B\nStrategies for Scaling DevOps\n\u2022 Training Center (sometimes referred to as a DOJO) - Where \npeople are taken out of their normal work routines to learn new \ntools or technologies, practices, and even culture for a period  \nof time, and then put back into their normal work environment \nwith the goal (hope?)\n\nthat their new way of working will stick \nand possibly even spread out to others.\n\n\u2022 Center of Excellenc e - Where all expertise lives and then \nconsults out to others.\n\n\u2022 Proof of Concept but Stall - A Proof of Concept (PoC) project, \nwhere a central team is given the freedom to build in whatever \nway they feel is best, often by breaking organizational norms \n(and often formal rules).\n\nHowever, the effort stalls after the PoC.\n\n\u2022 Proof of Concept as a Template - Starting with a small Proof of \nConcept (PoC) project (described above), and then replicating \nthis pattern in other groups, using the first as a pattern."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "\u2022 Proof of Concept as a Template - Starting with a small Proof of \nConcept (PoC) project (described above), and then replicating \nthis pattern in other groups, using the first as a pattern.\n\n\u2022 Proof of Concept as a Seed - Starting with a small Proof of \nConcept (PoC), then spreading PoC knowledge to other groups.\n\nThis is done by breaking up PoC (either the first PoC group or \nsubsequent/ parallel PoC groups) and sending them to other groups as a way to share the knowledge and practices learned.\n\nThis may also be described as a rotation, where the PoC \nmembers are immersed in other teams to spread the new \npractices and culture and used as teachers.\n\nThey may stay in \nthis new group indefinitely or just long enough to ensure the \nnew practices are sustainable."}, {"source": "sources/todo/state-of-devops-2019.pdf", "content": "They may stay in \nthis new group indefinitely or just long enough to ensure the \nnew practices are sustainable.\n\n\u2022 Communities of Practice -  Where groups that share common \ninterests in tooling, language, or methodologies are fostered \nwithin an organization to share knowledge and expertise with \neach other, across teams, and around the organization.\n\n\u2022 Big Bang - Where the whole organization transforms  \nto DevOps methodologies (however they choose to  \n define it) all  at once, often with top-down directive.\n\n\u2022 Bottom-up or Grassroots  - Where small teams close to the work \npull together resources to transform and then informally share \ntheir success throughout the organization and scale without \nany formal organizational support or resources.\n\n\u2022 Mashup - Where the org implements several approaches \ndescribed above, often only partially executed or with \ninsufficient resources or prioritization to enable success."}]