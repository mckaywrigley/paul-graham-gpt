[{"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "Rethinking \nProductivity \nin Sof  tware \nEngineering\n\u2014\nEdited by\nCaitlin Sadowski\nThomas Zimmermann"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "Edited by\u00a0\nCaitlin\u00a0Sadowski\nThomas\u00a0ZimmermannRethinking Productivity in \nSoftware Engineering"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "Rethinking Productivity in Software Engineering\nISBN-13 (pbk): 978-1-4842-4220-9                     IS BN-13 (electronic): 978-1-4842-4221-6\nhttps://doi.org/10.1007/978-1-4842-4221-6\nLibrary of Congress Control Number: 2019934471\nCopyright \u00a9 The Author(s) and Editor(s) 2019\nThis work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is \nconcerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, \nreproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, \nelectronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed.\nOpen Access  This b ook is\u00a0licensed\u00a0under the terms of the Creative Commons Attribution-\nNonCommercial-NoDerivatives 4.0 International License (http://creativecommons.org/licenses/\nby-nc-nd/4.0/), which permits any noncommercial use,  sharing, distribution and reproduction in \nany medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to \nthe Creative Commons license and indicate if you modified the licensed material. You do not have permission under \nthis license to share adapted material derived from this book or parts of it.\nThe images or other third party material in this book are included in the book\u2019s Creative Commons license, unless \nindicated otherwise in a credit line to the material. If material is not included in the book's Creative Commons \nlicense and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.\nChapter 9 is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://\ncreativecommons.org/licenses/by/4.0/). For further details, see license information in the chapter.\nTrademarked names, logos, and images may appear in this book. Rather than use a trademark symbol with every \noccurrence of a trademarked name, logo, or image we use the names, logos, and images only in an editorial fashion \nand to the benefit of the trademark owner, with no intention of infringement of the trademark.\nThe use in this publication of trade names, trademarks, service marks, and similar terms, even if they are not identified \nas such, is not to be taken as an expression of opinion as to whether or not they are subject to proprietary rights.\nWhile the advice and information in this book are believed to be true and accurate at the date of publication, neither \nthe authors nor the editors nor the publisher can accept any legal responsibility for any errors or omissions that may \nbe made. The publisher makes no warranty, express or implied, with respect to the material contained herein.\nManaging Director, Apress Media LLC: Welmoed Spahr\nAcquisitions Editor: Susan McDermott\nDevelopment Editor: James Markham\nCoordinating Editor: Jill Balzano\nCover image designed by Freepik (www.freepik.com)\nDistributed to the book trade worldwide by Springer Science+Business Media New\u00a0York, 233 Spring Street, 6th \nFloor, New\u00a0York, NY 10013. Phone 1-800-SPRINGER, fax (201) 348-4505, e-mail orders-ny@springer-sbm.com, or \nvisit www.springeronline.com. Apress Media, LLC is a California LLC and the sole member (owner) is Springer \nScience + Business Media Finance Inc (SSBM Finance Inc). SSBM Finance Inc is a Delaware  corporation.\nFor information on translations, please e-mail rights@apress.com, or visit www.apress.com/rights-permissions.\nApress titles may be purchased in bulk for academic, corporate, or promotional use. eBook versions and licenses \nare also available for most titles. For more information, reference our Print and eBook Bulk Sales web page at www.\napress.com/bulk-sales.\nAny source code or other supplementary material referenced by the author in this book is available to readers on"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "apress.com/bulk-sales.\nAny source code or other supplementary material referenced by the author in this book is available to readers on \nGitHub via the book's product page, located at www.apress.com/9781484242209. For more detailed information, \nplease visit www.apress.com/source-code.\nPrinted on acid-free paperCaitlin\u00a0Sadowski\nMountain View, CA, USAThomas\u00a0Zimmermann\nBellevue, WA, USA"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "To Mr. Wiggles.\n\u2014Caitlin Sadowski\nTo my parents.\n\u2014Thomas Zimmermann"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "vAbout the Editors  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd xvii\nAcknowledgments  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd xix\nIntroduction  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd xxiTable of Contents\nPart I: Measuring Productivity: No Silver Bullet  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 1\nChapter 1: The Mythical 10x Programmer  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 3\nSome Work Time Variability Data  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 3\nInsisting on Homogeneity \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 4\nDeciding What We Even Mean  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 5\nUninsisting on Homogeneity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 6\nQuestioning the Base Population  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 6\nIt\u2019s Not Only About Development Effort  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 7\nAre Slower Programmers Just More Careful?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 7\nSecondary Factors Can Be Important  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 8\nThe Productivity Definition Revisited  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 9\nHow Would Real People Work?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 9\nSo What?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 10\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 10\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 11\nChapter 2 : No Single Metric Captures Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 13\nWhat\u2019s Wrong with Measuring Individual Performers?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 14\nWhy Do People Want to Measure Developer Productivity?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 14"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "viWhat\u2019s Inherently Wrong with a Single Productivity Metric?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 15\nProductivity Is Broad  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 15\nFlattening/Combining Components of a Single Aspect Is Challenging  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 16\nConfounding Factors  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 16\nWhat Do We Do Instead at Google?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 17\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 19\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 19\nChapter 3: Why We Should Not Measure Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 21\nUnintended Consequences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 22\nExplaining Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 23\nDealing with Change  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 24\nManagers as Measurers  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 25\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 26\nPart II: Introduction to Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 27\nChapter 4 : Defining Productivity in Software Engineering  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 29\nA Short History of Software Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 30\nTerminology in the General Literature  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 32\nProductivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 32\nProfitability  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 33\nPerformance  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 33\nEfficiency and Effectiveness  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 33\nInfluence of Quality  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 33\nAn Integrated Definition of Software Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 34\nSummary \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 36\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 36\nAcknowledgements \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 37\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 37Table of Con TenTs"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "viiChapter 5 : A Software Development Productivity Framework  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 39\nProductivity Dimensions in Software Development  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 40\nVelocity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 40\nQuality  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 40\nSatisfaction  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 41\nLenses  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 41\nThe Productivity Framework in Action: Articulating Goals, Questions, and Metrics  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 42\nExample 1: Improving Productivity Through an Intervention  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 43\nExample 2: Understanding How Meetings Impact Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 44\nCaveats  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 45\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 46\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 46\nChapter 6 : Individual, Team, Organization, and Market: Four Lenses of  \nProductivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 49\nThe Individual  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 49\nThe T eam \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 50\nThe Organization  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 51\nThe Market  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 52\nFull-Spectrum Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 53\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 53\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 53\nChapter 7 : Software Productivity Through the Lens of Knowledge Work  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 57\nA Brief History of Knowledge Work  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 57\nTechniques for Measuring Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 58\nOutcome-Oriented Techniques  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 58\nProcess-Oriented Techniques  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 59\nPeople-Oriented Techniques  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 60\nMulti-oriented Techniques  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 60Table of Con TenTs"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "viiiDrivers That Influence Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 61\nSoftw are Developers vs \ufffd Knowledge Workers: Similar or Different?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 63\nSummary \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 64\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 64\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 65\nPart III: The Context of Productivity \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd67\nChapter 8 : Factors That Influence Productivity: A Checklist  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 69\nIntroduction  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 69\nA Brief Histor y of Productivity Factors Research  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 70\nThe List of Technical Factors  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 70\nProduct Factors  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 70\nProcess Factors  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 72\nDevelopment Environment  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 73\nThe List of Soft Factors  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 74\nCorporate Culture  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 74\nTeam Culture  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 75\nIndividual Skills and Experiences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 76\nWork Environment  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 78\nProject  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 79\nSummary \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 79\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 80\nAcknowledgments  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 80\nAppendix: Review Design  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 80\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 81\nChapter 9 : How Do Interruptions Affect Productivity?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 85\nIntroduction  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 85\nControlled Experiments  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 86\nWhat Is the Aim of an Experiment?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 87\nA Typical Interruptions Experiment  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 87Table of Con TenTs"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "ixHow Is Disruptiveness of an Interruption Measured?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 88\nInterruptions Cause Errors  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 89\nMoving Controlled Experiments Out of the Lab  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 90\nSummary: Controlled Experiments  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 91\nCognitive Models  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 91\nWhat Are Cognitive Models?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 92\nWhat Can Cognitive Models Predict About the Impact of Interruptions on Productivity?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd93\nSummary: Cognitive Models  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 94\nObservational Studies  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 94\nObservational Studies of the Workplace  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 94\nBenefits and Detriments of Interruptions  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 95\nStress, Individual Differences, and Interruptions  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 96\nProductivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 96\nStrategies for Dealing with Interruptions  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 97\nSummary: Observational Studies  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 97\nKey Insights \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 98\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 99\nAcknowledgments  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 99\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 99\nChapter 10 : Happiness and the Productivity of Software Engineers  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 109\nWhy the Industry Should Strive for Happy Developers  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 110\nWhat Is Happiness,  and How Do We Measure It?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 110\nScientific Grounds of Happy and Productive Developers  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 111\nHow Happy Are Software Developers?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 112\nWhat Makes Developers Unhappy?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 113\nWhat Happens When Developers Are Happy (or Unhappy)?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 114\nAre Happy Developers More Productive?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 118\nPotential Impacts of Happiness on Other Outcomes  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 120\nWhat Does the Future Hold?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 121\nFurther Reading  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 121Table of Con TenTs"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 122\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 122\nChapter 11 : Dark Agile: Perceiving People As Assets, Not Humans  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 125\nRevisiting the Agile Manifesto  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 125\nAgile in Global Outsour cing Setups  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 126\nTracking Work to Increase Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 127\nDaily Stand-Up Meeting to Monitor Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 128\nStressful Work Environment  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 128\nCost of Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 129\nOpen Questions for Productivity in Software Engineering  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 131\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 132\nAcknowledgments  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 132\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 133\nPart IV: Measuring Productivity in Practice  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 135\nChapter 12 : Developers\u2019 Diverging Perceptions of Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 137\nQuantifying Productivity: Measuring vs \ufffd Perceptions  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 137\nStudying Software Developers\u2019 Productivity Perceptions  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 138\nThe Cost of Context Switching  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 139\nA Productive Workday in a Developer\u2019s Life  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 139\nDevelopers Expect Different Measures for Quantifying Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 140\nCharacterizing Software Developers by Perceptions of Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 141\nOpportunities for Improving Developer Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 143\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 145\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 145\nChapter 13 : Human-Centered Methods to Boost Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 147\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 155\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 155Table of Con TenTs"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xiChapter 14 : Using Biometric Sensors to Measure Productivity \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 159\nOperationalizing Productivity for Measurement  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 159\nWhat the Ey e Says About Focus  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 160\nObserving Attention with EEG  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 161\nMeasuring Rumination  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 163\nMoving Forward  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 164\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 165\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 165\nChapter 15 : How Team Awareness Influences Perceptions of Developer \nProductivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 169\nIntroduction  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 169\nAwareness and Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 171\nEnabling Awareness in Collaborative Software Development  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 172\nAggregating Awareness Information into Numbers  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 173\nAggregating Awareness Information into Text  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 174\nRethinking Productivity and Team Awareness  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 175\nKey ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 177\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 177\nChapter 16 : Software Engineering Dashboards: Types, Risks, and Future  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 179\nIntroduction  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 179\nDashboar ds in Software Engineering  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 181\nDeveloper Activity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 181\nTeam Performance  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 182\nProject Monitoring and Performance  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 183\nCommunity Health  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 184\nSummary  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 184\nRisks of Using Dashboards  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 185Table of Con TenTs"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xiiRethinking Dashboards in Software Engineering \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 188\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 189\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 189\nChapter 17 : The COSMIC Method for  Measuring the Work-  Output  \nComponent of Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 191\nMeasurement of Functional Size  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 192\nThe COSMIC Method  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 193\nDiscussion of the COSMIC Model  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 195\nCorrelation of COSMIC Sizes with Development Effort  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 199\nAutomated COSMIC Size Measurement  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 201\nConclusions  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 202\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 202\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 203\nChapter 18 : Benchmarking: Comparing Apples to Apples  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 205\nIntroduction  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 205\nThe Use of Standar ds \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 206\nFunctional Size Measurement  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 206\nReasons for Benchmarking  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 208\nA Standard Way of Benchmarking  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 209\nNormalizing  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 210\nSources of Benchmark Data  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 211\nISBSG Repository  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 211\nInternal Benchmark Data Repository  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 212\nBenchmarking in Practice  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 212\nFalse Incentives  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 214\nSummary \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 214\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 215\nFurther Reading  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 216Table of Con TenTs"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xiiiPart V: Best Practices for Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 219\nChapter 19 : Removing Software Development Waste to Improve Productivity  \ufffd\ufffd\ufffd\ufffd221\nIntroduction  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 221\nTaxonomy of Software Development Waste  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 222\nBuilding the Wrong Feature or Product  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 223\nMismanaging the Backlog  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 224\nRework  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 225\nUnnecessarily Complicated or Complex Solutions  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 226\nExtraneous Cognitive Load  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 227\nPsychological Distress  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 228\nKnowledge Loss  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 229\nWaiting/Multitasking \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 230\nIneffective Communication  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 231\nAdditional Wastes in Pre-agile Projects  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 232\nDiscussion  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 234\nNot All Problems Are Wastes  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 234\nReducing Waste  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 235\nConclusion  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 238\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 239\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 239\nChapter 20 : Organizational Maturity: The Elephant Affecting Productivity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 241\nBackground  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 241\nThe Process Maturity Fr amework  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 242\nThe Impact of Maturity on Productivity and Quality  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 245\nUpdating Maturity Practices for an Agile-DevOps Environment  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 246\nSummary \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 248\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 248\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 248Table of Con TenTs"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xivChapter 21 : Does Pair Programming Pay Off?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 251\nIntroduction: Highly Productive Programming  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 251\nStudying Pair Programming  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 252\nSoftware Development As Knowledge Work  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 253\nWhat Actually Matters in Industrial Pair Programming  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 254\nConstellation A: System Knowledge Advantage  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 255\nConstellation B: Collective System Knowledge Gap  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 256\nConstellation C: Complementary Knowledge  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 256\nSo, Again: Does Pair Programming Pay Off?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 257\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 258\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 258\nChapter 22 : Fitbit for Developers: Self-  Monitoring at W ork \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 261\nSelf-Monitoring to Quantify Our Lives  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 261\nSelf-Monitoring Softw are Developers\u2019 Work  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 262\nSupporting Various Individual Needs Through Personalization  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 264\nSelf-Reporting Increases Developers\u2019 Awareness About Efficiency  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 265\nRetrospection About Work Increases Developers\u2019 Self-Awareness  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 265\nActionable Insights Foster Productive Behavior Changes  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 266\nIncreasing Team Awareness and Solving Privacy Concerns  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 267\nFostering Sustainable Behaviors at Work  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 268\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 269\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 269\nChapter 23 : Reducing Interruptions at Work with FlowLight  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 271\nThe Cost of Interruptions at Work  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 271\nFlowLight: A Light to Indicate When to Interrupt  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 272\nEvaluation and Benefits of FlowLight  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 273\nKey Success Factors of FlowLight  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 274\nPay Attention to Users  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 274\nFocus on Simplicity  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 275Table of Con TenTs"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xvPay Attention to Privacy Concerns  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 276\nFocus on Value First, Not on Accuracy  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 276\nLet Users Surprise You \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 277\nSummary \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 277\nGet Your Own FlowLight \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 277\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 278\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 278\nChapter 24 : Enabling Productive Software Development by  \nImproving Information Flow  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 281\nMylyn: Improving Information Flow for the Individual Software Developer  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 282\nTasktop Sync: Improving Information Flow for the Development Team  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 285\nTasktop Integration Hub: Improving Information Flow for a Software  \nDevelopment Organization  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 288\nTakeaways  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 290\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 291\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 291\nChapter 25 : Mindfulness as a Potential Tool for Productivity \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 293\nA Definition of Mindfulness  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 293\nMindfulness for Productivity?  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 294\nCognitive Benefits of Mindfulness  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 295\nMindfulness and Emotional Intelligence  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 296\nPitfalls of Mindfulness  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 297\nMindfulness Breaks  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 298\nConclusion  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 299\nKey Ideas \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 300\nReferences  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 300\n Index  \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 303Table of Con TenTs"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xviiAbout the Editors\nDr.\u00a0Caitlin \u00a0Sadowski  is a software engineer at Google in Mountain View, California, \nwhere she aims to understand and improve developer workflows. Currently, she is \nhelping Chrome developers make data-driven decisions as the manager of the Chrome \nMetrics team. In the past, she made static analysis useful at Google by creating the \nTricorder program analysis platform, and then co-founded a team that provides ongoing \ninsight into how developers spend their time and what makes them effective (the \nEngineering Productivity Research team). She is a committee member of top software \nengineering and programming language conferences (ICSE, ESEC/FSE, OOPSLA, and \nPLDI). She has a PhD from the University of California at Santa Cruz where she worked \non a variety of research topics related to programming languages, software engineering, \nand human computer interaction. She enjoys baking with her three-year-old, Naru \n(otherwise known as Mr. Wiggles).\nDr.\u00a0Thomas \u00a0Zimmermann  is a senior researcher at Microsoft Research, where \nhe analyzes data for a living. Currently, he works on the productivity of software \ndevelopers and data scientists at Microsoft. In the past, he analyzed data from digital \ngames, branch structures, and bug reports. He is the co-editor in chief of the Empirical \nSoftware Engineering journal and serves on the editorial boards of IEEE Transactions on \nSoftware Engineering, IEEE Software, Journal of Systems and Software, and Journal of \nSoftware: Evolution and Process. He is a committee member of top software engineering \nconferences (ICSE, ESEC/FSE, and ASE) and the chairman of ACM SIGSOFT.\u00a0He \npreviously edited books on recommender systems (Springer) and data science in \nsoftware engineering (Morgan Kaufmann). He has a PhD from Saarland University \nwhere he worked on mining software repositories. He likes movies, enjoys football at  \n-6 degrees Fahrenheit, and collects unicorns."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xixAcknowledgments\nThere are many people who made this book possible. We gratefully acknowledge the \nextensive and professional work of our authors and the Apress team, especially Todd \nGreen, Jill Balzano, and Susan McDermott. Special thanks to the staff and the organizers \nof Schloss Dagstuhl ( https://www.dagstuhl.de , where computer scientists meet), who \nhosted the original meeting that was the genesis of this book. Special thanks also to \nJaeheon Yi and Ambrose Feinstein, without whom it would have been impossible to find \nthe time to work on this."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xxiIntroduction\nCaitlin Sadowski\nThomas Zimmermann\nAs Marc Andreessen put it, software is eating the world [ 1], and there is an ever-  \ngrowing demand on software being built. Despite the immense growth in the number \nof professional software developers, there is still a shortage. To satisfy this demand, we \nneed more productive software engineers.\nOver the past four decades, there has been significant research on understanding \nand improving the productivity of software developers and teams. A substantial amount \nof work has examined the meaning of software productivity. Much of this introduced \ndefinitions of productivity (many of them!), considered organizational issues associated \nwith productivity, and focused on specific tools and approaches for improving \nproductivity. In fact, most of the seminal work on software productivity is from the 1980s \nand 1990s (Peopleware, Mythical Man-Month, Personal Software Process).\n Why This Book?\nHistorically, this book began as a weeklong workshop in Dagstuhl, Germany [ 2]. \nThe motivation for this seminar was that since the 1980s and 1990s many things \nhave changed and that it was time to revisit what makes modern  software engineers \nproductive.\nWhat has changed since the 1980s and 1990s? Today\u2019s software teams and engineers \nare often global and collaborate across borders and time zones, practice agile software \ndevelopment, frequently use social coding tools such as Stack Overflow and GitHub, and \noften work on laptops or their own personal devices. Today\u2019s software engineers must \ndeal with unprecedented complexity, can build large systems fast in the cloud, can store \nmillions (or even billions) of lines of code in a single repository, and can release software \nfrequently, often multiple times a day. They use on average 11.7 communication \nchannels such as web search, blogs, Q&A sites, and social networking sites [85]; in 1984, \nthe primary communication channels for software engineers were phone calls and"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xxiiin- person meetings [27]. The human-computer interaction (HCI) and computer-\nsupported cooperative work (CSCW) communities have made significant advances \nin supporting knowledge workers to become more productive that one might also \ntransfer to software engineers. Furthermore, the wide availability of data about software \ndevelopment enables a more sophisticated analysis of software productivity.\nThe goal of this seminar was to rethink, discuss, and address open issues of \nproductivity in software development and figure out how to measure and foster \nproductive behavior of software developers. Specifically, the discussion at the seminar \nfocused on the following questions:\n\u2022 What does productivity mean for individuals, teams, and \norganizations?\n\u2022 What are the dimensions and factors of productivity?\n\u2022 What are the purposes and implications of measuring productivity?\n\u2022 What are the grand challenges in research on productivity?\nThis book explores what productivity means for modern software development. \nThe chapters were written by participants at the Dagstuhl seminar (see Figure\u00a0 1), plus \nnumerous other experts. Our goal is to summarize and distribute their combined \nexperience, wisdom, and understanding about software productivity.InTrodu CTIon"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xxiii\nFigure 1.  The attendees of the Dagstuhl seminar called \u201cRethinking Productivity \nin Software Engineering\u201d in March 2017. The two editors of this book are in the \nsecond row on the right hand side.\n About This Book\nThis book is organized into five topic areas. We begin with a set of essays outlining \nchallenges with measuring productivity (\u201cMeasuring Productivity: No Silver Bullet\u201d). \nThis is followed by essays focused on breaking down productivity into its components \n(\u201cIntroduction to Productivity\u201d) and essays that identify productivity factors and how \nthey may give a different perspective on productivity (\u201cThe Context of Productivity\u201d). \nEven though productivity is difficult to measure in general, we include specific case \nstudies focused on measuring some aspect of productivity (\u201cMeasuring Productivity in \nPractice\u201d). We finish with a series of essays on interventions that do work to improve \nproductivity (\u201cBest Practices for Productivity\u201d).InTrodu CTIon"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xxiv Measuring Productivity: No Silver Bullet\nAre some programmers indeed ten times more productive than others, as some people \nclaim? Lutz Prechelt digs into the data to address this question in Chapter 1. Ciera Jaspan \nand Caitlin Sadowski then explain what is inherently wrong with focusing on a single \nproductivity metric (and what you can do instead) in Chapter 2. Amy J. Ko describes a \nthought experiment identifying the unintended consequences of measuring productivity \nin Chapter 3.\n An Introduction to\u00a0Productivity\nWe begin this part with an overview of ways that productivity has been defined in the \npast with Chapter 4 by Stefan Wagner and Florian Deissenboeck. In Chapter 5, Caitlin \nSadowski, Margaret-Anne Storey, and Robert Feldt describe a framework for breaking down \nproductivity into three dimensions: quality, velocity, and satisfaction\u2014and how to apply \nthat framework when considering productivity metrics. Amy J. Ko then describes how it is \nimportant to consider productivity in context through a particular lens in Chapter 6.  \nEmerson Murphy-Hill and Stefan Wagner conclude this introduction to productivity \nconcepts with an overview of productivity research in a related context (knowledge \nwork) in Chapter 7.\n The Context of\u00a0Productivity\nThere are many different factors that may affect the productivity of software engineers. \nStefan Wagner and Emerson Murphy-Hill overview the space of these factors in  \nChapter 8. We do a deep dive into two of these factors in the following two chapters: \nDuncan Brumby, Christian Janssen, and Gloria Mark provide an overview of research \non interruptions in Chapter 9, and then Daniel Graziotin and Fabian Fagerholm discuss \nresearch about the relationship between happiness and productivity in Chapter 10. We \nend this part with Pernille Bj\u00f8rn\u2019s cautionary tale about the importance of considering \nsocial factors for productivity in Chapter 11.InTrodu CTIon"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xxv Measuring Productivity in\u00a0Practice\nAndr\u00e9 N.\u00a0Meyer, Gail C. Murphy, Thomas Fritz, and Thomas Zimmermann dig into \nthe varying ways developers perceive productivity and the implications for self-\nreported productivity measurement in Chapter 12. Brad A.\u00a0Myers, Amy J. Ko, Thomas \nD.\u00a0LaToza, and YoungSeok Yoon then discuss how qualitative research methods \ncan aid in understanding productivity challenges or improvements in Chapter 13. \nMarieke van Vugt then overviews the benefits and limitations of using eye trackers and \nelectroencephalography (EEG) scans to measure productivity in Chapter 14. Christoph \nTreude and Fernando Figueira Filho discuss the importance of awareness of what is \ngoing on in the larger team (team awareness) for productivity and investigate how team \nawareness can be measured in Chapter 15. In Chapter 16, Margaret-Anne Storey and \nChristoph Treude overview benefits and challenges of presenting productivity metrics in \ndashboards.\nSome organizations perform productivity benchmarking using International \nOrganization for Standardization (ISO) standard methods; the final two chapters \ngive a perspective into this world. Charles Symons overviews one such measurement \n(COSMIC) in Chapter 17. Frank Vogelezang and Harold van Heeringen describe a case \nstudy of how organizations use a benchmarking method like COSMIC in Chapter 18.\n Best Practices for\u00a0Productivity\nThere are too many \u201cbest practices\u201d for improving the productivity of software \nengineers to include in this book, so we give an overview of different interventions \nthat provide a variety of perspectives into what such an intervention could look \nlike. Todd Sedano, Paul Ralph, and C\u00e9cile P\u00e9raire describe how changing the mind-\nset from \u201cimproving productivity\u201d to \u201creducing waste\u201d can make productivity \nimprovements tractable in Chapter 19. Bill Curtis describes the importance of having \nclear, mature processes in Chapter 20. In Chapter 21, Franz Zieris and Lutz Prechelt \ngive an answer to the question of whether pair programming pays off.\nThere are also tool-supported interventions to improve productivity. The \nbenefits and challenges of self-tracking for productivity are described by Andr\u00e9 \nN.\u00a0Meyer, Thomas Fritz, and Thomas Zimmermann in Chapter 22. Manuela Z\u00fcger, \nAndr\u00e9 N.\u00a0Meyer, Thomas Fritz, and David Shepherd present a system to surface \ninformation about when to interrupt software engineers in Chapter 23. In Chapter \n24, Gail C.\u00a0Murphy, Mik Kersten, Robert Elves, and Nicole Bryan review an evolution InTrodu CTIon"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xxviof technologies focused on improving the access and flow of information between \nthe humans and tools involved in creating software systems. Lastly, Marieke van \nVugt focuses inward and overviews the role of mindfulness in productivity in \nChapter 25.\n The Future of\u00a0Software Productivity\nWhile these essays were written by experts, they are hardly complete. Software \ndevelopment is always changing, and there is a lot we don\u2019t know yet about software \nproductivity. At the Dagstuhl seminar, the attendees identified several open questions \nand grand challenges. The three main grand challenges are building a body of knowledge \nabout what we know about software productivity, improving the measurement of \nproductivity, and affecting and improving software productivity through interventions.\n Building a\u00a0Body of\u00a0Knowledge About\u00a0Software  \nProductivity\nThe following are the next steps towards building a body of knowledge about software \nproductivity:\n\u2022 Develop a theoretical framework for productivity.\n\u2022 Define laws or rules of productivity  similar to the laws of software \nevolution. For example, a happier developer is a more productive \ndeveloper; a participatory culture in a team is more productive.\n\u2022 Examine the difference of software development to all other kinds \nof knowledge workers and learn what is unique about software \ndevelopment and what is not.\n\u2022 Develop a mapping from questions on productivity to a methodology \nof studying it.InTrodu CTIon"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xxvii Improving the\u00a0Measurement of\u00a0Productivity\nThe following are the next steps for improving the measurement of productivity:\n\u2022 Collect examples of where measuring productivity was done well \nwith good outcomes. Distill the insights and guidelines from this \ncollection.\n\u2022 Develop an approach that can track \u201ceverything\u201d at every moment, \nincluding detailed data across a company; biometric data from \nindividuals; and data on aspects such as satisfaction, mood, fatigue, \nand motivation. Use the data to profile development work and \nproductivity. Obviously, it will be hard (if not impossible) to get the \nprivacy right for an approach like this.\n Improve the\u00a0Productivity of\u00a0Software Engineers\nThe following are the next steps for improving the productivity of software engineers:\n\u2022 Understand how to support and facilitate productivity.\n\u2022 Conduct a multitude of comparative studies on productivity at \ndifferent companies and on different interventions.\nExciting times are ahead. We hope you enjoy this book!\n References\n [1] M arc Andreessen. Why Software Is Eating The World. Wall Street \nJournal 2011. https://www.wsj.com/articles/SB1000142405311\n1903480904576512250915629460\n [2] Thom as Fritz, Gloria Mark, Gail C.\u00a0Murphy, Thomas \nZimmermann. Rethinking Productivity in Software Engineering \n(Dagstuhl Seminar 17102). Dagstuhl Reports, Volume 7, Number \n3, March 2017, pages 19\u201326. http://dx.doi.org/10.4230/\nDagRep.7.3.19InTrodu CTIon"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "xxviii [3] M.-A.\u00a0Storey, A.\u00a0Zagalsky, F .\u00a0F . Filho, L.\u00a0Singer, and D.\u00a0M. German. \nHow social and communication channels shape and challenge a \nparticipatory culture in software development. IEEE Transactions \non Software Engineering, 43(2):185\u2013204, 2017.\n [4] T.\u00a0DeMarco and T.\u00a0Lister. Programmer performance and the \neffects of the workplace. In Proceedings of the 8th international \nconference on Software engineering, pages 268\u2013272. IEEE \nComputer Society Press, 1985.InTrodu CTIon"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "PART I\nMeasuring Productivity: \nNo Silver Bullet"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "3\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_1CHAPTER 1\nThe Mythical 10x \nProgrammer\nLutz Prechelt, Freie Universit\u00e4t Berlin, Germany\nAre some programmers indeed ten times more productive than others, as some people \nclaim? To a shocking degree, the answer depends on what exactly the question is \nintended to mean. In this chapter, we will work our way toward this insight by way of a \nfictious dialogue that is based on actual programming research data.\nAlice : \u201cI\u2019ve heard the claim that \u2018Some programmers are ten times as productive as \nothers. \u2019 Sounds a bit exaggerated to me. Do you happen to have data on this?\u201d\nBob : \u201cIndeed I do. \u201d (Bob is an evidence buff.)\n Some Work Time Variability Data\nBob (pointing at  Figure  1-1): \u201cLook at this plot. Each circle shows the work time \nof one person for a particular small program, and each of the programs solves the \nsame problem. The box indicates the \u2018inner half, \u2019 from the 25th percentile to the 75th \npercentile, leaving out the lower and upper fourth of the data points. The fat dot is the \nmedian (or a 50/50 split point), the M shows the mean and its standard error, and the \nwhiskers extend from minimum to maximum. \u201d"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "4Alice : \u201cWait. Not so fast. Are all these implementations working correctly?\u201d\nBob : \u201c23 of them have minor defects left in them; 50 work perfectly. All are more than \n98 percent reliable and can be considered acceptable. \u201d\nAlice : \u201cI see. So min to max\u2026that is how much?\u201d\nBob : \u201cMinimum is 0.6 hours; maximum is 63. That\u2019s a 105x  ratio. \u201d\n Insisting on\u00a0Homogeneity\nAlice : \u201cWow, impressive. And are these data points indeed comparable?\u201d\nBob : \u201cWhat do you mean, comparable?\u201d\nAlice : \u201cI don\u2019t know. Um, for instance...were these solutions all written in the same \nprogramming language? Maybe some languages are better suited to the problem than \nothers. What type of problem is that anyway?\u201d\nBob : \u201cIt\u2019s an algorithmic problem, a search-and-encode task. The data set mixes \nseven different languages, and some of those are indeed less suitable for the task than \nothers. \u201d\nAlice : \u201cSo, could we kick those out, please?\u201d\nBob (showing  Figure  1-2): \u201cWe can do even better because one of the seven groups \nprovides 30 percent of the whole. This is what it looks like for only the Java solutions. \u201dWork Time [Hours]\nFigure 1-1.  Distribution of work times for 73 developers for the same small \nprogramChapter 1  the Mythi Cal 10x progra MMer"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "5Alice : \u201cUh-huh. Five of the six slowest are still there, but many of the fastest are not. \nSo, that is still how much? 20x?\u201d\nBob : \u201c3.8 to 63, so it\u2019s 17x .\u201d\n Deciding What We\u00a0Even Mean\nAlice (shaking her head) : \u201cOkay, but I think I see the problem now. I said \u2018faster than \nother  programmers, \u2019 but if those others are the worst possible ones, the difference can be \nany  size because some people may need an arbitrarily long time. \u201d\nBob : \u201cI agree. The experimenters for this data had expected this to be a half-day \ntask for most people and a full day for the slower ones, but apparently the slowest ones \ninstead came back every day for a week. Dogged folks!\u201d\nAlice : \u201cSo, I think what the statement really ought to mean is \u2018faster than normal  \nprogrammers. \u2019\u201d\nBob : \u201c And \u2018normal\u2019 is just the average? No, I don\u2019t agree with that definition. The \ncomparison group then would include everybody and also those who are fast or even \nvery fast. Would anybody expect to be 9x faster nevertheless?\u201d\nAlice : \u201cGood point. So, then the statement should mean \u2018faster than ordinary-not-so-  \ngreat programmers\u2019?\u201d\nBob : \u201cProbably. And that means what?\u201d\nAlice : \u201cHmm, I suggest those are the slower half of all. \u201d\nBob : \u201cSounds fair to me. And how are they represented, by the slower-half mean or \nthe slower-half median?\u201d\nAlice : \u201cMedian. Or else a single super-obstinate slow person taking 1,000 hours could \nstill make it easy to be 10x as fast. \u201dWork Time [Hours]\nFigure 1-2.  Distribution of work times for 22 developers for the same small Java \nprogramChapter 1  the Mythi Cal 10x progra MMer"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "6Bob : \u201cOkay. The median of the slower half is the 75th percentile. That\u2019s simply the \nright edge of the box. That leaves \u2018some. \u2019\u201d\nAlice : \u201cExcuse me?\u201d\nBob : \u201cWhat do we mean by \u2018 some  programmers?\u2019\u201d\nAlice : \u201c Ah, yes. There should be more than one. \u201d\nBob : \u201cHow about the top 2 percent?\u201d\nAlice : \u201cNo, that is almost irrelevant in practice. We need to have a few more of \nthese people before it starts to matter that they exist. I\u2019d say we take the top 10 percent. \nProgrammers overall need to be pretty intelligent people, and to be among the top 10 \npercent of those is quite elite. Where does that get us?\u201d\nBob : \u201cThe median of the top 10 percent is the 5th percentile. For the Java people, that \ncomes out at 3.8 as well. And the 75th percentile is 19.3. That\u2019s a 5x ratio. \u201d\nAlice : \u201cHa! I knew it! 10x is just too much. On the other hand... \u201d\nAlice stares into the distance.\n Uninsisting on\u00a0Homogeneity\nBob : \u201cWhat?\u201d\nAlice : \u201cWho picked the programming language used?\u201d\nBob : \u201cEach programmer decided this for him or herself. \u201d\nAlice : \u201cThen the suitability of the language and all its effects should be part of the \nperformance we consider. Insisting on a fixed language will artificially dampen the \ndifferences. Let\u2019s go back to the complete data. What\u2019s the ratio then?\u201d\nBob : \u201cThe 5th percentile is 1; the 75th percentile is 11. An 11x  ratio. \u201d\nAlice (shaking her head) : \u201cGosh. Over ten again\u2014a wild ride. \u201d\n Questioning the\u00a0Base Population\nAlice : \u201cSo, maybe I was wrong after all. Although...who were  these people?\u201d\nBob : \u201cEverybody essentially. It is a diverse mix from students to seasoned \nprofessionals, people with much language experience to little, scruffy ones and neat, and \nwhat-have-you. The only thing similar about them is their motivation to take part in the \nexperiment. \u201d\nAlice (looking hopeful) : \u201cSo, can we make the set a little more homogeneous?\u201dChapter 1  the Mythi Cal 10x progra MMer"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "7Bob (grinning sardonically) : \u201cBased on what? Their productivity?\u201d\nAlice : \u201cNo, I mean...there must be something !\u201d\nHer face lightens up. \u201cI bet there are freshmen and sophomores among the \nstudents?\u201d\nBob : \u201cNo. All seniors or graduate students. Besides, many places in industry have \nsome people with no formal computer science training at all!\u201d\nAlice : \u201cSo, you mean this is an adequate population to study our question?\u201d\nBob : \u201cProbably. At least it is unclear what a better one ought to look like. \u201d\nAlice : \u201cSo 11x is the answer?\u201d\nBob : \u201c At least approximately, yes. What else?\u201d\nAlice thinks hard for a while.\n It\u2019s Not Only About Development Effort\nAlice : \u201cOops. \u201d\nBob : \u201cOops what?\u201d\nAlice : \u201cWe\u2019ve overlooked a big part of the question. We\u2019ve assumed development \ntime is all there is to productivity because the resulting programs are all equivalent. But \nyou said it was an algorithmic problem. What if the program is run often or with large \ndata in a cloud computing scenario? Then the programs could have wildly different \nexecution costs. High cost means the program is less valuable; that must be factored into \nthe productivity. \u201d\nBob : \u201cGood thinking. \u201d\nAlice : \u201cBut I guess your data does not contain such information?\u201d\nBob : \u201cIn fact it does. For each program there is a benchmark result stating run time \nand memory consumption. \u201d\n Are Slower Programmers Just More Careful?\nAlice : \u201cFantastic! I bet some of the slower programmers have spent time on producing \nfaster and leaner programs, and once we factor that in, the productivity becomes more \neven. Can we please look at a scatterplot with work time on the x-axis and memory \nconsumption multiplied by run time on the y-axis? Both those latter factors produce \nproportional execution cost increases in the cloud, so they ought to be multiplied. \u201dChapter 1  the Mythi Cal 10x progra MMer"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "8Bob (showing  Figure  1-3): \u201cHere we are. Note the logarithmic axes. Some of those \ncosts are extreme. \u201d\nAlice : \u201cOh, there\u2019s hardly any correlation at all. I wouldn\u2019t have expected this. \u201d\nBob : \u201cDo you still think the ratio will go down?\u201d\nAlice : \u201cNo, I guess not. \u201d\n Secondary Factors Can Be\u00a0Important\nAlice : \u201cBy the way, what\u2019s the difference between the plot symbols?\u201d\nBob : \u201cThe circles represent programs written in a dynamically typed scripting \nlanguage; the Xs are statically typed programs. \u201d\nAlice : \u201cThe scripts tend to be written much faster, so picking a scripting language was \na clever move. \u201d\nBob : \u201cYes. That\u2019s because scripts get only half as long. This is what drove up the ratio \ncompared to the Java-only group. \u201d\nAlice : \u201cInteresting. Yet scripts compete okay in terms of execution cost. \u201d\nBob : \u201cExcept against the very best nonscripts, yes. \u201dLog Wo rk TimeLog Cloud Execution Cost\n101520\n0246o\noo\nooo\nooo oo\nooo\no\no oo ooo\noo\noo\noo\nooooo\nooo\noo\no\nxx\nxxxx\nxx\nxx\nxx\nxx\nx xxx\nxxx\nxxx\nxx\nxxxx\nx\nx xx\nx\nFigure 1-3.  Work time versus cloud execution cost (memory consumption times \nrun time), log scaleChapter 1  the Mythi Cal 10x progra MMer"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "9 The Productivity Definition Revisited\nAlice : \u201cBut back to our question. Let\u2019s incorporate this execution cost idea: productivity \nis value per effort. Effort is our work time. Value goes down as cost goes up; so, value is \nthe inverse of cost. Can you show that?\u201d\nBob (showing  Figure  1-4): \u201cSure. Here\u2019s the resulting plot. \u201d\nBob : \u201cIt\u2019s hopeless without the logarithm and has a really strange unit of \nmeasurement, so it is difficult to make sense of intuitively. Larger is better now, so for \nour ratio we look at the 95th percentile, which is 2200, and the 25th percentile, the left \nbox edge, which is 23.6, which makes the ratio 93x . I guess you should get used to the \nfact that 10x differences exist. \u201d\n How Would Real People Work?\nAlice : \u201cPerhaps. On the other hand, I now recognize that even with our refined \nunderstanding of what the question should mean we are asking the wrong question. \u201d\nBob : \u201cWhy is that?\u201d\nAlice : \u201cI see two reasons. First, in a real scenario, one would not assign a task with \ncost implications as big as this one has to a developer from the lower half. Few people \nwould be so shortsighted. Let\u2019s ignore the lower half. \u201d\nBob : \u201c And instead of the 25th percentile of everybody take the 25th percentile of the \nupper productivity half?\u201d\nAlice : \u201cHmm, nobody can know that exactly in advance, but for simplicity\u2019s sake let\u2019s \nsay yes. \u201d\nBob : \u201cThat would be the 62.5th percentile then. That\u2019s 385 and leads to a ratio of 6x.\u201dLog Productivity\nFigure 1-4.  \u201cProductivity\u201d for 73 developers for the same small programChapter 1  the Mythi Cal 10x progra MMer"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "10Alice : \u201c Aaaaah, that sounds a lot more reasonable to me. \u201d\nBob : \u201cI\u2019m always happy to help. \u201d\nAlice : \u201cBut that\u2019s not all. Second, if you build a solution with very high execution cost, \nyou will go and optimize it. And if the original developer is not capable enough to do that \nproperly, somebody else will come to the rescue. Or should at least. Productivity is about \nteams, really, not individuals!\u201d\n So What?\nThe next day, Bob runs into Alice in the kitchen.\nBob : \u201cThat was a really interesting discussion yesterday. But what is your take-home \nmessage from it?\u201d\nAlice : \u201cMy answer to the question of whether some programmers are indeed 10x \nmore productive than others?\u201d\nBob : \u201cYes. \u201d\nAlice : \u201cMy answer is that is a misleading question. Other productivity facts are way \nmore useful. \u201d\nBob : \u201c And that would be which?\u201d\nAlice : \u201cFirst, as the data showed, the low end of productivity can be reeeeeally  low. \nSo, do your best not to have such people on your team. Second, productivity is a lot \nabout quality. There was not much information about this in your particular data set, but \nin the real world, I am strongly convinced that it makes little sense to talk about effort \nwithout talking about quality as well. Third, my personal conclusion is to assign critical \ntasks to the best engineers and noncritical tasks however they fit. Finally, although the \ndata didn\u2019t have a lot to say about this, I firmly believe in improving a product over time. \nProductivity differences are a fact of life, but if you invest incrementally where it matters, \nthey will not hurt very much. \u201d\nThe End.\n Key Ideas\nHere are the key ideas from this chapter in a nutshell:\n\u2022 The low end of productivity can be really low.\n\u2022 Quality matters, too, not only raw development speed.Chapter 1  the Mythi Cal 10x progra MMer"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "11\u2022 Assign critical tasks to your best engineers.\n\u2022 Do your best not to have very weak engineers on your team at all.\n References\nThe original study for the data used in this chapter is [ 1]. You can find a shorter report at [ 2]  \nbut will miss the add-on analyses. The data itself can be downloaded from [ 3].\n [1] Lutz Prechelt. \u201c An empirical comparison of C, C++, Java, Perl, \nPython, Rexx, and Tcl for a search/string-processing program. \u201d \nTechnical Report 2000\u20135, 34 pages, Universit\u00e4t Karlsruhe, Fakult\u00e4t \nf\u00fcr Informatik, March 2000.  http://page.mi.fu-berlin.de/\nprechelt/Biblio/jccpprtTR.pdf\n [2] Lutz Prechelt. \u201c An empirical comparison of seven programming \nlanguages. \u201d IEEE Computer 33(10):23\u201329, October 2000.\n [3] Lutz Prechelt. http://page.mi.fu-berlin.de/prechelt/\npackages/jccpprtTR.csv\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 1  the Mythi Cal 10x progra MMer"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "13\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_2CHAPTER 2\nNo Single Metric  \nCaptures Productivity\nCiera Jaspan, Google, USA\nCaitlin Sadowski, Google, USA\n\u201cMeasuring software productivity by lines of code is like measuring prog -\nress on an airplane by how much it weighs. \u201d\n\u2014Bill Gates\n\u201cThe purpose of software engineering is to control complexity, not to create it. \u201d\n\u2014Pamela Zave\nThe urge to measure the productivity of developers is not new. Since it is often the \ncase at organizations that more code needs to be written, many attempts have been \nmade to measure productivity based on lines of code (LOC). For example, in early \n1982, the engineering management of developers working on software for the Apple \nLisa computer decided to start tracking LOC added by each developer. One week, the \nmain user interface designer, Bill Atkinson, optimized QuickDraw\u2019s region calculation \nmachinery and removed  about 2,000 LOC.\u00a0The management stopped asking for his \nLOC [ 3]."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "14Although measuring engineer productivity by LOC is clearly fraught, anecdotes like \nthis abound on the Internet [ 7]. Organizations have continued to search for better and \neasier ways to measure developer productivity [ 6]. We argue that there is no metric that \nadequately captures the full space of developer productivity and that attempting to find \none is counterproductive. Instead, we encourage the design of a set of metrics tailored \nfor answering a specific goal.\n What\u2019s Wrong with\u00a0Measuring Individual \nPerformers?\nTracking individual performance can create a morale issue, which perversely could \nbring down overall productivity. Research has shown that developers do not like  having \nmetrics focused on identifying the productivity of individual engineers [ 5]; this has also \nbeen our experience at Google. Developers are concerned about privacy issues and \nabout how any measurement could be misinterpreted, particularly by managers who \ndo not have technical knowledge about inherent caveats any metric has. If productivity \nmetrics directly feed into an individual\u2019s performance grading, then they will impact \nhow developers are compensated and whether they continue to keep their jobs\u2014a \nserious consequence for getting it wrong. These high stakes further incentivize gaming \nthe metrics, for example, by committing unnecessary code just to increase LOC ratings.\nMeasuring productivity to identify low performers may not even be necessary. \nIt is our experience that managers (and peers) frequently already know who the low \nperformers are. In that case, metrics serve only to validate a preexisting conception for \nwhy an individual is a low performer, and so using them to identify people in the first \nplace is not necessary and serves only to demoralize the higher-performing employees.\n Why Do People Want to\u00a0Measure Developer \nProductivity?\nAs critiqued earlier, one possible motivation for measuring developer productivity \nis identifying high/low-performing individuals and teams. However, there are many \nreasons why a company may want to measure the productivity of their engineers. Other \nmotivations include surfacing global trends across a company, rating the effectiveness of Chapter 2  No Si Ngle Metri C Capture S produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "15different tools or practices, running comparisons for an intervention meant to improve \nproductivity, and highlighting inefficiencies where productivity can be improved.\nWhile each of these scenarios has a goal of measuring productivity, the metrics, \naggregations, and reporting are different. For example, identifying high- and low-  \nperforming individuals means aggregating a metric on an individual level, while running \na comparison would mean aggregating across a group of developers. More important, \nthe type of productivity metric used for these scenarios is different. There are many \ndifferent stakeholders who may be interested in measuring productivity with different \ngoals. If the goal is to identify low performers or to surface global trends, the stakeholders \ninterested in the metric will be looking for metrics that measure task completion. If the \ngoal is to run a comparison for a specific intervention or to highlight inefficiencies within \na specific process, the productivity metrics used will be measuring subtasks that address \nthe goals of the intervention or the process being investigated. What is actionable for an \nindividual is different than what is actionable for a team.\n What\u2019s Inherently Wrong with\u00a0a\u00a0Single Productivity \nMetric?\nAny single productivity metric is intrinsically problematic. Productivity is too broad of a \nconcept to be flattened into a single metric, and confounding factors will exacerbate the \nchallenges with attempting such a flattening.\n Productivity Is Broad\nProductivity  is a broad concept with many aspects. The problem is that productivity \nmetrics are poor proxies of the underlying behavior or activity that we want to measure. \nAs poor proxies, they are ripe for misuse.\nWhen we create a metric, we are examining a thin slice of a developer\u2019s overall time \nand output. Developers engage in a variety of other development tasks beyond just \nwriting code, including providing guidance and reviewing code for other developers, \ndesigning systems and features, and managing releases and configuration of software \nsystems. Developers also engage in a variety of social tasks such as mentoring or \ncoordination that can have a significant impact on overall team or organization output.Chapter 2  No Si Ngle Metri C Capture S produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "16Even for the narrow case of measuring productivity of developers in terms of code \ncontributions, quantifying the size of such contributions misses critical aspects of code \nsuch as quality, or maintainability. These aspects are not easy to measure; measuring \ncode readability, quality, understandability, complexity, or maintainability remain open \nresearch problems [ 2, 4].\n Flattening/Combining Components of\u00a0a\u00a0Single Aspect Is \nChallenging\nFurthermore, flattening all of these into a single measure along with quantity has limited \napplicability and risks, reducing the actionability of a metric. Is a developer with few \ncode contributions of very high quality more or less productive than a developer with \nmany contributions but some quality issues? Does it make a difference if the engineer \nwith some quality issues comes back and fixes the issues later? It is not clear which is \nmore productive because it depends on the trade-offs of the project in question.\nAn additional problem with flattening or combining metrics is that flattened metrics \nmay not make intuitive sense and so may be distrusted or misinterpreted. For example, if \na variety of factors (e.g., cyclomatic complexity, time to complete, test coverage, size) are \ncompressed into one number representing the productivity impact of a patch, it will not \nbe immediately clear why one patch scores 24 and another one scores 37. Furthermore, \na single score is not directly actionable  since a variety of interrelated factors contribute to \nthat score.\n Confounding Factors\nEven if we are able to tease out a single metric that holistically covers some aspect of \nproductivity, confounding factors can make the metric meaningless. Take the case \nof comparing programming languages. It is difficult to measure the productivity of \nlanguages in particular because of the number of confounding factors. There is the \nlanguage itself, the tools, the libraries, the culture, the types of projects, and the types of \ndevelopers who are attracted to that language.\nAs another example, a Google team wanted to show that high test coverage improves \ncode quality. To do this, they compared the test coverage of different teams with the \nnumber of bugs filed. They found no correlation. Was there really no improvement \nin code quality, though? In this case, there may have been a confounding cultural Chapter 2  No Si Ngle Metri C Capture S produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "17component . Teams that have high test coverage may also file more bug reports. The \nprojects with low test coverage may have been prototypes or just teams that don\u2019t track \nbugs as accurately.\nThere can also be confounds from intrinsic complexity differences  between teams. \nFor example, two teams may have a difference in their average patch completion time. \nOne likely explanation is that these teams are working on different projects. There \nmay be project-specific differences in the size of patches they submit or their overall \ncomplexity.\nThere can even be externalities  that are not captured within a metric. For example, \none team might appear to be submitting fewer lines of code than another team. There \nare many possible causes for such a difference that do not mean the team has lower \nproductivity; perhaps the team is taking more steps to improve quality and therefore has \nfewer bugs down the road, or perhaps the team has taken on several new employees and \nis ramping them up. Again, confounding factors are at play. We can\u2019t separate those out \nbecause they come from nonmeasurable sources.\n What Do We\u00a0Do Instead at Google?\nAlthough there is no general-purpose measurement that can be used in any situation \nfocused on developer productivity, it is still possible to make data-driven improvements \nto a software engineering workflow . Given a specific research question, it is possible to \nbreak measurements down into a specific context and know what the caveats are.\nAt Google, we work with teams to figure out how they can leverage metrics to help \nmake data-driven decisions. The process starts with clarifying the research questions \nand motivation. We then come up with custom metrics targeted toward those specific \nquestions. This kind of thinking is similar to the Goal\u2013QuestionMetric paradigm [ 1]. We \nvalidate these metrics against qualitative research (encompassing techniques such as \nsurveys and interviews) to ensure that the metrics measure the original goal.\nFor example, a team at Google working on a distributed version control layer wanted \nto show that using multiple smaller patches speeds up the review process (perhaps \nbecause they are easier to review). After investigating and rejecting not meaningful \nmetrics related to the number of changes or LOC committed per week, the team \ninvestigated how long it took developers to commit code scaled by the size of code \nchanges . They were able to show improvement in the time to commit per LOC changed.Chapter 2  No Si Ngle Metri C Capture S produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "18We can likewise find improvements for other tools, investigate the current cost \non developers, and then put those into a Return on Investment (ROI) calculation. For \nexample, we have determined how much time is lost because of waiting for builds (or \nbecause of unnecessary context switching as a result of builds). After contrasting this \nwith the cost of speeding up builds (through human or machine resources), we have \nprovided an estimated ROI for different build improvements.\nWe often see teams that either don\u2019t have a research question that matches their \nmotivation for coming up with a metric or have a mismatch between the metrics and \nthe research questions of interest. For example, we talked to one team that wanted to \nmeasure codebase modularity. After some discussion, we determined that they wanted \nto see whether developers were faster at developing software after an intervention and \nneeded to consider ways to measure velocity. Teams also need to carefully consider \nthe time window and aggregations (for example, team versus individual versus larger \norganization) of interest, as well as any selection criteria for individuals being measured.\nQualitative analysis helps understand what a metric is actually measuring, and data \nanalysis and cross-validation can make sure the results are sensible. For example, by \nexamining distributions of log events for individual developers, we discovered logs that \nshow developers making an action on a web page tens of thousands of times \u2013 actions \nthat were actually the result of a Chrome extension. Similarly, we found out during an \ninterview that developers have good reasons for doing something we had thought was an \nanti-pattern.\nOur approach works because we explicitly do not attempt to create a single metric to \nmeasure engineering productivity. We instead narrow down the problem into a concrete \nresearch statement and seek metrics that address precisely the question at hand. This \nallows us to validate each individual metric against a specific goal, rather than against \nthe vague concept of productivity. In practice, we find that several of our metrics get \nreused from one productivity question to the next. While this approach does not scale \nas fast as applying a single productivity metric, it scales well enough while providing \nprecise, reliable data that we can trust when making investment decisions.Chapter 2  No Si Ngle Metri C Capture S produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "19 Key Ideas\nThe following are the key ideas from this chapter:\n\u2022 There is no single productivity metric for software engineers.\n\u2022 Instead, focus on a set of custom metrics targeted to a specific \nquestion.\n References\n [1] B asili, V ., Caldiera, G., and H.\u00a0Dieter Rombach. (1994). The goal \nquestion metric approach. Encyclopedia of Software Engineering \n2, 528\u2013532.\n [2] Buse, R.\u00a0P ., & Weimer, W.\u00a0R. (2010). Learning a metric for code \nreadability. IEEE Transactions on Software Engineering, 36(4), \n546\u2013558.\n [3] Hertzfeld, A. -2000 Lines Of Code. https://www.folklore.org/\nStoryView.py?project=Macintosh&story=Negative_2000_\nLines_Of_Code.txt\n [4] Shin, Y., Meneely, A., Williams, L., & Osborne, J.\u00a0A. (2011). \nEvaluating complexity, code churn, and developer activity metrics \nas indicators of software vulnerabilities. IEEE Transactions on \nSoftware Engineering, 37(6), 772\u2013787.\n [5] Treude, C., Figueira Filho, F ., & Kulesza, U. (2015). Summarizing \nand measuring development activity. In Proceedings of \nFoundations of Software Engineering (FSE), 625\u2013636. ACM.\n [6] Thom pson, B.\u00a0Impact: a better way to measure codebase change. \nhttps://blog.gitprime.com/impact-a-better-way-to-\nmeasure-codebase-change/\n [7] Y Combinator. Thread on -2000 LOC Story.  https://news.\nycombinator.com/item?id=7516671Chapter 2  No Si Ngle Metri C Capture S produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "20Open Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 2  No Si Ngle Metri C Capture S produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "21\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_3CHAPTER 3\nWhy We\u00a0Should Not \nMeasure Productivity\nAmy J. Ko, University of Washington, USA\nSoftware moves faster every year. Markets shift rapidly, releases are ever more frequent, \nand languages, APIs, and platforms evolve at a relentless pace. And so the interest \nin productivity, both by developers who want to keep up with these changes and by \nmanagers and organizations that need to compete, appears entirely rational. Moreover, \nimproving software faster holds even greater promise to the rest of humanity: getting \nmore work done with less effort may mean an increased quality of life for everyone.\nIn pursuit of productivity, however, there can be unintended consequences from \ntrying to measure it. Here are some examples:\n\u2022 Measuring productivity can warp incentives, especially if not \nmeasured well.\n\u2022 Sloppy inferences from measurements could result in worse  \nmanagement decisions rather than better ones.\nAre these bad enough that we shouldn\u2019t even try to measure it? To find out, let\u2019s do \na thought experiment. I want you to imagine an organization that you\u2019ve worked for or \nare working for now. Let\u2019s consider what might happen if it invested seriously in trying to \nmeasure productivity. As we go, test the argument against your own experience."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "22 Unintended Consequences\nThe first unintended consequence comes from trying to use any single concrete \nmeasure of productivity. Take, for example, a measure of productivity that focuses on \ntime to release . An individual developer committing faster means a team reviewing \nfaster, which ultimately means shipping faster, right? But unless your organization also \nmeasures the outcomes of shipping\u2014positive outcomes such as adoption, customer \ngrowth, and sales increases, or negative outcomes such as software failures or harm \nto brand\u2014one risks optimizing for an intermediate outcome at the expense of an \norganization\u2019s ultimate goal.\nFor example, in the race to release, a team might ship more defects than it would \nhave otherwise or take on more technical debt than is desirable for longer-term goals. \nMost other single metrics have the same problems. Counting the number of bugs closed, \nthe number of lines of code written, the number of user stories completed, the number \nof requirements met, and even the number of customers acquired\u2014if your organization \ntried to measure these, optimizing any one of them would almost always come at the \nexpense of others.\nBut this is a bit obvious. I bet it\u2019s even more obvious if you\u2019ve been in an organization \nthat did this because you probably lived those unintended consequences every day, \nfeeling tension between the official measures of productivity and the other concerns that \nrelated to that measure. So, let\u2019s take our thought experiment in a more radical direction.\nImagine it was possible for your organization to measure all dimensions of \nproductivity. After all, software has a vast array of quality dimensions Redundant, as \ndo software development methodologies. Perhaps measuring all of these dimensions \ncan overcome any overfitting to one metric. Let\u2019s put aside for the moment that we \ndon\u2019t know how to measure most of these dimensions well, imagining a future in which \nwe can accurately observe and measure every dimension of work. Would a holistic, \nmultidimensional metric of productivity be any better?\nIt would certainly make the activities of a team more observable . Developers and \nmanagers would know every aspect of every developer\u2019s work, able to observe every \ndimension of progress or lack thereof. It would provide a perfect model of developer \nactivity.\nBut this omniscient vision of software development work still comes with significant \nunintended consequences. First, if this monitoring were done at a team or organization \nlevel by managers, how would being monitored change developers\u2019 behavior? The effect \nof being observed so thoroughly might actually result in developers self-monitoring Chapter 3  Why We\u00a0Should Not Mea Sure produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "23their every action, unintentionally reducing  productivity. Even if this were a net increase \nin productivity, it might also lead to developers leaving the organization, moving to \norganizations that were a little less like Big Brother.\n Explaining Productivity\nFor the sake of our thought experiment, let\u2019s imagine that you and every developer in \nyour organization fully embraced rich monitoring of productivity of all kinds. What \nwould a manager actually do with this data to improve productivity?\n\u2022 They could use the data to rank the productivity of individual \ndevelopers and teams to make promotion or investment decisions.\n\u2022 If the data were real-time enough, they might use it to intervene in \nteams that are seeing drops in productivity.\n\u2022 With enough detail, the data might even reveal which practices \nand tools are associated with increased productivity, allowing an \norganization to change practices to increase productivity.\nThis rich stream of real-time data could empower an organization to fine-tune its \nactivities to more rapidly achieve its goals.\nUnfortunately, there\u2019s a hidden requirement to achieve this vision. For a manager to \nactually go from data to intervention, they need to make a creative leap: a manager has \nto take all of the measures, correlations, and models to ultimately infer a theory for what \nexplains  the productivity they\u2019re observing. Making these inductive leaps can be quite \nchallenging, and coming up with a wrong theory means any intervention based on that \ntheory would likely not be effective and may even be harmful.\nEven if we assume that every manager is capable of creatively and rigorously \ninferring explanations of a team\u2019s productivity and effectively testing those theories, \nthe manager would need richer data about causality. Otherwise, they\u2019d be blindly \ntesting interventions, with no sense of whether improvements are because of their \nintervention or just the particular time and context of the test. Where would this causal \ndata come from?\nOne source of richer data is experiments . But designing experiments requires control \ngroups that are as close to identical as the treatment group or sufficiently randomized to \ncontrol for individual differences. Imagine trying to create two teams that are identical in \nnearly every way, except for the process or tools they use, and randomizing everything else. Chapter 3  Why We\u00a0Should Not Mea Sure produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "24As a scientist of software engineering, I\u2019ve tried, and not only is it extremely time-  consuming \nand therefore expensive, but it\u2019s almost always impossible to do, even in the laboratory, let \nalone in a workplace.\nAnother source of rich data about causality is qualitative data. For example, \ndevelopers could report their subjective  sense of their team\u2019s productivity. Every \ndeveloper could write a narrative each week about what was slowing them down, \nhighlighting all of the personal, team, and organizational factors that they believe are \ninfluencing all of those elaborate quantitative metrics being measured in our omniscient \nvision. This would help support or refute any theories inferred from productivity data \nand might even surface some recommendations from developers about what to do \nabout the problems they\u2019re facing.\nThis would be ideal, right? If we combine holistic qualitative  data from developers \nwith holistic quantitative  data about productivity, then we\u2019ll have an amazingly rich and \nprecise view into what is either causing or preventing an organization\u2019s desired level of \nproductivity. What could be more valuable for improving developer productivity?\n Dealing with\u00a0Change\nAs usual, there\u2019s another fatal flaw. Such a rich model of productivity would be incredibly \npowerful if developers, teams, and organizations were a relatively stable phenomena to \nmodel. But new developers arrive all the time, changing team dynamics. Teams disband \nand reform. Organizations decide to enter a new market and leave an old one. All of \nthese changes mean that the phenomena one might model are under constant change, \nmeaning that whatever policy recommendations our rich model might suggest would \nlikely need to change again in response to these external forces. It\u2019s even possible that by \nhaving such a seamless ability to improve productivity, one would accelerate the pace \nat which new productivity policies would have to be introduced, only creating more \nentropy in an ever-accelerating system of work.\nOne final flaw in this thought experiment is that, ultimately, all productivity changes \nwill come from changes in the behavior of developers and others on a team. Depending \non their productivity goals, they\u2019ll have to write better code, write less code, write code \nfaster, communicate better, make smarter decisions, and so on. Even with a perfect \nmodel of productivity, a perfect understanding of its causes in an organization, and \na perfect policy for improving productivity, developers will have to learn new skills, \nchanging how they program, communicate, coordinate, and collaborate to implement Chapter 3  Why We\u00a0Should Not Mea Sure produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "25more productive processes. And if you\u2019ve had any experience changing developer or \nteam behavior, you know how hard it is to change even small things about individual and \nteam behavior. Moreover, once a team changes its behavior, one has to understand the \ncauses of behavior all over again.\nThis thought experiment suggests that regardless of how accurately or elaborately \none can measure productivity, the ultimate bottleneck in realizing productivity \nimprovements is behavior change. And if our productivity utopia relies on developer \ninsight into their own productivity to identify opportunities for individuals to change, \nwhy not just focus on developers in the first place, working with them individually and \nin teams to identify opportunities for increased productivity, whatever the team and \norganizational goals? This would be a lot cheaper than trying to measure productivity \naccurately, holistically, and at scale. It would also better recognize the humanity and \nexpertise of the people ultimately responsible for achieving productivity. A focus \non developers\u2019 experiences with productivity also leaves room for all the indirect  \ncomponents of productivity that are far too difficult to observe, including factors such \nas developers\u2019 motivation, engagement, happiness, trust, and attitudes toward the work \nthey are doing. These factors, likely more than anything else, are the higher-order bits in \nhow much work a developer gets one per unit time.\n Managers as\u00a0Measurers\nOf course, all these individual and emotional factors about probing developer \nexperience are just fancy ways of talking about good management . Great managers, \nby respecting the humanity of the people they are managing and understanding how \ntheir developers are working, are constantly building and refining rich models of their \ndevelopers\u2019 productivity all the time and using them to make identify opportunities for \nimprovements. The best ones already achieve our productivity measurement ideal but \nthrough interpersonal communication, interpretation, and mentorship. The whole idea \nof measuring  productivity is really just an effort to be more objective about the subjective \nfactors that are actually driving software development work.\nSo, what does this mean for improving productivity? I argue that instead of \nmeasuring  productivity, we should instead invest in finding, hiring, and growing \nmanagers who can observe  productivity as part of their daily work with developers. \nIf organizations grow good managers and can trust that their great managers will \nconstantly seek ways to improve productivity, developers will be more productive, even \nif we can\u2019t objectively measure it.Chapter 3  Why We\u00a0Should Not Mea Sure produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "26Of course, part of growing good management can involve measurement. One can \nthink of measurement like a form of self-reflection scaffolding, helping a manager to reflect \non process in more structured ways. That structure might help inexperienced managers \ndevelop more advanced skills of management observation that do not necessarily involve \ncounting things. More advanced managers can be more intuitive, gathering insights as they \nwork with their team and making changes to team dynamics as the world around the team \nchanges. This vision of management ultimately frames measurement as just one small tool \nin a much larger toolbox for organizing and coordinating software development work.\nNow all we need is a measure of good management.\n Key Ideas\nThe following are the key ideas from the chapter:\n\u2022 Improving productivity requires explaining the factors that affect it, \nbut that requires qualitative insights into team behavior.\n\u2022 Teams are always changing, making it even harder to get insights \nabout team behavior through data.\n\u2022 Managers are best positioned to get these qualitative insights by \ninteracting with their team.\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 3  Why We\u00a0Should Not Mea Sure produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "PART II\nIntroduction to \nProductivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "29\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_4CHAPTER 4\nDefining Productivity \nin\u00a0Software Engineering\nStefan Wagner, University of Stuttgart, Germany\nFlorian Deissenboeck, CQSE GmbH, Germany\nSuccessful software systems are subject to perpetual change as they need to be \ncontinuously improved and adapted to continuously changing requirements. Software \nevolution  is the term used in software engineering to refer to this process of developing \nsoftware initially and then repeatedly updating it. It is an essential goal to minimize \nthe cost and to maximize the benefits of software evolution. In addition to financial \nsavings, for many organizations, the time needed to implement software changes largely \ndetermines their ability to adapt their business processes to changing market situations \nand to implement innovative products and services. With the present yet increasing \ndependency on large-scale software systems, the ability to develop and change existing \nsoftware in a timely and economical manner is essential for numerous enterprises and \norganizations in most domains.\nWe commonly call this productivity,  which across disciplines and domains refers \nto the ratio between output and input. The input side\u2014the cost spent\u2014is relatively \neasy to measure in software development. The challenge lies in finding a reasonable \nway to define output as it involves software quantity and quality. The software \nengineering community has so far been unable to develop a thorough understanding of \nproductivity in software evolution and the significance of the factors influencing it, let \nalone universally valid methods and tools to analyze, measure, compare, and improve \nproductivity. Perhaps the most difficult issues are the many factors that influence"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "30productivity\u2014and that they are different in every project, which makes it so hard to \ncompare them. What complicates the situation is the lack of an established, clearly \ndefined terminology that serves as a basis for further discussions.\nHence, we see the disambiguation of the terms that are central to productivity as \na first important step toward a more mature management of productivity in software \nengineering. For that, we make use of the existing work from other research areas with a \nfocus on knowledge work . We discuss the terms frequently associated with productivity, \nnamely, efficiency , effectiveness , performance , and profitability , and explain their \nmutual dependencies. As a first constructive step, we propose a clear and integrated \nterminology.\nTo better put the terminology in the perspective of software engineering, we start \nwith a description of the history of software productivity.\n A Short History of\u00a0Software Productivity\nA wide variety of definitions of software development productivity have been discussed \nfor more than four decades. In the beginning, however, this discussion was usually \nbased on anecdotal evidence presented by renowned researchers and practitioners of \nthe field. For example, Brooks stressed in 1975 the importance of people-related factors \nfor software productivity [ 3], which was more recently followed up on by DeMarco and \nLister [ 4], as well as Glass [ 5]. First isolated experiments were carried out to investigate \nproductivity variations and its causes as early as 1968 [ 7, 11].\nThe late 1970s and early 1980s brought the first attempts to tackle software \ndevelopment productivity in a more comprehensive manner. As measuring productivity \nrequires a well-defined notion of the size of the generated product, considerable effort \nwas spent on the definition of size metrics that do not suffer from limitations of the \nclassic lines of code (LOC) metric. In 1979, Albrecht introduced function points  to \nexpress the amount of functionality of an information system rather than the size of its \ncode. Based on the specification of a system instead of on its implementation, function \npoints were designed to support early development effort estimation and to overcome \nlimitations inherent to the measurement of LOC, e.g., comparability between different \nlanguages. Function points provide a basis for productivity measures such as function \npoints per week or work-hours per function point.\nIn parallel, Boehm developed his cost estimation model COCOMO\u2014now COCOMO \nII [1]\u2014which is part of the standard software engineering knowledge today. While Chapter 4  Defining proDuCtivity in\u00a0Software engineering"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "31not directly based on function points but on LOC, COCOMO addresses development \nproductivity by explicitly including productivity factors such as required reliability  \nor the capability of the analysts . Boehm also recognized the importance of reuse, a \nphenomenon unknown in manufacturing, for software productivity and introduced a \nseparate factor that should cover this influence.\nThe 1980s deepened the understanding of software productivity by significantly \nenlarging the then poor empirical knowledge base. Most notably, Jones contributed to \nthis through his systematic provision and integration of a large amount of data relevant \nfor productivity analyses. In his books, he discusses various factors for productivity and \npresents industrial averages for these factors that potentially form a basis for productivity \nassessments. Nevertheless, one of his insights [ 6] is that for each project a different set of \nfactors may be most influential.\nIn the beginnings of the 2000s, several researchers proposed economic-driven \nor value-based software engineering as an important paradigm in future software \nengineering research. For example, Boehm and Huang [ 2] point out that it is not only \nimportant to track the costs in a software project but also the real earned value, i.e., the \nvalue for the customer. They explain that it is important to develop the software business \ncase and keep it up-to-date. By doing so, they open up a new perspective on software \nproductivity that reaches beyond development costs and explicitly includes the benefits \nprovided for the customer.\nDuring the 2000s and the recent years, agile software development has made a strong \nimpact on many organizations that develop software. One of the core principles of agile \ndevelopment is to create customer value . Hence, many aspects of agile development \naim to focus on this value generation. One example is the evolution from continuous \nintegration to continuous delivery [ 13], i.e., to deliver value to customers not at the \nend of the project or a sprint but continuously. Another aspect related to productivity \nbrought in by agile development was the counting of story points  and the calculation \nof velocity  as the number of story points per sprint. However, many proponents of agile \ndevelopment recommend not to use this measure of velocity as a productivity measure \nbecause it can lead to unwanted effects. For example, Jeffreys [ 15] states, \u201cVelocity is \nso easy to misuse that one cannot recommend it. \u201d The effects can include that story \npoints are inflated instead of used as a means to identify too large stories and keeping \ndevelopers from working on stories with a small number of story points. Hence, agile \nsoftware development has no clear definition of productivity  or a solution for measuring \nproductivity.Chapter 4  Defining proDuCtivity in\u00a0Software engineering"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "32 Terminology in\u00a0the\u00a0General Literature\nOur starting point is Tangen\u2019s [ 12] Triple-P-Model, which is a well-established model in \nknowledge work research to differentiate productivity , profitability , and performance  as \nwell as the programming productivity Wikipedia article ( https://en.wikipedia.org/\nwiki/Programming_productivity ). Especially in software engineering, efficiency  is used \ninstead of productivity ; we also discuss it and differentiate it from effectiveness . Finally, \nfollowing Drucker [ 8], we include a short discussion on the influence of quality on \nproductivity. We discuss each of these terms separately in the following sections and will \nintegrate them afterward.\n Productivity\nWhile there is no commonly agreed on definition of productivity , there appears to be \nconsensus that productivity describes the ratio between output and input.\nProductivity = Output / Input\nAcross the various disciplines, however, different notions and different measurement \nunits for input and output can be found. The manufacturing industry uses a \nstraightforward relation between the number of units produced per time unit and the \nnumber of units consumed in production. Nonmanufacturing industries use person-  \nhours or similar units to enable comparison between outputs and inputs.\nAs long as classical production processes are considered, a metric of productivity \nis straightforward: how many units of a product of specified quality are produced at \nwhich costs? For intellectual work, productivity is much trickier. How do we measure \nthe productivity of authors, scientists, or engineers? Because of the rising importance \nof \u201cknowledge work\u201d (as opposed to manual work; see also \u201cWhat We Can Learn \nfrom Productivity Research About Knowledge Workers\u201d [ 8]), many researchers have \nattempted to develop productivity measurement means that can be applied in a \nnonmanufacturing context. It is commonly agreed on that the nature of knowledge work \nfundamentally differs from manual work and, hence, factors besides the simple output/\ninput ratio need to be taken into account, e.g., quality, timeliness, autonomy, project \nsuccess, customer satisfaction, and innovation. However, the research communities in \nneither discipline have been able to establish broadly applicable and accepted means for \nproductivity measurement yet [ 9].Chapter 4  Defining proDuCtivity in\u00a0Software engineering"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "33 Profitability\nProfitability and productivity are closely linked and are, in fact, often confused. However, \nprofitability  is most often defined as the ratio between revenue and cost.\nProfitability = Revenue / Cost\nThe number of factors that influence profitability is even greater than the number \nof factors that influence productivity. Particularly, profitability can change without any \nchange to productivity, e.g., due to external conditions such as cost or price inflation.\n Performance\nThe term performance  is even broader than productivity and profitability and covers a \nplethora of factors that influence a company\u2019s success. Hence, well-known performance \ncontrol instruments such as the Balanced Scorecard [ 14] do include productivity as \na factor that is central but not unique. Other relevant factors are, for example, the \ncustomers\u2019 or stakeholders\u2019 perception of the company.\n Efficiency and\u00a0Effectiveness\nEfficiency  and effectiveness  are terms that provide further confusion as they are often \nmixed up themselves; additionally, efficiency is often confused with productivity. \nThe difference between efficiency and effectiveness is usually explained informally as \n\u201cefficiency is doing things right\u201d and \u201ceffectiveness is doing the right things. \u201d While there \nare numerous other definitions [ 12], an agreement prevails that efficiency  refers to the \nutilization of resources and mainly influences the required input of the productivity \nratio. Effectiveness  mainly aims at the usefulness and appropriateness of the output as it \nhas direct consequences for the customer.\n Influence of\u00a0Quality\nDrucker [ 8] stresses the importance of quality for the evaluation of knowledge worker \nproductivity. Productivity of knowledge work therefore has to aim first at obtaining \nquality\u2014and not minimum quality but optimum if not maximum quality. Only then can \none ask, \u201cWhat is the volume, the quantity of work?\u201d However, most of the literature in \nnonsoftware disciplines does not explicitly discuss the role of quality in the output of \nthe productivity ratio [ 8]. More recent work from nonmanufacturing disciplines have Chapter 4  Defining proDuCtivity in\u00a0Software engineering"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "34a stronger focus on knowledge, office, or white-collar work and hence increasingly \ndiscuss the role of quality with respect to productivity [ 4, 9, 10]. Still, it appears that these \nefforts to include quality in the determination of productivity have not yet led to an \noperationalizable concept.\n An Integrated Definition of\u00a0Software Productivity\nAs discussed, for measuring software productivity we need a measurement of input and \noutput of a software project. The input is the effort dedicated to its development and \nevolution. The output is the value of the software for its users or customers. The value \ncannot always be defined by the market value of the software as it is often developed and \nused internally by organizations and as such does not have a market value. Furthermore, \nthe market value may be influenced by factors that we put to the level of profitability or \nperformance, such as currency valuations or competition on the market.\nHence, we suggest a purpose-based definition of software value. Given a purpose \n(a business goal or an application vision), we ask, how well does the software address \nits purpose in terms of functional and nonfunctional requirements? The answer to this \nquestion is determined by the functionality as well as the nonfunctional quality of the \nsoftware.\nOn the basis of the purpose-based view, we build a consolidated summary of the \nproductivity-related terms. As shown in Figure\u00a0 4-1, from the purpose, we derive an \nideal functionality and quality as well as the ideal effort to serve the purpose correctly. \nThe ideal functionality means the optimal set of features (nothing missing, nothing too \nmuch) to fulfil the purpose. Similarly, the ideal quality is the level of the various quality \nattributes that fit to the purpose in an optimal way. For example, the application scales \neasily to the needed number of parallel users but not beyond. The ideal effort denotes \nthe number of person-hours if people trained well for the problems to be solved (i.e., \nthe ideal functionality and quality) would have worked in a supportive environment on \nthe software. Comparing the ideal with the actually produced functionality and quality \nshows the effectiveness of the software development activities; the relation of the ideal to \nthe actual effort gives the efficiency. Both have an influence on productivity.Chapter 4  Defining proDuCtivity in\u00a0Software engineering"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "35We embed this in the Triple-P-Model from Tangen [ 12] so that it results in the \nPE Model  that illustrates how purpose, functionality, quality, and effort relate to \neffectiveness, efficiency, productivity, profitability, and performance (Figure\u00a0 4-2). The \noriginal Triple-P-Model already provided the idea that profitability contains productivity \nbut adds further factors such as inflation and pricing. In turn, performance contains \nprofitability and adds factors such as customer perception.\nFigure 4-1.  Purpose-based effectiveness and efficiency\nFigure 4-2.  PE Model for software evolution productivityChapter 4  Defining proDuCtivity in\u00a0Software engineering"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "36We add in the PE Model that productivity is expressed as the combination of \neffectiveness and efficiency: a team can be productive only if it is effective and efficient! \nWe would neither consider a software team productive if it was not building the features \nneeded by the customers nor if it spent an unnecessary amount of effort on building the \nsoftware. For effectiveness, we need to consider the purpose, functionality, and quality of \nthe software. For efficiency, we further consider costs. Hence, the PE Model allows us to \nset all terms discussed earlier in this chapter into relation with each other.\n Summary\nThere is still a lot of work to do until we can have a clear understanding of productivity in \nsoftware engineering. The complexity of capturing good  knowledge work is an obstacle \nin general to unambiguously measuring the productivity of such work. We hope that at \nleast our classification of the relevant terms and the resulting PE Model can help to avoid \nconfusion and to focus further efforts.\nOur discussion of the related terms complements the productivity framework in \nChapter 5. The framework focuses on the three dimensions of velocity , quality , and \nsatisfaction . While quality is covered in both chapters, we have not incorporated velocity. \nVelocity can be different from effort as it concentrates on how fast features are delivered \nto customers. Being faster might actually need more effort. We also have not integrated \nwork satisfaction explicitly as it was not part of the Triple-P-Model. This is surprising \nas\u2014in hindsight\u2014we would expect that to play a big role in knowledge work in general. \nTherefore, we believe that a combination of our PE Model and the productivity framework \nin Chapter 5 will clarify terms and cover the most important dimensions.\nIn Chapter 7, you can read about research on knowledge work as well as how (not) to \nmeasure productivity.\n Key Ideas\nThis chapter covers the following key ideas:\n\u2022 A clear terminology is important for further discussions on \nproductivity factors and productivity measurement.\n\u2022 We should reflect on the history of productivity research in software \nengineering.Chapter 4  Defining proDuCtivity in\u00a0Software engineering"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "37\u2022 We need to learn from research on knowledge work productivity and \nuse compatible terms.\n\u2022 The purpose of the software is the necessary basis for all definitions \nof productivity and related terms.\n Acknowledgements\nWe are grateful to Manfred Broy for fruitful discussions on definitions of productivity in \nsoftware engineering.\n References\n [1] Boehm, B. et\u00a0al. Software Cost Estimation with COCOMO II, 2000\n [2] Boehm, B. and Huang, L.\u00a0Value-Based Software Engineering: A \nCase Study. IEEE Software, 2003\n [3] Brooks, F .\u00a0P . The mythical man-month. Addison-Wesley, 1975\n [4] DeMarco, T. and Lister, T.\u00a0Peopleware: Productive Projects and \nTeams. B&T, 1987\n [5] Glass, R.\u00a0L. Facts and Fallacies of Software Engineering. Addison-\nWesley, 2002\n [6] Jones, C.\u00a0Software Assessments, Benchmarks, and Best Practices. \nAddison-Wesley, 2000\n [7] Sackman, H.; Erikson, W.\u00a0J. and Grant, E.\u00a0E. Exploratory \nexperimental studies comparing online and offline programming \nperformance, Commun. ACM, ACM, 1968, 11, 3\u201311\n [8] Drucker, P .\u00a0F . Knowledge-Worker Productivity: The Biggest \nChallenge. California Management Review, 1999, 41, 79-94\n [9] Ram\u00edrez, Y.\u00a0W. and Nembhard, D.\u00a0A. Measuring knowledge worker \nproductivity: A taxonomy. Journal of Intellectual Capital, 2004, 5, \n602\u2013628Chapter 4  Defining proDuCtivity in\u00a0Software engineering"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "38 [10]  Ray, P . and Sahu, S.\u00a0The Measurement and Evaluation of White-\ncollar Productivity.\nInternational Journal of Operations & Production Management, \n1989, 9, 28\u201347\n [11]  Sackman, H.; Erikson, W.\u00a0J. and Grant, E.\u00a0E. Exploratory \nexperimental studies comparing online and offline programming \nperformance, Commun. ACM, ACM, 1968, 11, 3\u201311\n [12]  Tangen, S.; Demystifying productivity and performance. \nInternational Journal of Productivity and Performance, 2005, 54, \n34\u201336\n [13]  Jez Humble, David Farley. Continuous Delivery. Reliable Software \nReleases Through Build, Test, and Deployment Automation. \nAddison-Wesley, 2010.\n [14]  Robert S.\u00a0Kaplan, David P .\u00a0Norton: The Balanced Scorecard\u00a0\u2013 \nMeasures that Drive Performance. In: Harvard Business Review. \n(January\u2013February), 1992, S. 71\u201379.\n [15]  Ron Jeffries. Should Scrum die in a fire?  https://ronjeffries.\ncom/articles/2015-02-20-giles/\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 4  Defining proDuCtivity in\u00a0Software engineering"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "39\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_5CHAPTER 5\nA Software Development \nProductivity Framework\nCaitlin Sadowski, Google, USA\nMargaret-Anne Storey, University of Victoria, Canada\nRobert Feldt, Chalmers University of Technology, Sweden\nProductivity is a challenging concept to define, describe, and measure for any kind of \nknowledge work that involves nonroutine creative tasks. Software development is a \nprime example of knowledge work, as it too often involves poorly defined tasks relying \non extensive collaborative and creative endeavors. As in other areas of knowledge \nwork, defining productivity in software development has been a challenge facing \nboth researchers and practitioners who may want to understand and improve it by \nintroducing new tools or processes.\nIn this chapter, we present a framework for conceptualizing productivity in \nsoftware development according to three main dimensions that we propose are \nessential for understanding productivity. To help clarify productivity goals, we \nalso propose a set of lenses  that provide different perspectives for considering \nproductivity along these three dimensions. We contend that any picture of \nproductivity would be incomplete if the three dimensions and various lenses are not \nconsidered."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "40 Productivity Dimensions in\u00a0Software Development\nThe three dimensions in the proposed productivity framework for software engineering \nare as follows:\n\u2022 Velocity : How fast work gets done\n\u2022 Quality : How well work gets done\n\u2022 Satisfaction : How satisfying the work is\nWhen trying to define productivity goals or measure productivity, it is important to \nconsider all three of these dimensions because they work together synergistically. Even \nthough productivity is often considered in terms of increased output (higher velocity), an \nincrease in velocity may not correspond to an actual productivity improvement if there \nis a corresponding drop in the quality of that output. Velocity and quality taken together \nmake up overall work efficiency and effectiveness, while velocity and quality may  \nimpact satisfaction in different ways. An increase in velocity may lead to reduced costs \n(and improve the satisfaction of managers), but at the same time it can lead to increased \nstress for developers (and reduce their satisfaction and in turn incur future costs).  \nA detailed example of the perils of low satisfaction, even with high velocity and quality, \ncan be found in Chapter 11.\n Velocity\nThe velocity dimension captures how productivity is often conceptualized in terms of the \ntime spent doing a task or the time taken (or cost) to achieve a given quantity of work. \nHow one may conceptualize or measure velocity is highly task dependent, and the type \nof task needs to be considered, as well as the granularity, complexity, and routineness of \na particular task. For example, developer velocity metrics could include the number of \nstory points per sprint or the time taken to go from code to a release.\n Quality\nThe quality dimension encapsulates doing a good job when producing artifacts (such as \nsoftware) or the quality of provided services. Quality may be an internal consideration \nin a project (e.g., code quality) or external to a project (e.g., product quality from the \nperspective of the end users). Metrics for quality in a software project could include Chapter 5  a Software Development proDuCtivity framework"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "41counts of negative characteristics such as post-release defects or self-reported ratings of \ndelays incurred by technical debt.\n Satisfaction\nEngineering satisfaction is a multifaceted concept, which makes it challenging to \nunderstand, predict, or measure. This dimension captures human factors of productivity \nand has several possible subcomponents, including physiological factors such as fatigue, \nteam comfort measures such as psychological safety, and individual feelings of flow/\nfocus, autonomy, or happiness. Learning or skill development that may positively \nimpact long-term quality, developer retention, or velocity may manifest as an increase \nin satisfaction. For developers, satisfaction may be impacted by the real or perceived \neffectiveness of their personal work or their team\u2019s work.\n Lenses\nThe three dimensions of productivity can be viewed through different lenses. These \nlenses may help to narrow a research goal and provide perspective on the subsequent \nmethods we may use to understand or measure productivity. The following are the main \ntypes of lenses we feel are important to consider:\n\u2022 Stakeholders : Different stakeholders (e.g., developer, manager, vice \npresident, etc.) may have varied goals and interpretations of any \nsort of productivity measurement. Before trying to understand and \nmeasure productivity, it is essential to identify which stakeholders are \nof concern and what is important to those stakeholders. It may not \nbe immediately obvious which stakeholders should be considered; \na researcher or practitioner may need to carefully elicit which \nstakeholder perspectives are important.\n\u2022 Context : Particular project, social, and cultural factors will change \nperceptions of productivity. For example, if developers feel that \nhelping others is valued by their team, then they will feel that \ntime spent answering questions is productive. The underlying \ndevelopment context (e.g., open source projects versus projects Chapter 5  a Software Development proDuCtivity framework"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "42focused on profits) affects productivity goals. Though context lenses \nare often implicit, sometimes it may be necessary to explicitly \nconsider the impact of any norms, values, or attitudes.\n\u2022 Level : Each lens in the level category represents a particular scale (in \nterms of group size) at which productivity is considered. Individual \ndevelopers, teams, organizations and the surrounding community \nwill lead to different perceptions of productivity, and productivity \ngoals may also be in tension across these different groups. An \nintervention that may benefit one level may not hold at all levels. As \na concrete example, interruptions that negatively impact the person \nwho is interrupted may lead to a net gain from a team perspective. \nFor an in-depth look at four different level lenses, see Chapter 6.\n\u2022 Time period : Productivity perceptions vary greatly according to the period \nof time that is considered (shorter terms such as days, weeks, or sprints \nor longer terms such as months, years, or milestones). For example, a \nprocess change may slow down velocity in the short term but lead to \nenhanced team learning over time and thus speed up velocity over a \nlonger time period. Similarly, short-term velocity enhancements may lead \nto fatigue and lower developer satisfaction over a longer period of time.\n The Productivity Framework in\u00a0Action: Articulating \nGoals, Questions, and\u00a0Metrics\nGiven a particular high-level productivity goal, a common desire is to derive specific metrics \nthat track such a goal. Unfortunately, going from goals to metrics is not trivial as metrics are \ntypically proxies for specific aspects of a goal. One technique to bridge this divide is to have \nan intermediate state under consideration. For example, the goal-question-metric (GQM)  \napproach for understanding and measuring the software process [ 1, 2] works by first \ngenerating \u201cquestions\u201d that define goals and then specifying measures that could answer \nthose questions. GQM suggests a systematic approach to do the following:\n\u2022 Con ceptualize goals  aimed at understanding or improving software \nengineering tools and processes\n\u2022 Specify research questions  to operationalize those goals\n\u2022 Define metrics  for understanding or measuring tools and processesChapter 5  a Software Development proDuCtivity framework"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "43Similar to GQM, the HEART framework is used for measuring usability in design \nprojects [ 3]. HEART first decomposes a high-level usability goal (such as \u201cmy app is \nawesome\u201d) into subgoals, abstract \u201csignals\u201d that could measure those subgoals (e.g., \ntime spent with app), and specific metrics for those signals (e.g., number of shares or \nnumber of articles read in app). In addition to this goals-signals-metrics breakdown, \nthe HEART framework splits usability into five dimensions: happiness, engagement, \nadoption, retention, and task success.\nInspired by the way that the HEART framework involves both splitting by dimensions \nand breaking down from goals to metrics, we propose splitting into goals, questions, \nand metrics in combination with the productivity dimensions and lenses. This \ntechnique can guide the development of specific questions and metrics toward the \nconcrete productivity goals identified. Such goals include measuring the impact of an \nintervention, identifying anti-patterns or problem spots causing productivity losses, \ncomparing groups, or understanding productivity for a particular context. To illustrate \nhow the framework may be used, we sketch two hypothetical examples in the following \nsections.\n Example 1: Improving Productivity Through\u00a0an \nIntervention\nA manager of a software development team (the stakeholder) in a large software \ncompany (the context) would like to improve productivity through the introduction of a \nnew continuous integration system  (the stakeholder\u2019s productivity goal). She hopes that \nproductivity will be improved for both individual developers and the team overall (the \nlevels) and intends to measure the change over the time frame of a few months (the \ntime period).\nA set of specific questions about productivity improvements arises from \nconsidering the productivity goal through the identified lenses along each dimension. \nSince these questions are specific, it is possible to identify a set of metrics that may \nhelp to answer them, as shown in Table 5-1. Note that productivity metrics are always \nproxies for what you really want to measure, and there is a many-to-one relationship \nbetween metrics and a specific question, as well as between a set of specific questions \nand one or more productivity goals.Chapter 5  a Software Development proDuCtivity framework"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "44 Productivity Goal 1: Improve Productivity at\u00a0the\u00a0Individual \nand\u00a0Team Levels Through\u00a0the\u00a0Introduction of\u00a0a\u00a0New  \nContinuous Integration System\nTable 5-1.  Breaking Down Productivity Goal 1 Along the Three Dimensions\nProductivity \nDimensionsQuestions Example Metrics\nQuality is the committed code of a higher \nquality?test covera ge.  \nnumber of bugs post release.\nvelocity are developers able to deploy their \nfeatures more quickly?time from crea ting a patch to patch release.  \ntime to reach team milestones.\nSatisfaction are developers more satisfied with \nthe engineering process using the \nnew tool?Developer ratings for the new system. \nDeveloper ratings of team communication \nenabled by tool.\n Example 2: Understanding How Meetings Impact  \nProductivity\nFor this example, we consider a situation where the stakeholder wants to understand \nrather than try to improve productivity (although improving it may be a longer-term \ngoal). The scenario we present here is the case where developers (the stakeholders) \nworking in a team that also collaborates with other teams at their large company (the \ncontext) would like to understand how meetings impact productivity  (the goal). Here \nthe developers are more interested in an exploratory approach to understanding the \nimpact of meetings on productivity. The dimensions and the lenses help form research \nquestions, as shown in Table\u00a0 5-2. In this example, even though no metrics have been \ndefined, research questions can help sharpen an exploratory analysis by making it more \nconcrete. Since the needs and goals of individual developers might conflict with those of \nthe team and/or organization an exploratory analysis can help clarify such conflicts and \nform a basis for later change. Note that in the table we show only a sample of possible \nrelevant questions along each dimension.Chapter 5  a Software Development proDuCtivity framework"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "45 Productivity Goal 2: Develop an\u00a0Understanding of\u00a0How Meetings \nMay Impact Productivity\n Caveats\nThe framework we propose is abstract by its nature and thus may not suit all studies of \nproductivity, nor may it match every nuanced definition of productivity. Other researchers \nand practitioners may want to consider additional dimensions or lenses depending on \ntheir needs. For example, learning/education could be considered as an explicit fourth \ndimension if this is important to the productivity goals under consideration.\nWhen the dimensions framework is used with GQM, it may not be immediately \nevident to the researcher or practitioner what should be framed as a goal and what \nshould be framed as one or more questions, as a goal could be stated as a research \nquestion or vice versa. As mentioned earlier, the HEART framework offers an alternative \nof using signals instead of questions. We have found it useful in practice to iteratively \nbreak down productivity measures along these three dimensions, and GQM is one \napproach for this.\nAs we noted earlier, any metrics defined are proxies for the concepts being \nmeasured. It is important to choose metrics that adequately capture key aspects of \nmeasured concepts and to be aware that every metric has limitations. We also stress \nthat measuring engineer satisfaction is challenging, as satisfaction is influenced by and \nrefers to many different concepts. The lenses together with the research goal may help \nin identifying how satisfaction should be conceptualized or measured. When it comes to \nsatisfaction in particular, we stress there is no one-size-fits-all solution.Table 5-2.  Breaking Down Productivity Goal 2 Along the Three Dimensions\nProductivity Dimensions Questions\nQuality which meetings prompt follow-up work?\nwhich meetings feel like a waste of time?\nwere all meeting participants needed in the meeting?\nvelocity what characterizes meetings that are the right length?\nwhat is the right length for meetings?\nSatisfaction what characterizes meetings where people feel good after attending?Chapter 5  a Software Development proDuCtivity framework"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "46Finally, identifying/focusing on the right goals is outside the scope of this framework. \nA researcher or practitioner may assume the work being done is the right work when in \nfact it may not be (that is, the wrong tasks may be worked on in a productive manner!).\n Key Ideas\nHere are the key ideas from this chapter:\n\u2022 Productivity should be considered along three dimensions: quality, \nvelocity, and satisfaction.\n\u2022 Thes e three dimensions complement each other but often are in \ntension with each other.\n\u2022 The dimens ions have several possible attributes; measuring them is \nhighly task and situation dependent.\n\u2022 Productivity goals may be refined by considering the three \ndimensions through a set of perspective lenses.\n\u2022 The m ain lenses we suggest include the stakeholders, the \ndevelopment context, the levels, and the time scale.\n References\n [1] V ictor R.\u00a0Basili, Gianluigi Caldiera, and H.\u00a0D. Rombach. The \nGoal Question Metric Approach. In Encyclopedia of Software \nEngineering (John J.\u00a0Marciniak, Ed.), John Wiley & Sons, Inc., \n1994, Vol. 1, pp.528\u2013532.\n [2] V.\u00a0R. Basili, G.\u00a0Caldiera, and H.\u00a0Dieter Rombach. The Goal \nQuestion Metric Approach. NASA GSFC Software Engineering \nLaboratory, 1994. ( ftp://ftp.cs.umd.edu/pub/sel/papers/gqm.pdf )\n [3] HEART framework for measuring UX.  https://www.interaction-\ndesign.org/literature/article/google-s-heart-framework-\nfor-measuring-uxChapter 5  a Software Development proDuCtivity framework"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "47Open Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 5  a Software Development proDuCtivity framework"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "49\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_6CHAPTER 6\nIndividual, Team, \nOrganization, and\u00a0Market: \nFour Lenses of\u00a0Productivity\nAmy J. Ko, University of Washington, USA\nWhen we think about productivity in software development, it\u2019s reasonable to start with \na basic concept of work per unit of effort. The more work a developer accomplishes with \ntheir efforts, the better.\nBut when researchers have investigated how developers think about productivity, \nsome surprising nuances surface about what software engineering \u201cwork\u201d actually \nis and at what level this work should be considered [ 14]. In particular, there are four \nlenses through which one can reason about productivity, and each of these has different \nimplications for what actions one might take to increase productivity in a company.\n The Individual\nThe first and most obvious lens is the individual  perspective. For a developer, a tester, \nor any other contributor to a software team, it\u2019s reasonable to think about the tasks \nthey are assigned, how efficiently those tasks can be completed, and what affects how \nefficiently those tasks are completed. Obviously, a developer\u2019s experience\u2014what they\u2019ve \nlearned in school, online, or in other jobs\u2014can affect how efficiently they accomplish \ntasks. For example, one study showed that in terms of task completion time, the skill of \ncomprehending  what a program does explains much of the variance in task completion"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "50time [ 3]. But these skills aren\u2019t static. For example, while one might expect inexperienced \ndevelopers to always be less efficient than experts, teaching novices expert strategies \ncan make them match expert performance quite quickly [ 17]. As any developer knows, \nhowever, there\u2019s no such thing as mastery; even senior developers are always engaged \nin learning new concepts, architectures, platforms, and APIs [ 5]. This constant learning \nis even more necessary for new hires, whose instincts are often to hide their lack of \nexpertise from the people they need help from [ 1].\nBut experience isn\u2019t the only factor that affects individual productivity. For example, \nwe know that tools strongly influence how efficiently a development task can be \ncompleted. IDEs, APIs, and programming languages, for example, pose many barriers, \nincluding finding relevant APIs, learning to use them correctly, and learning to test and \ndebug them correctly [ 7]. For example, one study found that simply using rudimentary \ntools for navigating code (scroll bars, text search, etc.) can account for up to a third of the \ntime spent debugging code [ 8]. Another study found that tracking the specific structural \nelements in code that a developer navigates and making those structures and their \ndependencies visible can nearly reduce this overhead [ 6].\nHaving the right documentation with the right information (e.g., Stack Overflow \nor other sources of information about API usage) can also accelerate program \nconstruction [ 11], but when that documentation is wrong, it can actually have the \nopposite effect on time to complete tasks [ 18].\nThese discoveries have some simple implications for individual developer \nproductivity. For example, teaching developers strategies that have proven to be more \neffective seems like an unqualified win. Training developers on tools that increase \nproductivity is a potentially cheap way to help developers get more work done in the \nsame amount of time.\n The Team\nAnd yet, when we use a team  lens on productivity, some of these improvements to \ndeveloper productivity suddenly seem less important. For example, if one developer \nis twice as efficient as others on a team but is constantly blocked waiting for work from \nothers, is the team really more productive? Research shows that team productivity \nis actually bounded not by how efficiently individual developers work but by Chapter 6  Ind IvIdual, team, Organ IzatIOn, and\u00a0 market: F Our lenses OF\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "51communication and coordination overhead [ 5]. This is partly because teams work only \nas fast as decisions can be made, and many of the most important decisions are not \nmade individually but collaboratively. However, this is also because even for individual \ndecisions, developers often need information from teammates, which studies have \nshown is always one or two orders of magnitude slower to obtain than referencing \ndocumentation, logs, or other automatically retrievable content [ 10]. These interactions \nbetween individual productivity and team work are also affected by changes in team \nmembership: one study found that slowly  adding people to a team (i.e., waiting for them to \nsuccessfully onboard) reduced  defects, but quickly  adding them increased  in defects [ 13].\nOther team needs can lower productivity for individuals but increase it for the team. \nFor example, interruptions can be a nuisance for individual developers, but if they have \nknowledge that others need to be unblocked, it may improve team productivity overall. \nSimilarly, senior developers may need to teach skills or knowledge to junior developers \nto help junior developers be independently productive. That will reduce the senior \ndeveloper\u2019s productivity for a time but will probably increase the team\u2019s long-term \nproductivity.\nIf we view a team\u2019s work as correctly meeting requirements, then the influence \nof communication and collaboration on a team is clearly just as important as the \nproductivity of individual developers on meeting those requirements. Finding a way to \nmanage teams that streamlines communication, coordination, and decision-making is \ntherefore key and perhaps more impactful than making individual developers faster. All \nof these responsibilities fall upon an engineering manager, whose notion of productivity \nisn\u2019t about how efficiently  individual engineers work but rather about how efficiently a \nteam can meet high-value requirements.\n The Organization\nEven a team lens, however, is a narrow view. An organizational  lens reveals other \nimportant factors. For example, companies often set norms around how projects are \nmanaged, and these norms can greatly influence how efficiently work can move at the \nindividual and team levels [ 4]. Organizations also set policies on whether developers \nare collocated, work down the hall, work at home, or work in entirely different countries. \nThese policies, and their implications for coordination, can directly affect the speed of \ndecisions proportionally to distance [ 16]. Organizations can also set formal policies and  Chapter 6  Ind IvIdual, team, Organ IzatIOn, and\u00a0 market: F Our lenses OF\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "52informal expectations about work-life balance, which can inadvertently lead to \nfatigue and defects [ 9]. Organizations have different norms of code ownership, which \naffects coordination within and between teams and can lead to defects when no \none owns part of an implementation [ 2]. Organizations also invest infrastructure for \nmaintaining awareness of work in other parts of the organization [ 12], such as Google, \nwhich has a single company-wide repository, versus other companies that have vast \nnumbers of disconnected repositories. Companies also have different norms about \nhow interruptions are handled, which can have organization-wide detrimental effects \non productivity [ 15]. All of these cultural and policy factors can also complicate the \nrecruiting and retention of productive developers, as we observed with Yahoo\u2019s decision \nto require that all engineers work on the main Yahoo campus.\nGiven all of these complex factors of organizational culture, one might imagine that \na fruitful way to think about productivity from an organizational perspective is to reason \nabout the unintended consequences of norms and policies on individual and team \nproductivity. An organization\u2019s executives might be charged with monitoring for these \nproblems and developing new policies, norms, and processes with fewer impacts on \nproductivity.\n The Market\nFinally, the organizational lens has its own limitations. Viewing productivity from \na market  lens acknowledges that the whole purpose of an organization that creates \nsoftware is to provide value  to customers and other stakeholders. When Google says its \nmission is to \u201corganize the world\u2019s information, \u201d it\u2019s stating the goal by which the entire \norganization\u2019s performance is judged. Google is therefore more effective when its users \nare more productive at finding information and answering questions relative to other \norganizations with similar goals. To measure productivity in terms of value, a company \nhas to define value propositions  for its product, which is some hypothesis about what \nvalue a product is offering to people relative to competing solutions. Some research has \nframed the refinement and measurement of value propositions as an organization\u2019s \nprimary goal [ 9]. These ever-evolving understandings of an organization\u2019s goal then filter \ndown to new organizational policies, new team-level project management strategies, \nand new developer work strategies targeted at improving this top-level notion of \nproductivity.Chapter 6  Ind IvIdual, team, Organ IzatIOn, and\u00a0 market: F Our lenses OF\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "53 Full-Spectrum Productivity\nWhile it\u2019s easy to assume that each individual in an organization might have to concern \nthemselves with only one of these lenses, studies of software engineering expertise show \nthat great developers are capable of reasoning about code through all of these lenses [ 5]. \nAfter all, when a developer writes or repairs a line of code, not only are they getting an \nengineering task done, they\u2019re also meeting a team\u2019s goals, achieving an organization\u2019s \nstrategic objectives, and ultimately enabling an organization to test its product\u2019s value \nproposition in a market. And the code they write can be seen as a different thing through \neach of these lenses, including not just code but also systems, software, platforms, and \nservices, and products.\nWhat does all of this mean for measuring  productivity? It means you\u2019re not going \nto find one measure for everything. Individuals, teams, organizations, and markets \nneed their own metrics because the factors that affect performance at each of these \nlevels are too complex to reduce to a single measure. I actually believe that individual \ndevelopers, teams, organizations, and markets are so idiosyncratic that each may need \nits own unique measures of performance that capture a valid notion of their work output \n(productivity, speed, product quality, actual versus plan, etc.). That might mean a core \ncompetency of everyone in an organization needs to be finding valid ways of conceiving \nof performance so one can measure and improve it.\n Key Ideas\nThe following are the key ideas from this chapter:\n\u2022 Individuals, teams, organizations, and markets need different \nproductivity metrics.\n\u2022 Productivities for these different lenses are often in tension.\n References\n [1] B egel, A., & Simon, B. (2008). Novice software developers, all over \nagain. ICER.\n [2] Bird, C., Nagappan, N., et\u00a0al. (2011). Don\u2019t touch my code! \nExamining the effects of ownership on software quality. ESEC/FSE.Chapter 6  Ind IvIdual, team, Organ IzatIOn, and\u00a0 market: F Our lenses OF\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "54 [3] Dagenais, B., Ossher, H., et\u00a0al. (2010). Moving into a new software \nproject landscape. ICSE.\n [4] DeMarco, T. & Lister, R. (1985). Programmer performance and the \neffects of the workplace. ICSE.\n [5] Li, P .L., Ko, A.J., & Zhu, J. (2015). What makes a great software \nengineer? ICSE.\n [6] Kersten, M., & Murphy, G.\u00a0C. (2006). Using task context to improve \nprogrammer productivity. FSE.\n [7] Ko, A.\u00a0J., Myers, B.\u00a0A., & Aung, H.H. (2004). Six learning barriers in \nend-user programming systems. VL/HCC.\n [8] Ko, A.J., Aung, H.H., & Myers, B.A. (2005). Eliciting design \nrequirements for maintenance-oriented IDEs: a detailed study of \ncorrective and perfective maintenance tasks. ICSE.\n [9] Ko, A.J. (2017). A Three-Year Participant Observation of Software \nStartup Software Evolution. ICSE SEIP .\n [10]  LaToza, T.D., Venolia, G., & DeLine, R. (2006). Maintaining mental \nmodels: a study of developer work habits. ICSE SEIP .\n [11]  Mamykina, L., Manoim, B., et\u00a0al. (2011). Design lessons from the \nfastest Q&A site in the west. CHI.\n [12]  Milewski, A.\u00a0E. (2007). Global and task effects in information-\nseeking among software engineers. ESE, 12(3).\n [13]  Meneely, A., Rotella, P ., & Williams, L. (2011). Does adding \nmanpower also affect quality? An empirical, longitudinal analysis. \nESEC/FSE.\n [14]  Meyer, A.N., Fritz, T., et\u00a0al. (2014). Software developers\u2019 \nperceptions of productivity. FSE.\n [15]  Perlow, L.\u00a0A. (1999). The time famine: Toward a sociology of work \ntime. Administrative science quarterly, 44(1).\n [16]  Smite, D., Wohlin, C., et\u00a0al. (2010). Empirical evidence in global \nsoftware engineering: a systematic review. ESE, 15(1).Chapter 6  IndIvIdual, team, Organ IzatIOn, and\u00a0 market: F Our lenses OF\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "55 [17]  Benjamin Xie, Greg Nelson, and Amy J. Ko (2018). An Explicit \nStrategy to Scaffold Novice Program Tracing. ACM Technical \nSymposium on Computer Science Education (SIGCSE).\n [18] Fischer, F ., B\u00f6ttinger, K., Xiao, H., Stransky, C., Acar, Y., Backes, M., & \nFahl, S. (2017). Stack overflow considered harmful? The impact of \ncopy&paste on android application security. IEEE Symposium on \nSecurity and Privacy (SP).\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 6  Ind IvIdual, team, Organ IzatIOn, and\u00a0 market: F Our lenses OF\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "57\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_7CHAPTER 7\nSoftware Productivity \nThrough the\u00a0Lens \nof\u00a0Knowledge Work\nEmerson Murphy-Hill, Google, USA\nStefan Wagner, University of Stuttgart, Germany\nWhile this book focuses on software developer productivity, other fields have studied \nproductivity more broadly. Such work lends a perspective that can contribute to a solid \nfoundation to what we know about software developer productivity. In this chapter, we \nprovide an overview of related work about perhaps the most relevant allied field outside \nof software engineering, namely, the productivity of knowledge workers .\n A Brief History of\u00a0Knowledge Work\nThe term knowledge work  was coined by the management guru Peter Drucker in 1959 [ 1]. \nUnlike manual labor where the main output is largely physical goods, knowledge workers \ndeal primarily with information, where each task is usually different from the last, and the \nmain output of the work is knowledge.\nLater, Drucker challenged the field of management research to improve the \nproductivity of knowledge workers in the same way they improved the productivity \nof manual laborers [ 2]. Drucker's contrast of knowledge worker productivity against \nmanual worker productivity is insightful. While productivity of the manual worker can"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "58be improved by understanding and automating the routine steps involved in creating a \nphysical good, the steps involved in the tasks performed by knowledge workers are so \nnonroutine that similar kinds of automation cannot be easily employed.\nFor the past half-century, studies in management and other social sciences have \nexamined how to improve the productivity of the knowledge worker. Because software \ndevelopers are one kind of knowledge worker, it stands to reason that much of what such \nstudies have learned will be applicable to software developer productivity as well.\nStudies about knowledge workers can teach us at least two things about productivity \nof software developers: techniques for measuring productivity and a set of drivers that \nhave been shown to affect knowledge worker productivity. We next discuss each in turn.\n Techniques for\u00a0Measuring Productivity\nAs we discuss elsewhere in this book, measuring software developers' productivity is \nchallenging, and likely no single metric will do (see Chapters 2 and 3). This problem \nalso afflicts researchers in knowledge work, yet they have made progress on the \nproblem by developing a breadth of techniques for measuring productivity. We next \ndescribe the techniques used to measure knowledge worker productivity by turning to \na taxonomy of techniques from Ram\u00edrez and Nembhard [ 4]. We describe some of those \ntechniques and discuss the trade-offs in using each technique. Further, we group these \ntechniques into four categories, which we call outcome-oriented, process-oriented, \npeople-oriented, and multi-oriented techniques. Software engineering practitioners \nand researchers can use these categories to choose appropriate productivity measures \nfor their contexts.\n Outcome-Oriented Techniques\nIn the original literature on improving the productivity of manual workers, it was \ncommon to measure productivity by looking primarily at the output of work per unit \ntime. For software developers, this could be realized by measuring the number of \nlines of code written per day, for instance. This measurement technique has also been \nextended in knowledge worker research by accounting for inputs to the process\u2014such \nas resources or salaries used by the workers. Such outcome-oriented techniques have \nthe advantage of being relatively straightforward to measure. However, as Ram\u00edrez and \nNembhard point out, the knowledge worker research community has largely converged Chapter 7  Software produ Ctivity through the\u00a0Len S of\u00a0Know Ledge worK"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "59on the opinion that such outcome-oriented techniques are generally inadequate \nbecause they fail to take into account output quality , which they generally regard as a \ncritical aspect of productivity. See Chapter 5 for an in depth discussion of the importance \nof quality when measuring productivity. An additional challenge to outcome-oriented \nmetrics for software engineering is that difficult software problems may have similar-\nappearing output to easy problems.\nAnother refinement of these outcome-oriented techniques is using organizational \neconomic output as the outcome, such as a company\u2019s earnings. The main advantage \nof this approach is that economic output is arguably the most direct measure of \nproductivity, at least at a large scale\u2014if a developer\u2019s work does not produce profit \ndirectly or indirectly, are they really being productive? The disadvantages of this \napproach is that, as Ram\u00edrez and Nembhard point out, tracing profits down to individual \nknowledge workers is difficult and also that present economic output is not necessarily \nindicative of future potential economic output. In complex software organizations, \nmeasuring the economic effect of key but indirect developers\u2014such as open source \ndevelopers or infrastructure teams\u2014is relatively challenging.\n Process-Oriented Techniques\nRather than looking at the outcomes of work, some studies examine how knowledge \nworkers\u2019 tasks are performed. For instance, using the multiminute measurement  \ntechnique, knowledge workers fill out forms at regular intervals, reporting what they \nhave done from a predefined list of tasks. Building on this, productivity measurement \ntechniques can measure the time spent in value-added activities, which looks at what \npercentage of time knowledge workers spend doing desirable activities compared to \nthe total number of hours worked. In software engineering, we could define desirable \nactivities as activities that add value to the software product. This could include \nconstructive activities, such as writing code, but also analytical, improving activities, \nsuch as performing code reviews. The advantage of such techniques is that they are \namenable to some amount of automation, such as through experience sampling tools \n(for example, www.experiencesampler.com /) or instrumentation like RescueTime \n(https://www.rescuetime.com /). The primary disadvantages are that simply measuring \nactivities doesn\u2019t measure how well knowledge workers conduct those activities and \nthat it doesn\u2019t take into account quality. To the latter point, some activity-tracking \ntechniques have also been extended to measure quality-enhancing activities, such as by Chapter 7  Software produ Ctivity through the\u00a0Len S of\u00a0Know Ledge worK"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "60counting thinking and organizing as activities that enhance quality and thus enhance \nproductivity. This shows, however, that it is difficult to clearly distinguish between value-\nadding and non-value-adding activities. Potentially, the categorization of waste  could be \nuseful (see Chapter 19).\n People-Oriented Techniques\nIn contrast to the prior techniques, which seek to define productive outcomes and \nactivities up-front, people-oriented techniques empower knowledge workers to define \nmetrics for productivity for themselves. One way to do this is through the achievement \nmethod , which measures productivity by determining the ratio of completed goals to \nplanned goals. An extension of the achievement method is the normative productivity \nmeasurement  methodology, which works to establish consensus among knowledge \nworkers about the different dimensions of productivity. The advantage of these \ntechniques is that measuring productivity as completion of self-determined goals has \ngood construct validity, as research suggests that task or goal completion is the top \nreason that software developers report having a productive workday [ 5].\nUsing interviews and surveys to measure productivity is \u201ca straightforward and \ncommonly used method\u201d to measure knowledge worker productivity and to determine \nknowledge worker compensation [ 4]. Such techniques have the advantage of being \nrelatively easy to administer with existing instruments from the literature and can \ncapture a wide variety of productivity factors. On the other hand, such techniques may \nhave low reliability. To increase the reliability of these techniques, many studies have \nused peer evaluations , where knowledge workers rate their peers\u2019 productivity. However, \nthe disadvantage of this technique is the so-called halo effect, where a peer might rate a \nknowledge worker\u2019s past performance as indicative of their current performance, even if \npast and present productivity are unrelated.\n Multi-oriented Techniques\nAs we describe in Chapters 5 and 6, productivity can be measured through multiple \nfacets within an organization; likewise, the knowledge worker literature has sought \nto understand productivity through multiple facets. For example, the multiple output \nproductivity indicator  can be used to measure productivity when a knowledge worker \nhas more than one output. For instance, a software developer not only produces code Chapter 7  Software produ Ctivity through the\u00a0Len S of\u00a0Know Ledge worK"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "61but also produces infrastructure tools and trains peers in organizational development \npractices. A multiple-level productivity measurement technique is the macro, micro, \nand mid-knowledge worker productivity models , which seeks to measure productivity at \nthe factory, individual contributor, and department levels, respectively. This technique \nmeasures productivity over time using attributes such as quality, cost, and lost time. \nThe main advantage of these techniques is that they provide a more holistic view of \norganizational productivity than many other metrics, but at the same time, collecting \nthem can be complex.\nThese three kinds of techniques\u2014process-, people-, and multi-oriented\u2014provide \na variety of options for practitioners and researchers to use. One way these techniques \ncan be used is to enable those who want to measure productivity to use off-the-shelf, \nvalidated techniques, rather than creating new techniques with unknown validity. \nAnother way these techniques can be used is as a framework to broaden productivity-  \nmeasurement efforts; if an organization is already using process-oriented productivity \ntechniques, they could broaden their portfolio by adding people-oriented techniques. \nSimilarly, researchers can choose multiple techniques to increase the validity of their \nstudies through triangulation.\n Drivers That Influence Productivity\nThe second major contribution of research on knowledge workers that can be applied \nto software engineers is an understanding of what drivers can change knowledge \nworkers\u2019 productivity. Understanding productivity drivers is valuable because it tells \norganizations what changes they can make to improve knowledge worker productivity. \nWhile some productivity drivers are specific to software development, such as code \ncomplexity (see also Chapter 8), other drivers probably apply equally well to knowledge \nworkers generally and software developers specifically, such as the need for quiet spaces \nrequired for concentration.\nWe draw on prior research, which we have found personally insightful, that catalogs \nproductivity drivers among knowledge workers. In an attempt to measure knowledge \nworker productivity, Palvalin created SmartWoW, a survey that captures all the drivers \nthat affect productivity, according to the knowledge work literature [ 3]; readers who want \nto know the strength of the scientific evidence for each factor are encouraged to explore Chapter 7  Software produ Ctivity through the\u00a0Len S of\u00a0Know Ledge worK"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "62the research cited by Palvalin. Palvalin showed that his survey has reasonable validity \nand reliability by assessing it at nine companies with almost 1,000 knowledge workers. \nSmartWoW divides productivity drivers into five types, which we describe here:\nPhysical environment.  The physical environment refers to the place where the \nwork occurs, whether that\u2019s in the office or at home. Studies of knowledge workers \nhave found that a physical environment that increases productivity is one where there \nis adequate space for solitary work for concentration, official and unofficial meetings, \nand informal collaboration. A physical environment that enhances productivity also has \ngood ergonomics with low noise and few interruptions. Software developers\u2019 frequent \ncomplaints about open offices underscore the importance of work environment drivers.\nVirtual environment.  The virtual environment refers to the technology that \nknowledge workers use. A virtual environment that enhances productivity is one where \nthe technology is easy to use and available wherever the knowledge worker is working. \nKnowledge work studies have also identified several specific types of technology as \nproductivity-enhancing, including use of instant messaging, video conferencing, access \nto co-workers\u2019 calendars, and other collaborative groupware. This research suggests that \nusable programming languages and powerful tools, as well as collaboration platforms \nlike GitHub, are important for improving software developer productivity.\nSocial environment.  The social environment refers to the attitudes, routines, \npolicies, and habits performed by workers in an organization. Productive social \nenvironments are those where knowledge workers are given freedom to choose their \nwork methods, work times, and work locations; information flows freely among workers; \nmeetings are efficient; clear technology usage and communication policies exist; \ngoals are cohesive and clearly defined; work is assessed in terms of outcomes, not just \nin terms of activities; and experimentation with new work methods is encouraged. \nA social environment for software development that enhances productivity is one \nwhere, for example, developers are given freedom to try new tools and methodologies. \nThe importance of the social environment is underscored by Google\u2019s finding that \npsychological safety\u2014that members of a team should be able to take risks without fear\u2014\nis the most important predictor of effective teams.\nIndividual work practices.  While the prior environmental drivers enable  productive \nwork through organizational practices, individual work practices measure to what extent \nknowledge workers will actually implement these practices. Productive individual \nwork practices include knowledge workers using technology to reduce unnecessary \ntravel, using mobile devices when waiting (e.g., during travel), prioritizing important \ntasks, using quiet spaces and shutting down disruptive software during tasks that Chapter 7  Software produ Ctivity through the\u00a0Len S of\u00a0Know Ledge worK"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "63require concentration, preparing for meetings, taking care of their well-being, using \nthe organizations\u2019 official communication channels, planning out their workday, and \nexperimenting with new tools and work methods. This suggests that developers are \nproductive when, for example, they can code, test, and push while commuting to work \non shared transit.\nWell-being at work.  Finally, Palvalin includes a knowledge worker\u2019s well-being \nat work both as a driver of productivity at work and as an outcome of productivity. A \nproductive knowledge worker is one who enjoys and is enthusiastic about their work, \nfinds meaning and purpose in their work, is not continuously stressed, is appreciated, \nhas a work-life balance, finds the work atmosphere pleasant, and resolves conflicts with \nco-workers quickly. This suggests that the famous 80-hour workweek developer is not a \nproductive developer.\n Software Developers vs. Knowledge Workers: \nSimilar or Different?\nIn this chapter, we\u2019ve drawn parallels between software developer and knowledge \nworker productivity, so it\u2019s natural to ask whether one should consider their productivity \nthe same or different. Our opinion is that each extreme is a cop-out; considering \nsoftware developer productivity the same as knowledge worker productivity would \nabdicate our responsibility to study the productivity of software developers, while \nconsidering them as entirely different would allow us to reinvent the wheel by ignoring \nprior studies about knowledge worker productivity.\nThe reality is that knowledge workers and software developers are similar in some \nways and different in others, both in kind and in degree. In kind, arguably everything that \ncould possibly affect software developer productivity can be pigeonholed into one the \nfive types of productivity drivers described in the prior section, but doing so elides some \ndrivers that software developers may be uniquely positioned to measure and change, \nsuch as software complexity. In degree, software developers\u2019 productivity is similar in \nsome ways and different in others. For instance, while surveying Google\u2019s employees, the \nfirst author found that job enthusiasm affects productivity to a nearly identical degree \nfor both Google\u2019s knowledge workers and its software developers; on the other hand, he \nalso found that time management autonomy affected knowledge workers\u2019 productivity \nsubstantially more  than it affected software developers\u2019 productivity.Chapter 7  Software produ Ctivity through the\u00a0Len S of\u00a0Know Ledge worK"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "64In sum, those who want to understand the productivity of software developers \nshould also understand the productivity of knowledge workers, not because the latter \ncan replace the former but instead so they can make informed choices about when \nexisting measures and factors ought to be used and when new measures and factors \nought to be invented.\n Summary\nWhile software development has its specific characteristics, there is a lot to learn \nfrom studies of general knowledge work. First, it is not sufficient to look at quantity of \noutput but to include the quality of the work as well (see Chapters 4 and 5). Second, it \nprovides approaches to measure productivity besides outcome. Still, knowledge work \nresearch has not found a suitable way to capture all important aspects of productivity. \nThird, it provides a set of drivers for productivity that are directly applicable to software \ndevelopment, such as enough space for solitary work and a pleasant work atmosphere.\n Key Ideas\nThe following are the key ideas from the chapter:\n\u2022 Software developers are a specific kind of knowledge worker. \nKnowledge worker productivity has been studied in a variety of \ncontexts, and those studies can be used to understand software \ndevelopers.\n\u2022 Ther e are four main techniques for measuring knowledge worker \nproductivity: outcome-, process-, people-, and multi-oriented \nproductivity measurement techniques.\n\u2022 Ther e are five categories of drivers that knowledge worker research \nsuggests influence productivity: the physical environment, the virtual \nenvironment, the social environment, individual work practices, and \nwell-being at work.Chapter 7  Software produ Ctivity through the\u00a0Len S of\u00a0Know Ledge worK"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "65 References\n [1] Dr ucker, P .\u00a0F . (1959). Landmarks of tomorrow. Harper & Brothers.\n [2] Drucker, P .\u00a0F . (1999). Knowledge-worker productivity: The biggest \nchallenge. California management review, 41(2), 79-94.\n [3] Palvalin, M. (2017). How to measure impacts of work environment \nchanges on knowledge work productivity\u2013validation and \nimprovement of the SmartWoW tool. Measuring Business \nExcellence, 21(2).\n [4] Ram\u00edrez, Y.\u00a0W., & Nembhard, D.\u00a0A. (2004). Measuring knowledge \nworker productivity: A taxonomy. Journal of intellectual capital, \n5(4), 602\u2013628.\n [5] Meyer A. N., Fritz T., Murphy G. C., Zimmermann T. (2014). \nSoftware developers\u2019 perceptions of productivity. SIGSOFT FSE \n2014: 19\u201329. \nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 7  Software produ Ctivity through the\u00a0Len S of\u00a0Know Ledge worK"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "PART III\nThe Context of Productivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "69\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_8CHAPTER 8\nFactors That Influence \nProductivity: A\u00a0Checklist\nStefan Wagner, University of Stuttgart, Germany\nEmerson Murphy-Hill, Google, USA\n Introduction\nIn all areas of professional work, there are a lot of factors that influence productivity. \nEspecially in knowledge work, where we do not have easily and clearly measurable \nwork products, it is difficult to capture these factors. Software development is a type of \nknowledge work that comes with even more specific difficulties, as software developers \ndeal nowadays with incredibly large and complex systems.\nYet, developers have to run software projects, manage other software developers, \nand optimize software development to make projects more competitive. Hence, we need \na good overview of factors influencing productivity in software development so that \ndevelopers and managers know what to focus and work on. Developers and managers \nprobably have learned some factors that affect individual productivity, as well as team \nproductivity, from experience. Even more useful, however, would be a list of factors that \nempirically have been shown to impact productivity in a more general way.\nWe provide such a list in this chapter as a kind of checklist that a developer or \nsoftware manager can use to improve productivity. We will discuss technical factors \nrelated to the product, the process, and the development environment, as well as \nsoft factors related to the corporate culture, the team culture, individual skills and \nexperiences, the work environment, and the individual project."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "70 A Brief History of\u00a0Productivity Factors Research\nThere has been research on productivity in software development since the 1970s. The \nfirst studies have been very influential, and several of the factors we have compiled in \nthis chapter were identified back then. However, some of the factors from the 1970s, such \nas chief programmer team usage or previous experience with operational computers, \nhave become less important over time.\nThe 1980s saw a more systematic collection of data with, for example, a series of \nbooks by Jones [ 7]. But researchers also realized the importance of psychological and \nsociological factors. Most important, as De Marco and Lister discuss in Peopleware [ 3],  \nare aspects such as employee turnover and the developers\u2019 workplace. They also \nemphasize product quality as an important factor for productivity. Around the same \ntime, the most famous effort prediction model was published, COCOMO [ 6].\nMaybe as a result of Peopleware, the 1990s saw more research on soft factors. There \nwere studies on project duration and the usage of object-oriented approaches. In the \n2000s, no completely new aspects were introduced, but the understanding of several \nfactors, such as requirements volatility or customer participation, was investigated.\nWe will summarize the main factors from these decades of research and add a brief \nreview of newer factors that have been investigated in the 2010\u2019s so far.\n The List of\u00a0Technical Factors\nThe following three tables show the product, process, and environment factors that have \nbeen found in the literature to have an impact on software development productivity. \nThe factors in the tables are sorted alphabetically.\n Product Factors\nThe list of product factors has seen little change over the past ten years. There are several \nfactors related to size and complexity. Software size usually means the size of the code \nneeded for the software system. Product complexity tries to capture how difficult it is to \nimplement the system with more or less code. In any case, the extent and complexity \nof the software including its data is a major factor that reduces productivity. Related are \nalso technical dependencies. Newer studies have focused on the dependencies between \ndifferent software modules or components and how this is reflected in social dependencies \nin the development team. A high number of dependencies reduces productivity.Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "71Factor Description Source\ndeveloped for reusability to wha t extent should the components be reusable? [ 1]\ndevelopment flexibility how strong are the constraints on the system? [1]\nexecution time constraints how much of the available execution time is consumed? [ 1]\nMain storage constraint how much of the available storage is consumed? [ 1]\nprecedentedness how similar are the projects? [1]\nproduct complexity the complexity of the function and structure of the \nsoftware.[1]\nproduct quality the quality of the product influences motivation and hence \nproductivity.[1]\nrequired software reliability the level of reliability needed. [1]\nreuse the extent of reuse. [1]\nsoftware size the amount of code in the system. [1]\nuser interface the degree of complexity of the user interface. [1]\ntechnical dependencies data-related or functional dependencies such as call \ngraphs or coupled changes.[5, 11]\nA further set of factors that are related are constraints on execution time, main \nstorage constraints, and constraints overall, what we term development flexibility. This \ncould be integrated into a single factor. However, the first two describe more specific \nreal-time and embedded systems, while the latter can also cover other constraints. \nAn example of these constraints might be the use of specific operating systems or \ndatabase systems or a high number of concurrent users. Additional constraints \npotentially slow down development.\nFurthermore, the requirements on the user interface play an important role.  \nIt is a difference if a graphical user interface has to be developed or if the product is a \nbackground service. Sophisticated user interfaces typically reduce productivity.\nThe next product factors are related to quality. The current product quality \nmakes it easier or more complicated to work on the software. Higher requirements \non reliability and reusability can increase the effort needed. New publications widen \nthis also to other quality attributes.Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "72Finally, what the organization has done before plays a role: precedentedness \ndescribes how similar the project in question is to existing software, and reuse describes \nhow much of the new software can be achieved by reusing existing software (e.g., \ninternal or open source).\n Process Factors\nThe next category of factors are still technical but relate more to the process than the \nproduct itself. These factors are related to the project: project length and project type. \nLonger projects are more difficult to organize but benefit more from rules and custom \ntools. A more recent study [ 8] distinguished between development and integration \nprojects. Development projects create most of the software during the project, while \nintegration projects mostly connect and configure existing software. They found that \nintegration projects are more productive.\nFactor Description Source\nagile Is an agile development process used? [10, 12, 13]\narchitecture risk resolution how are the risks mitigated by architecture? [ 1]\nCompleteness of design the amount of the design that is completed when \ncoding starts.[1]\nearly prototyping early in the process prototypes are built. [1]\neffective and efficient v&v the degree to which defects are found and the \nrequired effort therein.[1]\nhardware concurrent \ndevelopmentIs the hardware developed concurrently? [1]\noutsourcing and global \ndistributiondegree of outsourcing of the work of the project. [ 9]\nplatform volatility time span between major changes. [1]\nprocess maturity the well-definedness of the process. [1]\nproject duration length of the project. [1]\nproject type Integration or development project. [8]Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "73From the next factors, we see that different development activities have an impact \non productivity. Architecture risk resolution is important in architecture design and \nevolution. The completeness of design before the start of coding impacts how much \nchanges need to be done later. Finally, effective and efficient V&V (verification & \nvalidation) describes suitable tests, reviews, and automated analysis. Early prototyping \ncan increase productivity because requirements can be clarified and risks can be \nresolved. Today, this is often replaced by iterative and incremental development. \nSuch a development probably is able to better deal with volatile requirements, but the \ncompleteness of the design during initial coding is low.\nMost systems today are not completely stand-alone but rely on specific platforms \nor hardware. If the platform changes frequently (platform volatility), it creates a lot of \nadaptation effort. The concurrent development of hardware also means that it is difficult \nto rely on the hardware and might require adaptation efforts in the software.\nThe last factors are about the process model and the distribution of the work. A \ngeneral factor is the process maturity, meaning how well-defined the development \nprocess is. In the recent years, research has focused on agile processes and found that \nthey impact productivity. A further aspect of recent studies is outsourcing and global \ndistribution of the project.\n Development Environment\nIn the last category, we group factors that are not part of the product but not directly part \nof the process either.\nFactor Description Source\ndocumentation match to \nlife-cycle needshow well the documentation fits the needs [1]\ndomain applica tion domain such as embedded software, \nmanagement information system, or web application[4]\nprogramming language the programming language used [1, 21]\nuse of software tools the degree of tool use [1]\nuse of modern development \npracticesFor example, continuous integration, automated testing, or \nconfiguration management[1]Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "74A very general factor is the domain of the application to be developed. \nEmbedded software systems, for example, often have specific aspects such as \ncross-compiling that make development more difficult. Also quite general is the \nprogramming language used and the use of modern development practices. The \nlatter includes methods such as continuous integration or automated tests that often \ncome with agile development processes but are not restricted to them. Furthermore, \nthe use of software tools such as modern IDEs or test frameworks impacts \nproductivity. Finally, we also count the match of documentation to environmental \nfactors. In particular, it is important if the documentation fits the needs of the \ncurrent state of development.\n The List of\u00a0Soft Factors\nAs most people in a software engineering team have a technical background, we tend to \nfocus on technical aspects. Yet, especially for productivity, many more soft factors play \nan important role. We will discuss the soft factors we have found in the following five \ncategories: Corporate Culture contains the factors that are on a more company-wide \nlevel, whereas Team Culture denotes similar factors on the team level. In Individual \nSkills and Experiences, we summarize factors that are related to individuals. Work \nEnvironment stands for properties of the environment such as the workplace itself. \nFinally, project-specific factors are in the Project category. We sort the factors in each \ncategory again alphabetically.\n Corporate Culture\nWe start with the factors related to the culture of the complete organization. All these \nfactors could also be interesting on the team level, but the culture of a company overall \nreflects down to the teams as well. Researchers have studied the three factors credibility, \nfairness, and respect especially on the organizational level.\nFactor Description Source\nCredibility open communication and competent organization [ 1]\nFairness Fairness in compensation and diversity [1]\nrespect opportunities and responsibilities [1]Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "75Credibility is probably the most general factor that describes that communication \nis open overall in the company and the organization is competent in what it is doing. \nIn our context, this could mean, for example, that there is an understanding on the \norganizational level of how to plan and run software projects. In fairness, we include \nequal payment opportunities for all employees and diversity in terms of gender or \nbackground in the organization. Respect, finally, means that the organization sees \ntheir employees not only as \u201chuman resources\u201d but as people; management gives the \nemployees opportunities and trusts them with responsibilities.\n Team Culture\nThere has been considerably more research on the team level than on the corporate \nlevel. There can be strong differences between teams in the same company. The higher \nnumber of studies brought us eight factors in team culture influencing productivity.\nFactor Description Source\nCamaraderie social and friendly atmosphere. [1]\nClear goals how clearly defined are the group goals? [1]\nCommunication the degree and efficiency of which information flows in the team. [ 1]\npsychological safety the atmosphere is safe for risk-taking. [14, 15]\nsense of eliteness the feeling in the team that they are superior. [1]\nsupport for innovation to wha t degree assistance for new ideas is available. [1]\nteam cohesion the cooperativeness of the stakeholders. [1]\nteam identity a common identity of the team members. [1]\nturnover the amount of change in the personnel. [1]\nCamaraderie means a social and friendly atmosphere where team members \nsocialize but also help each other. The second factor in this category consists of clear \ngoals that are necessary so that all team members work toward the same objective. Most \ngeneral is the factor communication that includes the degree as well as the efficiency \nof information flow inside the team. In general, what is surprising in the studies is that \ncommunication effort is positive for productivity. In discussions, we often hear that Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "76communication should be reduced to decrease unnecessary work. However, the actual \nproblems seems to be the increase of communication effort when putting more and \nmore people on a project. Yet, a high fraction of effort on communication seems like a \ngood investment.\nPsychological safety is similar to camaraderie but more specifically refers to an \natmosphere where individual developers can take risks and share personal information, \nbut know that teammates will handle these risks with respect and kindness. This is a \nfactor that more recently came into productivity discussions in the context of software \nprojects because of a large study at Google [ 14]. Also similar but aiming in a different \ndirection is the sense of eliteness of the team. If the team believes that they are the best \nengineers always building the highest-  qualit y software, they are more likely to go the \nextra mile to actually achieve this.\nAlso related to psychological safety is support for innovation. This contains to \nsome degree safety for taking risks, but it also means that the team members are open \nto bring in innovations and also change the way they work. Yet another view on this \nis team cohesion. Team cohesion describes how well all team members are willing to \nwork together. This does not necessarily include a social and friendly atmosphere but a \nprofessional approach to working together.\nA common team identity also seems to support productivity, probably by influencing \nother factors such as camaraderie or the sense of eliteness. Finally, the turnover in the \nteam might be influenced by the factors mentioned so far. Team changes could also be \nordered by management because of other influences. In any case, less turnover is better \nfor productivity, and it is one of the few factors that we can easily measure.\n Individual Skills and\u00a0Experiences\nBesides teams, individual skills and experiences are the most well-studied. We found \nit notable that although experience is often brought up and is in interviews considered \nimportant, in empirical studies it is rather insignificant. By far more interesting is the \ncapability of the developers. Hence, this suggests that being in a profession for a long \ntime does not necessarily make one productive.Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "77Factor Description Source\nanalyst capability the skills of the system analyst [1]\napplica tion domain experience the familiarity with the application domain [1]\ndeveloper personality Individual personality and the mix of different \npersonalities on the team[1, 19]\ndeveloper happiness positive experiences leading to positive emotions [ 16\u201318]\nlanguage and tool experience the familiarity with the programming language and tools\nManager application domain \nexperiencethe familiarity of the manager with the application [ 1]\nManager capability the control of the manager over the project. [1]\nplatform experience the familiarity with the hardware and software platforms [1]\nprogrammer capability the skills of the programmer [1]\nTherefore, we have factors for the analyst capability, the manager capability, and \nthe programmer capability. Each refers to the skills of the individuals in their respective \nroles. For each role, these skill sets will differ, but there is thus far no fixed set of skills \nnecessary for the roles that came out of the studies.\nExperience does play a role but more in the sense of the experience with application \ndomains and platforms. We have the three factors of application domain experience, manager \napplication domain experience, and platform experience. The first two refer to how long \nand with what intensity the developers and managers have worked on software in a specific \napplication domain. The latter refers to the experience of the individuals with a hardware \nand/or software platform such as the iOS operating system for mobile Apple devices.\nDeveloper personality has been investigated in many empirical studies. Few \nmeasure personality according to the state of the art in personality psychology. A more \nrecent study [ 19] found only one personality trait\u2014conscientiousness\u2014impacted \nproductivity (positively).\nSimilarly to the study of personalities, another important psychological area has \nrecently been investigated: the emotions of developers. Several studies [ 16\u201318] looked \nat the relationship of happiness of developers and their productivity. They found indeed \nthat happy developers are more productive. You can find more details in Chapter 10.Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "78 Work Environment\nThis category of factors could be seen on the organizational or team level. Yet, as there \nare five factors, we decided to put them in their own category. They describe the direct \nwork environment of the software engineers.\nFactor Description Source\ne-factor this environmental factor describes the ratio of uninterrupted hours \nand body-present hours.[1]\noffice layout private or open-plan office layout. [22]\nphysical separation the team members are distributed over the building or multiple sites. [1]\nproper workplace the suitability of the workplace to do creative work. [1]\ntime fra gmentation the amount of necessary \u201ccontext switches\u201c of a person. [ 1]\ntelecommunica tion \nfacilitiessupport for work at home, virtual teams, video conferencing with \nclients.[1]\nThe e-factor introduced by DeMarco and Lister in Peopleware [ 3] emphasizes that \nuninterrupted time for work is important for productivity. Chapter 9 discusses this in \nmore detail, and Chapter 23 shows an idea to improve the e-factor.\nAlthough we have not found studies focusing specifically on software engineering \nteams, there are several studies on office layout that should apply in our context. In \nsoftware companies, we frequently see open-plan offices with the reasoning that \ninteraction between team members is important. A recent large study [ 22] found no \nevidence that this is actually the case. Instead, interruptions are much higher; hence, the \ne-factor becomes worse in open-plan offices.\nDistributed development of software, meaning software teams physically distributed \nover several locations in potentially several different time zones, is common today. There \nis a considerable body of work on the potential problems with this working mode. It can \nhave a negative effect on productivity.\nAlso, the workplace itself has an effect on productivity. There are studies investigating \naspects such as if there are windows and natural light or the size of the room and space \non a desk. Time fragmentation is related to the e-factor but covers more the aspect of \nhow many different projects and kinds of tasks you have to work on. This results in costly \ncontext switches that could be avoided if you could focus on a single project.Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "79Finally, proper telecommunication facilities are important so that you can work from \nhome, work efficiently part-time, or interact efficiently with other team members who \nare in another physical location.\n Project\nFinally, there are factors related to the individual project that are not technical in the \nsense that they come from the technology or programming language. Instead, the people \nassociated with the project influence them.\nFactor Description Source\naverage team size number of people on the team [1]\nrequirements stability the number of requirements changes [1, 4, 20]\nschedule the appropriateness of the schedule for the development task [ 1]\nThere are many studies looking into the relationship of team size and productivity. \nIt is well established that larger teams lead to exponentially increasing communication \nefforts that, in turn, lead to lower productivity. Newer, agile software development \nprocesses therefore often recommend team sizes of about seven.\nAlso, the requirements stability over a project has been the subject of several \nstudies. Highly unstable requirements lead to time, effort, and budget overruns; overall \ndemotivation; decreased efficiency; and the need for post-implementation [ 20]. Again, \nagile development processes focus on this problem by reducing development cycles to a \nfew weeks.\nFinally, the planned project schedule needs to fit the actual work to be done. Several \nstudies show that schedules that are too tight in effect reduce the productivity.\n Summary\nOur taxonomy of factors influencing software development productivity is extremely \ndiverse. The technical factors range from detailed product factors, such as execution \ntime constraints, to general environment factors such as the use of software tools. The \nsoft factors have been investigated on the corporate, team, project, and individual levels. \nFor specific contexts, it will be necessary for practitioners to look into each of these Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "80factors in more detail. We hope that this chapter can be used as a starting point and \nchecklist for productivity improvement in practice.\n Key Ideas\nThese are the key ideas from this chapter:\n\u2022 The major factors influencing software development productivity can \nbe summarized in a checklist for developers and managers.\n\u2022 Some of the relevant research on productivity factors is decades old.\n Acknowledgments\nWe are grateful to Melanie Ruhe for previous discussions on productivity and \nproductivity factors.\n Appendix: Review Design\nThis chapter is not meant to be a full-fledged academic literature review. Instead, \nwe used our prior literature review [ 1] as a start and updated it with a search on \nGoogle Scholar. For the analysis, we also reused the search string from [ 1] to stay \nconsistent: software AND (productivity OR \u201cdevelopment efficiency\u201d OR \u201cdevelopment \neffectiveness\u201d OR \u201cdevelopment performance\u201d)\nIn contrast to the old review, however, we looked at only the first 30 results from 2017 \nto 2018\u00a0in Google Scholar. Of those results, we extracted any new relevant productivity \nfactors from empirical studies. We did not use studies that only validated factors already \non the list to keep this article concise. We also noted that while most of the factors \ncome from academic papers investigating these factors in more detail, the old literature \nreview [ 1] also included the books by Boehm [ 6] and Jones [ 7] as a baseline. They do not \ninvestigate single factors but use a set of factors to discuss productivity.\nFinally, the extracted academic studies have limitations, such as some of them use \nlines of code per person-hour as a productivity measure. This is easy to measure but \nhas significant problems because more code is not necessarily good. In many instances, \nless code is actually better as long as it fulfils the customer\u2019s requirements and needs. \nWe decided to not exclude these studies, however, as the identified factors still might be \ninteresting.Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "81 References\n [1] W agner, Stefan and Ruhe, Melanie. \u201c A Systematic Review of \nProductivity Factors in Software Development. \u201d In Proc. 2nd \nInternational Workshop on Software Productivity Analysis \nand Cost Estimation (SPACE 2008). Technical Report ISCAS-  \nSKLCS-  08-08, S tate Key Laboratory of Computer Science, Institute \nof Software, Chinese Academy of Sciences, 2008.\n [2] Hernandez-Lopez, Adrian, Ricardo Colomo-Palacios, and \nAngel Garcia-Crespo. \u201cSoftware engineering job productivity\u2014a \nsystematic review. \u201d International Journal of Software Engineering \nand Knowledge Engineering 23.03 (2013):387\u2013406.\n [3] T.\u00a0DeMarco, T.\u00a0Lister. \u201cPeopleware. Productive Projects and \nTeams. \u201d Dorset House Publishing, 1987.\n [4] Trendowicz, Adam, M\u00fcnch, J\u00fcrgen. \u201cFactors Influencing Software \nDevelopment Productivity\u00a0\u2013 State of the Art and Industrial \nExperiences. \u201d Advances in Computers, vol 77, pp.\u00a0185\u2013241, 2009.\n [5] Cataldo, Marcelo, James D.\u00a0Herbsleb, and Kathleen M.\u00a0Carley. \n\u201cSocio-technical congruence: a framework for assessing \nthe impact of technical and work dependencies on software \ndevelopment productivity. \u201d Proceedings of the Second ACM-IEEE \ninternational symposium on Empirical software engineering and \nmeasurement. ACM, 2008.\n [6] B.\u00a0W. Boehm, C.\u00a0Abts, A.\u00a0W. Brown, S.\u00a0Chulani, B.\u00a0K. Clark, \nE.\u00a0Horowitz, R.\u00a0Madachy, D.\u00a0Reifer, and B.\u00a0Steece. Software Cost \nEstimation with COCOMO II.\u00a0Prentice-Hall, 2000.\n [7] C.\u00a0Jones. Software Assessments, Benchmarks, and Best Practices. \nAddison-Wesley, 2000.\n [8] Lagerstr\u00f6m, R., von W\u00fcrtemberg, L.M., Holm, H., Luczak, \nO.\u00a0Identifying factors affecting software development cost and \nproductivity. Software Qual J (2012) 20: 395. https://doi.\norg/10.1007/s11219-011-9137-8 .Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "82 [9] Tsunoda, M., Monden, A., Yadohisa, H. et\u00a0al. Inf Technol Manag \n(2009) 10: 193. https://doi.org/10.1007/s10799-009-0050-9 .\n [10]  Kautz, Karlheinz, Thomas Heide Johanson, and Andreas Uldahl. \n\u201cThe perceived impact of the agile development and project \nmanagement method scrum on information systems and software \ndevelopment productivity. \u201d Australasian Journal of Information \nSystems 18.3 (2014).\n [11]  Cataldo, Marcelo, and James D.\u00a0Herbsleb. \u201cCoordination \nbreakdowns and their impact on development productivity and \nsoftware failures. \u201d IEEE Transactions on Software Engineering 39.3 \n(2013): 343\u2013360.\n [12]  Cardozo, Elisa SF , et\u00a0al. \u201cSCRUM and Productivity in Software \nProjects: A Systematic Literature Review. \u201d EASE. 2010.\n [13]  Tan, Thomas, et\u00a0al. \u201cProductivity trends in incremental and \niterative software development. \u201d Proceedings of the 2009 3rd \nInternational Symposium on Empirical Software Engineering and \nMeasurement. IEEE Computer Society, 2009.\n [14]  Duhigg, Charles. \u201cWhat Google learned from its quest to build the \nperfect team. \u201d The New\u00a0York Times Magazine 26 (2016): 2016.\n [15]  Lemberg, Per, Feldt, Robert. \u201cPsychological Safety and Norm \nClarity in Software Engineering Teams. \u201d Proceedings of the 11th \nInternational Workshop on Cooperative and Human Aspects of \nSoftware Engineering. ACM, 2018.\n [16]  Graziotin, D., Wang, X., and Abrahamsson, P . 2015. Do feelings \nmatter? On the correlation of affects and the self-assessed \nproductivity in software engineering. Journal of Software: \nEvolution and Process. 27, 7, 467\u2013487. DOI=10.1002/smr.1673. \nAvailable: https://arxiv.org/abs/1408.1293 .\n [17]  Graziotin, D., Wang, X., and Abrahamsson, P . 2015. How do you \nfeel, developer? An explanatory theory of the impact of affects \non programming performance. PeerJ Computer Science. 1, e18. \nDOI=10.7717/peerj-cs.18. Available: https://doi.org/10.7717/\npeerj-cs.18 .Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "83 [18]  Graziotin, D., Fagerholm, F ., Wang, X., & Abrahamsson, P . (2018). \nWhat happens when software developers are (un)happy. Journal \nof Systems and Software, 140, 32-47. doi:10.1016/j.jss.2018.02.041. \nAvailable: https://doi.org/10.1016/j.jss.2018.02.041 .\n [19]  Zahra Karimi, Ahmad Baraani-Dastjerdi, Nasser Ghasem-\nAghaee, Stefan Wagner, Links between the personalities, styles \nand performance in computer programming, Journal of Systems \nand Software, Volume 111, 2016, Pages 228\u2013241, https://doi.\norg/10.1016/j.jss.2015.09.011 .\n [20]  D.\u00a0M\u00e9ndez Fern\u00e1ndez, S.\u00a0Wagner, M.\u00a0Kalinowski, M.\u00a0Felderer, \nP .\u00a0Mafra, A.\u00a0Vetr\u00f2, T.\u00a0Conte, M.-T.\u00a0Christiansson, D.\u00a0Greer, \nC.\u00a0Lassenius, T.\u00a0M\u00e4nnist\u00f6, M.\u00a0Nayabi, M.\u00a0Oivo, B.\u00a0Penzenstadler, \nD.\u00a0Pfahl, R.\u00a0Prikladnicki, G.\u00a0Ruhe, A.\u00a0Schekelmann, S.\u00a0Sen, \nR.\u00a0Spinola, A.\u00a0Tuzcu, J.\u00a0L. de la Vara, R.\u00a0Wieringa, Naming the \npain in requirements engineering: Contemporary problems, \ncauses, and effects in practice, Empirical Software Engineering \n22(5):2298\u20132338, 2017.\n [21]  Ray, B., Posnett, D., Filkov, V ., & Devanbu, P . (2014, November). A \nlarge scale study of programming languages and code quality in \ngithub. In Proceedings of the 22nd ACM SIGSOFT International \nSymposium on Foundations of Software Engineering (pp.\u00a0155\u2013\n165). ACM.\n [22]  Jungst Kim, Richard de Dear, \u201cWorkspace satisfaction: The \nprivacy-communication trade-off in open-plan offices, \u201d Journal of \nEnvironmental Psychology 36:18\u201326, 2013.Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "84Open Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 8  Fa Ctors that In Fluen Ce produ CtIvIty: a\u00a0CheCklIst"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "85\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_9CHAPTER 9\nHow Do Interruptions \nAffect Productivity?\nDuncan P.  Brumby, University College London, UK\nChristian P.  Janssen, Utrecht University, The Netherlands\nGloria Mark, University of California Irvine, USA\n Introduction\nWhen was the last time you were interrupted at work? If you use a computer for \nwork and if it has been more than a couple of minutes, count your blessings and be \nprepared for an upcoming interruption. Modern information work is punctuated \nby a constant stream of interruptions [ 16]. These interruptions can be from external \nevents (e.g., a colleague asking you a question, a message notification from a \nmobile device), or they can be self-initiated interruptions (e.g., going back and \nforth between two different computer applications to complete a task). A recent \nobservational study of IT professionals found that some people interrupt themselves \nafter just 20 seconds of settling into focused work [ 38].\nGiven the omnipresence of interruptions in the modern workplace, researchers have \nasked what impact these have on productivity. This question has been studied in many \napplication domains, from the hospital emergency room to the open-planned office, \nusing a variety of different research methods."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "86In this chapter, we provide a brief overview of three prominent and complementary \nresearch methods that have been used to study interruptions. The methods we review \nare as follows:\n\u2022 Controlled experiments that demonstrate that interruptions take \ntime to recover from and lead to errors\n\u2022 Cognitive models that offer a theoretical framework for explaining \nwhy and how interruptions are disruptive\n\u2022 Observational studies that give a rich description of the kinds of \ninterruptions that people experience in the workplace\nFor each of these three research approaches, we will explain the aim of the \nmethod, why it is relevant to the study of interruptions, and some of the key findings. \nOur aim is not to offer a comprehensive review of all studies in this area but rather \nan introduction focusing on our own past research, which spans each of these three \nmethods. We direct the interested reader to more comprehensive reviews of the \ninterruptions literature [ 28, 44, 45].\n Controlled Experiments\nThere is a long tradition of experiments being conducted to learn about the effect of \ninterruptions on task performance. The earliest studies were conducted in the 1920s and \nfocused on how well people remembered tasks that they had previously worked on. In \nthese experiments, Zeigarnik [ 50] demonstrated that people were better at recalling the \ndetails of incomplete or interrupted tasks than tasks that had been finished.\nSince the advent of the computer revolution, research has focused on investigating \nthe impact that interruptions have on task performance and productivity. This shift was \nprobably spurred on by people\u2019s annoyances with poorly designed computer notification \nsystems that interrupted them to attend to incoming e-mails or perform software \nupdates while trying to work on other important tasks. Experiments offer a suitable \nresearch method to address the question of whether these feelings of being annoyed by \ninterruptions and notifications translate into systematic and observable decrements in \ntask performance.Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "87 What Is the\u00a0Aim of\u00a0an\u00a0Experiment?\nBefore we review what has been learned from interruption experiments, it is worth \ntaking a moment to reflect on the purpose of an experiment. Experiments are designed \nto test a hypothesis. For example, do people work slower when interrupted compared \nto when they have not been interrupted? To test this hypothesis, the researcher \nmanipulates a feature of interest (the independent variable), which in our case might be \nthe presence or absence of an interrupting task. The researcher wants to learn whether \nthis manipulation has an effect on an outcome measure (the dependent variable), which \nin our case might be how quickly a task is completed.\nExperiments are designed to test the causal  relationship between variables. To do \nthis, the researcher will attempt to control all other extraneous variables. This is why \nexperiments are usually conducted in a controlled setting using a fixed set of instructions \nand tasks given to all participants who take part in the experiment. In doing so, the \nresearcher wants to be able to isolate whether a change in the independent variable has \na reliable (i.e., statistically significant) effect on the dependent variable. If an effect exists, \nthen it should show up time and again through the independent replication of results. \nAs we will learn in a moment, experiments have consistently shown that interruptions \nnegatively impact task performance.\n A Typical Interruptions Experiment\nIn a typical interruptions experiment, the researcher will ask a participant to work on a \ncontrived task that they have designed. For example, the participant might be asked to \nuse a computer interface to order some tasty donuts [ 32]. The cover story is provided to \ngive some context to the task that the participant has been asked to work on, and it can \nbe easily adjusted to suit the target domain of the study. For example, naval researchers \nhave asked participants to place orders for the construction of ships [ 46], and healthcare \nresearchers have asked participants to place orders for prescription medicines [ 18]. \nRegardless of the domain, the researcher gives the participant detailed instructions on \nhow to complete the task using the interface and plenty of opportunities to practice it \nbefore starting the main part of the experiment.\nIn the main part of the experiment, participants will be asked to complete a number \nof tasks (e.g., place ten orders for doughnuts) using the instructed procedure. While \nthe participant is working on this task, the researcher will occasionally interrupt them \nand ask them to work on a secondary task instead. The secondary task might require Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "88the participant to solve some mental arithmetic problems [ 32] or use a mouse to track a \nmoving cursor on the screen [ 39]. In these experiments, the arrival of this interrupting \ntask is carefully controlled by the experimenter, and the participant is often given no \nchoice but to switch from the primary task to the interrupting task. This is because the \nresearcher wants to learn whether the interrupting task affects the quality and pace of \nthe work produced on the primary task.\n How Is Disruptiveness of\u00a0an\u00a0Interruption Measured?\nThis discussion leads us to consider how we measure the impact of an interruption \non task performance. The primary measure that has been used is the time it takes a \nparticipant to resume work on the primary task after dealing with an interruption. This \ntime-based measure is referred to in the literature as the resumption lag  [4, 45]. The \nresumption lag measures the time it takes a person to re-engage with a task following \nan interruption. A longer resumption lag following an interruption reflects a general \ndecrease in productivity: people are taking more time to complete a task, even when \nthe time spent working on the interrupting task is deducted. In this way, the resumption \nlag is taken to reflect the time that is needlessly \u201cwasted\u201d as a consequence of being \ninterrupted and later having to resume an unfinished task.\nOver recent years a number of experiments have been reported that use the \nresumption lag measure to carefully unpack which features of an interrupting task \nmake it disruptive. Experiments have investigated whether longer interruptions \nare more disruptive than shorter interruptions\u2014finding that longer interruptions \nresult in longer resumption lags [ 19, 39]. Studies have also been conducted to \nlearn whether there are better or worse points in a task to be interrupted\u2014shorter \ninterruption lags are found when interruptions occur at natural breakpoints in a \ntask, such as the completion of a subtask [ 2, 7]. The content of an interrupting task \nalso matters\u2014interruptions that are relevant to the primary task are less disruptive \nthan interruptions that have nothing to do with the primary task [ 17, 21]. As we \nwill discuss, the resumption lag has been explained by assuming that interruptions \ninterfere with people\u2019s ability to remember what they were doing prior to the \ninterruption.Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "89 Interruptions Cause Errors\nWhen a person resumes a task following an interruption, it often matters whether they \nget it right or make a mistake. Previous research has shown that interruptions increase \nthe likelihood of errors being made on a task, in that important components of the task \nare either repeated or missed [ 9, 32, 46]. This finding has been taken as evidence to \nsupport the idea that following an interruption people fail to remember what they were \ndoing in a task prior to being interrupted.\nIt has also been informative to consider whether there is a link between how \nquickly a task is resumed and the likelihood that an error is made. As discussed, \ninterruption researchers have generally considered a longer resumption lag to be a \nbad thing\u2014 reflecting time needless wasted following an interruption. In contrast, \nBrumby et\u00a0al. [ 9] found that longer resumption lags following an interruption were \nin fact beneficial  in terms of reducing the occurrence of errors. This has important \npractical implications for the design of systems to encourage more reflective task \nresumption behavior in situations where interruptions are commonplace. Based \non these findings, Brumby et\u00a0al. developed and tested a post-interruption interface \nlockout that allowed users to look at the task interface but prohibited actions to \nbe made. This interface lockout led to a significant reduction in resumption errors \nbecause it encouraged users to take the time to cognitively re-engage with a task \nbefore diving back into it and making a mistake.\n Moving Controlled Experiments Out of\u00a0the\u00a0Lab\nA criticism that is often leveled at the kind of interruption experiments that we\u2019ve \nreviewed is that the controlled setting in which they are conducted bears little \nresemblance to people\u2019s actual work environments and how they manage the \ninterruptions that they experience at work. In other words, our experiments can \nlack ecological validity  because an important aspect of the phenomena that we are \nattempting to investigate is missing. This is an important concern because it means that \nthe results of these interruption experiments might be of limited practical value or that \nthey might not be valid at all when taken away from the controlled setting of the lab and \napplied to an actual work setting.Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "90How might an interruption experiment lack ecological validity? Interruption \nexperiments are often conducted in controlled environments in which the researcher \nactively works to remove unwanted distractions and interruptions (e.g., participants will \nbe asked to turn off their phone and give their complete attention to the researcher\u2019s \ntask). The reason for this is that the experimenter wants to carefully control the nature \nand the timing of any interruptions so as to learn how they affect performance. Ironically, \nthis desire for control presents a major threat to the ecological validity of the experiment. \nThis is because most of the everyday interruptions that we experience are not forced but \nare instead discretionary . For example, an e-mail notification might appear on a screen, \nbut we can choose whether to act on it or ignore it. By using enforced interruptions that \nparticipants have to attend to, interruption experiments can fail to capture this important \naspect of the phenomena that they are attempting to study in the lab.\nTo overcome concerns about low ecological validity, Gould et\u00a0al. [ 18] has taken an \napproach that relaxes experimental control over the environment in which participants \nwork to study how naturally occurring interruptions affect performance. To do this, Gould \net\u00a0al. used an online crowdsourcing platform, Amazon\u2019s Mechanical Turk, to host an \ninterruptions experiment. Just like in a regular interruptions experiment, participants were \nasked to use a browser-based task interface to place orders for prescription medicines. \nBut unlike a traditional lab experiment, participants worked on this task in their regular \neveryday environment: an office, a coffee shop, or their home. These are naturalistic \nenvironments that are filled with everyday interruptions and distractions. In addition, \nworkers on crowdsourcing platforms, like Amazon\u2019s Mechanical Turk, often work on \nmultiple tasks at the same time; the environment is designed to encourage workers \nto complete as many tasks as possible so as to maximize their pay. This means that a \ncompeting (interrupting) task is often present, vying for the participant\u2019s attention.\nBy running an interruptions experiment on a crowdsourcing platform, Gould et\u00a0al. [ 18]  \nfound that workers switched to other tasks once every five minutes. This was revealed \nby window switching events and pauses in progression through the task. These \ninterruptions were not inserted by the experimenter but were naturally occurring and \nat the discretion of the participant. Interestingly, this rate of interruptions corresponds \nto that seen in observational studies [ 16]. While these interruptions tended to be quite \nbrief (around 30 seconds on average), Gould et\u00a0al. found that they were sufficient to \nnegatively impact performance on the primary task: participants who interrupted more \noften were considerably slower at completing the task, even after accounting for the time \nspent not working on the task. We know this only because the primary task interface \nwas under the control of the researchers; this was not a naturalistic observation study. Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "91Gould et\u00a0al. \u2019s study provides a bridge between controlled experiments and observation \nstudies; it provides evidence that the disruptiveness of interruptions can be readily \ndetected out in the field and that it is not an artificial product of the controlled setting \nused in interruption experiments.\n Summary: Controlled Experiments\nBy conducting controlled experiments, researchers have been able to establish that \ntask interruptions take time to recover from and lead to errors. Experiments offer \nan empirical approach for systematically testing whether the manipulation of an \nindependent variable (e.g., the duration of a task interruption) has an effect on a \ndependent variable (e.g., the duration of the post-interruption resumption lag). \nEstablishing whether the manipulation of an independent variable has an effect on the \ndependent variable is of both practical and theoretical value.\nIn practical terms, knowledge is developed about what makes an interruption \ndisruptive, allowing practical intervention to be developed and tested. For example, \nBrumby et\u00a0al. [ 9] established that when people made faster task resumptions, they were \nmore likely to make an error. Learning about this prompted the development of an \ninterface lockout mechanism that stopped users from resuming a task quickly following \nan interruption, reducing task errors.\nIn theoretical terms, experiments support the development of theories that seek \nto explain  why longer interruptions result in a longer resumption lag. What is the \nmechanism that causes this? How can it be explained? In the next section, we turn our \nattention to reviewing efforts to develop theory using cognitive models.\n Cognitive Models\nOnce findings have been made in experiments, the data and results can be used to \ndevelop theories about human behavior and thought. Cognitive models can be used \nto formalize the cumulative knowledge that is gained from experiments into formal \ntheories (e.g., mathematical equations) that can generate predictions for future \nsituations. For example, a mathematical model can be used to predict the likelihood that \nan error will be made on a task based on the duration of an interruption [ 4, 7]. Stated \ndifferently, cognitive models help to explain why and how interruptions are disruptive.Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "92 What Are Cognitive Models?\nAn important characteristic of cognitive models is that they generate an exact prediction  \n(i.e., generate a number) as an outcome  (e.g., likelihood of an error), given an input  (e.g., \ntime away from the main task), and a formal description  of how input is transformed  \ninto output (i.e., a computer program that captures theory of the process of forgetting). \nOther more conceptual theories of interruptions [ 6] or multitasking [ 49] also provide \ninsight into human behavior and thought but typically tend to miss at least one of these \nthree components (output, input, or transformation step) or describe them in less formal \nterms, such that the details that are needed to give an exact prediction are not available.\nThe value of cognitive models lies in their ability to predict aspects of human \nbehavior and thought in detail . Cognitive modeling aims to unravel human thought by \nuncovering the details and making those details open for scientific debate [ 40]. As an \nexample, take the Memory for Goals theory of forgetting [ 4], which has been applied \nto explain the results of interruption experiments. The model can be used to make a \nprediction for how quickly tasks will be resumed after an interruption. To do so, the \nmodel uses a mathematical function, derived from psychological theory, to determine \nhow quickly a person will be able to recall what they were doing prior to dealing with \nan interruption based on the strength of this memory. The value of the model is that \nit gives a prediction for how quickly someone will resume a task (i.e., the resumption \nlag). Moreover, the general theory of memory retrieval that underpins this model helps \nexplain why  these resumption lags occur (namely, because of forgetting).\nSince the inception of the basic Memory for Goals theory, the theory has been \nrefined in many ways. Examples include the prediction of errors due to interruptions \n[46], the prediction of task switching performance [ 3], and the prediction of concurrent \nmultitasking performance [ 7]. The initial modeling effort was crucial in this regard: by \nspecifying a theory (of forgetting) in detail, it allowed researchers to make predictions \nregarding how memory impacts other settings, which could then be tested. In the end, \nthese new experiments led to further refinements of the theory and to an even broader \nunderstanding of the cognitive mechanisms involved in recovering from an interruption.\nAlthough the value of cognitive models lies in the details, this is also its Achilles\u2019 \nheel. If a model is to be used to make predictions for a new task, then a researcher or \npractitioner needs to be able to specify those details ahead of time. To then specify those \ndetails, they also need to have a detailed understanding of the modeling framework and \nhow these details should be specified within it. This is not feasible for every researcher \nand practitioner.Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "93Fortunately, building on a long tradition in human-computer interaction research \n[10], more and more tools are being made to allow for predictions in applied settings, \nincluding dynamic settings such as driving [ 8, 43]. Moreover, in some cases not all \ndetails might be needed to make a prediction. For example, based on the mathematical \nequations behind Memory for Goals theory, recent work by Fong, Hettinger, and  \nRatwani [ 15] was able to predict the likelihood that emergency physicians resumed their \noriginal task after an interruption on their everyday emergency ward.\n What Can Cognitive Models Predict About\u00a0the\u00a0Impact \nof\u00a0Interruptions on\u00a0Productivity?\nOne of the main insights to come from modeling work using the Memory for Goals \ntheory is that the longer an interruption, the more likely it is that errors are to occur, \nincluding forgetting to resume the task altogether (and for specific cases, the models can \ngive even more specific and exact predictions). Therefore, the implication of this work is \nthat there is value in avoiding being interrupted.\nModels can also be used to inform our understanding of discretionary self-  \ninterruptions. Previous studies have found that people often choose to interrupt \nthemselves, switching between different activities every few minutes [ 16, 18]. For \nexample, an information worker who is focusing on a particular work activity will still \nlikely choose to monitor and check their e-mail regularly, switching back and forth \nbetween application windows. How often should the person switch between these two \ndifferent activities?\nIn our own research, we have used cognitive models to examine how the demands \nof a task affect the benefit of different switching strategies (i.e., how long to focus on one \ntask before switching back to another task). We studied this in the context of a dual-  task \nexperiment in which participants had to control a dynamic task while performing a text-\nentry task [ 13, 26, 27]. We used a cognitive model to identify the best possible strategy \nfor dividing attention between these two tasks and then compared this to what people \nactually chose to do in the experiments. Across several studies, we found that people were \nvery quick at locating the best possible strategy for dividing their time between tasks. We \nlearn from this work that people are actually pretty good at multitasking, when the relative \nimportance of each task is made clear to them. Cognitive modeling was a vital step in this \nwork as it was used to identify the best possible switching strategy; without this, it would \nnot have been possible to objectively benchmark how well people were multitasking.Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "94 Summary: Cognitive Models\nCognitive models develop our understanding of why and how interruptions are \ndisruptive. They do this by instantiating theory using mathematical models and \nsimulations. This puts into practice the ideas we have for what is causing an interruption \nto impact performance. Through this line of research, Memory for Goals has emerged \nas an important theory. The core idea is that when dealing with an interruption, people \nforget what it is they were working on. Resuming a task therefore involves remembering \nwhat one was doing before the interruption. By casting this as a memory retrieval \nprocess, the Memory for Goals theory is able to draw on general theories about the nature \nof human memory. In practical terms, cognitive models can be used to both explain \nexisting data and make predictions about what will happen in novel situations or settings.\n Observational Studies\nWhereas controlled experiments and cognitive models enable a focus on testing specific \nvariables while controlling other factors, observational studies (also referred to as \nin-situ  studies) offer ecological validity. For example, in the laboratory, the effects of \ninterruptions may focus on a single interruption type from a single task. In a real-world \nenvironment, people generally work on multiple tasks, receiving interruptions from \na range of sources. In-situ studies can serve to uncover reasons for people\u2019s behavior \n(i.e., the \u201cwhy\u201d of people\u2019s practices). It is a trade-off, however, of generalizability with \necological validity. Observational studies can be very labor-intensive, limiting the scope \nand scale of study. Yet, with the current revolution in sensor technologies and wearables, \nin-situ studies are beginning to leverage these technologies for researchers to conduct \nobservational studies at a larger scale. Nevertheless, sensors still introduce limitations \non what can be observed and how the data can be interpreted.\nObservational Studies of the Workplace\nMost in-situ studies of interruptions have been conducted in the workplace. Workplaces can \nbe dynamic places, and interruptions can be triggered from a number of sources involving \npeople (colleagues, phone calls, ambient conversations), and computer and smartphone \nnotifications (e.g. e-mail, social media, text messaging). However, interruptions can also \noriginate from within an individual (e.g., due to mind-  wandering, [ 37]).Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "95Constant interruptions and the consequent fragmentation of work are a way of life \nfor many information workers [ 12, 33, 38]. By closely monitoring workers in-situ, it was \nfound that people switched activities (conversations, work on computer applications, \nphone calls) about every three minutes on average. At a less-granular level, when \nactivities were clustered into tasks, or \u201cworking spheres, \u201d these were found to be \ninterrupted or switched about every 11 minutes [ 16]. There is a relationship of length of \ntime on task and interruptions: the longer time spent in a working sphere, the longer is \nthe interrupting event. It has been proposed that when interruptions are used as breaks, \nthen such longer interruptions might be due to replenishing one\u2019s mental resources [ 47].\nIn a work environment, observations found that people self-interrupt almost as often \nas experiencing interruptions by an external source such as a phone call or colleague \nentering the office [ 16, 33]. When these field studies were done, more than a decade \nago now, most self-interruptions were found to be associated with people initiating \nin-person interactions. Most external interruptions were also due to verbal-based \ninterruptions from other people rather than due to notification mechanisms from their \ne-mail or voicemail. In more recent years, social media has become popular in the \nworkplace, and it is likely that the main triggers of self and external interruptions in the \npresent-day workplace may be different.\n Benefits and\u00a0Detriments of\u00a0Interruptions\nInterruptions may be beneficial or detrimental. In a workplace diary study, Czerwinski \net\u00a0al. [ 12] showed how the work context of information workers continuously changes \nbecause of interruptions. A study of corporate managers showed that while interruptions \ncan disrupt tasks, managers appreciate the usefulness of interruptions as it provides the \nopportunity to get useful work-related information [ 20]. While social media and online \nmicro-breaks may provide numerous benefits in the workplace, field studies have shown \nthat they create challenges due to switching contexts.\nGenerally, interruptions that disrupt concentration in a task, especially when they \noccur at a point that is not a natural breaking point for a task, can be detrimental [ 24]. \nExternal interruptions cause information workers to enter into a \u201cchain of distraction\u201d \nwhere stages of preparation, diversion, resumption, and recovery take time away from \nan ongoing task [ 22]. When notifications from smart phones were turned off for a week, \npeople reported higher levels of attention [ 31]. A large cost in switching tasks on the Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "96computer is that it has been associated with higher stress [ 34]. Yet, people are able to \nadjust their work practices to manage constant face-to-face interruptions [ 42], as well as \nto manage interruptions from computer-mediated communication [ 48].\nInterruptions in the workplace can also provide benefits. Longer interruptions (or \nwork breaks), such as taking a walk in nature during work hours, have been shown to \nincrease focus and creativity at work [ 1]. Observational studies have identified that \npeople use a variety of social media and news sites to take breaks to refresh and to \nstimulate themselves [ 29]. However, a growing number of workplaces have policies that \nregulate the use of social media at work [ 41], which can impact the ability of people to \ntake a mental break at work.\n Stress, Individual Differences, and\u00a0Interruptions\nA few field studies have examined the relationship of stress and interruptions. In a study \nthat focused specifically on the role of e-mail interruptions, Kushlev and Dunn [ 30] \nfound that limiting the amount of checking e-mail significantly reduced stress. Another \nfield study in the workplace found that cutting off e-mail (and consequently reducing \nboth internal and external interruptions) significantly reduced stress [ 36]. Cutting \noff smartphone notifications also significantly reduced inattention and symptoms of \nhyperactivity [ 31]. On the other hand, when e-mail notifications were turned off, another \nfield study showed that some individuals increased their self-interruptions to check \ne-mail due to the lack of awareness of incoming e-mails [ 23]. It is theorized that people \nwho multitask more and who are susceptible to interruptions may have lower ability to \nfilter out irrelevant stimuli [ 11]. Other individual differences have been observed, such as \nthe personality trait of higher neuroticism with higher task switching [ 35].\n Productivity\nField studies suggest that higher frequency of task switching is associated with lower \nperceived productivity [ 34, 38]. Several explanations have been proposed for this \nrelationship, including the depletion of cognitive resources used in attending to \ninterruptions, the redundancy of work when reorienting back to the task [ 34], and that a \npolychronic workstyle may be contrary to what most people prefer [ 5].Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "97 Strategies for\u00a0Dealing with\u00a0Interruptions\nObservational studies reveal that people use strategies to manage interruptions. Whereas \nmost people prefer monochronic work (finishing one task through to completion [ 5]), \nthe demands of the workplace result in polychronic work (i.e., the consequent switching \nof attention to different tasks). Because of the expectation of working in an environment \nwith interruptions, some people have been observed to develop strategies to adapt to the \nunpredictability of the working environment. Participants can externalize their memory \nof task information, for example in the form of artifacts such as sticky notes, the e-mail \ninbox (e-mails sent to oneself), or electronic planners, often updated throughout the \nday [ 16]. The challenge with conventional electronic planners is that they are generally \nnot designed at a level of granularity to help people recover from interruptions from a \npartially completed task.\nTechnological solutions have also been implemented in the field to detect when \npeople are interruptible, with the intent to minimize interruptions at inopportune \ntimes. Promising techniques tested in the field have shown that it is possible to predict \nwhen people are in cognitive states where they can be interrupted that can minimize \ninterruptions, reduce stress, and thus minimize cognitive resources needed to reorient \nback to a task [ 14, 25, 51, 52].\n Summary: Observational Studies\nObservational studies document the kinds of interruptions that people experience in \ntheir actual workplace. These studies are resource intensive to conduct and so often \nfocus in on a small number of participants, giving a detailed and rich account of a \nparticular work setting. We have learned from observational studies that workplace \ninterruptions are extremely commonplace. Some of these interruptions reflect the \nfragmented nature of work: people work on different tasks and activities through the day, \nand this requires constant switching between them. People also seek out interactions \nwith others\u2014either by having conversations with colleagues or by communicating \nthrough social networking sites and e-mail. Consistent with the results from interruption \nexperiments, observational studies also reveal that frequent interruptions result in \nfeelings of reduced productivity. However, regular breaks from work are also necessary, \nand people return from breaks feeling energized and ready to resume their work.Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "98 Key Insights\nWe have given a brief overview of three prominent and complementary research \nmethods that have been used to study interruptions: controlled experiments, cognitive \nmodels, and observational studies. Across these three research approaches a consistent \npattern of insights emerges to help us understand how interruptions affect productivity.\nThe key insights are as follows:\n\u2022 Interruptions can take time from which to recover from and can lead \nto errors.\n\u2022 Shorter interruptions are less disruptive than longer interruptions.\n\u2022 Interruptions delivered during a natural break in a task are less \ndisruptive.\n\u2022 Interruptions that are relevant to the current task are less disruptive.\n\u2022 Resuming a task too quickly can lead to errors being made.\n\u2022 All of these characteristics of the resumption lag can be explained by \nan underlying memory retrieval process.\n\u2022 People self-interrupt almost as often as being interrupted by external \nsources.\n\u2022 People often work on multiple tasks at the same time, and self-  \ninterruptions are important for keeping up with these different \nactivities.\n\u2022 Interruptions can cause stress, particularly e-mail interruptions.\n\u2022 Interruptions can provide an opportunity for a break to refresh, and \npeople take longer breaks after working on a task for longer.Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "99 Key Ideas\nThis chapter has offered a practical and reflective account of the complementary \nbenefits and challenges of conducting research using each of the following three \nmethods. The main points to reflect on are these:\n\u2022 Controlled experiments are designed to test a specific hypothesis, \nbut there are challenges with designing the experiment so that it has \necological validity.\n\u2022 Cognitive models offer a theoretical framework for explaining why \nand how things happen (e.g., how interruptions affect productivity), \nbut these models can be complex and difficult to develop.\n\u2022 Observational studies offer a rich description of situated activity, \nbut these studies are resource intensive and can produce an \noverwhelming amount of data of which to make sense.\n Acknowledgments\nThis work was supported by the UK Engineering and Physical Sciences Research Council \ngrants EP/G059063/1 and EP/L504889/1, by a European Commission Marie Sklodowska-  \nCurie Fellowship H2020-MSCA-IF-2015 grant 705010, and by the U.S.\u00a0National Science \nFoundation under grant #1704889.\n References\n [1] A bdullah, S., Czerwinski, M., Mark, G., & Johns, P . (2016). Shining \n(blue) light on creative ability. In Proceedings of the 2016 ACM \nInternational Joint Conference on Pervasive and Ubiquitous \nComputing (UbiComp \u201916). ACM, New\u00a0York, NY, USA, 793-804. \nDOI: https://doi.org/10.1145/2971648.2971751 .\n [2] Adamczyk, P .\u00a0D., & Bailey, B.\u00a0P . (2004). If not now, when?: the \neffects of interruption at different moments within task execution. \nIn Proceedings of the SIGCHI Conference on Human Factors in \nComputing Systems (CHI \u201904). ACM, New\u00a0York, NY, USA, 271-278. \nDOI: https://doi.org/10.1145/985692.985727 .Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "100 [3] Altm ann, E., & Gray, W.\u00a0D. (2008). An integrated model of \ncognitive control in task switching. Psychological Review, 115, \n602\u2013639. DOI: https://doi.org/10.1037/0033-  295X.115.3.602 .\n [4] Altm ann, E., & Trafton, J.\u00a0G. (2002). Memory for goals: an \nactivation-based model. Cognitive Science, 26, 39\u201383. DOI: \nhttps://doi.org/10.1207/s15516709cog2601_2 .\n [5] Bluedorn, A.\u00a0C., Kaufman, C.\u00a0F . and Lane, P .\u00a0M. (1992). How many \nthings do you like to do at once? An introduction to monochronic \nand polychronic time. The Executive, 6(4), 17-26. DOI: http://\nwww.jstor.org/stable/4165091 .\n [6] Boehm-Davis, D.\u00a0A., & Remington, R.\u00a0W. (2009). Reducing \nthe disruptive effects of interruption: a cognitive framework \nfor analysing the costs and benefits of intervention strategies. \nAccident Analysis & Prevention, 41, 1124\u20131129. DOI: https://\ndoi.org/10.1016/j.aap.2009.06.029 .\n [7] Borst, J.\u00a0P ., Taatgen, N.\u00a0A., & van Rijn, H. (2015). What makes \ninterruptions disruptive?: a process-model account of the \neffects of the problem state bottleneck on task interruption \nand resumption. In Proceedings of the 33rd Annual ACM \nConference on Human Factors in Computing Systems (CHI \n\u201815). ACM, New\u00a0York, NY, USA, 2971-  2980. D OI: https://doi.\norg/10.1145/2702123.2702156 .\n [8] Brumby, D.\u00a0P ., Janssen, C.\u00a0P ., Kujala, T., & Salvucci, D.\u00a0D. (2018). \nComputational models of user multitasking. In A.\u00a0Oulasvirta, \nP .\u00a0Kristensson, X.\u00a0Bi, & A.\u00a0Howes (eds.) Computational Interaction \nDesign. Oxford, UK: Oxford University Press.\n [9] Brumby, D.P ., Cox, A.L., Back, J., & Gould, S.J.J. (2013). Recovering \nfrom an interruption: investigating speed-accuracy tradeoffs in \ntask resumption strategy. Journal of Experimental Psychology: \nApplied, 19, 95-107. DOI: https://doi.org/10.1037/a0032696 .\n [10]  Card, S.\u00a0K., Moran, T., & Newell, A. (1983). The Psychology of \nHuman-Computer Interaction. Hillsdale, NJ: Lawrence Erlbaum \nAssociates.Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "101 [11]  Carrier, L.\u00a0M., Rosen, L.\u00a0D., Cheever, N.\u00a0A., & Lim, A.\u00a0F . (2015). \nCauses, effects, and practicalities of everyday multitasking. \nDevelopmental Review, 35, 64-78. DOI: https://doi.\norg/10.1016/j.dr.2014.12.005 .\n [12] Czerwinski, M., Horvitz, E., & Wilhite, S. (2004). A diary study of \ntask switching and interruptions. In Proceedings of the SIGCHI \nConference on Human Factors in Computing Systems (CHI \n\u201804). ACM, New\u00a0York, NY, USA, 175-182. DOI: https://doi.\norg/10.1145/985692.985715 .\n [13]  Farmer, G.\u00a0D., Janssen, C.\u00a0P ., Nguyen, A.\u00a0T. and Brumby, D.\u00a0P . \n(2017). Dividing attention between tasks: testing whether explicit \npayoff functions elicit optimal dual-task performance. Cognitive \nScience. DOI: https://doi.org/10.1111/cogs.12513 .\n [14]  Fogarty, J., Hudson, S.\u00a0E., Atkeson, C.\u00a0G., Avrahami, D., \nForlizzi, J., Kiesler, S., Lee, J.\u00a0C., & Yang, J. (2005). Predicting \nhuman interruptibility with sensors. ACM Transactions on \nComputer- Human Interaction, 12, 119-146. DOI:  https://doi.\norg/10.1145/1057237.1057243 .\n [15]  Fong, A., Hettinger, A.\u00a0Z., & Ratwani, R.\u00a0M. (2017). A predictive \nmodel of emergency physician task resumption following \ninterruptions. In Proceedings of the 2017 CHI Conference \non Human Factors in Computing Systems (CHI \u201817). \nACM, New\u00a0York, NY, USA, 2405-2410. DOI: https://doi.\norg/10.1145/3025453.3025700 .\n [16]  Gonz\u00e1lez, V .\u00a0M., & Mark, G.\u00a0J. (2004). \u201cConstant, constant, multi-\ntasking craziness\u201d: managing multiple working spheres. In \nProceedings of the SIGCHI Conference on Human Factors in \nComputing Systems (CHI \u201804). ACM, New\u00a0York, NY, USA, 113-120. \nDOI: https://doi.org/10.1145/985692.985707 .\n [17]  Gould, S.\u00a0J. J., Brumby, D.\u00a0P ., & Cox, A.\u00a0L. (2013). What does it \nmean for an interruption to be relevant? An investigation of \nrelevance as a memory effect. In Proceedings of the Human \nFactors and Ergonomics Society Annual Meeting, 57, 149\u2013153. \nDOI: https://doi.org/10.1177/1541931213571034 .Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "102 [18]  Gould, S.\u00a0J. J., Cox, A.\u00a0L., & Brumby, D.\u00a0P . (2016). Diminished \ncontrol in crowdsourcing: an investigation of crowdworker \nmultitasking behavior. ACM Transactions on Computer-\nHuman Interaction, 23, Article 19. DOI: https://doi.\norg/10.1145/2928269 .\n [19]  Hodgetts, H.\u00a0M., & Jones, D.\u00a0M. (2006). Interruption of the Tower \nof London task: Support for a goal activation approach. Journal of \nExperimental Psychology: General, 135, 103-115. DOI: https://\ndoi.org/10.1037/0096-3445.135.1.103 .\n [20]  Hudson, J.\u00a0M., Christensen, J., Kellogg, W.\u00a0A., & Erickson, T. \n(2002). \u201cI\u2019d be overwhelmed, but it\u2019s just one more thing to \ndo\u201d: availability and interruption in research management. In \nProceedings of the SIGCHI Conference on Human Factors in \nComputing Systems (CHI \u201902). ACM, New\u00a0York, NY, USA, 97-104. \nDOI: https://doi.org/10.1145/503376.503394 .\n [21]  Iqbal, S.\u00a0T., & Bailey, B.\u00a0P . (2008). Effects of intelligent notification \nmanagement on users and their tasks. In Proceedings of the \nSIGCHI Conference on Human Factors in Computing Systems \n(CHI \u201908). ACM, New\u00a0York, NY, USA, 93-102. DOI: https://doi.\norg/10.1145/1357054.1357070 .\n [22]  Iqbal, S.\u00a0T., & Horvitz, E. (2007). Disruption and recovery \nof computing tasks: field study, analysis, and directions. In \nProceedings of the SIGCHI Conference on Human Factors in \nComputing Systems (CHI \u201907). ACM, New\u00a0York, NY, USA, 677-686. \nDOI: https://doi.org/10.1145/1240624.12407302007 .\n [23]  Iqbal, S.\u00a0T., & Horvitz, E. (2010). Notifications and awareness: a \nfield study of alert usage and preferences. In Proceedings of the \n2010 ACM conference on Computer supported cooperative work \n(CSCW \u201910). ACM, New\u00a0York, NY, USA, 27-30. DOI: https://doi.\norg/10.1145/1718918.1718926 .\n [24]  Iqbal, S.\u00a0T., Adamczyk, P .\u00a0D., Zheng, X.\u00a0S., & Bailey, B.\u00a0P . (2005). \nTowards an index of opportunity: understanding changes in \nmental workload during task execution. In Proceedings of the Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "103SIGCHI Conference on Human Factors in Computing Systems \n(CHI \u201905). ACM, New\u00a0York, NY, USA, 311-320. DOI: https://doi.\norg/10.1145/1054972.1055016 .\n [25]  Iqbal, S.T., & Bailey, B.P . (2010). Oasis: A framework for linking \nnotification delivery to the perceptual structure of goal-directed \ntasks. ACM Transactions on Computer-  Human Interaction, 17, \nArticle 15. DOI: https://doi.org/10.1145/1879831.1879833 .\n [26]  Janssen, C.\u00a0P ., & Brumby, D.\u00a0P . (2015). Strategic adaptation to \ntask characteristics, incentives, and individual differences in \ndual-tasking. PLoS ONE, 10(7), e0130009. DOI: https://doi.\norg/10.1371/journal.pone.0130009 .\n [27]  Janssen, C.\u00a0P ., Brumby, D.\u00a0P ., Dowell, J., Chater, N., & Howes, \nA. (2011). Identifying optimum performance trade-offs using \na cognitively bounded rational analysis model of discretionary \ntask interleaving. Topics in Cognitive Science, 3, 123\u2013139. DOI: \nhttps://doi.org/10.1111/j.1756-8765.2010.01125.x .\n [28]  Janssen, C.\u00a0P ., Gould, S.\u00a0J., Li, S.\u00a0Y. W., Brumby, D.\u00a0P ., & Cox, A.\u00a0L. \n(2015). Integrating knowledge of multitasking and Interruptions \nacross different perspectives and research methods. International \nJournal of Human-Computer Studies, 79, 1\u20135. DOI: https://doi.\norg/10.1016/j.ijhcs.2015.03.002 .\n [29]  Jin, J., & Dabbish, L. (2009). Self-interruption on the computer: a \ntypology of discretionary task interleaving. In Proceedings of the \nSIGCHI Conference on Human Factors in Computing Systems \n(CHI \u201909). ACM, New\u00a0York, NY, USA, 1799-1808. DOI: https://\ndoi.org/10.1145/1518701.1518979 .\n [30]  Kushlev, K., & Dunn, E.W. (2015). Checking e-mail less frequently \nreduces stress. Computers in Human Behavior, 43, 220-228. DOI: \nhttps://doi.org/10.1016/j.chb.2014.11.005 .\n [31] Kushlev, K., Proulx, J., & Dunn, E.W. (2016). \u201cSilence Your \nPhones\u201d: smartphone notifications increase inattention and \nhyperactivity symptoms. In Proceedings of the 2016 CHI \nConference on Human Factors in Computing Systems  Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "104(CHI \u201916). ACM, New\u00a0York, NY, USA, 1011-1020. DOI: https://\ndoi.org/10.1145/2858036.2858359 .\n [32]  Li, S.\u00a0Y. W., Blandford, A., Cairns, P ., & Young, R.\u00a0M. (2008). The \neffect of interruptions on postcompletion and other procedural \nerrors: an account based on the activation-  based goal memory \nmodel. Journal of Experimental Psychology: Applied, 14, 314 \u2013328. \nDOI: https://doi.org/10.1037/a0014397 .\n [33]  Mark, G., Gonz\u00e1lez, V ., & Harris, J. (2005). No task left behind?: \nexamining the nature of fragmented work. In Proceedings of the \nSIGCHI Conference on Human Factors in Computing Systems \n(CHI \u201905). ACM, New\u00a0York, NY, USA, 321-330. DOI: https://doi.\norg/10.1145/1054972.1055017 .\n [34]  Mark, G., Iqbal, S.\u00a0T., Czerwinski, M., & Johns, P . (2015). \nFocused, aroused, but so distractible: temporal perspectives on \nmultitasking and communications. In Proceedings of the 18th \nACM Conference on Computer Supported Cooperative Work & \nSocial Computing (CSCW \u201915). ACM, New\u00a0York, NY, USA, 903-916. \nDOI: https://doi.org/10.1145/2675133.2675221 .\n [35] Mark, G., Iqbal, S., Czerwinski, M., Johns, P ., & Sano, A. \n(2016). Neurotics can\u2019t focus: an in situ study of online \nmultitasking in the workplace. In Proceedings of the 2016 CHI \nConference on Human Factors in Computing Systems (CHI \n\u201916). ACM, New\u00a0York, NY, USA, 1739-1744. DOI: https://doi.\norg/10.1145/2858036.2858202 .\n [36]  Mark, G., Voida, S., & Cardello, A. (2012). \u201c A pace not dictated \nby electrons\u201d: an empirical study of work without e-mail. In \nProceedings of the SIGCHI Conference on Human Factors in \nComputing Systems (CHI \u201912). ACM, New\u00a0York, NY, USA, 555-564. \nDOI: https://doi.org/10.1145/2207676.2207754 .\n [37]  Mason, M.\u00a0F ., Norton, M.\u00a0I., Van Horn, J.\u00a0D., Wegner, D.\u00a0M., Grafton, \nS.\u00a0T., & Macrae, C.\u00a0N. (2007). Wandering minds: the default network \nand stimulus-independent thought. Science, 315(5810), 393-395. \nDOI: https://doi.org/10.1126/science.1131295 .Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "105 [38] Meyer, A.\u00a0N., Barton, L.\u00a0E., Murphy, G.\u00a0C., Zimmerman, \nT., & Fritz, T. (2017). The work life of developers: activities, \nswitches and perceived productivity. IEEE Transactions on \nSoftware Engineering, 43(12), 1178\u20131193. DOI: https://doi.\norg/10.1109/TSE.2017.2656886 .\n [39]  Monk, C.\u00a0A., Trafton, J.\u00a0G., & Boehm-Davis, D.\u00a0A. (2008). The effect \nof interruption duration and demand on resuming suspended \ngoals. Journal of Experimental Psychology: Applied, 14, 299-313. \nDOI: https://doi.org/10.1037/a0014402  .\n [40]  Newell, A. (1990). Unified Theories of Cognition. Cambridge, MA: \nHarvard University Press.\n [41]  Olmstead, K., Lampe, C., & Ellison, N. (2016). Social media and \nthe workplace. Pew Research Center. Retrieved from http://\nwww.pewinternet.org/2016/06/22/social-  media- and-the-\nworkplace/ .\n [42]  Rouncefield, M., Hughes, J.\u00a0A, Rodden, T., & Viller, S. (1994). \nWorking with \u201cconstant interruption\u201d: CSCW and the small \noffice. In Proceedings of the 1994 ACM conference on Computer \nsupported cooperative work (CSCW \u201994). ACM, New\u00a0York, NY, \nUSA, 275-  286. D OI: https://doi.org/10.1145/192844.193028 .\n [43]  Salvucci, D.\u00a0D. (2009). Rapid prototyping and evaluation of in-\nvehicle interfaces. Transactions on Computer-Human Interaction, \n16, Article 9. DOI: https://doi.org/10.1145/1534903.1534906 .\n [44]  Salvucci, D.\u00a0D., & Taatgen, N.\u00a0A. (2011). The Multitasking Mind. \nNew\u00a0York, NY: Oxford University Press.\n [45]  Trafton, J.\u00a0G., & Monk, C.\u00a0M. (2008). Task interruptions. In D.\u00a0A. \nBoehm-Davis (Ed.), Reviews of human factors and ergonomics \n(Vol. 3, pp.\u00a0111\u2013126). Santa Monica, CA: Human Factors and \nErgonomics Society.\n [46] Trafton, J.\u00a0G., Altmann, E.\u00a0M., & Ratwani, R.\u00a0M. (2011). A \nmemory for goals model of sequence errors. Cognitive Systems \nResearch, 12, 134\u2013143. DOI: https://doi.org/10.1016/j.\ncogsys.2010.07.010 .Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "106 [47]  Tr ougakos, J.\u00a0P ., Beal, D.\u00a0J., Green, S.\u00a0G., & Weiss, H.\u00a0M. (2008). \nMaking the break count: an episodic examination of recovery \nactivities, emotional experiences, and positive affective displays. \nAcademy of Management Journal, 51, 131-146. DOI: https://\ndoi.org/10.5465/amj.2008.30764063 .\n [48]  Webster, J., & Ho, H. (1997). Audience engagement in multi-media \npresentations. SIGMIS Database 28, 63-77. DOI: https://doi.\norg/10.1145/264701.264706 .\n [49]  Wickens, C.\u00a0D. (2008). Multiple resources and mental workload. \nHuman Factors, 50, 449- 455. DOI: https://doi.org/10.1518/00\n1872008X288394 .\n [50]  Zeigarnik, B. (1927). Das Behalten erledigter und unerledigter \nHandlungen. Psychologische Forschung, 9, 1-85. Translated in \nEnglish as: Zeigarnik, B. (1967). On finished and unfinished tasks. \nIn W.\u00a0D. Ellis (Ed.), A sourcebook of Gestalt psychology, New\u00a0York: \nHumanities press.\n [51]  Z\u00fcger, M., & Fritz, T. (2015). Interruptibility of software \ndevelopers and its prediction using psycho-physiological \nsensors. In Proceedings of the 33rd Annual ACM Conference \non Human Factors in Computing Systems (CHI \u201915). \nACM, New\u00a0York, NY, USA, 2981-  2990. D OI: https://doi.\norg/10.1145/2702123.2702593 .\n [52]  Z\u00fcger, M., Corley, C., Meyer, A.\u00a0N., Li, B., Fritz, T., Shepherd, D., \nAugustine, V ., Francis, P ., Kraft, N., & Snipes, W. (2017). Reducing \nInterruptions at Work: A Large-Scale Field Study of FlowLight. In \nProceedings of the 2017 CHI Conference on Human Factors in \nComputing Systems (CHI \u201817). ACM, New\u00a0York, NY, USA, 61\u201372. \nDOI:  https://doi.org/10.1145/3025453.3025662 .Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "107Open Access  This chapter is distributed under the terms of the Creative \nCommons Attribution 4.0 International License ( http://creativecommons.\norg/licenses/by/4.0/ ), which permits use, duplication, adaptation, distribution and \nreproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, a link is provided to the Creative Commons license \nand any changes made are indicated.\nThe images or other third party material in this chapter are included in the work\u2019s \nCreative Commons license, unless indicated otherwise in the credit line; if such material \nis not included in the work\u2019s Creative Commons license and the respective action is not \npermitted by statutory regulation, users will need to obtain permission from the license \nholder to duplicate, adapt or reproduce the material.Chapter 9  how Do Interrupt Ions affeCt proDuCtIvIty?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "109\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_10CHAPTER 10\nHappiness and\u00a0the\u00a0 \nProductivity of\u00a0Software \nEngineers\nDaniel Graziotin, University of Stuttgart, Germany\nFabian Fagerholm, Blekinge Institute of Technology,  \nSweden and University of Helsinki, Finland\nSoftware companies nowadays often aim for flourishing happiness among developers. \nPerks, playground rooms, free breakfast, remote office options, sports facilities near the \ncompanies...there are several ways to make software developers happy. The rationale is \nthat of a return on investment: happy developers are supposedly more productive and, \nhopefully, also retained.\nBut is it the case that happy software engineers = more productive software engineers1? \nMoreover, are perks the way to go to make developers happy? Are developers happy at all? \nThese questions are important to ask both from the perspective of productivity and from \nthe perspective of sustainable software development and well-being in the workplace.\nThis chapter provides an overview of our studies on the happiness of software \ndevelopers. You will learn why it is important to make software developers happy, \nhow happy they really are, what makes them unhappy, and what is expected for their \nproductivity while developing software.\n1 In our studies, we consider a software developer to be \u201ca person concerned with any aspect of \nthe software construction process (such as research, analysis, design, programming, testing, or \nmanagement activities), for any purpose including work, study, hobby, or passion. \u201d [4, page 326]. \nWe also interchange the terms software developer  and software engineer  so that we do not repeat \nourselves too many times."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "110 Why the\u00a0Industry Should Strive for\u00a0Happy \nDevelopers\nWe could think that happiness is a personal issue that individual developers are \nresponsible for on their own time. In this line of thinking, software companies should \nfocus on maximizing the output they get from each developer. However, to get \nproductive output from a human, we must first invest. As humans, software developers\u2019 \nproductivity depends on their skills and knowledge\u2014but to access those, we need to \ncreate favorable conditions that allow the human potential to be realized. As noted \nin Chapter 5, developer satisfaction is important for productivity because reduced \nsatisfaction can incur future costs; it follows that companies should be interested in the \ngeneral well-being of their software developers. Furthermore, we believe we should \nsimply strive to create better working environments, teams, processes, and, therefore, \nproducts.\n What Is Happiness, and\u00a0How Do We\u00a0Measure It?\nThis is a very deep question that ancient and modern philosophers have aimed to \nanswer in more than one book. However, present-day research does give us concrete \ninsight into happiness and ways to measure it. We define happiness (as many others do) \nas a sequence of experiential episodes. Being happy corresponds to frequent positive \nexperiences, which lead to experiencing positive emotions. Being unhappy corresponds \nto the reverse: frequent negative experiences leading to negative emotions. Happiness \nis the difference or balance between positive and negative experiences. This balance is \nsometimes called affect balance .\nThe Scale of Positive and Negative Experience (SPANE, [ 8]) is a recent but valid \nand reliable way to assess the affect balance (happiness) of individuals. Respondents \nare asked to report on their affect, expressed with adjectives that individuals recognize \nas describing emotions or moods, from the past four weeks. This provides a balance \nbetween the sampling adequacy of affect and the accuracy of human memory to recall \nexperiences and reduce ambiguity. The combination of the scoring of the various items \nyields an affect balance (SPANE-B) score, which ranges from -24 (extremely unhappy) to \n+24 (extremely happy), where 0 is to be considered a neutral score of happiness.Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "111 Scientific Grounds of\u00a0Happy and\u00a0Productive \nDevelopers\nWhile it is intuitive that happiness is beneficial for productivity and well-being, these \nideas are also supported by scientific research. We have previously shown that happy \ndevelopers solve problems better [ 1], that there is a relationship between affect and how \ndevelopers assess their own productivity [ 2], and that software developers themselves \nare calling for research in this area [ 5]. We have also presented a theory that provides an \nexplanation of how affect impacts programming performance [ 3]: events trigger affects \nin programmers. These affects might earn importance and priority to a developer\u2019s \ncognitive system, and we call them attractors . Together with affects, attractors drive or \ndisturb programmers\u2019 focus, which impacts their performance. On a larger scale, our \nstudies show that affect is an important component of performance in software teams \nand organizations [ 11]. Affect is linked to group identity\u2014the feeling of belonging to the \ngroup\u2014affecting cohesion and social atmosphere, which in turn are key factors for team \nperformance and retention of team members.\nWe will now consider four important and ambitious questions.\n\u2022 How happy are software developers overall?\n\u2022 What makes them (un)happy?\n\u2022 What happens when they are (un)happy?\n\u2022 Are happy developers more productive?\nAnswering these questions is challenging. We spent a year designing a comprehensive \nstudy [ 4, 6] to address them. We needed data from as many software developers \nas possible. We also needed as much diversity as possible in terms of age, gender, \ngeographical location, working status, and other background factors. We designed and \npiloted a questionnaire in such a way that the results could be generalizable (with a certain \nerror tolerance) to the entire population of software developers. Our questionnaire had \ndemographic questions, SPANE, and open-ended questions asking about developers\u2019 \nfeelings of happiness and unhappiness when developing software. We asked them to \ndescribe a concrete recent software development experience, what could have caused \nthem to experience their feelings in that situation, and if their software development was \ninfluenced by these feelings in any way, and, if so, how.\nWe obtained 1,318 complete and valid responses to all our questions.Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "112 How Happy Are Software Developers?\nIn Figure\u00a0 10-1 , you can see how happy our 1,318 participants were.\nOur participants had a SPANE-B average score of 9.05, and we estimated the \ntrue mean happiness score of software developers to be between 8.69 and 9.43 with \na 95 percent confidence interval. In other words, most software developers are \nmoderately happy.\nFigure 10-1.  Distribution of happiness of software developers (SPANE-B score)Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "113We compared our results with similar studies (Italian workers, U.S. college students, \nSingapore university students, Chinese employees, South African students, and Japanese \ncollege students). All results from other studies reported a mean SPANE-B score higher \nthan 0 but lower than in our study. Software developers are indeed a slightly happy  \ngroup\u2014and they are happier than what we would expect based on knowledge about \nvarious other groups of the human population. This is good news, indeed, but there is \nroom for improvement nonetheless. Some developers have a negative SPANE-B score, \nand there were many examples in the open responses about episodes of unhappiness \nthat could be avoided.\n What Makes Developers Unhappy?\nOur analysis of the responses of our 1,318 participants uncovered 219 causes of \nunhappiness, which were mentioned 2,280 times in the responses [ 4]. We present here a \nbrief summary of the results and the top three categories of things that make developers \nunhappy.\nThe causes of unhappiness that are controllable by managers and team leaders \nare mentioned four times as often as those being personal and therefore beyond direct \nmanagerial control. We also expected the majority of the causes to be related to human \naspects and relationships. However, most of them came from technical factors related to \nthe artifact (software product, tests, requirements and design document, architecture, \netc.) and the process. This highlights the importance of strategic architecture and \nworkforce coordination.\nBeing stuck in problem-solving and time pressure are the two most frequent causes \nof unhappiness, which corroborates the importance of recent research that attempts to \nunderstand these issues. We recognize that it is in software development\u2019s nature to be \nbasically problem-solving under deadlines: we cannot avoid problem-solving in software \ndevelopment. However, developers feel bad  when they are stuck and under pressure, \nand several detrimental consequences do happen (see the rest of this chapter). This is \nwhere researchers and managers should intervene to reduce the detrimental effects of \ntime pressure and getting stuck. Psychological grit could be an important characteristic \nto train among software developers. Another could be how to switch your mind-set to get \nunstuck.Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "114The third most frequent cause of unhappiness is to work with bad code and, more \nspecifically, with bad code practices. Developers are unhappy when they produce \nbad code, but they suffer tremendously when they meet bad code that could have \nbeen avoided in the first place. As our participants stated, bad code can be a result \nof management decisions aiming to save time and effort in the short term. Similar \nnegative effects were mentioned regarding third persons (such as colleagues, team \nleaders, or customers) who make developers feel inadequate with their work, forced \nrepetitive mundane tasks, and imposed limitations on development. Many of the \nnegative consequences can be avoided by rotating tasks, by making better decisions, \nand by actually listening to developers. Several top causes are related to perceptions \nof inadequacy of the self and others, validating recent research activities related to \ninterventions that improve the affect of developers [ 3].\nFinally, we see that factors related to information needs in terms of software quality \nand software construction are strong contributors to unhappiness among developers. \nChapter 24 shows an example of how current software tools may overload developers \nwith information and illustrates how problems related to information flow could be \nsolved for individual developers, teams, and organizations. More research is needed on \nproducing tools and methods that make communication and knowledge management \nin software teams easier and that help effortlessly store, retrieve, and comprehend \ninformation in all stages of the software development life cycle.\n What Happens When Developers Are Happy (or Unhappy)?\nWe classified the answers to our open-ended questions and found dozens of causes \nand consequences of happiness and unhappiness while developing software [ 4, 6]. \nDevelopers in our study reported a variety of consequences of being unhappy. We \nhave summarized these consequences in Figure\u00a0 10-2 . There is a pictogram for each \nmajor consequence, and they are divided into internal and external consequences. The \ninternal consequences, pictured inside the mind of the developer, are directed toward \ndevelopers themselves and have a personal impact. The external consequences are ones \nthat have an effect outside the individual developer. They might impact a project, the \ndevelopment process, or a software artifact.Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "115As you can see, developers reported several productivity-related consequences\u2014and \nsome even explicitly reported experiencing lower productivity. Other consequences \ninclude delays, process deviations, low code quality, throwing away code, and breaking \nthe process flow in projects. These external effects are direct impacts on productivity \nand performance. Internal consequences, such as low motivation and reduced cognitive \nperformance, indirectly affect productivity as well. Work withdrawal and mental unease, \nor, in the worst case, signs of disorders, are among the gravest consequences mentioned \nthat impact developers personally.\nFor the purposes of this chapter, it is worth going into more detail on the \nconsequences of happiness and unhappiness, because several of them are productivity-  \nrelated and productivity was the most populated category of consequences. We are \nreporting them in an order that favors narrative, not by frequency of occurrence.\nFigure 10-2.  Consequences of unhappiness while developing software. Available \nas CC-BY from Graziotin et\u00a0al. [ 16]Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "116 Cognitive Performance\nWe found that being happy or unhappy influences several factors related to cognitive \nperformance, that is, how we efficiently process information in our brain. Happiness \nand unhappiness influence how we can focus while coding, as put by one participant: \n\u201c[\u2026] The negative feelings lead to not thinking things through as clearly as I would \nhave if the feeling of frustration was not present. \u201d The opposite also holds true: \u201cMy \nsoftware development is influenced because I can be more focused on my tasks and \ntrying to solve one problem over another. \u201d As the focus can be higher when happy (or \nlower when unhappy), a natural consequence is that problem-solving abilities are \ninfluenced: \u201cI mean, I can write codes and analyze problems quickly and with lesser \nor no unnecessary errors when I\u2019m not thinking of any negative thoughts. \u201d Being \nhappy while developing software brings higher learning abilities: \u201cIt made me want to \npursue a master\u2019s in computer science and learn interesting and clever ideas to solve \nproblems. \u201d However, being unhappy causes mental fatigue, and participants reported \n\u201cgetting frustrated and sloppy. \u201d\n Flow\nParticipants mentioned how being unhappy caused breaks in their flow. Flow  is a state \nof intense attention and concentration resulting from task-related skills and challenges \nbeing in balance (see more about that in Chapter 23). Unhappiness causes interruptions \nin developers\u2019 flow, resulting in adverse effects on the process. As put by a participant, \n\u201cThings like that [of unhappiness] often cause long delays or cause one getting out of the \nflow, making it difficult to pick up the work again where one has left off. \u201d When happy, \ndevelopers can enter a state of sustained flow. They feel full of energy and with strong \nfocus. In such a state, they are \u201cunaware of time passing. \u201d They can \u201ccontinue to code \nwithout any more errors for the rest of the day\u201d and \u201cjust knock out lines of code all day, \u201d \nwith \u201cdancing fingers. \u201d Flow is related to mindfulness, which is discussed in Chapter 25.\n Motivation and\u00a0Withdrawal\nMotivation was often mentioned by our participants. They were clear in stating that \nunhappiness leads to low motivation for developing software: \u201c[The unhappiness] \nhas left me feeling very stupid, and as a result I have no leadership skills, no desire to \nparticipate, and feel like I\u2019m being forced to code to live as a kind of punishment. \u201d The \nparticipants also stated that increased motivation occurred when they were happy.Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "117Unhappiness and happiness are causes of work withdrawal and work engagement, \nrespectively. Work withdrawal is a destructive consequence of unhappiness, and \nit emerged often among the responses. Work withdrawal is a family of behaviors \nthat is defined as employees\u2019 attempts to remove themselves, either temporarily or \npermanently, from daily work tasks. We found varying degrees of work withdrawal, \nranging from switching to another task (\u201c[\u2026] You spend like two hours investigating on \nGoogle for a similar issue and how it was resolved, you find nothing, and desperation \nkicks in. \u201d) to considering quitting developing software (\u201cI really start to doubt myself and \nquestion whether I\u2019m fit to be a software developer in the first place. \u201d) or even quitting \nthe job. High work engagement and perseverance, on the other hand, were reported to \noccur when respondents were happy. This means, for example, pushing forward with \na task: \u201cI think I was more motivated to work harder the next few hours. \u201d This is slightly \ndifferent from motivation, which is more about the energy directed to acting toward a \ngoal. Work engagement is committing to the act of moving toward a goal.\n Happiness and\u00a0Unhappiness, and\u00a0How They Relate \nto\u00a0the\u00a0Productivity of\u00a0Developers\nFinally, participants directly mentioned how unhappiness hinders their productivity. \nWe grouped all responses related to performance and productivity losses. The \nresponses within this category ranged from simple and clear (\u201cproductivity drops\u201d \nand \u201c[Negative experience] definitely makes me work slower\u201d) to more articulated \n(\u201c[Unhappiness] made it harder or impossible to come up with solutions or with good \nsolutions. \u201d). Unhappiness also causes delays in executing process activities: \u201cIn both \ncases [negative experiences] the emotional toll on me caused delays to the project. \u201d Of \ncourse, participants reported that happiness leads to high productivity: \u201cWhen I have \nthis [happy] feeling, I can just code for hours and hours, \u201d \u201cI felt that my productivity \ngrew while I was happy, \u201d and \u201cThe better my mood, the more productive I am. \u201d Here \nare more details on that by one participant: \u201cI become productive, focused, and enjoy \nwhat I\u2019m doing without wasting hours looking here and there in the code to know how \nthings are hooked up together. \u201d An interesting aspect is that, when happy, developers \ntend to take on undesired tasks: \u201cI think that when I\u2019m in this happy state, I am more \nproductive. The happier I am, the more likely I\u2019ll be able to accomplish tasks that I\u2019ve \nbeen avoiding. \u201d On the other hand, unhappy developers could be so unproductive that \nthey become destructive. We found some instances of participants who destroyed the \ntask-related codebase (\u201cI deleted the code that I was writing because I was a bit angry\u201d) Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "118up to deleting entire projects (\u201cI have deleted entire projects to start over with code \nthat didn\u2019t seem to be going in a wrong direction. \u201d). Another intriguing aspect is about \nlong-term considerations of being happy: \u201cI find that when I feel [happy], I\u2019m actually \nmore productive going into the next task, and I make better choices in general for the \nmaintenance of the code long-term. [\u2026] I\u2019m more likely to comment code thoroughly. \u201d\n Are Happy Developers More Productive?\nBut are happy developers really  more productive? Whenever science attempts to show if \na factor X causes an outcome Y, researchers design controlled  experiments. Controlled \nexperiments attempt to keep every possible factor constant ( A, B, C, ...) except for the \nfactors ( X) that should cause a change to the outcome Y. You can find more about \ncontrolled experiments in Chapter 9. Whenever this control is not possible, we call these \nstudies quasi-experiments .\nHere is the issue with research on happiness: it is challenging to control the \nhappiness (or the mood, the emotions) of people. One of the reasons is that a perfectly \ncontrolled experiment would need to be quite unethical to make the unhappy control \ngroup truly unhappy. The effects of asking participants to remember sad events, or \nshowing depressing photographs, is negligible. Still, we set up two quasi-experiments to \nobserve some correlations.\nOne of these studies [ 1] has received considerable media attention. We tested a \nhypothesis regarding a difference of intellectual (cognitive-driven) performance in \nterms of the analytical (logical, mathematical) problem-solving of software engineers \naccording to how happy they were. We also wanted to perform a study where all the tools \nand measurements came from psychology research and were validated. So, we designed \na quasi-experiment in a laboratory, where 42 BSc and MSc students of computer science \nhad their happiness measured and then conducted a task resembling algorithmic \ndesign. For measuring happiness, we opted for SPANE (explained previously).\nThe analytic task was similar to algorithm design and execution. We decided to \nadminister the Tower of London test (also known as Shallice test) to our participants. \nThe Tower of London test resembles the Tower of Hanoi game. The test comprises \ntwo boards with stacks and several colored beads. There are usually three stacks per \nboard, and each stack can accommodate only a limited number of beads. The first \nboard presents predefined stacked beads. The participants received the second board, \nwhich has the same beads as the first board but stacked in a different configuration. The Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "119participants have to re-create the configuration of the first board by unstacking one bead \nat a time and moving it to another stack. The Psychology Experiment Building Language \n(PEBL) is an open source language and a suite of neuropsychology tests [ 13, 14]. The \nTower of London test is among them.\nPEBL was able to collect the measures that let us calculate a score for the analytic \nperformance. We compared the scores obtained in both tasks with the happiness of \ndevelopers. The results showed that the happiest software developers outperformed \nthe other developers in terms of analytic performance. We estimated the performance \nincrease to be about 6 percent. The performance increase was not negligible, and we \nconfirmed it by measuring Cohen\u2019s d statistic. Cohen\u2019s d is a number usually ranging \nfrom 0 to 2, which represents the magnitude of the effect size of a difference of means. \nOur Cohen\u2019s d for the difference between the two groups mean was 0.91\u2014a large effect \ngiven that we did not obtain extreme cases of happiness and unhappiness. The margins \ncould even be higher than that.\nIn another study [ 2], we did something more esoteric. We aimed to continue using \npsychology theory and measurement instruments for understanding the linkage \nbetween the real-time affect (let\u2019s say happiness) raised by a software development task \nand the productivity related to the task itself. Eight software developers (four students \nand four from software companies) worked on their real-world software project. The \ntask length was 90 minutes (as it is about the typical length for a programming task). \nEach ten minutes, the developers filled a questionnaire formed by the Self-Assessment \nManikin (SAM) and an item for self-assessing the productivity.\nSAM is a scale for assessing an emotional state or reaction. SAM is peculiar because \nit is a validated way to measure the affect raised by a stimulus (like an object, or a \nsituation) and it is picture-based (no words). SAM is simply three rows of puppets with \ndifferent face expressions and body language. Therefore, it is quick for a participant \nto fill SAM, especially if implemented on a tablet (only three touches). We analyzed \nhow developers felt during the task and how they self-assessed themselves in terms of \nproductivity. Self-assessment is not a very objective way of measuring productivity, but \nit has been demonstrated that individuals are actually good at self-assessing themselves \nif they are observed alone [ 15]. The results have shown that high pleasure with the \nprogramming task and the sensation of having adequate skills are positively correlated \nwith the productivity. This correlation holds over time. We also found that there are \nstrong variations of affect in 90 minutes of time. Happy software developers are indeed \nmore productive.Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "120 Potential Impacts of\u00a0Happiness on\u00a0Other Outcomes\nHappiness influences so many things besides productivity, most of which are still related \nto development performance. Here we list three of them.\nUnhappiness causes glitches in communication and a disorganized process: \n\u201cMiscommunication and disorganization made it very difficult to meet deadlines. \u201d But \nhappy developers can also mean more collaborative team members, leading to increased \ncollaboration. Often, we saw a repeating pattern of willingness to share knowledge (\u201cI\u2019m very \ncurious, and I like to teach people what I learned\u201d) and to join an effort to solve a problem \n(\u201cWe never hold back on putting our brains together to tackle a difficult problem or plan a \nnew feature\u201d), even when not related to the task at hand or the current responsibilities (\u201cI \nwas more willing to help them with a problem they were having at work. \u201d).\nBeing happy or unhappy influences not only the productivity of the code writing \nprocess but also the quality of the resulting code. Participants reported that \u201cEventually \n[due to negative experiences], code quality cannot be assured. So this will make my \ncode messy, and more bug can be found in it, \u201d but also mentioned making the code \nless performant, or \u201c As a result, my code becomes sloppier. \u201d Sometimes, being unhappy \nresults in discharging quality practices (\u201c[...] so I cannot follow the standard design \npattern\u201d) as a way to cope with the negative experiences. Yet, being happy improves \nthe quality of code. A participant told a small story about their work: \u201cI was building \nan interface to make two applications talk. It was an exciting challenge, and my happy \nand positive feelings made me go above and beyond to not only make it functional \nbut I made the UX nice too. I wanted the whole package to look polished and not just \nfunctional. \u201d When happy, developers tend to make less mistakes, see solutions to \nproblems more easily, and make new connections to improve the quality of the code. \nA participant told us this: \u201cWhen I\u2019m in a good mood and I feel somehow positive, \nthe code I write seems to be very neat and clean. I mean, I can write code and analyze \nproblems quickly and with lesser or no unnecessary errors. \u201d As a result, the code is \ncleaner, more readable, better commented and tested, and with less errors and bugs.\nThe last factor we would like to report is mostly related to unhappiness, and it is \nquite an important one. It is about mental unease and mental disorder. We created \nthis category to collect those consequences that threaten mental health. Participants \nreported that unhappiness while developing software is a cause of anxiety (\u201cThese kinds \nof situations make me feel panicky. \u201d), stress (\u201c[The] only reason [for] my failure [is] due \n[to] burnout. \u201d), self-doubt (\u201cIf I feel particularly lost on a certain task, I may sometimes \nbegin to question my overall ability to be a good programmer. \u201d), and sadness and feeling Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "121depressed (\u201c[\u2026] feels like a black fog of depression surrounds you and the project. \u201d). \nIn addition, we found mentions of feelings of being judged, frustration, and lack of \nconfidence in one\u2019s ability.\n What Does the\u00a0Future Hold?\nIn 1971, Gerald Weinberg\u2019s book The psychology of programming  [12] drew attention to \nthe fact that software development is a human endeavor, and the humans doing it\u2014the \ndevelopers\u2014are individuals with feelings. To this day, we still have more to understand \nabout the human factor in software development. Software development productivity \nis still often managed as if it were about delivering code on an assembly line (see, e.g., \nChapter 11). On the other hand, many companies do understand the importance of \nhappy developers, invest in their well-being, and consider it to be worthwhile.\nAs we have shown, the link between happiness and productivity in software \ndevelopment is real. It is possible to quantify the happiness of software developers, and \nthere are distinct patterns in the causes and consequences of their happiness.\nWhat if we could include happiness as a factor in software development productivity \nmanagement? In the future, an increasing number of people will work with digital \nproducts and services and perform tasks that are, in effect, software development. It \nwould be worth investing in their happiness. It is important that we learn more about \nthe relationship between well-being and software development performance. Rigorous \nresearch and educating practitioners on the research results are keys to improve the \nfield. Besides sharp technical skills, we would like to give future software developers an \nunderstanding of the social and psychological factors that influence their own work.\n Further Reading\nIn this chapter, we reported on several studies on the happiness of software engineers. \nSome of these studies [ 1, 2, 3, 5, 11] were self-contained and independent. Other studies \n[4, 6] are part of an ongoing project that we described in the section \u201cScientific Grounds \nof Happy and Productive Developers. \u201d\nAt the time of writing of this chapter, we still have to uncover all the categories, \nincluding those about what makes developers happy. We invite readers to inspect our \nopen science repository [ 10], where we add new papers and results as we uncover them. \nThe repository contains the entire taxonomy of what makes developers unhappy.Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "122 Key Ideas\nHere are the key ideas from this chapter:\n\u2022 Science says the industry should strive for happy developers.\n\u2022 The o verall happiness of software developers is slightly positive. Yet, \nmany are still unhappy.\n\u2022 The c auses of unhappiness among software engineers are numerous \nand complex.\n\u2022 Happiness and unhappiness bring a plethora of benefits and \ndetriments to software development processes, people, and products.\n References\n [ 1]  G raziotin, D., Wang, X., and Abrahamsson, P . 2014. Happy software \ndevelopers solve problems better: psychological measurements \nin empirical software engineering. PeerJ. 2, e289. DOI=10.7717/\npeerj.289. Available: https://doi.org/10.7717/peerj.289 .\n [2] Graziotin, D., Wang, X., and Abrahamsson, P . 2015. Do feelings \nmatter? On the correlation of affects and the self-assessed \nproductivity in software engineering. Journal of Software: \nEvolution and Process. 27, 7, 467\u2013487. DOI=10.1002/smr.1673. \nAvailable: https://arxiv.org/abs/1408.1293 .\n [3] Graziotin, D., Wang, X., and Abrahamsson, P . 2015. How do you \nfeel, developer? An explanatory theory of the impact of affects \non programming performance. PeerJ Computer Science. 1, e18. \nDOI=10.7717/peerj-cs.18. Available: https://doi.org/10.7717/\npeerj-cs.18 .\n [4] Graziotin, D., Fagerholm, F ., Wang, X., and Abrahamsson, P . 2017. \nOn the Unhappiness of Software Developers. 21st International \nConference on Evaluation and Assessment in Software Engineering. \n21st International Conference on Evaluation and Assessment in \nSoftware Engineering, 324\u2013333. DOI=10.1145/3084226.3084242. \nAvailable: https://arxiv.org/abs/1703.04993 .Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "123 [5] Graziotin, D., Wang, X., and Abrahamsson, P . 2014. Software \nDevelopers, Moods, Emotions, and Performance. IEEE Software. 31, \n4, 24\u201327. DOI=10.1109/MS.2014.94. Available: https://arxiv.org/\nabs/1405.4422 .\n [6] Graziotin, D., Fagerholm, F ., Wang, X., & Abrahamsson, P . \n(2018). What happens when software developers are (un)happy. \nJournal of Systems and Software, 140, 32-47. DOI=10.1016/j.\njss.2018.02.041. Available: https://doi.org/10.1016/j.\njss.2018.02.041\n [7] Zelenski, J.\u00a0M., Murphy, S.\u00a0A., and Jenkins, D.\u00a0A. 2008. The Happy-\nProductive Worker Thesis Revisited. Journal of Happiness Studies. \n9, 4, 521\u2013537. DOI=10.1007/s10902-008-9087-4.\n [8] Diener, E., Wirtz, D., Tov, W., Kim-Prieto, C., Choi, D.-w., Oishi, S., \nand Biswas-  Diener , R. 2010. New Well-being Measures: Short Scales \nto Assess Flourishing and Positive and Negative Feelings. Social \nIndicators Research. 97, 2, 143-156. DOI=10.1007/s11205-009-9493-y.\n [9] Bradley, M.\u00a0M. and Lang, P .\u00a0J. 1994. Measuring emotion: The \nself-assessment manikin and the semantic differential. Journal \nof Behavior Therapy and Experimental Psychiatry. 25, 1, 49-59. \nDOI=10.1016/0005-7916(94)90063-9.\n [10]  Graziotin, D., Fagerholm, F ., Wang, X., and Abrahamsson, P . 2017. \nOnline appendix: the happiness of software developers. Figshare. \nAvailable: https://doi.org/10.6084/m9.figshare.c.3355707 .\n [11] Fagerholm, F ., Ikonen, M., Kettunen, P ., M\u00fcnch, J., Roto, V ., \nAbrahamsson, P . 2015. Performance Alignment Work: How \nsoftware developers experience the continuous adaptation of team \nperformance in Lean and Agile environments. Information and \nSoftware Technology. 64, 132\u2013147. DOI=10.1016/j.infsof.2015.01.010.\n [12]  Weinberg, G.\u00a0M. (1971). Psychology of Computer Programming  \n(1 ed.). New\u00a0York, NY, USA: Van Nostrand Reinhold Company.\n [13] Piper, B.\u00a0J., Mueller, S.\u00a0T., Talebzadeh, S., Ki, M.\u00a0J. 2016. Evaluation of the \nvalidity of the Psychology Experiment Building Language tests of vigilance, \nauditory memory, and decision making. PeerJ. 4, e1772. DOI=10.7717/\npeerj.1772. Available: https://doi.org/10.7717/peerj.1772 .Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "124 [14] Piper, B.\u00a0J., Mueller, S.\u00a0T., Geerken, A.\u00a0R, Dixon, K.\u00a0L., Kroliczak, \nG., Olsen, R.\u00a0H. J., Miller, J.\u00a0K. 2015. Reliability and validity of \nneurobehavioral function on the Psychology Experimental Building \nLanguage test battery in young adults. PeerJ. 3, e1460. DOI=10.7717/\npeerj.1460. Available: https://doi.org/10.7717/peerj.1460 .\n [15]  Miner, A.\u00a0G., Glomb, T.\u00a0M., 2010. State mood, task performance, \nand behavior at work: A within-persons approach. Organizational \nBehavior and Human Decision Processes. 112, 1, 43\u201357.  \nDOI=10.1016/j.obhdp.2009.11.009.\n [16]  Graziotin, Daniel; Fagerholm, Fabian; Wang, Xiaofeng; \nAbrahamsson, Pekka (2017): Slides for the consequences \nof unhappiness while developing software. https://doi.\norg/10.6084/m9.figshare.4869038.v3 .\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 10  happiness and\u00a0the\u00a0 produ Ctivity of\u00a0 software engineers"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "125\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_11CHAPTER 11\nDark Agile: Perceiving \nPeople As\u00a0Assets, Not \nHumans\nPernille Bj\u00f8rn, University of Copenhagen, Denmark\n Revisiting the\u00a0Agile Manifesto\nThe agile principles for software engineering were developed as a reaction against \nstructuring software engineering processes in strict stepwise and sequential ways. \nThe idea that it was possible to create a clearly predefined scope prior to the actual \nsoftware engineering activities was questioned\u2014and the agile methodology was an \nattempt to rephrase the basic nature of software engineering. The agile understanding of \nsoftware engineering is that the fundamental nature of software means that we cannot \npredetermine scope, goals, and objectives up front. Instead, goals, scope, and objectives \nare transformed throughout the software development process. This setup requires \nparticipants (developers and clients) to balance and negotiate resources and priorities, \nand this is what drives agile development. Agile development is not one thing but can \ninstead be seen as a set of principles that guide the organization of work and can be \nimplemented in different ways. The main principles provided by the agile manifesto \n(http://agilemanifesto.org ) are as follows:\n\u2022 Individuals and interaction over processes and tools\n\u2022 Working software over comprehensive documentation"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "126\u2022 Customer collaboration over contract negotiation\n\u2022 Responding to change over following a plan\nThese agile principles are based upon the main idea of providing the power over \nsoftware engineering to the people\u2014the software team. Instead of letting software \ndevelopers be controlled from the outside, the software teams are to be empowered to \nfind and prioritize their own work. The software team is to be a self-organized team, \nand the client or customer is to be part of the team supporting the prioritizing of tasks \nbased upon available resources. When we, in computer science departments at Danish \nuniversities, teach computer science students about software engineering, we talk about \nthe benefits of agile development and the problems with the waterfall model. We explain \nhow the waterfall model does not take into account the iterative and creative process of \ndeveloping software. Furthermore, if you visit any kind of Danish IT company and talk to \nthe developers and ask them about methods, they will tell you how the waterfall model \ndoes not work and how agile methodologies provide better quality within an appropriate \ntime frame. Agile is seen as a positive perspective on software engineering in Denmark.\nHowever, the story about agile is quite different when we change perspective from \nScandinavia and turn to India.\n Agile in\u00a0Global Outsourcing Setups\nBased upon a long-term research project called Next-Generation Tools and Processes \nfor Global Software Development (NexGSD; nexsgsd.org ), we have studied how global \nsoftware development takes place in different places around the world. Concretely, \nwe went to observe and interview software developers in the Philippines about their \nexperiences working with software developers in Denmark [ 4, 5, 7], and we also went \nto India, more concretely Bangalore, Mumbai, and Chennai, to observe and interview \nsoftware developers about their experiences collaborating with software teams and \nvendors located in Northern Europe and the United States [ 6, 8, 11, 12]. Throughout all \nthese empirical studies, we began to notice the consequences of implementing agile \nprinciples such as scrum methodologies in global outsourcing setups. We witnessed a \ntransformation in the way global software development was organized between 2011, \nwhen we started the project, until 2014, where all the organizations we studied went \nfrom waterfall models toward agile models [ 1, 2].Chapter 11  Dark agile: perCeiving people as\u00a0assets, not humans"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "127So, what does this mean? Let\u2019s take a closer look at the experience of agile \ndevelopment seen from a software developer working out of India in one of our \nempirical case studies between Bangalore, India, and Phoenix, United States [ 3].\nGlobal software development can at a high level be organized as outsourcing or \noff-shoring. Outsourcing is when you move work from one internal location toward an \nexternal partner, who then does the work for you. Differently, global off-shoring is when \nwork is moved to a different location, but still within the same company\u2014like IBM USA \nworking with IBM India. In our empirical cases, we are looking at global out-sourcing, \nwhich means that work is moved from either the United States or Denmark to a different \ngeographical location and a different organizational setting.\nIn outsourcing setups, it is important to note that the power remains with the client. \nThis mean the client chooses which company is doing the work, and deciding to move \nwork to other outsourcing vendors (still in the same region of the world) is always an \noption. In one of our cases, the U.S. client put together a global agile team comprised of \nexperts from different IT vendor companies in India and then one representative from \nthe client was the project owner. This meant that the team members, even being in the \nsame team, were simultaneously in competition. The client was able to exchange specific \nmembers with new people if particular individuals were not performing well accordantly \nto the client. This multivendor setup created a high-performance team, which despite \nbeing geographically distributed was highly productive. The global agile setup raised the \ncompetition among the team members, and from a productivity perspective, this was \na huge success. But how did the agile principles\u2014concretely manifested in the scrum \nmethodology\u2014impact the global outsourcing team?\n Tracking Work to\u00a0Increase Productivity\nOne of the main processes in scrum is that members of the team specify what they are \ncurrently working on, directly linked to specific numbers of hours. How many hours \nspecific tasks might take is up to the team members, who negotiate the resources \nrequired during planning. In this way, each team member is tasked with assignments \nto be accomplished and finished within detailed time frames. In India, the workday \nof software developers is ten hours. In all software projects, some hours will be spent \non other activities than directly on the project. Therefore, the hours that are tracked \nare eight hours a day. This means that each day, each team member is committing to \nproduce software tasks resembling the work of eight hours. Thus, regardless of what Chapter 11  Dark agile: perCeiving people as\u00a0assets, not humans"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "128might happen, each team member must produce the task assignment. Even if their child \ngets sick and they need to leave the office, they cannot. They have to stay on task and \ncomplete the task as planned or else their client might move the task to a competing \nIT-vendor company (still in India). Interestingly, the software developers working in \nBangalore explained to us how they prefer waterfall over agile. Waterfall had less time \npressure since they had a specific target\u2014and longer deadlines, which made it possible \nto pick up a sick child if needed, rather than being constantly pushed by short deadlines.\n Daily Stand-Up Meeting to\u00a0Monitor Productivity\nBesides agile allowing clients to constantly track the productivity of each individual \nteam member, global agile also forced team members to participate in daily stand-up \nmeetings. While the stand-up meeting alone was not problematic, the time of day for \nthe meeting was. Because of the time difference between the East Coast in the United \nStates and India, the time for stand-up meetings were set to late evening (10 p.m.) Indian \ntime. This was regardless of the day of the week\u2014so all days including Friday, there \nwere stand-up meetings in the evening. This meant that team members involved in \nglobal agile outsourcing were forced to work out of sync locally to accommodate global \nwork. Working out of sync locally is problematic in terms of family life or social events, \nespecially in situations where the software developers had their families in villages far \naway. Several developers we spoke with moved to the electronic city of Bangalore during \nthe week and then traveled back on the weekends. The stand-up meetings made it \ndifficult to travel home Friday evening. Furthermore, the tenure of the projects changed \nfrom being four- or five-month-long projects to being more than a year. This provided \nconstant pressure on the software developers; there was no time for breaks or vacations. \nThe high level of productivity for the extended time led to a stressful environment.\n Stressful Work Environment\nOver the three years we conducted interviews, it became apparent that, while the global \nagile team had high productivity and was the preferred IT vendor for the customer, the \nsoftware developers working in the global agile setting felt \u201cmore pressure, more time \npressure, stress\u201d and the experience of agile methodology was that it \u201cis very stressful, at \nthe tester level. \u201d It is important to note that while it can be expected that people in higher Chapter 11  Dark agile: perCeiving people as\u00a0assets, not humans"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "129positions working in global projects be available at odd times and work many hours, the \npeople working under pressure in this situation were the developers and testers working \nin low-level positions. The way global agile was implemented meant that the customer \npressured the team on speed constantly\u2014so even though agile principles stipulate that \nthe ideal sprint size is two to three weeks, the customer pushed it down to one week. \nAnalyzing, designing, implementing, and testing workable deliveries within five days of \nwork is hard, especially for the testers. As a delivery manager explained to us: \u201cYes, for \nthe techies, or for the technical department, it is a very stressful, stressful methodology I \nwould say because the expectation is too high from the customer\u2019s side. \u201d\n Cost of\u00a0Productivity\nThere is no doubt that the IT vendor we studied was highly productive in terms of speed \nand quality, delivered good quality work on time, and was the customers\u2019 preferred IT \nvendor, even in the competitive multivendor setup. As the preferred IT vendor, they \ngained more tasks, especially in situations where other vendors were not able to deliver. \nNow the question is, what was the cost of this high productivity?\nFinancially, global agile is more expensive than waterfall methods for the customer: \nwhen talking with the IT vendor, it was clear that they were able to produce the same \nkind of products much cheaper under the waterfall methodology. The argument for \nglobal agile as a way to save costs, which are often a fundamental problem in global \nsoftware development [ 10], was not on the agenda. When we asked the IT vendor why \nthey were using agile principles in the first place, they explained that it was a request \nfrom the customers: the customers wanted the vendor to use scrum. Let\u2019s take a step \nback and reflect on this request from the customers. When you, as a company, are \nhired to deliver a service or a product, negotiations about the price, timeline, and \ncollaboration are to be expected. Clients direct requests for how the vendor is to use \nspecific methods are less obvious. So, why did the client request this? Despite it being a \nmore expensive methodology for the client, they gained direct access to highly qualified \npeople, who all had proportionally high salaries (though the IT vendor then had \ndifficulty including and training new people to work on the projects).\nWhat about the human costs of this high productivity? What happens to people \nwhen agile goes global? If we return to the principles in the agile manifesto, we find that \nthe principles of \u201cworking software over comprehensive documentation, \u201d \u201ccustomer \ncollaboration over contract negotiation, \u201d and \u201cresponding to change over following a plan\u201d Chapter 11  Dark agile: perCeiving people as\u00a0assets, not humans"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "130are all very pertinent in the global agile outsourcing setting as well. In our case, there was \nclose collaboration with the customer, the scope and objectives were a moveable target, \nand there was a constant focus on working software deliveries. However, if we look at the \nfirst principle of \u201cindividuals and interaction over processes and tools, \u201d we see a shift. The \nprocesses and tools created to structure the agile delivery were used to micromanage the \nsoftware developers\u2019 work in all the small details. We can view the global agile principles \nin our case as an algorithmic machine, with specific input and output features. The input \nmeasures are the numbers, the hours, and the deliverables deadlines, which are then used \nto push people to maximize their efforts. Given the tools and processes of agile, the remote \nclient is able to monitor and control every little aspect of the work done by the software \ndevelopers. Sure, global agile is very productive. If the only criteria for success is high-\nquality work done fast, global agile is attractive.\nNevertheless, there is a dark side to global agile, since in the case of scrum comes \ntools and processes that can be used to micromanage software developers. Focusing \nonly on productivity, we risk losing sight of individuals and the \u201cmushy stuff\u201d that is at \nthe core of the agile ideals. According to Jim Highsmith for the Agile Alliance, \u201c At the \ncore, I believe agile methodologists are really about the \u2018mushy\u2019 stuff about delivering \ngood products to customers by operating in an environment that does more than talk \nabout \u2018people as our most important asset\u2019 but actually \u2018acts\u2019 as if people were the most \nimportant and lose the word \u2018asset\u2019\u201c ( http://agilemanifesto.org/history.html ).\nI that we must consider the conditions for work created by the constant focus on \nproductivity introduced and controlled by agile tools and processes. This risk of the \n\u201cglobal agile algorithmic machine\u201d is that it turns people into assets, resources, and \nnumbers\u2014and we lose sight of individual developers. While waterfall methodologies \nhave been criticized for heavily regulating work and introducing micromanagement, our \nempirical observations point to how the global agile methodology can also be used for \nmicromanagement and strong regulation of software developers.\nGlobal agile provides good conditions for high productivity in software engineering \nbut also these risks:\n\u2022 Perceiving people as assets, not human beings\n\u2022 Creating stressful work environments in continuous work cycles\n\u2022 Supporting clients in micromanagement from afar\n\u2022 Making developers and testers work out of sync with their local time \nzonesChapter 11  Dark agile: perCeiving people as\u00a0assets, not humans"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "131What we risk losing is the focus on the software developers and the self-organization \nand empowerment that are supposed to be introduced with agile methodologies. \nSoftware engineering organized by global agile methodologies in highly competitive \nmultivendor settings risks resembling the assembly line in factory work. Is this really \nwhat we want the future of software engineering to look like?\n Open Questions for\u00a0Productivity in\u00a0Software \nEngineering\nI am not arguing that global agile is problematic per se. Clearly, in all the NexGSD \nempirical studies, closely coupled collaboration was essential to get that collaboration \nto function across sites, and the agile principles enable and stipulate closely coupled \ncollaboration. However, I am arguing that \u201cbeing a software developer involved in global \noutsourcing\u201d means different things depending on where you physically are located in \nthe world. Software developers at low-level positions working in Bangalore, India, have \ndifferent conditions for work than software developers working in Ballerup, Denmark \n[9]. This means that they will experience the implementation of global agile in different \nways. Software engineers located in Denmark have a privileged position in the global \nsetup. For software engineers located in India, the way global agile techniques, tools, \nand processes shapes work do not provide the same conditions for self-organization \nand empowerment. Moreover, it means that when we are designing software tools \nand processes to support global work, we should take into consideration the different \nconditions and not just focus on productivity. Fast delivery and high-quality code should \nnot be our main measurements; instead, we should start to develop measurements that \nare more nuanced and take into consideration work conditions. We must think about \nhow artifacts such as \u201cburndown charts\u201d reflect only partial aspects of productivity [ 10], \nand we should ask, what is not represented in such artifacts? What are artifacts and \ntools neglecting to make visible? Finally, we need to consider how to ensure that we do \nnot lose our human values when we think about how we design tools and processes \nand create good work conditions for all, no matter where in the world they are placed. \nPeople work more and more in the global setting; and as life and work starts to blend due \nto us bringing home our laptops and continuing checking e-mail in the evenings and \non weekends, we need to prepare long-term strategies for dealing with the pressure of \nproductivity\u2014even for low-level software developers and testers working in India.Chapter 11  Dark agile: perCeiving people as\u00a0assets, not humans"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "132When software developers complain that they have to attend a meeting at 10 p.m. \nand are not able to leave work to pick up sick children, they are not complaining about \nagile development per se. Instead, they are complaining about the lack of power and \ndecision-making within the organizational setup. Agile development works well for \nsoftware developers in Scandinavia, Northern Europe, and United States because the \nsoftware teams are powerful and privileged. When clients demand agile development \nfrom software developers elsewhere, those developers are not empowered. Instead, the \npower to choose and organize their work is taken away from them. The following are \nimportant questions we must ask:\n\u2022 What kind of productivity and values do we want software \nengineering to reflect?\n\u2022 How do we ensure that these values are manifested in our \nproductivity measurements shaping software engineering processes \nand tools?\n\u2022 How can we design software engineering practices and technologies \nto support productivity without losing human values?\n Key Ideas\nThe following are the key ideas from this chapter:\n\u2022 Global agile software development has several risks: perceiving \npeople as assets, not humans; creating a stressful work environment; \nmicromanagement; and making engineers work out of sync with \nlocal time zones.\n\u2022 Productivity measurement should be about more than speed and \nquality.\n Acknowledgments\nThis chapter is based upon the academic research paper co-authored by Pernille \nBj\u00f8rn, Anne-Marie S\u00f8derberg, and S.\u00a0Krishna titled \u201cTranslocality in Global Software \nDevelopment: The Dark Side of Global Agile\u201c and published in the journal of Human-  \nComputer Interaction [ 3]. Further, the work referred to is part of several subprojects Chapter 11  Dark agile: perCeiving people as\u00a0assets, not humans"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "133in the NexGSD research project ( nexgsd.org ), which was financially supported by the \nNational Council for Strategic Research, Ministry of Science, Innovation, and Higher \nEducation in Denmark.\n References\n [1] Bj\u00f8rn, P . (2016). \u201cNew fundamentals for CSCW research: From \ndistance to politics. \u201d Interactions (ACM SIGCHI) 23(3): 50\u201353.\n [2] Bj\u00f8rn, P ., M.\u00a0Esbensen, R.\u00a0E. Jensen and S.\u00a0Matthiesen (2014). \n\u201cDoes distance still matter? Revisiting the CSCW fundamentals on \ndistributed collaboration. \u201d ACM Transaction Computer Human \nInteraction (ToChi) 21(5): 1\u201327.\n [3] Bj\u00f8rn, P ., A.-M.\u00a0S\u00f8derberg and S.\u00a0Krishna (2017). \u201cTranslocality \nin Global Software Development: The Dark Side of Global Agile. \u201d \nHuman-Computer Interaction 10.1080/07370024.2017.1398092.\n [4] Christensen, L. and P .\u00a0Bj\u00f8rn (2014). Documentscape: \nIntertextuallity, sequentiality and autonomy at work. ACM CHI \nConference on Human Factors in Computing Systems Toronto, \nON, Canada, ACM.\n [5] Christensen, L.\u00a0R., R.\u00a0E. Jensen and P .\u00a0Bj\u00f8rn (2014). Relation \nwork in collocated and distributed collaboration. COOP: 11th \nInternational Conference on Design of Cooperative Systems. Nice, \nFrance, Springer.\n [6] Esbensen, M. and P .\u00a0Bj\u00f8rn (2014). Routine and standardization \nin Global software development. GROUP .\u00a0Sanible Island, Florida, \nUSA, ACM.\n [7] Jensen, R.\u00a0E. and B.\u00a0Nardi (2014). The rhetoric of culture as an act \nof closure in cross- national software development department. \nEuropean Conference of Information System (ECIS). Tel Aviv, AIS.\n [8] Matthiesen, S. and P .\u00a0Bj\u00f8rn (2015). Why replacing legacy systems \nis so hard in global software development: An information \ninfrastructure perspective. CSCW.\u00a0Vancouver, Canada, ACM.Chapter 11  Dark agile: perCeiving people as\u00a0assets, not humans"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "134 [9] Matthiesen, S. and P .\u00a0Bj\u00f8rn (2016). Let\u2019s look outside the office: \nAnalytical lens unpacking collaborative relationships in global \nwork. COOP2016. Trento, Italy, Springer.\n [10]  Matthiesen, S. and P .\u00a0Bj\u00f8rn (2017). \u201cWhen distribution of tasks and \nskills are fundamentally problematic: A failure story from global \nsoftware outsourcing. \u201d PACM on Human-Computer Interaction: \nOnline first 2018 ACM Conference on Computer-  supported \nCooperative Woek and Social Computing 1(2, Article 74): 16.\n [11]  Matthiesen, S., P .\u00a0Bj\u00f8rn and L.\u00a0M. Petersen (2014). \u201cFigure Out \nHow to Code with the Hands of Others\u201d: Recognizing Cultural \nBlind Spots in Global Software Development. Computer \nSupported Cooperative Work (CSCW). Baltimore, USA, ACM.\n [12]  S\u00f8derberg, A.-M., S.\u00a0Krishna and P .\u00a0Bj\u00f8rn (2013). \u201cGlobal Software \nDevelopment: Commitment, Trust and Cultural Sensitivity in \nStrategic Partnerships. \u201d Journal of International Management  \n19(4): 347\u2013361.\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 11  Dark agile: perCeiving people as\u00a0assets, not humans"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "PART IV\nMeasuring Productivity  \nin Practice"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "137\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_12CHAPTER 12\nDevelopers\u2019 Diverging \nPerceptions of\u00a0Productivity\nAndr\u00e9 N.  Meyer, University of Zurich, Switzerland\nGail C. Murphy, University of British Columbia, Canada\nThomas Fritz, University of Zurich, Switzerland\nThomas Zimmermann, Microsoft Research, USA\n Quantifying Productivity: Measuring vs. Perceptions\nTo overcome the ever-growing demand for software, software development \norganizations strive to enhance the productivity of their developers. But what does \nproductivity mean in the context of software development? A substantial amount of work \non developer productivity has been undertaken over the past four decades. The majority \nof this work considered productivity from a top-down perspective  (the manager view) \nin terms of the artifacts and code created per unit of time. Common examples of such \nproductivity measures are the lines of source code modified per hour, the resolution \ntime for modification requests, or function points created per month. These productivity \nmeasures focus on a single, output-oriented factor for quantifying productivity and do \nnot take into account developers\u2019 individual work roles, practices, and other factors \nthat might affect their productivity, such as work fragmentation, the tools used, or the \nwork/office environment. For example, a lead developer who spends a big part of work \nsupporting co-workers with their inquiries might develop less code in the process"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "138and would thus be considered less productive when using traditional, top-down \nmeasurements compared to developers who focus solely on coding.\nAnother approach to quantify productivity is bottom-up , starting at the \nproductivity of individual software developers to then also learn more about \nquantifying productivity more broadly. By investigating developers\u2019 individual \nproductivity, it is possible to better understand individual work habits and patterns, \nhow they relate to productivity perceptions, and also which factors are most relevant \nfor a developer\u2019s productivity.\n Studying Software Developers\u2019 Productivity \nPerceptions\nThere are various ways to investigate productivity from the bottom up. In this \nchapter, we describe three studies that we conducted using a variety of methods, \nfrom very detailed observations to two-week field studies using a monitoring \napplication.\n\u2022 First, to gather insights into what developers\u2019 considered productive \nand unproductive work, we conducted an online survey with 389 \nprofessional software developers, followed by observations and \nfollow-up interviews with 11 developers to corroborate some of the \nfindings of the survey [ 1].\n\u2022 To better understand activities developers pursue at work, the \nfragmentation of their work, and how these activities relate to self-  \nreported productivity, we conducted a two-week field study with \n20 professional software developers. For this study, we deployed a \nmonitoring application that logged developers\u2019 computer interaction \nand collected self-reports on their productivity every 90 minutes [ 2].\n\u2022 To analyze and compare the situations when developers feel \nproductive, we conducted a further online survey with 413 \nprofessional software developers [ 3].\nThe remainder of this chapter highlights the most prominent findings. Detailed \ndescriptions of the studies and findings can be found in the corresponding papers.Chapter 12  Developers\u2019 Diverging perCeptions of\u00a0 proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "139 The Cost of\u00a0Context Switching\nDevelopers reported that they usually feel most productive when they make progress \non tasks and when they have only a few context switches and interruptions. However, \nobserving developers\u2019 workdays revealed that they constantly switch contexts, often \nmultiple times an hour. For example, developers switched tasks on average 13 times \nan hour and spent just about 6 minutes on a task before switching to another one. An \nexample of a task switch is a developer who is switching from implementing a feature to \nanswering e-mails that are unrelated to the previous task. Similarly, when we looked at \nhow much time developers spend on activities\u2013actions they usually pursue at work (e.g., \nwriting code, running tests, or writing an e-mail)\u2013we found out that they usually remain \nin an activity only between 20 seconds and 2 minutes before switching to another one. \nThis high number of task and activity switches and the high variety of activities and tasks \ndevelopers pursue each day illustrate the high fragmentation of a developer\u2019s work.\nSurprisingly, many developers still felt productive despite the high number of \ncontext switches. The follow-up interviews with the developers revealed that the cost \nof context switches varies. The cost or \u201charm\u201d of a context switch depends on several \nfactors: the duration of the switch, the reason for the switch, and the focus on the current \ntask that is interrupted. A short switch from the IDE to respond to a Slack message is \nusually less costly than being interrupted from a task by a co-worker and discussing \na topic unrelated to the main task for half an hour. Also, short context switches, such \nas writing a quick e-mail while waiting for a build to complete, do not usually harm \nproductivity, as self-reported by our participants.\nInterruptions from co-workers are one of the most often mentioned reasons for \ncostly context switches, especially when they happen at an inopportune moment, \nsuch as when a developer is focused on a challenging problem. Chapter 23 presents \none possible solution of how developers and other knowledge workers can reduce the \nnumber of costly interruptions by visualizing their current focus to the team.\n A Productive Workday in\u00a0a\u00a0Developer\u2019s Life\nInvestigating how developers organize their time at work and what activities they pursue \nrevealed notable differences. During an average workday of 8.4 hours, developers spend \nabout half of their time, on average 4.3 hours, actively working on their computer. \nSurprisingly, they spend only about one-fourth of their total work time with coding-  \nrelated activities and another fourth of their time with collaborative activities such Chapter 12  Developers\u2019 Diverging perCeptions of\u00a0 proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "140as meetings, e-mails, and instant messaging. There are also big differences across \ncompanies, for example how much time their developers spend reading or writing \ne-mails. At one of the observed companies, developers spent less than one minute with \ne-mail each workday, compared to developers at another company where they spent \nmore than an hour.\nRelating the activities developers pursue at work with how productive they feel \nduring these activities revealed that productivity is highly individual and differs greatly \nacross developers. The majority of developers reported coding as the most productive \nactivity, as coding allows them to make progress on the tasks that are most important to \nthem. With most other activities, there was no clear consensus about whether an activity \nis generally productive or not. Meetings were the most controversial activity: more than \nhalf of the developers considered meetings as unproductive, especially when they lack \ngoals, have no outcome, or there are too many attendees; the other half of developers \nconsidered meetings to be productive. E-mails are considered to be a less productive \nactivity by many developers. However, no single activity is considered exclusively \nproductive or unproductive by all developers. Coding, for instance, was not always \nconsidered to be a productive activity, for example when the developer was blocked on a \ntask. This suggests that measures or models that attempt to quantify productivity should \ntake individual differences, such as the context of a developer\u2019s workday, into account, \nand attempt to capture a developer\u2019s work more holistically rather than reducing them to \na single activity and one outcome measure.\n Developers Expect Different Measures \nfor\u00a0Quantifying Productivity\nWhen we asked developers about how they would like to quantify their productivity, the \nmajority wanted to assess their productivity based on the number of completed tasks but \nalso combine it with other measures. These additional measures include output-related \nmeasures, such as the lines of code, number of commits, number of bugs found or fixed, \nand e-mails sent, but they also include higher-level measures, such as how focused they \nwere during their work, if they were working \u201cin the flow\u201d (or \u201cthe zone\u201d), and if they felt \nthey had made any significant progress. Across all measures that developers were asked \nabout, there was no single measure or combination of multiple measures that were \nconsistently rated higher by most developers. This result indicates that there are a variety \nof aspects that impact the productivity of developers and their feeling of productivity Chapter 12  Developers\u2019 Diverging perCeptions of\u00a0 proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "141differently. For example, on days when a developer spends a lot of time working on \ndevelopment task, a measure of the number of work items completed or check-ins \nmade may be appropriate. However, the same measure on days a developer spends \nmost of the time in meetings or helping co-workers would result in a low productivity \nand high frustration for the developer. Furthermore, the findings suggest that it is \ndifficult to broadly measure productivity without defining specific objectives. We will \nhave to find ways to do measure productivity more holistically, by not only leveraging \noutput measures, but also considering developers\u2019 individual abilities, work habits, \ncontributions to the team, and more. Chapters 2 and 3 discuss this further and argue that \nproductivity should be considered not only from the perspective of individuals but also \nfor teams and organizations.\n Characterizing Software Developers by\u00a0Perceptions \nof\u00a0Productivity\nThe differences in how developers feel about productivity makes it also more challenging \nto determine meaningful actions that could help increase productivity on a team or \norganizational level. One way to better understand differences and commonalities in \ndevelopers\u2019 perceptions of productivity is to investigate if we can find patterns or group \ndevelopers with similar perceptions. Analyzing productivity ratings from hourly self-\nreports during three workweeks, we found that developers can roughly be categorized \ninto three groups that are similar to the circadian rhythm: morning person, afternoon \nperson, and low-at-lunch person, as visualized in Figure\u00a0 12-1 . The curved regression \nline in the three figures shows the overall pattern of what part of the day an individual \ndeveloper typically felt more or less productive with the shaded area showing the \nconfidence range. Morning people were rare in our sample, with only 20 percent of all \nparticipants. The biggest group were afternoon people (40 percent), who may be those \nwho are industrious later in the day or who feel more productive as a result of having \nthe majority of their workday behind them. These results suggest that while developers \nhave diverse perceived productivity patterns, individuals do appear to follow their own \nhabitual patterns each day.Chapter 12  Developers\u2019 Diverging perCeptions of\u00a0 proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "142In another effort to group developers with similar perceptions of productivity \ntogether, we asked participants to describe productive and unproductive workdays, \nrate their agreement with a list of factors that might affect productivity, and rate the \ninterestingness of a list of productivity measures at work. We found that developers can \nbe clustered into six groups: social, lone, focused, balanced, leading, and goal-oriented.\n\u2022 The social developers  feel productive when helping co-workers, \ncollaborating, and doing code reviews. To get things done, they come \nearly to work or work late and try to focus on a single task.\n\u2022 The lone developers  avoid disruptions such as noise, e-mail, meetings, \nand code reviews. They feel most productive when they have little to \nno social interactions and when they can work on solving problems, \nfixing bugs, or coding features in quiet and without interruptions. \nTo reflect about work, they are mostly interested in knowing the \nfrequency and duration of interruptions they encountered. Note that \nthis group of developers is almost the opposite of the first group (the \nsocial developer) in how productive they feel when encountering \nsocial interactions.\n\u2022 The focused developers  feel most productive when they are working \nefficiently and concentrated on a single task at a time. They feel \nunproductive when they are wasting time and spend too much time \non a task because they are stuck or working slowly. They are interested \nin knowing the number of interruptions and length of focused time.\nFigure 12-1.  Three types of developers and their perceptions of productivity over \nthe course of a workdayChapter 12  Developers\u2019 Diverging perCeptions of\u00a0 proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "143\u2022 The balanced developers  are less affected by disruptions. They feel \nunproductive when tasks are unclear or irrelevant, when they are \nunfamiliar with a task, or when tasks are causing overhead.\n\u2022 The leading developers  are more comfortable with meetings and \ne-mails and feel less productive with coding activities than other \ndevelopers. They feel more productive when they can write and \ndesign things, such as specifications. They do not like broken builds \nand blocking tasks, preventing them (or the team) from doing \nproductive work.\n\u2022 The goal-oriented developers  feel productive when they complete \nor make progress on tasks. They feel less productive when they \nmultitask, are goal-less, or are stuck. They are more open to meetings \nand e-mails compared to the other groups if they help them \nachieve their goals. In contrast to focused developers, goal-oriented \ndevelopers care more about actually getting stuff done (i.e., crossing \nitems off the task-list), while focused developers care more about \nworking efficiently.\nEach developer can belong to one or more of these groups. The six groups and their \ncharacteristics highlight differences in developers\u2019 productivity perceptions and show \nthat their ideal workdays, tasks, and work environments often look differently. We can \nfurther use these findings to tailor process improvements and tools to the different types \nof developers, as discussed in the next section.\n Opportunities for\u00a0Improving Developer Productivity\nDevelopers and development teams might benefit from these findings in various ways. \nOn the individual level, we could build self-monitoring tools that allow developers \nto increase their awareness about productive and unproductive behaviors and use \nthe insights they gain to set well-founded goals for self-improvements at work (see \nChapter 22).Chapter 12  Developers\u2019 Diverging perCeptions of\u00a0 proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "144These approaches should provide a variety of measures and support developers \nin getting insights into individual aspects of their work, such as identifying productive \nor unproductive work habits or identifying external or internal factors that have the \nbiggest impact on their productivity. In addition to self-monitoring that has been \nshown to motivate positive behavior changes in other fields (e.g., physical activity and \nhealth), supporting developers with setting goals to improve themselves at work through \nactionable insights might be a next step toward fostering productivity. Maybe one day, \nwe can further build virtual assistants, such as Alexa for Developers, that recommend \n(or automatically take) actions, depending on the goals of developers or based on the \nproductivity patterns/roles/clusters of developers. For example, such a virtual assistant \ncould block out notifications from e-mail, Slack, and Skype during coding sessions to \navoid disruptions for the \u201clone developer\u201d but allow them for the \u201csocial developer. \u201d Or \nthey could recommend the \u201cfocused developer\u201d to come to work early to have a few \nhours of uninterrupted work time or suggest the \u201cbalanced developer\u201d to take a break to \navoid boredom and tiredness.\nBy knowing the trends of developers\u2019 perceived productivity and the activities they \nconsider as particularly productive/unproductive, it might be possible to schedule the \ntasks and activities developers must perform in a way that best fits their work patterns. \nFor example, if a developer is a morning person and considers coding particularly \nproductive and meetings as impeding productivity, blocking calendar time in the \nmorning for coding tasks and automatically assigning afternoon hours for meeting \nrequests may allow the developer to best employ their capabilities over the whole day. \nOr, it could remind developers to reserve slots for unplanned work or interruptions at \ntimes where they usually happen.\nOur studies also revealed that interruptions, one specific type of a context switch, \nare one of the biggest impediments to productive work. Productivity could potentially be \nimproved on the team level by enhancing the coordination and communication between \nco-workers, depending on their preferences, availabilities, and current focus. For example, \non the team level, quiet, less interruption-prone offices could be provided to the \u201clone \ndevelopers\u201d and \u201cfocused developers, \u201d and \u201csocial developers\u201d who feel more comfortable \nwith discussions every now and then could be seated in open space offices. Alternatively, \ninterruptions at inopportune moments could be reduced by visualizing the developer\u2019s \ncurrent focus and concentration to other developers using an external cue. Hence, \nat times when the developer is \u201cin the flow\u201d or is usually most productive, expensive \ninterruptions could be postponed to a more opportune moment (see Chapter 23).Chapter 12  Developers\u2019 Diverging perCeptions of\u00a0 proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "145 Key Ideas\nThe following are the key ideas from this chapter:\n\u2022 Different software developers experience productivity differently, \nwhich is why they do not agree on how to measure productivity.\n\u2022 Most developers follow their own habitual patterns each day and are \nmost productive either in the morning, during the day (and not at \nlunch), or in the afternoon.\n\u2022 Measuring developer productivity should not only include output \nmeasures but also include measures inherent to developers\u2019 abilities, \nworkdays, work environments, and more.\n References\n [1] Andr\u00e9 N Meyer, Thomas Fritz, Gail C Murphy, and Thomas \nZimmermann. 2014. Software Developers\u2019 Perceptions of \nProductivity. In Proceedings of the 22Nd ACM SIGSOFT \nInternational Symposium on Foundations of Software \nEngineering, 19\u201329.\n [2] Andr\u00e9 N\u00a0Meyer, Laura E Barton, Gail C Murphy, Thomas \nZimmermann, and Thomas Fritz. 2017. The Work Life of \nDevelopers: Activities, Switches and Perceived Productivity. \nTransactions of Software Engineering (2017), 1\u201315.\n [3] Andr\u00e9 N Meyer, Thomas Zimmermann, and Thomas Fritz. \n2017. Characterizing Software Developers by Perceptions of \nProductivity. In Empirical Software Engineering and Measurement \n(ESEM), 2017 International Symposium on.Chapter 12  Developers\u2019 Diverging perCeptions of\u00a0 proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "146Open Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 12  Developers\u2019 Diverging perCeptions of\u00a0 proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "147\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_13CHAPTER 13\nHuman-Centered Methods \nto\u00a0Boost Productivity\nBrad A.  Myers, Carnegie Mellon University, USA\nAmy J. Ko, University of Washington, USA\nThomas D.  LaToza, George Mason University, USA\nYoungSeok Yoon, Google, Korea\nSince programming is a human activity, we can look to fields that have already \ndeveloped methods to better understand the details of human interactions with \ntechnologies. In particular, the field of human-computer interaction (HCI) has dozens, \nif not hundreds, of methods that have been validated for answering a wide range of \nquestions about human behaviors [ 4]. (And many of these methods, in turn, have been \nadapted from methods used in psychology, ethnography, sociology, etc.) For example, \nin our research, we have documented our use of at least ten different human-  centered \nmethods across all the phases of software development [ 11], almost all of which have \nimpacts on programmer productivity.\nWhy would one want to use these methods? Even though productivity may be hard \nto quantify, as discussed in many previous chapters of this book, it is indisputable \nthat problems exist with the languages, APIs, and tools that programmers use, and \nwe should strive to fix these problems. Further, there are more ways to understand \nproductivity than just metrics. HCI methods can help better understand programmers\u2019 \nreal requirements and problems , help design  better ways to address those challenges, and \nthen help evaluate  whether the design actually works for programmers. Involving real \nprogrammers in these investigations reveals real data that makes it possible to identify \nand fix productivity bottlenecks."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "148For example, a method called contextual inquiry  (CI) [ 1] is commonly used \nto understand barriers in context . In a CI, the experimenter observes developers \nperforming their real work where it actually happens and makes special note of \nbreakdowns  that occur. For example, in one of our projects, we wondered what key \nbarriers developers face when fixing defects, so we asked developers at Microsoft to \nwork on their own tasks while we watched and took notes about the issues that arose \n[7]. A key problem for 90 percent of the longest tasks was understanding the control flow  \nthrough code in widely separated methods, which the existing tools did not adequately \nreveal. CIs are a good way to gather qualitative data and insights into developers\u2019 real \nissues. However, they do not provide quantitative statistics, owing to the small sample \nsize. Also, a CI can be time-consuming, especially if it is difficult to recruit representative \ndevelopers to observe. However, it is one of the best ways to identify what is really  \nhappening in the field that affects the programmers\u2019 productivity.\nAnother useful method to understand productivity barriers is doing exploratory \nlab user studies  [14]. Here, the experimenter assigns specific tasks to developers and \nobserves what happens. The key difference from a CI is that here the participants \nperform tasks provided by the experimenter instead of their own tasks, so there is less \nrealism. However, the experimenter can see whether the participants use different \napproaches to the same task. For example, we collected a detailed data set at the \nkeystroke level of multiple experienced developers performing the same maintenance \ntasks in Java [ 5]. We discovered that the developers spent about one-third of their \ntime navigating around the code base, often using manual scrolling. This highlights \nan important advantage of these observational techniques\u2014when we asked the \nparticipants about barriers when performing these tasks, no one mentioned scrolling \nbecause it did not rise to the level of salience. However, it became obvious to us that \nthis was a barrier to the programmers\u2019 productivity when we analyzed the logs of what \nthe developers actually did. Knowing about such problems is the first step to inventing \nsolutions. And these kinds of studies can also provide numeric data, which can later be \nused to measure the difference that a new tool or other intervention makes.\nNeither of these methods can be used to evaluate how often  an observed barrier \noccurs, which might be important for calculating the overall impact on productivity. \nFor this, we have used surveys  [16] and corpus data mining  [9]. For example, after we \nobserved in our CIs that understanding control flow was important, we performed a \nsurvey to count how often developers have questions about control flow and how hard \nthose questions are to answer [ 7]. The developers reported asking such questions on \naverage about nine times a day, and most felt that at least one such question was hard Chapter 13  human-Centered methods to\u00a0Boost produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "149to answer. In a different study, we felt that programmers were wasting significant time \ntrying to backtrack  (return code to a previous state) while editing code. We had observed \nthat this seemed to be error-prone as changes often had to be undone in multiple places. \nTherefore, we analyzed 1,460 hours of  fine-  grained code-editing logs from 21 developers, \ncollected during their regular work [ 18]. We detected 15,095 backtracking instances, for \nan average rate of 10.3 per hour.\nOnce such productivity barriers have been identified, an intervention might be \ndesigned, such as a new programming process, language, API, or tool. We have used a \nvariety of methods during the design process to help ensure that the intervention will \nactually help. Natural-programming elicitation  is a way to understand how programmers \nthink about a task and what vocabulary and concepts they use so the intervention \ncan be closer to the users\u2019 thoughts [ 10]. One method for doing natural-programming \nelicitation is to give target programmers a \u201cblank paper\u201d participatory design task, \nwhere we describe the desired functionality and have the programmers design how that \nfunctionality should be provided. The trick is to ask the question in a way that does not \nbias the answers, so we often use pictures or samples of the results , without providing \nany vocabulary, architecture, or concepts.\nRapid prototyping  [15] allows quick and simple prototypes of the intervention to \nbe tried, often just drawn on paper, which helps to refine good ideas and eliminate bad \nones. Sometimes it might be too expensive to create the real intervention before being \nable to test it. In these cases, we have used another recommended human-  centered \nmethod called iterative design  using prototypes  [14]. Typically, the first step employs \nlow-fidelity prototypes , which means that the actual interventions are simulated. For \nmany of our tools, we have used paper prototypes , which are quickly created using \ndrawing tools or even just pen and paper. For example, when trying to help developers \nunderstand the interprocedural control flow of code, we used a Macintosh drawing \nprogram called OmniGraffle to draw mock-ups of a possible new visualization and \nprinted them on paper. We then asked developers to pretend to perform tasks with them. \nWe discovered that the initial visualization concepts were too complex to understand yet \nlacked information important to the developers [ 7]. For example, a key requirement was \nto preserve the order in which methods are invoked, which was not shown (and is not \nshown by other static visualizations of call graphs, either). In the final visualization, the \nlines coming out of a method show the order of invocation, as shown in Figure\u00a0 13-1 .Chapter 13  human-Centered methods to\u00a0Boost produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "150No matter what kind of intervention it is, the creator might want to evaluate how well \nprogrammers can use it and whether it actually improves productivity in practice. For \nexample, our observations about backtracking difficulties motivated us to create Azurite, \na plug-in for the Eclipse code editor that provides more flexible selective undo, in which \ndevelopers can undo past edits without necessarily undoing more recent ones [ 19]. But \nhow can we know if the new intervention can actually be used? There are three main \nmethods we have used to evaluate  interventions: expert analyses, think-  aloud usability \nevaluations, and formal A/B testing.\nFigure 13-1.  (a) A p aper prototype of the visualization drawn with the \nOmnigraffle drawing tool revealed that the order of method calls was crucial to \nvisualize, as is shown in the final version of the tool (b), which is called Reacher \n[7]. The method EditPane.setBuffer(..)  makes five method calls (the five lines \nexiting setBuffer  shown in order from top to bottom, with the first and third being \ncalls to EditBus.send(..) ). Lines with \u201c?\u201d icons show calls that are conditional \n(and thus may or may not happen at runtime). Other icons on lines include \na circular arrow to show calls inside of loops, diamonds to show overloaded \nmethods, and numbers to show that multiple calls have been collapsed.Chapter 13  human-Centered methods to\u00a0Boost produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "151In expert analyses, people who are experienced with usability methods perform the \nanalysis by inspection. For example, heuristic evaluation  [13] employs ten guidelines to \nevaluate an interface. We used this method to evaluate some APIs and found that the \nreally long function names violated the guideline of error prevention because the names \ncould be easily confused with each other, wasting the programmer\u2019s time [ 12]. Another \nexpert-analysis method is called cognitive walkthrough  [8]. It involves carefully going \nthrough tasks using the interface and noting where users will need new knowledge to be \nable to take the next step. Using both of these methods, we helped a company iteratively \nimprove a developer tool [ 3].\nAnother set of methods is empirical and involves testing the interventions with the \ntarget users. The first result of these evaluations is an understanding of what participants \nactually do, to see how the intervention works. In addition, we recommend using a think-\naloud study  [2], in which the participants continuously articulate their goals, confusion, \nand other thoughts. This provides the experimenter with rich data about why  users \nperform the way they do so problems can be found and fixed. As with other usability \nevaluations, the principle is that if one participant has a problem, others will likely have \nit too, so it should be fixed if possible. Research shows that a few representative users can \nfind a great percentage of the problems [ 14]. In our research, when we have evidence of \nusefulness from early needs analysis through CI and surveys, it is often sufficient to show \nusability of tools through think-alouds with five or six people. However, the evaluations \nshould not involve participants who are associated with the tool because they will know \ntoo much about how the tool should work.\nUnlike expert analyses and think-aloud usability evaluations, which are informal, \nA/B testing  uses formal, statistically valid experiments [ 6]. This is the key way to \ndemonstrate that one intervention is better  than another, or better than the status quo, \nwith respect to some measure. For example, we tested our Azurite plugin for selective \nundo in Eclipse against using regular Eclipse, and developers using Azurite were twice \nas fast [ 19]. Such formal measures can be useful proxies for the productivity gains that an Chapter 13  human-Centered methods to\u00a0Boost produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "152intervention might bring. The resulting numbers might also help convince developers \nand managers to try new interventions and change developers\u2019 behaviors because they \nmight find having numbers more persuasive than just the creator\u2019s claims about the \nintervention. However, these experiments can be difficult to design correctly and require \ncareful attention to many possibly confounding factors [ 6]. In particular, it is challenging \nto design tasks that are sufficiently realistic yet doable in an appropriate time frame for \nan experiment (an hour or two).\nTo get a more realistic evaluation of an intervention, it may need to be measured \nin actual practice. We have found this to be easiest to do by instrumenting the tools \nto gather the desired metrics during real use, and then we can use data mining  and  \nlog analysis . For example, we used our Fluorite logger, which is another plugin for \nEclipse, to investigate how developers used the Azurite tool [ 17]. We found that \ndevelopers often selectively undid a selected block of code, such as a whole method, \nrestoring it to how it used to work and leaving the other code as is, which we call \nregional undo , confirming our hypothesis that this would be the most useful kind of \nselective undo [ 19].\nMany other HCI methods are available that can answer additional questions \nthat creators of interventions might have (see Table\u00a0 13-1  for a summary). Large \ncompanies such as Microsoft and Google already embed user interface specialists \ninto their teams that create developer tools (such as in Microsoft\u2019s Visual Studio \ngroup). However, even small teams can learn to use at least some of these methods. \nBased on our extensive use of these methods over many years, we argue that they \nwill be useful for better understanding the many different kinds of barriers that \nprogrammers face, for creating useful and usable interventions to address those \nbarriers, and for better evaluating the impact of the interventions. In this way, these \nmethods will help increase the positive impact of future interventions on developers\u2019 \nproductivity.Chapter 13  human-Centered methods to\u00a0Boost produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "153Table 13-1.  Methods We Have Used  (Adapted from [ 11] )\nMethod Cite Software Development \nActivities SupportedKey Benefits Challenges and Limitations\nContextual inquiry [1] requirements and  \nproblem analysis.experimenters gain insight into  \nday- to- day activities and \nchallenges. experimenters gain \nhigh-quality data on the developer\u2019s \nintent.Contextual inquiry is  \ntime-consuming.\nexploratory lab user studies [ 14] requirements and  \nproblem analysis.Focusing on the activity of interest \nis easier. experimenters can \ncompare participants doing the \nsame tasks. numerical data can  \nbe collected.the experimental setting \nmight differ from the real-\nworld context.\nsurveys [16] requirements and  \nproblem analysis.  \nevaluation and testing.surveys provide quantitative data. \nthere are many participants. \nsurveys are (relatively) fast.the data is self- reported \nand is subject to bias and \nparticipant awareness.\ndata mining (including corpus \nstudies and log analysis)[9] requirements and  \nproblem analysis.  \nevaluation and testing.data mining provides large \nquantities of data. experimenters \ncan see patterns that emerge only \nwith large corpuses.inferring or reconstructing \nthe developer\u2019s intent \nis difficult. data mining \nrequires careful filtering.\nnatural- programming \nelicitation[10] requirements and  \nproblem analysis. design.experimenters gain insight into \ndeveloper expectations.the experimental setting \nmight differ from the real-\nworld context.\n(continued )Chapter 13  human-Centered methods to\u00a0Boost produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "154Table 13-1.  (continued )\nMethod Cite Software Development \nActivities SupportedKey Benefits Challenges and Limitations\nrapid prototyping [15] design experimenters can gather  \nfeedback at low cost before \ncommitting to high-cost \ndevelopment.rapid prototyping has lower \nfidelity than the final tool, \nlimiting what problems might \nbe revealed.\nheuristic evaluations [ 13] requirements and problem \nanalysis. design. evaluation \nand testing.evaluations are fast. they do not \nrequire participants.evaluations reveal only some \ntypes of usability issues.\nCognitive walk-throughs [ 8] design. evaluation and \ntesting.Walk-throughs are fast. they do  \nnot require participants.Walk-throughs reveal only \nsome types of usability issues.\nthink-aloud usability \nevaluations[2] requirements and problem \nanalysis. design. evaluation \nand testing.evaluations reveal usability  \nproblems and the developer\u2019s  \nintent.the experimental setting might \ndiffer from the real-world \ncontext. evaluations require \nappropriate participants. task \ndesign is difficult.\na/B testing [6] evaluation and testing testing provides direct evidence  \nthat a new tool or technique  \nbenefits developers.the experimental setting \nmight differ from the real-\nworld context. testing requires \nappropriate participants. task \ndesign is difficult.Chapter 13  human-Centered methods to\u00a0Boost produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "155 Key Ideas\nThe following are the key ideas from the chapter:\n\u2022 There are many methods used in human-computer interaction \nresearch that can also be used to study what hinders and improves \nsoftware developer productivity, to help design interventions that \nincrease productivity, and to then evaluate and improve their impact.\n\u2022 The ten methods listed in this chapter have proven useful at various \nphases of the process.\n References\n [1] H.\u00a0Beyer and K.\u00a0Holtzblatt. Contextual Design: Defining Custom-\nCentered Systems . San Francisco, CA, Morgan Kaufmann \nPublishers, Inc. 1998.\n [2] Chi, M.\u00a0T. (1997). Quantifying qualitative analyses of verbal data: A \npractical guide. The journal of the learning sciences, 6(3), 271\u2013\n315.\n [3] Andrew Faulring, Brad A.\u00a0Myers, Yaad Oren and Keren Rotenberg. \n\u201c A Case Study of Using HCI Methods to Improve Tools for \nProgrammers, \u201d Cooperative and Human Aspects of Software \nEngineering (CHASE\u20192012) , An ICSE 2012 Workshop, Zurich, \nSwitzerland, June 2, 2012. 37\u201339.\n [4] Julie A.\u00a0Jacko. (Ed.). (2012). Human computer interaction \nhandbook: Fundamentals, evolving technologies, and emerging \napplications. CRC press.\n [5] Amy J. Ko, Brad A.\u00a0Myers, Michael Coblenz and Htet Htet Aung. \n\u201c An Exploratory Study of How Developers Seek, Relate, and \nCollect Relevant Information during Software Maintenance Tasks, \u201d \nIEEE Transactions on Software Engineering . Dec, 2006. 33(12). \npp.\u00a0971\u2013987.Chapter 13  human-Centered methods to\u00a0Boost produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "156 [ 6]  K o, A.\u00a0J., Latoza, T.\u00a0D., & Burnett, M.\u00a0M. (2015). A practical guide to \ncontrolled experiments of software engineering tools with human \nparticipants. Empirical Software Engineering, 20(1), 110\u2013141.\n [7] Thom as D.\u00a0LaToza and Brad Myers. \u201cDevelopers Ask Reachability \nQuestions, \u201d ICSE\u20192010: Proceedings of the International Conference \non Software Engineering , Capetown, South Africa, May 2-8, 2010. \n185\u2013194.\n [8] C.\u00a0Lewis et\u00a0al., \u201cTesting a Walkthrough Methodology for \nTheoryBased Design of Walk-Up-and-Use Interfaces, \u201d Proc. \nSIGCHI Conf. Human Factors in Computing Systems (CHI 90) , \n1990, pp.\u00a0235\u2013242.\n [9] Menzies, T., Williams, L., & Zimmermann, T. (2016). Perspectives \non Data Science for Software Engineering. Morgan Kaufmann.\n [10] Brad A.\u00a0Myers, John F .\u00a0Pane and Amy J. Ko. \u201cNatural Programming \nLanguages and Environments, \u201d Communications of the ACM . Sept, \n2004. 47(9). pp.\u00a047\u201352.\n [11] Brad A.\u00a0Myers, Amy J. Ko, Thomas D.\u00a0LaToza, and YoungSeok \nYoon. \u201cProgrammers Are Users Too: Human-Centered Methods \nfor Improving Programming Tools, \u201d IEEE Computer , vol. 49, issue \n7, July, 2016, pp.\u00a044\u201352.\n [12] Brad A.\u00a0Myers and Jeffrey Stylos. \u201cImproving API Usability, \u201d \nCommunications of the ACM.  July, 2016. 59(6). pp.\u00a062\u201369.\n [13] J.\u00a0Nielsen and R.\u00a0Molich. \u201cHeuristic evaluation of user interfaces, \u201d \nProc. ACM CHI\u201990 Conf, see also: http://www.useit.com/\npapers/heuristic/heuristic_list.html . Seattle, WA, 1\u20135 April, \n1990. pp.\u00a0249\u2013256.\n [14]  Jakob Nielsen. Usability Engineering . Boston, Academic Press. \n1993.\n [15] Marc Rettig. \u201cPrototyping for Tiny Fingers, \u201d Comm. ACM. 1994. \nvol. 37, no. 4. pp.\u00a021\u201327.Chapter 13  human-Centered methods to\u00a0Boost produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "157 [16] Rossi, P .\u00a0H., Wright, J.\u00a0D., & Anderson, A.\u00a0B. (Eds.). (2013). \nHandbook of survey research. Academic Press.\n [17] YoungSeok Yoon and Brad A.\u00a0Myers. \u201c An Exploratory Study of \nBacktracking Strategies Used by Developers, \u201d Cooperative and \nHuman Aspects of Software Engineering (CHASE\u20192012) , An ICSE \n2012 Workshop, Zurich, Switzerland, June 2, 2012. 138\u2013144.\n [18] YoungSeok Yoon and Brad A.\u00a0Myers. \u201c A Longitudinal Study \nof Programmers\u2019 Backtracking, \u201d IEEE Symposium on Visual \nLanguages and Human-Centric Computing (VL/HCC\u201914) , \nMelbourne, Australia, 28 July\u20131 August, 2014. 101\u2013108.\n [19] YoungSeok Yoon and Brad A.\u00a0Myers. \u201cSupporting Selective Undo \nin a Code Editor, \u201d 37th International Conference on Software \nEngineering (ICSE 2015) , Florence, Italy, May 16\u201324, 2015. 223\u2013233 \n(volume 1).\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 13  human-Centered methods to\u00a0Boost produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "159\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_14CHAPTER 14\nUsing Biometric Sensors \nto\u00a0Measure Productivity\nMarieke van Vugt, University of Groningen, The Netherlands\n Operationalizing Productivity for\u00a0Measurement\nIf we want to be productive, it would be great if we could track productivity in some way, \nsuch that it is possible to determine what factors help and hinder productivity. Biometric \nsensors may be helpful for such productivity tracking. But what does being productive \nmean? A simplistic notion of productivity is being able to pay attention without getting \ndistracted. Indeed, to be productive in simple tasks such as filling out routine forms, \none needs to carefully monitor one\u2019s goals and ensure not to get distracted. On the \nother hand, for more complex tasks such as developing a new software architecture \nor implementing a complex function, one also needs creativity and outside-the-  \nbox thinking, which is incompatible with a singular focus. In other words, aspects of \nproductivity such as creativity depend not on concentration but on its opposite: mind-  \nwandering [ 1], which is a process of task-unrelated thinking. How would that work? \nMind-wandering, when it involves thinking about other things while you are engaged \nin a task such as writing a computer program can help you to access new information \nthat brings an alternative perspective on what you are doing. This means that when the \ncontents of mind-wandering are monitored and are not too engrossing, it can in fact \nbe very useful. Moreover, this also means that a singular focus does not always indicate \nproductivity because, for example, being very concentrated on a single stupid task such \nas writing the same line of code over and over again is not very productive."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "160In summary, productivity requires sometimes singular focus and sometimes \ndistraction. What is crucial is monitoring to ensure that attention is being paid to the \nmost relevant goals and that the degree of attentional focus is in line with those goals. \nThe attentional focus should be neither too narrow nor too wide and should be directed \nto the task that is most important at that moment.\nInterestingly, most current attempts at developing biometric sensors focus on \nmeasuring attentional focus. Here I argue that another (albeit more technically \nchallenging) target could be the goal-directedness of attention. A goal-directed attention \nis one that does not get pulled into patterns of thoughts that are difficult to disengage \nfrom, such as, for example, rumination and worry.\nIn this chapter, I will first discuss biometric sensors on the basis of eye tracking \nand electroencephalography (EEG) that simply track attention and then preview some \nnew potential sensors that track the broader definition of productivity that depends on \nfocusing on the most relevant goals and not being sidetracked by thoughts that pull one \naway.\n What the\u00a0Eye Says About Focus\nArguably the simplest method to measure attention is by following the eye gaze and the \nwidth of the pupil. In laboratory studies this is measured with fancy cameras that are \nfollowing the eyes, but potentially similar functions could be provided by webcams that \nare present on almost every computer. In our lab we have demonstrated that webcam-  \nbased eye tracking is sensitive enough to predict upcoming choices from a set of stimuli \npresented on the screen.\nSo, what can you measure with eye tracking? In one experiment investigating \ndistraction by external stimuli, we found that when we had a participant do a memory \ntask on the screen but showed cat videos on a flanking screen, their eyes were drawn to \nthe video [ 9]. The frequency with which the eyes were drawn to the cat video depended \non the difficulty of the task, such that the more visual resources a task consumed \n(e.g., requiring poring over a visual image very precisely), the less likely a person was \ndistracted by the cat videos. On the other hand, the more memory resources a task \nrequired (e.g., keeping in mind a series of numbers), the more likely the person\u2019s eyes \nwere drawn to the cat videos. In other words, video screens with moving images are \na terrible idea on the work floor. In another study, we used eye tracking to examine \nwhether a person was keeping a location on the computer screen in mind that they were Chapter 14  Using Biometri C sensors to\u00a0 measUre prodUCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "161trying to memorize [ 3]. We found that when they were distracted, as you would expect, \npeople\u2019s eyes were less fixated on the visual locations than when they were attentive. In \nshort, when you are doing a task where your eyes have to be located at a specific spot \n(such as a coding window that occupies only part of the screen), then using eye gaze can \nbe an effective measure of your attention.\nHowever, most of the time, your work does not require your attention to be focused \non a single spot. In that case, potentially we could still use eye-based biosensors but \nfocus instead on the size of the pupil. Already for many decades, pupil size has been \nassociated with a state of mental effort [ 4] and arousal [ 2]. For example, when we make \nthe task more difficult, we tend to see an increase in pupil size. In addition, when we \nreward people for successfully performing a difficult task, their pupil size increases even \nmore.\nMany studies have associated mind-wandering with a decreased pupil size [ 3, 11], \nso another potential marker for being on the ball and being productive would be the size \nof your pupil. A larger pupil would be indicative of higher productivity. In fact, we have \npreviously used pupil size as a marker for when it would be best to interrupt the user [ 5]. \nInterruptions are generally best when a person is experiencing low workload, i.e., when \nhe or she is somewhere between subtasks, not when he or she is trying to remember \nsomething or manipulate complex information in his mind. The study showed that we \nwere successful in finding low-workload moments and performance was better when we \ninterrupted on low-workload moments. This suggests that pupil size can successfully be \nused even on a single-trial basis and is a good candidate for measuring mental effort as \nan index of productivity.\n Observing Attention with\u00a0EEG\nAnother potential biomarker of productivity is EEG. EEG reflects the electrical activity \nemitted by the brain, as measured by electrodes on the scalp. EEG has frequently been \nused to track both mind-wandering and mental effort. A common finding is that when \na person is mind-wandering, the brain activity evoked by a stimulus is reduced. This \nis thought to indicate a state in which the person is relatively disconnected from their \nenvironment with their attention more internally directed. While there has been long-  \nstanding research in the role of alpha waves\u2014which are typically referred to as the \nbrain\u2019s \u201cidling waves\u201d\u2014in mind-wandering, that research has not demonstrated clear \nmappings between these brain waves and mind-wandering.Chapter 14  Using Biometri C sensors to\u00a0 measUre prodUCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "162The most advanced studies in this field have started to use machine learning \nclassifiers to predict an individual\u2019s attentional state. For example, a study by Mittner \nand colleagues [ 6] demonstrated that it was possible to predict with almost 80 \npercent accuracy whether a person was on-task or mind-wandering on the basis of \na combination of behavioral and neural measures. These neural measures involved \nfunctional magnetic resonance imaging (fMRI). The problem with fMRI is that it is not a \nvery suitable measure in an applied context because it requires an expensive and heavy \nMRI scanner in which the person has to lie down to be scanned. Moreover, MRI scanners \nproduce a large amount of noise, making it not conducive for work. Nevertheless, \nrecent work in our lab suggests that it is possible to achieve up to 70 percent accuracy \nin predicting mind-wandering using the more portable EEG.\u00a0Moreover, in our study, \nthis accuracy was achieved across two different behavioral tasks, suggesting that it can \ntap into a general mind-wandering measure, which is crucial for application in a work \nenvironment.\nEEG has been used to measure not only mind-wandering but also mental effort. \nThe most frequently used index of mental effort in EEG is the P3, an EEG potential that \noccurs roughly 300 to 800 ms after a stimulus has been shown to an individual [ 10]. This \ncomponent is larger when a person exerts mental effort. This component is also smaller \nwhen a person is mind-wandering, suggesting that the P3 is potentially not a very \nunique index of mental effect. However, because this EEG component is time-locked \nto a discrete stimulus, it may be challenging to monitor such potentials in the office \nenvironment, unless you display periodic discrete stimuli to the individual with the \npurpose of measuring this P3 potential.\nTaking these concerns into account, if EEG is potentially usable for monitoring \ndistraction and productivity, then a problem to take into consideration is that despite \nthat it is less unwieldy than MRI, an EEG system is typically still quite inconvenient \nand takes a lot of time to set up (usually somewhere between 15 and 45 minutes). A \nresearch-grade EEG system consists of a fabric cap in which anywhere between 32 and \n256 electrodes are embedded, and for each of these electrodes, the connection with the \nscalp needs to be ascertained by means of an electrode gel and manual adjustments. On \ntop of that, the cap needs to be connected to an amplifier that enhances the weak signals \nrecorded on the scalp such that they are elevated above the noise. Only with these \nprocedures a sufficiently clean signal can be collected. Clearly this would not be feasible \nfor the workplace.Chapter 14  Using Biometri C sensors to\u00a0 measUre prodUCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "163Luckily, recently there has been a boom in the development of low-cost EEG \ndevices that have only between 1 and 8 sensors and that do not need extensive \npreparation (e.g., Emotiv and MUSE). If these electrodes were placed in the correct \nlocations, they could potentially serve as productivity-monitoring devices. In fact, \nthey are frequently marketed as devices that can record concentration. Despite these \nclaims, however, I have found that when comparing a research-grade EEG system to \nthese portable devices, that the portable EEG devices do not provide a reliable signal. \nMany place electrodes on the forehead, which are primarily expected to capture \nmuscle activity instead of brain activity. Of course, muscle activity can be an index of \nhow stressed a person is, since stress is associated with muscle tension, but it does not \nsay much about a person\u2019s mind-  wandering and distraction. For example, it is possible \nto be quite tense while working on a software development project while being really \nrelaxed and browsing social media. So, at this time EEG is really only a useful measure \nof productivity in a laboratory setting.\n Measuring Rumination\nAs mentioned, only measuring focus is not sufficient for productivity. In addition, \na certain amount of mental flexibility and allocation of attention to relevant goals is \ncrucial. This mental flexibility is difficult to monitor with biometric devices, but one \nrelated candidate signal is the one associated with \u201csticky mind-wandering\u201d\u2014a mind-  \nwandering process that is very difficult to disengage from [ 12]. Sticky mind-wandering \nis a precursor of rumination (narrowly focused uncontrolled repetitive thinking that \nis mostly negatively balenced and self-referential [ 7]). For example, rumination may \ninvolve repeated thinking that \u201cI am worthless, I am a failure, \u201d supplemented by recall \nof experiences, such as a poor evaluation of a piece of work you delivered. This thinking \nrepeatedly intrudes into a person\u2019s consciousness, thereby making it difficult for them \nto concentrate, one of the major complaints that depressed people are suffering from. \nSticky mind-wandering can take the form of recurrent worries, for example, about not \nbeing good enough, about their children, their future, and so on. These are the kinds of \nthoughts that are particularly harmful for productivity because they disrupt particular \ndifficult thinking processes, which are crucial for software developers.Chapter 14  Using Biometri C sensors to\u00a0 measUre prodUCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "164Recent work has started to map and experimentally manipulate these \u201csticky\u201d \nforms of mind-wandering. We found that when people have a thought that they think \nis difficult to disengage from, then their task performance just prior to that moment \ntends to be worse and more variable in duration [ 12]. Other research where people \nwere equipped with smart phones to measure their thoughts over the course of many \ndays showed that sticky mind-wandering interfered more with ongoing activities and \nrequired more effort to inhibit. It was further suggested that a sticky form of mind-\nwandering is associated with reduced heart-rate variability compared to nonsticky \nmind-wandering [ 8]. In general, larger heart-rate variability is associated with increased \nwell-being, and therefore reduced heart-rate variability is not desirable. This means that \nheart-rate variability is a potentially attractive target for biometric monitoring, especially \nbecause more and more low-cost heart-rate trackers are becoming available, such as \nthose integrated in smart watches.\n Moving Forward\nThe studies discussed here together suggest that there are several ways in which it \nmay be possible to measure productivity biometrically. Possibilities include pupil size, \nheart-rate variability, and EEG, which each has its own possibilities and limitations. \nNevertheless, the majority of these measures were tested in a relatively simple and \nartificial laboratory context, in which only a limited set of events can happen. In \ncontrast, in the real world, many more scenarios play out, and it is not clear how these \nbiometric measures fare in those contexts. What is needed is a better understanding \nof the boundary conditions under which different biometric measures can work, and \npotentially a combination of different measures can give a suitably accurate index of \ndistraction, thereby potentially differentiating between helpful mind-wandering and \nharmful mind-wandering.\nSuch an index could potentially be integrated into an interception system that makes \nthe user aware of their distraction and then reminds them of their longer-term goals. \nDistraction usually arises when goals with short-term rewards or instant rewards such as \nsocial media are less active in our minds than longer-term goals. Even in the case of the \nstickier ruminative mind-wandering, a small reminder may be enough to allow a person \nto step out of this thought process and redirect attention to more productive long-term \ngoals such as writing a paper or finishing a computer program.Chapter 14  Using Biometri C sensors to\u00a0 measUre prodUCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "165In short, I have discussed what it means to be productive and how we can \npotentially measure this. Since most jobs require more than mechanical concentration \non a single thing, measurement of productivity is nontrivial. Nevertheless, scientific \nstudies on tracking attention provide a good starting point, and they demonstrate that \neye movements, pupil size, heart rate variability, and EEG all provide some useful \ninformation about a person\u2019s attentional state. On the other hand, none of these \nmeasures by themselves provides a fool-proof metric of productivity. Moreover, in many \nof them there are challenges to measuring it in a real-world context. For this reason, I \nthink that the most productive use of biometric monitoring is not tracking productivity \nper se but rather helping the user to monitor himself or herself. The biometric sensors \ncould be combined and in this way could help a user to become aware of potential \nlapses of productivity and remind them of their most important long-term goals.\n Key Ideas\nThe following are the key ideas from this chapter:\n\u2022 While some forms of productivity require targeted attentional focus, \nother forms of productivity require mental flexibility.\n\u2022 With eye tracking, we can follow whether a person is paying attention \nand exert mental effort.\n\u2022 The EE G can also track attention but is difficult to measure with \nmobile sensors.\n\u2022 Rumination is an important factor to consider in productivity.\n References\n [1] B aird, B., J.\u00a0Smallwood, M.\u00a0D. Mrazek, J.\u00a0W. Y.\u00a0Kam, M.\u00a0J. \nFrank, and J.\u00a0W. Schooler. 2012. \u201cInspired by Distraction. Mind \nWandering Facilitates Creative Incubation. \u201d Psychological Science \n23 (10):1117\u201322. https://doi.org/10.1177/0956797612446024 .\n [2] Gilzenrat, M.\u00a0S., S.\u00a0Nieuwenhuis, M.\u00a0Jepma, and J.\u00a0D. Cohen. 2010. \n\u201cPupil Diameter Tracks Changes in Control State Predicted by the \nAdaptive Gain Theory of Locus Coeruleus Function. \u201d Cognitive, \nAffective & Behavioral Neuroscience  10 (2):252\u201369.Chapter 14  Using Biometri C sensors to\u00a0 measUre prodUCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "166 [3] Huijser, S., M.\u00a0K. van Vugt, and N.\u00a0A. Taatgen. 2018. \u201cThe \nWandering Self: Tracking Distracting Self-Generated Thought in \na Cognitively Demanding Context. \u201d Consciousness and Cognition  \nConsciousness & Cognition 58, 170-185.\n [4] Kahneman, D., and J.\u00a0Beatty. 1966. \u201cPupil Diameter and Load \non Memory. \u201d Science  154 (3756). American Association for the \nAdvancement of Science:1583\u20135.\n [5] Katidioti, Ioanna, Jelmer P Borst, Douwe J Bierens de Haan, \nTamara Pepping, Marieke K van Vugt, and Niels A Taatgen. 2016. \n\u201cInterrupted by Your Pupil: An Interruption Management System \nBased on Pupil Dilation. \u201d International Journal of Human\u2013\nComputer Interaction  32 (10). Taylor & Francis:791\u2013801.\n [6] Mittner, Matthias, Wouter Boekel, Adrienne M Tucker, Brandon \nM Turner, Andrew Heathcote, and Birte U Forstmann. 2014. \n\u201cWhen the Brain Takes a Break: A Model-Based Analysis of \nMind Wandering. \u201d The Journal of Neuroscience  34 (49). Soc \nNeuroscience:16286\u201395.\n [7] Nolen-Hoeksema, S., and J.\u00a0Morrow. 1991. \u201c A Prospective Study \nof Depression and Posttraumatic Stress Symptoms After a \nNatural Disaster: The 1989 Loma Prieta Earthquake. \u201d Journal of \nPersonality and Social Psychology  61 (1):115\u201321.\n [8] Ottaviani, C., B.\u00a0Medea, A.\u00a0Lonigro, M.\u00a0Tarvainen, and \nA.\u00a0Couyoumdjian. 2015. \u201cCognitive Rigidity Is Mirrored by \nAutonomic Inflexibility in Daily Life Perseverative Cognition. \u201d \nBiological Psychology  107. Elsevier:24\u201330.\n [9] Taatgen, N. A, M. K. van Vugt, J. Daamen, I. Katidioti, and  \nJ. P Borst. \u201cThe Resource- Availability Theory of Distraction and \nMind-Wandering. \u201d (under review)\n [10]  Ullsperger, P , A-M Metz, and H-G Gille. 1988. \u201cThe P300 \nComponent of the Event-  Related Brain Potential and Mental \nEffort. \u201d Ergonomics  31 (8). Taylor & Francis:1127\u201337.Chapter 14  Using Biometri C sensors to\u00a0 measUre prodUCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "167 [11] Unsworth, Nash, and Matthew K Robison. 2016. \u201cPupillary \nCorrelates of Lapses of Sustained Attention. \u201d Cognitive, Affective, & \nBehavioral Neuroscience  16 (4). Springer:601\u2013 15.\n [12] van Vugt, M.\u00a0K., and N.\u00a0Broers. 2016. \u201cSelf-Reported Stickiness \nof Mind-Wandering Affects Task Performance. \u201d Frontiers in \nPsychology  7. Frontiers Media SA:732.\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 14  Using Biometri C sensors to\u00a0 measUre prodUCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "169\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_15CHAPTER 15\nHow Team Awareness \nInfluences Perceptions \nof\u00a0Developer Productivity\nChristoph Treude, University of Adelaide, Australia\nFernando Figueira Filho, Federal University of Rio Grande do \nNorte, Brazil\n Introduction\nIn their day-to-day work, software developers perform many different activities: \nthey use numerous tools to develop software artifacts ranging from source code \nand models to documentation and test cases, they use other tools to manage and \ncoordinate their development work, and they spend a substantial amount of time \ncommunicating and exchanging knowledge with other members on their teams and \nthe larger software development community. Making sense of this flood of activity and \ninformation is becoming harder with every new artifact created. Yet, being aware of all \nrelevant information in a software project is crucial to enable productivity in software \ndevelopment.\nIn formal terms, awareness is defined as \u201can understanding of the activities of others, \nwhich provide context for your own activity. \u201d In any collaborative work environment, \nbeing aware of the work of other team members and how it can affect one\u2019s own work \nis crucial. Maintaining awareness ensures that individual contributions are relevant \nto the group\u2019s work in general. Awareness can be used to evaluate individual actions \nagainst the group\u2019s goals and progress, and it allows groups to manage the process of \ncollaborative working [ 1]."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "170Contributing to a software project requires a multitude of different kinds of \nawareness, ranging from high-level status information (e.g., What is the overall status \nof the project? What are the current bottlenecks?) to more fine-grained information \n(e.g., Who else is working on the same file right now and has uncommitted changes? \nWho is affected by the source code I am writing at the moment?). Awareness includes \nboth short-term, momentary awareness (awareness of events at this particular point in \ntime, such as the current build status) and long-term, historical awareness (awareness \nof past events, such as code evolution and team velocity). As the complexity of software \nsystems grows, maintaining awareness of all relevant context is becoming increasingly \nchallenging. To address this situation, many tools have been developed over the last \ndecades to help developers maintain awareness of everything that goes on in a project.\nGiven the plethora of information available, tools that support awareness for \nsoftware developers inevitably need to abstract some details and have to aggregate \ninformation. This leads to risks. The aggregation of developer activity information has \nthe potentially unintended side effect of quantifying the developer\u2019s work, enabling \nproductivity comparisons across developers and time. As an example, imagine a tool \nthat aims to provide high-level information about what a developer is working on at \nthe moment. Such a tool will likely be able to say that a developer is working on three \nfeatures (by counting the open issues assigned to this developer, for example), but it \nmight not be able to say that a developer is currently working on refactoring a database \nconnector, fixing a bug in the persistence layer of the application, and improving the \nperformance of a query (which would require an automated understanding of the \nsemantics of the open issues). Of course, a tool could simply list all open issues, but this \nwould lead to information overload.\nIn this chapter, we discuss this tension between awareness information and \nproductivity measures, and we advocate for the design of tools that enable awareness \nwithout quantifying information. We also report on the findings from an empirical study \nin which we asked developers about how to design such tools. The study revealed that \nawareness can influence developers\u2019 perceptions of the productivity of their colleagues \nand that developers do not feel that productivity can be collapsed into a single metric. \nWe conclude that while automated tools for making sense of everything that goes on in \na software project are necessary to enable developer awareness, such tools need to focus \non summarizing instead of measuring information.Chapter 15  how team awareness Influen Ces perCeptIons of\u00a0Developer proDuCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "171 Awareness and\u00a0Productivity\nWe first illustrate the relationship between team awareness and developer productivity, \nusing an existing categorization of awareness types as a guideline [ 2].\n\u2022 Collaboration awareness : Collaboration awareness refers to the \nperception of group availability, i.e., whether people are in the same \nphysical place, who is online/offline, and their virtual availability. \nIn software development\u2014and in many other domains\u2014these \nconcepts are directly related to productivity. If a member of a \nsoftware development team is perceived to be unavailable, it is easy \nto conclude that they are not productive, whereas a team member \nwho is always online and/or in the same physical place would be \nperceived as being productive.\n\u2022 Location awareness : Location awareness refers to the geographical and \nphysical nature of spaces, e.g., where someone is physically located. \nSimilar to collaboration awareness, the physical location of team \nmembers can be related to perceptions of their productivity. This might \nbe the case if co-workers who share the same office space are perceived \nas having more or less productivity compared to others, but it might also \nhave cultural implications, e.g., if developers in an outsourcing location \nare perceived differently simply based on their location.\n\u2022 Context awareness : Context awareness allows a group of co-  \nworkers to maintain a sense of what is going on in the virtual space. \nIn software development projects, context awareness can, for \nexample, refer to the context of a shared task, e.g., the progress of a \ndevelopment team toward the next release. If the development team \nis perceived as not being on track, this type of awareness can easily be \nused to reach conclusions about a team's lack of productivity.\n\u2022 Social awareness : According to Antunes et\u00a0al., social awareness is \nrelated to the understanding of \u201csocial practice, i.e., the others\u2019 roles \nand activities, or what and how the group members are contributing \nto a task. \u201d It is easy to see then how social awareness in a software \ndevelopment team is linked to developer productivity. If a team \nmember\u2019s contributions to a task are perceived as not good enough, \nthey will be considered as unproductive, and vice versa.Chapter 15  how team awareness Influen Ces perCeptIons of\u00a0Developer proDuCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "172\u2022 Workspace awareness : Workspace awareness is defined as the \nup-to-  the-momen t understanding of another person\u2019s interaction \nwith the shared workspace, i.e., awareness of people and how \nthey interact with the workspace rather than just awareness of the \nworkspace itself [ 3]. This type of awareness is also directly linked to \nproductivity: if a developer\u2019s interactions with the shared workspace, \ne.g., the issue tracking system of a software project, are not as \nfrequent or fruitful as expected, this developer will be seen as being \nunproductive.\n\u2022 Situation awareness : Situation awareness refers to being aware of \nwhat is happening in the vicinity to understand how information, \nevents, and one\u2019s own actions will impact goals and objectives. \nApplied to software development, this definition could refer to \nperipheral awareness of the work of other teams that are working \non the same product, awareness of updates to libraries that a \nparticular product relies on, or awareness of technology trends [ 4]. \nAs with the other awareness types, this kind of awareness also links \nto productivity: if another team is not delivering the feature they are \nsupposed to deliver or a critical bug in a library is not being fixed, \ndevelopers can be seen as unproductive.\n Enabling Awareness in\u00a0Collaborative Software \nDevelopment\nThere are many different kinds of information that developers need to be aware of in any \nsoftware development project, as discussed in the previous section. However, with the \nflood of activity and information in a software repository, it is impossible and also often \nnot necessary for a developer to maintain awareness of every aspect of a project. As a \nresult, a mechanism for filtering and aggregating relevant information is needed.\nMany tools such as feeds and dashboards (see Chapter 16) have been developed \nto help developers maintain awareness and aggregate relevant information. However, \nthese tools often focus on quantitative instead of qualitative aspects since it is arguably \neasier to count the number of open issues than interpret what these issues are about, \nfor example. In the next sections, we discuss developers\u2019 opinions on the aggregation of \nawareness information using both quantitative and qualitative means.Chapter 15  how team awareness Influen Ces perCeptIons of\u00a0Developer proDuCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "173 Aggregating Awareness Information into Numbers\nAutomated tools for extracting, aggregating, and summarizing development activity are \nessential to provide software teams with crucial awareness information. To investigate \nhow to design such tools, in earlier work [ 5] we asked developers how they would design \nquantitative and qualitative aspects of such tools. We first summarize our findings with \nregard to the quantitative aspects, which revealed the risk of misinterpreting awareness \ninformation as productivity measures.\nOur study participants stressed that no single metric, e.g., lines of code, number of \ntasks, etc., would truly reflect the wide range of activities a developer may take action on \nthroughout the development life cycle of a software product. For instance, conceptual \nwork is hardly measurable and may go unnoticed just by monitoring a metric, as shown \nin this example from one of our study participants: \u201cIt\u2019s difficult to measure output. \nChanging the architecture or doing a conceptual refactoring may have significant impact \nbut very little evidence on the code base. \u201d Similarly, the difficulty of a task cannot be \nmeasured in lines of code.\nSoftware projects may go through different stages in their development cycle. \nAccording to our study participants, these variabilities from project to project make \nit difficult to devise any uniform, one-size-fits-all measurement system that would \nwork across different project contexts and distinct development workflows (challenges \ndetailed in Chapter 2). Also, developers may assume different roles in a single day. For \ninstance, interacting with customers and users was regarded by our study participants \nas an activity that is difficult to measure, although it is an integral part of development \nwork: \u201cWe do systems for people in the first place. \u201d\nAnother problem perceived by our study participants is that measures can be gamed \nso that any automatic system aimed at measuring productivity would be potentially \nexploitable. This applies in particular to simple measures such as the number of issues \nor number of commits: \u201c A poor-quality developer may be able to close more tickets than \nanyone else, but a high-quality developer often closes fewer tickets but of those few, \nalmost none get reopened or result in regressions. For these reasons, metrics should seek \nto track quality as much as they track quantity. \u201d\nGiven the limited value of numbers as a means to provide developers with \nmeaningful information, we next investigate the potential of qualitative mechanisms, in \nparticular summarization, to improve the quality of awareness information.Chapter 15  how team awareness Influen Ces perCeptIons of\u00a0Developer proDuCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "174 Aggregating Awareness Information into Text\nAs we have discussed in the previous section, aggregating the work of software \ndevelopers into numbers has many disadvantages. However, information in a software \nrepository has to be aggregated to enable awareness without having to look at every \nartifact created, modified, or deleted. With this in mind, in our earlier work [ 5], we \npresented our study participants with the following scenario: \u201c Assume it\u2019s Monday \nmorning and you have just returned from a week-long vacation. One of your colleagues \nis giving you an update on their development activities last week. \u201d We then asked them \nwhat information they would expect to be included in such a summary. In the following \nparagraphs, we summarize the answers we received from developers.\nMany of the events in the day-to-day work of software developers can be categorized \naccording to whether they are expected or unexpected. Expected events comprise \nstatus updates that are generally not surprising to a software developer\u2014such as \na development task moving from open to closed\u2014while unexpected events are \nunforeseen, for example the presence of a critical bug. Our participants requested that \nboth kinds of events should be included in summaries of development activity.\nSummaries of expected events in software development projects are mostly \nconcerned with how different artifacts, such as development tasks or user stories, move \nthrough the development cycle. For example, one participant requested what they called \n\u201ctask state transition history\u2014which tasks were taken, which were done, which were \ntested. \u201d An important dimension of expectations is planning\u2014our participants were \nalso interested to hear about short-term and long-term plans as well as the goals driving \nthese plans.\nBasic awareness tools for software developers typically support this kind of \nawareness of development artifacts and plans. For example, a burndown chart \nvisualizes the actual work being done compared to a plan, and a kanban board shows \ntasks along with their current status. However, these tools are still limited in their \nexpressiveness: A burndown chart cannot explain why a project is not on track, and \nit can also easily be misinterpreted as measuring productivity. In addition, it can be \ngamed, for example by overestimating user stories. Kanban boards can aggregate only \nto a certain extent\u2014if the number of tasks or work items included in the kanban board \nbecomes too large, it becomes hard to obtain a high-level overview of the project \nstatus from looking at the board.Chapter 15  how team awareness Influen Ces perCeptIons of\u00a0Developer proDuCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "175If everything in a software project is progressing as expected, no particular action \noutside of a developer\u2019s routine might be required. However, things tend not to always go \naccording to plan in software projects. Requirements might change, a major refactoring \nmight be needed, or a critical bug might be discovered. In those situations, developers \nneed to act, which explains why anything unexpected should play a major role in a \nsummary of software development activity: \u201cWe cut our developer status meetings way \ndown and started stand up meetings focusing on problems and new findings rather than \ndead-boring status. [The] only important point is when something is not on track, going \nfaster than expected and why. \u201d\nWhen we asked our participants about how to automatically detect such unexpected \nevents, several examples were mentioned, in particular related to the commit history: \n\u201cCommits that take particularly long might be interesting. If a developer hasn\u2019t \ncommitted anything in a while, his first commit after a long silence could be particularly \ninteresting, for example because it took him a long time to fix a bug. Also, important \ncommits might have unusual commit messages, for example including smileys, lots \nof exclamation marks, or something like that\u2026basically something indicating that the \ndeveloper was emotional about that particular commit. \u201d While developer tools that \nsummarize expected events already exist\u2014albeit often still focusing on numbers rather \nthan textual content\u2014research on what constitutes important unexpected events in a \nsoftware project is still in its infancy.\n Rethinking Productivity and\u00a0Team Awareness\nThroughout a software project\u2019s life cycle, developers generate a vast corpus of software \nartifacts and perform a multitude of actions; however, only a fraction of those events are \nrelevant to one\u2019s own activity. Automated methods for aggregating and summarizing \nawareness information are important, as they potentially save developers from the \ncumbersome task of manually inspecting a large number of events\u2014or asking others\u2014to \nanswer the various questions that may arise in one\u2019s development work.\nAutomated methods for aggregating awareness information are likely to produce \nquantitative over qualitative information since aggregating numbers (e.g., the number \nof issues per developer) is much easier than aggregating textual information (e.g., \nwhat kinds of issues a developer is working on). Unsurprisingly, measures such as \nlines of code and number of issues open/closed are available in most development Chapter 15  how team awareness Influen Ces perCeptIons of\u00a0Developer proDuCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "176tools, but many developers in our study found them too limited to be used as \nawareness information and worried that such simple numbers may act as a proxy of \ntheir productivity. In short, awareness can influence developers\u2019 perceptions of the \nproductivity of their colleagues\u2014and these perceptions are often not accurate if based \non the awareness information that tools commonly provide.\nFrom the perspective of who receives awareness information, numeric measures \nshould not be provided in isolation: they should be augmented with useful information \nabout recent changes in the project that happened according to plan, i.e., expected \nevents, and most importantly, they should provide information about the unexpected. \nAs we noticed, awareness tool design has given greater emphasis to the former type of \ninformation, leaving information about unexpected events to be gathered by developers \nthemselves. Similarly, awareness tools have fed developers more information about what \nhappened and less information about why things happened.\nAs empirical evidence shows, the design of automated awareness mechanisms \nshould consider the tension between team awareness and productivity measures in \ncollaborative software development. Developers\u2019 information needs are indirectly \nrelated to productivity aspects, yet the way information is typically presented by \nawareness tools (e.g., kanban boards, burndown charts) can have negative effects as \nthey facilitate judgment on the productivity of developers. We found that the ultimate \ngoal of developers is not associated with productivity measurement: they seek to answer \nquestions that are impacting their own work and the expected flow of events. They want \nto become aware of the unexpected so that they can adapt more easily and quickly.\nWhile tools that help developers make sense of everything that goes on in a software \nproject are necessary to enable developer awareness, these tools currently favor \nquantitative information over qualitative information. To accurately represent what \ngoes on in a software project, awareness tools need to focus on summarizing instead \nof measuring information and be careful when presenting numbers that could be used \nas an unintended proxy for productivity measures. We argue for the use of natural \nlanguage and text processing techniques to automatically summarize information from \na software project in textual form. Based on the findings of our study, we suggest that \nsuch tools should categorize the events in a software project according to whether they \nare expected or unexpected and use natural language processing to provide meaningful \nsummaries rather than numbers and graphs that are likely to be misinterpreted as \nproductivity measures.Chapter 15  how team awareness Influen Ces perCeptIons of\u00a0Developer proDuCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "177 Key ideas\nThe following are the key ideas from the chapter:\n\u2022 Tools that help developers make sense of everything that goes on in a \nsoftware project are necessary to enable developer awareness.\n\u2022 Thes e tools currently favor quantitative information over qualitative \ninformation but need to focus on summarizing instead of measuring \ninformation.\n\u2022 Team awareness can influence developers\u2019 perceptions of their \ncolleagues\u2019 productivity, and developers do not feel that productivity \ncan be collapsed into a single metric.\n References\n [1] P aul Dourish and Victoria Bellotti. 1992. Awareness and \ncoordination in shared workspaces. In Proceedings of the 1992 \nACM conference on Computer-supported cooperative work \n(CSCW '92). ACM, New\u00a0York, NY, USA, 107-114. DOI= https://\ndoi.org/10.1145/143457.143468 .\n [2] Pedro Antunes, Valeria Herskovic, Sergio F .\u00a0Ochoa, Jos\u00e9 A.\u00a0Pino, \nReviewing the quality of awareness support in collaborative \napplications, Journal of Systems and Software, Volume 89, 2014, \nPages 146-169, ISSN 0164-1212, https://doi.org/10.1016/j.\njss.2013.11.1078 .\n [3] Gutwin, C. & Greenberg, S.\u00a0Computer Supported Cooperative \nWork (CSCW) (2002) 11: 411. https://doi.org/10.1023\n/A:1021271517844 .Chapter 15  how team awareness Influen Ces perCeptIons of\u00a0Developer proDuCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "178 [ 4]  L eif Singer, Fernando Figueira Filho, and Margaret-Anne \nStorey. 2014. Software engineering at the speed of light: how \ndevelopers stay current using twitter. In Proceedings of the \n36th International Conference on Software Engineering (ICSE \n2014). ACM, New\u00a0York, NY, USA, 211-221. DOI: https://doi.\norg/10.1145/2568225.2568305 .\n [5] Christoph Treude, Fernando Figueira Filho, and Uir\u00e1 Kulesza. \n2015. Summarizing and measuring development activity. In \nProceedings of the 2015 10th Joint Meeting on Foundations of \nSoftware Engineering (ESEC/FSE 2015). ACM, New\u00a0York, NY, USA, \n625-636. DOI: https://doi.org/10.1145/2786805.2786827 .\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 15  how team awareness Influen Ces perCeptIons of\u00a0Developer proDuCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "179\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_16CHAPTER 16\nSoftware Engineering \nDashboards: Types, \nRisks, and\u00a0Future\nMargaret-Anne Storey, University of Victoria, Canada\nChristoph Treude, University of Adelaide, Australia\n Introduction\nThe large number of artifacts created or modified in a software project and the flood of \ninformation exchanged in the process of creating a software product call for tools that \naggregate this data to communicate higher-level insights to all stakeholders involved. In \nmany projects\u2014in software engineering as well as in other domains\u2014dashboards are \nused to communicate information that may bring insights on the productivity of project \nactivities and other aspects. Stephen Few defines a dashboard as \u201ca visual display of the \nmost important information needed to achieve one or more objectives which fits entirely \non a single computer screen so it can be monitored at a glance\u201d [ 4].\nDashboards are cognitive awareness and communication tools designed to help \npeople visually identify trends, patterns and anomalies, reason about what they see, \nand help guide them toward effective decisions [ 3]. Their real value and one of the \nmain reasons for their popularity is their ability to \u201creplace hunt-and-  peck data-\ngathering techniques with a tireless, adaptable, information flow mechanism\u201d [ 9]. \nThe goal of dashboards is to transform the raw data contained in an organization\u2019s \nrepositories into consumable information. In software engineering, dashboards are \nused to provide information related to questions such as \u201cIs this project on schedule?\u201d"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "180and \u201cWhat are the current bottlenecks?\u201d and \u201cWhat is the progress of other teams?\u201d [ 7]. \nIn this chapter, we review the different types of dashboards that are commonly used in \nsoftware engineering and the risks that are associated with their use. We conclude with \nan overview of current trends in software engineering dashboards.\nThe link between productivity and dashboards becomes apparent when investigating \none of the dimensions that Few proposes for the categorization of dashboards: type of \nmeasures . While not always intended this way, much of the quantitative data presented \nin developer dashboards can also be interpreted as a measure of developer productivity \n(discussed in more detail in Chapter 15). For example, a bar chart that shows open issues \ngrouped by team can easily be interpreted as a chart highlighting the most productive \nteam (i.e., the team with the least open issues). The relationship between productivity of \na development team and the number of open issues is obviously much more complex, \nas one of our interviewees in a study on developer dashboards confirmed: \u201cJust because \none team has a lot more defects than another that doesn\u2019t necessarily mean that the \nquality of that component is any worse\u201d [ 7]. Instead, a component might have more \ndefects because it is more complex, because it has a user-  facin g role, or because it is a \ntechnically more central component that other components depend on, exposing it to \nmore unexpected conditions.\nFew also proposes a categorization of dashboards based on their role , in particular \ndiscussing dashboards in terms of their strategic, analytical, and operational purposes. \nIn software projects, the use of dashboards for operational purposes is the most \ncommon. Such dashboards are dynamic and based on real-time data, supporting \ndrilling down to specific artifacts such as critical bugs in a software project. Dashboards \nfor strategic purposes (so called \u201cexecutive dashboards\u201d) tend to avoid interactive \nelements and focus on snapshots rather than real-time data.\nSoftware developers produce many textual artifacts, ranging from source code \nand documentation to bug reports and code reviews. Therefore, it is unsurprising \nthat dashboards used in software projects often combine different types of data , i.e., \nqualitative and quantitative data. A bar graph showing the number of open issues \ngrouped by team would be a simple example of quantitative data, whereas a tag cloud of \nthe most common words used in bug reports is a simple representation of some of the \nqualitative data present in a software repository.\nAnother important dimension highlighted by Few is the span of data . When creating \na dashboard for a software project, many considerations have to be taken into account; \ne.g., should the dashboard feature enterprise-wide data or just data from a single project \n(bearing in mind that projects tend not to be independent)? Should each developer have Chapter 16  Software engineering Da Shboar DS: typeS, riSkS, anD\u00a0future"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "181their own personalized dashboard, or do all dashboards from a project look the same? In \naddition, dashboards can cover different timespans, such as the entire lifetime of a project, \nthe current release, or the last week. In software projects, one week is not necessarily like \nany other. For example, development activity during feature or code freeze is expected to \nbe different from the activity when starting to work on features for a new release.\n Dashboards in\u00a0Software Engineering\nWithin software engineering, dashboards are used to provide information and metrics \non the product under development, as well as to display information or to support \nthe analysis of the development process. Typically, they are designed with a specific \nstakeholder and goal in mind, and many of these goals relate directly or implicitly to \nsome aspect of productivity, including the product quality, work velocity, or stakeholder \nsatisfaction (see Chapter 5).\nIn the following text, we present some high-level categories of dashboards (those \nthat support individual developers, teams, projects, and communities), alluding to the \nstakeholders who use the dashboard and to the kinds of tasks they support within each \ncategory, as well as where those dashboards tend to be hosted.\nWe do not aim to be exhaustive but rather to illustrate the myriad of dashboards \nthat are used to support software engineering productivity. Most software engineering \ndashboards support operational or analytical tasks, while fewer support strategic \ntasks. Many of these dashboards are static, but more and more, software dashboards \nare becoming interactive as they play an increasingly important role in how software \nproductivity is understood, measured, and managed.\n Developer Activity\nDashboards may be used to display individual developer activity and performance, \nsuch as how coding time is spent (authoring, debugging, testing, searching, etc.), how \nmuch focus time the developers have in a given time frame, the number and nature of \ninterruptions they may face, time spent using other ancillary tools, coding behaviors \n(e.g., speed of correcting syntactical errors), and metrics indicating how many lines \nof code or features they contributed to a repository. This information, when used by \nthe developers themselves, can assist in personal performance monitoring, as well \nas personal productivity improvements especially when the dashboards allow the Chapter 16  Software engineering Da Shboar DS: typeS, riSkS, anD\u00a0future"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "182comparison of such information over time. Such dashboards also help developers reveal \nbottlenecks from the project code itself (which areas they spend much of their coding \ntime on) or from their own development process (see Chapter 22 for another example of \na dashboard to increase developers\u2019 awareness about their work and productivity).\nCodealike is one example of a dashboard service that integrates with a developer\u2019s \nIDE and supports developers in visualizing their own activities showing time spent \nnavigating the Web (if they opt to use an additional web browser plugin), focus and \ninterruption time, coding behavior over time, and coding effort on specific areas of the \nproject code. WakaTime similarly produces dashboards to show metrics and insights \non programming activity (such as programming language usage) and supports private \nleaderboards to allow developers to compete with other developers if they wish (in \nan effort to be more productive). RescueTime offers interactive features that allow \ndevelopers to set personal goals and to alert them when they may go off track (e.g., if they \nspend more than two hours on Facebook, they receive an alert).\nIn addition to presenting personal productivity information in dashboards, many \nof these services go beyond that and will also send information on a regular basis to \nthe developers (or other stakeholders) in an e-mail; they may even produce a metric \nto represent a productivity score (see RescueTime for an example that allows the \ndevelopers to customize the productivity score), or they may further block web sites in \nan attempt to improve personal productivity. The primary feature of these services are \nthe dashboards they provide, but we also see that they start to offer more features that go \nbeyond the restrictive definition of dashboards given by Few.\n Team Performance\nAlthough many dashboards are primarily designed for developers to gain insights on \ntheir own activities and behaviors, many display or aggregate information across a team \nfor other stakeholders, such as team leads, managers, business analysts, or researchers.\nThis team-level information may be used to improve the working environment, \ndevelopment process, or tools they use. Many services (such as Codealike) provide \nspecific-team level dashboards showing team metrics and even ranking information \nacross developers. Some services also provide support for teams to actively improve \ntheir performance together. However, there is concern that information captured \nabout individual developer behaviors may be inaccurate at capturing all the activities \nindividual developers may do and that the information may be used inappropriately.Chapter 16  Software engineering Da Shboar DS: typeS, riSkS, anD\u00a0future"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "183Keeping track of and monitoring work at a team level is especially important for \ndistributed teams. The Atlassian tool suite offers dashboards that help not only the \nindividual developers but also the team (see https://www.atlassian.com/blog/\nagile/jira-software-agile-dashboard ) to maintain awareness across the team and \nto regulate their work at both the individual and team levels [ 2]. GitHub also supports \nmany dashboards to present project information to teams (as we will discuss). Also, for \nmonitoring, development teams may use task boards for task tracking (such as Trello). \nAlthough such task boards are not typically referred to as dashboards, they can be used \nto give an overview of team performance and support team regulation.\nAgile teams use many different tools for tracking project activities as they have to \ndeal with a lot of data to help them manage and reflect on their process, in particular \ntracking their performance across sprints (e.g., see https://www.klipfolio.com/blog/\ndashboards-agile-software-development ). In agile teams, dashboards especially may \nplay an important role for managers. Managers, who are responsible for keeping track of \nall things in flight during a sprint, may rely on dashboards that visualize all open issues \nfor a particular project to see who open issues are assigned to and what is the priority of \nopen issues. Burndown charts, shown in dashboards, may show how the team is tracking \nagainst a predicted burndown line. Axosoft is another service to support agile teams in \nvisually tracking their progress so that they can plan more accurately.\nTeams commonly use TV monitors for displaying dashboards so that the team and \nmanagers can maintain awareness at a glance on how sprints are progressing in agile \nprojects, while dashboard services such as the one provided by Geckoboard can be used \nto show project-level monitoring information on TV screens to help teams focus on key \nperformance metrics.\n Project Monitoring and\u00a0Performance\nFor showing activity at a specific project level, GitHub, like other repository services, \nextensively uses dashboards to provide insights to managers, project owners, and other \ndevelopers who may want to decide on the value of using, depending on or contributing \nto particular projects (see https://help.github.com/categories/visualizng-  \nrepository-  data-with-graphs/ ). Grafana, used by the GitHub Stats monitoring \nproject, visualizes project forks, stars, number of issues, and other project metrics over \ntime. Bitergia also provides many dashboards for visualizing project and organization \ninformation pulling data from many diverse tools and integrations.Chapter 16  Software engineering Da Shboar DS: typeS, riSkS, anD\u00a0future"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "184As many projects nowadays rely on continuous integration and deployment services, \nmany dashboards visualize how code is moving through the pipeline, especially as \nnew features are flighted in A/B testing experiments. Additional DevOps support may \nbe provided by visualizing the performance of running services, tracking outages, etc. \n(see https://blog.takipi.com/the-top-5-devops-dashboards-every-engineer-  \nshould- consider/ , https://blog.newrelic.com/2017/01/18/dashboards-devops-  \nmeasurement/  and https://www.klipfolio.com/resources/dashboard-examples/\ndevops  for some discussion on DevOps dashboards).\nThere are also project-level dashboards that focus particularly on customer \nmanagement. Zendesk dashboards visualize how customers use specific web \napplications, as well as how they use their support channels for communicating with \nthe development team, and they visualize satisfaction levels of the end users. Similarly, \nAppNeta creates dashboards that provide insights on end-user satisfaction with web \napplications over time. UserVoice also provides dashboards but goes one step further \nby helping to prioritize customer feedback in the form of a road map to guide future \ndevelopment priorities.\n Community Health\nClosely related to project-level dashboards, other dashboard services aim specifically at \nvisualizing data at a community or ecosystem level. For example, the CHAOSS web site \ngathers and visualizes data to support the analytics of community health for open source \ncommunities such as Linux. For Linux, the foundation defines interesting health metrics \nsuch as number of licenses used among others (see https://github.com/chaoss/\nmetrics/blob/master/activity-metrics-list.md ).\n Summary\nAs we can see, the landscape of dashboards that already exist (and could exist) for \nvisualizing software development information is extremely broad and varied. They \nsupport a wide array of stakeholders and tasks and are hosted on different media. \nWe also see some dashboards stretching the definition of a dashboard by providing \nadditional features and services. However, we can also anticipate that the power they \nprovide in terms of analytics introduces some risks, which we discuss next.Chapter 16  Software engineering Da Shboar DS: typeS, riSkS, anD\u00a0future"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "185 Risks of\u00a0Using Dashboards\nDespite their usefulness to turn repository data into consumable information, \ndashboards come with a number of risks. Indeed, just as others in our community are \nrethinking productivity in software engineering, we suggest that how dashboards are \nused should be reconsidered at the same time. In the following, we discuss these risks in \nthe context of software engineering projects and software developer productivity.\n\u2022 Dashboards favor numbers over text : While many of the artifacts \nthat software developers work with are textual, such as requirement \nspecifications, commit messages, or bug reports, presenting the \ncontent of these textual artifacts on a dashboard is not trivial. \nTechniques that aggregate textual information\u2014for example, topic \nmodeling or summarization algorithms\u2014do not always produce \nperfect results, and it is therefore often easier to present numbers \ninstead of text on a dashboard. As a result, a developer dashboard is \nmore likely to contain information on how many issues were closed \nthan information on which feature is the most mentioned in bug \nreports. To address this challenge, further advances in text processing \nresearch, especially applied to the heterogeneous artifact landscape \nof a software project, are needed.\n\u2022 Dashboards might not display relevant context : The aggregation of \ninformation implies missing some of the details, which often means \nthat not all contextual information is available. A dashboard that \ndisplays information about a critical bug fix might not contain all the \ncaveats of this bug fix, and a dashboard that compares time spent \nin a browser to time spent in an IDE might not contain information \nabout which of the activities were related to software development. In \naddition, no two software projects are alike. While the presentation of \naggregated information on dashboards might invite users to compare \nbetween projects and companies, these comparisons are often \nflawed since they miss important context. To some extent, this can be \naddressed by making a dashboard interactive and allowing its users \nto drill down to more complete information.Chapter 16  Software engineering Da Shboar DS: typeS, riSkS, anD\u00a0future"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "186\u2022 Dashboards often don\u2019t explain : A dashboard might be able to show \nthat one team has fewer open issues than another team, that one \ncomponent has fewer bugs than another component, or that a \ndeveloper has spent more time in the IDE compared to the previous \nmonth. However, many dashboards do not provide explanations for \nsuch observations, and without explanations, this information might \nnot be actionable. For example, a team would not know what they \nneed to do to decrease the number of open issues they have, it might \nnot be obvious why one component has more issues than another, \nand a developer might not know what they can do to improve their \nproductivity.\n\u2022 You get what you measure : Goodhart\u2019s law\u2014usually cited as \u201cWhen \na measure becomes a target, it ceases to be a good measure\u201d\u2014\ndescribes another risk of the use of dashboards in software \ndevelopment projects. For example, if a dashboard emphasizes the \nnumber of open issues, developers will become more careful about \nopening new issues, e.g., by combining several smaller issues into \none. Similarly, if a dashboard conceptualizes productivity as time \nspent in the IDE, developers might become hesitant to look up \ninformation outside of the IDE.\u00a0In both examples, this was likely not \nthe intent of the dashboard, yet decades of research on gamification \nhave shown that humans tend to game such systems. As one of our \ninterviewees in a previous study [ 8] told us: \u201cDevelopers are the most \ncapable people on Earth to game any system you create. \u201d\n\u2022 Dashboards can only be as good as the underlying data : Many \nstudies have found that data captured in software repositories does \nnot always accurately reflect the development reality. For example, \nAranda and Venolia [ 1] found that the coordination that happens \naround software bugs cannot solely be extracted from software \nrepositories as it would lead to incomplete and often erroneous \naccounts of coordination. In a study on GitHub, Kalliamvakou et\u00a0al. \n[5] found that almost 40 percent of all pull requests do not appear \nas merged, even though they actually have been merged. These are \njust two examples of cases where looking at repository data alone \nprovides an inaccurate account of different aspects of software Chapter 16  Software engineering Da Shboar DS: typeS, riSkS, anD\u00a0future"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "187development. If a dashboard is based on such data, it is impossible \nfor this dashboard to display accurate information.\n\u2022 Dashboards can only display data that has been tracked somewhere : \nWhile today\u2019s software repositories are able to capture many of the \nactions taken by software developers, there are still many activities \nthat are not captured. For example, a repository would not be able to \ncapture the watercooler conversation between developers that might \nhave provided a crucial piece of coordination for fixing a particular \nbug. Negotiations with clients taking place outside of the confines of \na developer office would be another example of critical information \nthat is often not appropriately captured in a software repository. \nInformation that does not exist in a repository cannot be displayed \nin a dashboard, and users of dashboards have to be aware that a \ndashboard might not always provide the complete picture.\n\u2022 Performance-related data on dashboards can easily be misinterpreted as \nproductivity data : Many of the metrics that can be easily visualized on a \ndashboard, such as number of open issues or number of lines of code, can \nbe interpreted as productivity measures, enabling comparisons between \ndevelopers, teams, or components that ignore the many complexities of \nsoftware development. As discussed in the previous chapter, developers \nhave many reservations about such productivity measures. As a result, \nthey will only accept dashboards that do not attempt to reduce the \ncomplexity of a developer\u2019s contribution to a single number. Stephen Few \nnotes that analytical dashboards need subtle performance measures\u2014\nuntil such performance measures have been established, they should not \nbe replaced with their nonsubtle counterparts.\n\u2022 Dashboards often do not encode the actual goals well : There can be a \ntension between the goals of a software development organization \nand the items that are surfaced in a dashboard. While the goal of an \norganization might be long-term value creation, dashboards often \nuse relatively short time spans. Values such as customer satisfaction \nare not readily extractable from a software repository, even though \nthey might actually align with the organization\u2019s goal much better \nthan the number of open issues in a project or time spent in the IDE.Chapter 16  Software engineering Da Shboar DS: typeS, riSkS, anD\u00a0future"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "188 Rethinking Dashboards in\u00a0Software Engineering\nAs software engineering becomes more and more data driven and the tools for creating \ndashboards become easier to use, we expect to see a growth in the role that dashboards \nplay in software engineering and an increase in the number of features they provide. \nFor individual developers, dashboards provide insights on personal productivity, \nwhile teams and projects use them for monitoring performance, and managers and \ncommunity leaders use them for decision making.\nWe expect that artificial intelligence, natural language processing, and  \nsoftware bots [ 6] will also impact dashboard design and the features they provide \nin the next few years. There is certainly opportunity to automate the display of \nmore and more insights on data but also to improve how developers and other \nstakeholders collaborate with one another through dashboards. Furthermore, \nartificial intelligence and natural language processing could be used to gather \ninsights on how and when dashboards are used, on the impact they may have on \nsoftware projects, and on how their design could be improved over time.\nWe may also wonder if dashboards may even partially replace other modes \nof information exchange (e.g., PowerPoint slides), and indeed we have observed \n(informally) that this is the case at some large software companies. Once these \ndashboards render relevant data, will some stakeholders interpret the view they show \nas \u201ctruth\u201d even though the underlying data or how it is analyzed and presented may be \ninaccurate, biased or misleading? Do we have sufficient understanding on the significant \nrole they may play in software engineering projects and furthermore on the ethical \nconcerns they may introduce when they accentuate or reveal data that may be sensitive \nto some stakeholders?\nDashboards and the technologies to create them are likely to become ubiquitous and \neasier to use over time. Whether they will enhance or possibly harm and detract from \nproductivity or whether they may just give insights on productivity remains to be seen, \nbut care should be taken in how they are created and used. We hope this chapter brings \nsome insights on the diverse way they may be used as well as some awareness of some of \nthe risks as well as opportunities they may bring to our community.Chapter 16  Software engineering Da Shboar DS: typeS, riSkS, anD\u00a0future"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "189 Key Ideas\nThese are the key ideas from this chapter:\n\u2022 The landscape of dashboards that exist for visualizing software \ndevelopment information is extremely broad and varied.\n\u2022 For individual developers, dashboards provide insights on personal \nproductivity, while teams and projects use them for monitoring \nperformance and managers and community leaders use them for \ndecision-making.\n\u2022 The power that dashboards provide in terms of analytics introduces \nrisks such as the misinterpretation of productivity data and the \nmisalignment of goals.\n References\n [1] Jorge Aranda and Gina Venolia. 2009. The secret life of bugs: \nGoing past the errors and omissions in software repositories. In \nProceedings of the 31st International Conference on Software \nEngineering (ICSE \u201909). IEEE Computer Society, Washington, DC, \nUSA, 298\u2013308.\n [2] Arciniegas-Mendez, M., Zagalsky, A., Storey, M.\u00a0A., & Hadwin, A.\u00a0F .  \n2017. Using the Model of Regulation to Understand Software \nDevelopment Collaboration Practices and Tool Support. In CSCW \n(pp.\u00a01049\u20131065).\n [3] Brath, R. & Peters, M. (2004) Dashboard design: Why design is \nimportant. DM Direct, October 2004. Google Scholar\n [4] Few, Stephen. 2006. Information dashboard design: the effective \nvisual communication of data. Beijing: O\u2019Reilly.\n [5] Kalliamvakou, E., G.\u00a0Gousios, K.\u00a0Blincoe, L.\u00a0Singer, D.\u00a0M. German, \nand D.\u00a0Damian. 2014. The promises and perils of mining GitHub. \nIn Proceedings of the 11th Working Conference on Mining \nSoftware Repositories (MSR 2014). ACM, New\u00a0York, NY, USA, \n92\u2013101.Chapter 16  Software engineering Da Shboar DS: typeS, riSkS, anD\u00a0future"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "190 [6] Storey, M.\u00a0A., & Zagalsky, A. 2016. Disrupting developer \nproductivity one bot at a time. In Proceedings of the 2016 24th \nACM SIGSOFT International Symposium on Foundations of \nSoftware Engineering (pp.\u00a0928\u2013931). ACM.\n [7] Treude, C. and M.\u00a0A. Storey 2010, \u201c Awareness 2.0: staying aware \nof projects, developers and tasks using dashboards and feeds, \u201d \n2010 ACM/IEEE 32nd International Conference on Software \nEngineering, Cape Town, 2010, pp.\u00a0365\u2013374.\n [8] Treude, C., F .\u00a0Figueira Filho, and U.\u00a0Kulesza. 2015. Summarizing \nand measuring development activity. In Proceedings of the 2015 \n10th Joint Meeting on Foundations of Software Engineering \n(ESEC/FSE 2015). ACM, New\u00a0York, NY, USA, 625\u2013636.\n [9] Gregory L. Hovis, \u201cStop Searching for InformationMonitor it with \nDashboard Technology, \u201d DM Direct, February 2002.\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 16  Software engineering Da Shboar DS: typeS, riSkS, anD\u00a0future"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "191\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_17CHAPTER 17\nThe COSMIC Method for\u00a0 \nMeasuring the\u00a0Work-  Output  \nComponent of\u00a0Productivity\nCharles Symons, Common Software Measurement International \nConsortium (COSMIC), UK\nThe productivity of a software activity may be defined generally as work-output/work-  \ninput, where work-input is the effort needed to produce the work-output. In this chapter, \nwe describe the ISO standard COSMIC method, which was designed to measure a size \nof the work-output from a software process. Measured sizes must be useful for both \nproductivity measurement and for effort estimation, for most types of software.\nFor this chapter, we leave aside all the issues of how to interpret and exploit \nmeasurements of the productivity of software activities (e.g., the factors that affect \nproductivity, the effect of measurements on the persons measured, etc.). Our challenge \nis how to measure a size of the work-output of software developers in a way that:\n\u2022 Is independent of the technology used (e.g., language, platform,  \ntools etc.), enabling productivity comparisons across different \ntechnology-  sets\n\u2022 Is credible and acceptable to the team or project whose performance \nis measured so that there is a clear connection with their total \nwork-input, so not just, for example, the code size produced by the \nprogrammers in the team"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "192\u2022 Is demonstrably useful for estimating the effort for future activities\n\u2022 Does not take up too much time and effort in relation to how the \nresults will be used (automatic measurement being the ideal)\nAs well as being able to measure a delivered  size and/or a developed  size in the \ncase of new software, the method must be able to measure a changed  size in the  \ncase of a maintenance or enhancement task or a supported  size in the case of \nsupport activities.\n Measurement of\u00a0Functional Size\nIn the late 1970s, Allan Albrecht proposed a method for measuring a size of the \nfunctional requirements for a piece of software, an \u201camount of functionality delivered to \nthe user. \u201d This was a nice piece of lateral thinking that led to the development of function \npoint analysis. His method is now maintained by the International Function Point Users \nGroup (IFPUG) and is still widely used.\nFunction point analysis was a big advance over counting source lines of \ncode as a size measure since the latter are technology-dependent and cannot be \nestimated accurately until a software project is well advanced\u2014too late for most \nproject budgeting purposes. In contrast, sizes of requirements measured in units of \nfunction points are technology-independent. Hence, their use enables comparisons \nof productivity across different technologies, development methods, etc., and a \nsoftware size can be estimated quite early in a project, as requirements-elicitation \nproceeds.\nHowever, Albrecht\u2019s function point analysis has a number of disadvantages in  \nthe context of modern software development. In 1998, therefore, an international \ngroup of software measurement experts established the Common Software \nMeasurement International Consortium (COSMIC) aiming to develop a new method \nfor measuring functional requirements that overcomes the weaknesses of function \npoints. Table\u00a0 17- 1 summarizes the key differences between Albrecht\u2019s function  \npoint analysis and the COSMIC method. (FP = function points; CFP = COSMIC \nfunction points.)Chapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "193 The COSMIC Method\nThe method\u2019s design rests on two fundamental software engineering principles that are \nillustrated in Figures\u00a0 17-1  and 17-2 . In the following, all words in italics are precisely \ndefined COSMIC terms [ 2].\n\u2022 Software functionality consists of functional processes  that must \nrespond to events  outside the software, detected by or generated by \nits functional users  (defined as the \u201csenders or intended recipients of \ndata\u201d). Functional users  may be humans, hardware devices, or other \npieces of software.\n\u2022 Software does only two things. It moves data (entering from its \nfunctional users  and exiting to them across the software boundary  \nand from/to persistent storage ), and it manipulates  data.Table 17-1.  Comparison of Albrecht\u2019s FPA Method with the COSMIC  Method\nFactor Albrecht\u2019s FPA Method COSMIC Functional Size Measurement \nMethod\ndesign origin a 1970s-era IBM effort- estimation \nmethod.fundamental software engineering \nprinciples.\ndesign \napplicabilityWhole business applications. Business, real-time, and infrastructure \nsoftware, at any level of decomposition.\nSize scale Limited size ranges for any one \nprocess or file. for example,  a single \nprocess must have a size in the range \n3\u20137 fp.Continuous size scale.  the smallest \npossible size of a single process is 2 C fp, \nbut there is no upper limit to its size.\nMeasurement of \nchangesCan only measure the size of a whole \nprocess or of a whole file that must be \nchanged.Can measure the size of a change to any \npart of a process, so the smallest size of a \nchange is 1 C fp.\navailability Membership subscription. Open, free [ 1].Chapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "194As there is no simple way to account for data manipulation , especially early in the life \nof a piece of software when requirements are still evolving, the COSMIC size of a functional \nprocess  is measured by counting its data movements.  In other words, this approach \nassumes that each data movement  accounts for any associated data manipulation .\nBy definition, a data movement  is a subprocess that moves a group of data attributes  \nthat all describe a single object of interest  (think of an object-class, a relation in 3NF , or an \nentity-type). The unit of measurement is one data movement , designated as 1x COSMIC \nfunction point, or 1 CFP .\nA functional process  has a minimum size of 2 CFPs. It must have an Entry  plus either \nan Exit  or a Write , as the minimum outcome of its processing, but there is no maximum \nsize. Single processes of size 60 CFP have been measured in business applications and \nmore than 100 CFP in avionics software.\nThe functional size of a piece of software in CFPs is the sum of the sizes of all its \nfunctional processes . The size of any required change to a piece of software in CFPs is the \ncount of its data movements  that must be changed, regardless of whether changes must \nbe to the data group  moved and/or to the associated data manipulation .A\nTriggering\nEventcausesBoundary\nA\nFunctional \nUserto generate a data group \nthat is moved into aA Functional \nProcess\nFigure 17-1.  The event/functional user/data group/functional process \nrelationship\nFunctional Processes\nof the software\nbeing measuredBoundary\nFunctional Users \n\u2022Hardware devices,\n\u2022Other software or\n\u2022HumansEntries\nExits\nReads Writes\nPersistent \nStorage\nFigure 17-2.  The types of data movements of functional processesChapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "195Two examples illustrate the application of the method.\nA simple functional process for a human functional user to enter data online about \na new employee would have an Entry to move the new employee data, a Read of the \ndatabase to check whether the employee already exists, a Write to create the new record, \nand an Exit to convey any validation error messages. The total size would be 4 CFP .\nA functional process of a military aircraft may receive a triggering Entry from a \nsensor warning \u201cmissile approaching. \u201d The process will output several messages as \nExits. Each Exit becomes the triggering Entry to a process in another part of the aircraft\u2019s \ndistributed avionics system, for example, to issue warnings to the pilot to instruct the \naircraft to take evasive action and other countermeasures. All communicating software \ncomponents are functional users of each other; all input and output hardware devices \nare functional users of the software components with which they communicate.\n Discussion of\u00a0the\u00a0COSMIC Model\nIn this section, we discuss various aspects of the model that might be argued to limit its \npractical value as a measure of work-output.\nFor effort estimation, we need size estimates long before we know the \nrequirements in sufficient detail for a precise COSMIC size measurement.\nWhen there is a new software requirement, the thought process for an estimator is \nusually first \u201chow big is it?\u201d and then \u201cwhat productivity figure should I use to convert \nsize to effort?\u201d For example, an agile team would estimate the size of a user story in \nstory points and use a velocity figure measured on past sprints as the productivity \nvalue. This same thought process is involved when estimating the effort to develop or \nchange a piece of software at any level of aggregation from a single user story all the \nway up to a major new system. Estimators need a software size scale and a size/effort \nrelationship, i.e., productivity data, at each relevant level. The productivity data will \nhave been established from measurements on past, completed tasks, or projects with \ncharacteristics similar to the new challenge.\nHowever, a sponsor of a new software development typically needs a cost estimate \nfor budget purposes long before the requirements have been spelled out in sufficient \ndetail for a precise COSMIC size measurement. In practice, therefore, measurements \nof approximate sizes of early requirements for effort estimation may be as commonly \nneeded as are precise sizes of delivered requirements for productivity measurement.Chapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "196If the COSMIC models illustrated in Figures\u00a0 17-1  and 17-2  and the definitions of \nthe various terms are to succeed, it must mean that for any given artifacts of some \nsoftware to be measured, everyone will identify and agree on the same set of functional \nprocesses. (The artifacts may be early or detailed statements of requirements, designs, \nimplemented artifacts such as screen layouts and database definitions, or working code.) \nCorrectly identifying the functional processes is the basis for ensuring measurement \nrepeatability.\nCOSMIC method publications include a guideline [ 1] that describes several \napproaches, of varying sophistication, for measuring an approximate size of early \nrequirements. All such approaches rely on being able to identify or estimate, directly or \nindirectly, the number \u201cn\u201d of functional processes in the early requirements for the new \nsoftware. As an example, the simplest way of estimating an approximate COSMIC size \nof such requirements is to multiply the estimated \u201cn\u201d by an estimated average size of \none process. More sophisticated approaches to approximate sizing include identifying \npatterns of functional processes that are known to occur for the type of software being \nestimated.\nAn organization wanting to use any of these approaches to approximate COSMIC \nsize measurement will need to measure some software sizes accurately and use the \nresults to calibrate the chosen approximate sizing approach.\nWhat about nonfunctional requirements?\nA method that aims to measure a size of functional requirements might appear to \nintentionally ignore nonfunctional requirements (NFRs). This would be nonsense since \nNFRs may need a lot of effort to implement. Loosely speaking, functional requirements \ndefine what the software must do, whereas NFRs define constraints on the software and \nthe way it is developed or, in other words, how the software must do it.\nA joint COSMIC/IFPUG study developed a clear definition of NFRs and a \ncomprehensive glossary of NFR terms [ 3] and divided them broadly into two main \ngroups.\n\u2022 Technical NFRs such as the programming language or hardware \nplatform to be used, or constraints from the environment such as \nthe number of users to be supported. These NFRs do not affect \nsoftware functional size. Rather, they may be factors that you need to \nunderstand when interpreting productivity measurements and that \nmust usually be taken into account when estimating costs for a new \ndevelopment.Chapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "197\u2022 Quality NFRs such as requirements for usability, portability, \nreliability, maintainability, etc. These evolve as a project progresses, \nwholly or largely1, into requirements for software functionality. The \nsize of this functionality can be measured in the normal way, using \nthe standard rules of the COSMIC method, or can be estimated if \nrequired for a new development.\nSo, sizes measured using the COSMIC method should reflect all the functionality \noutput as a result of the work-input on the software, regardless of whether this \nfunctionality was initially stated in terms of functional or nonfunctional requirements.\nWhat about complexity?\nProductivity measurements based on functional sizes are sometimes criticized \nfor not reflecting software complexity. In a discussion of simplicity versus complexity, \nMurray Gell-Mann (in \u201cThe Quark and the Jaguar\u201d) shows that crude complexity can \nbe defined as \u201cthe length of the shortest message that will describe a system at a given \nlevel of coarse graining. \u201d According to this definition, therefore, a COSMIC size closely \nmeasures the crude complexity of the functional requirements of a software system at \nthe level of granularity of the data movements of its functional processes.\nHowever, as already noted, COSMIC sizes do not take into account the size or \ncomplexity of the data manipulation associated with each data movement, i.e., \nalgorithmic complexity. Experience suggests, however, that for a large part of business, \nreal-time and infrastructure software, the amount of data manipulation associated \nwith each type of data movement does not vary much. I know of only one actual \nmeasurement of the number of lines of algorithm (LOA) per data movement, which was \nfor a very large chunk of a real-time avionics system. This showed, for example, that the \nmedian number of LOA associated with one data movement was 2.5, with 99 percent of \ndata movements having no more than 15 LOA.\u00a0This one piece of evidence supports the \nvalidity of the COSMIC method design assumption for this domain that the count of data \nmovements reasonably accounts for any associated data manipulation, except for any \nareas of software that are dominated by mathematical algorithms. In business, real-time, \nand infrastructure software, these areas are typically few and concentrated.\n1 An NFR for a system response time may give rise partly to the need for specific hardware or use \nof a particular programming language (i.e., technical NFRs) and partly for requirements for \nspecific software functionality. The latter can be taken into account in the measure of functional \nsize.Chapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "198If the development of some software requires significant amounts of new algorithms, \nthe effort associated with this work should probably be separated out in any productivity \nmeasurement or should be estimated separately. Developing a new algorithm is \nessentially a creative process for which there may be no meaningful size/effort \nrelationship. Alternatively, the functional size associated with the algorithms may be \nmeasured, e.g., by a locally defined extension to the standard COSMIC method.\nAre sizes of functional requirements still relevant in a world of component-\ndriven software development?\nThis question can be expressed more generally as \u201cCan COSMIC sizing be used, and \nis it still relevant in the world of modern software development, where much software \nis assembled from reusable components, e.g., in the IoT or for mobile apps; when agile \ndevelopers don\u2019t believe in detailed documentation and their processes may involve \nmuch rework; in outsourced software contracts; etc.?\u201d\nThe first obvious point to make is that if we are ever to understand software \nproductivity and use the measurements for estimating purposes, then we need a \nplausible, repeatable, technology-independent measure of work-output. The COSMIC \nmethod meets this need; sizes may be measured at any point in the life of a piece of \nsoftware.\nIt is up to each organization to determine the problem it is trying to solve and \nthen decide for itself how and when  to apply the COSMIC method and how to use  the \nresulting measurements.\nBecause any one software activity could result in many types of COSMIC size \nmeasurements, the parameters of each measurement must be recorded to ensure that \nits meaning will be clear for future users. These parameters include the domain of the \nsoftware and its layer in the architecture and distinguish, for example the following:\n\u2022 Sizes of new developments from sizes of changes or enhancements\n\u2022 Sizes of developed from delivered software, where the latter includes \nbought-in or reused software\n\u2022 The level of decomposition (or of aggregation) of the software\nExperience suggests that an organization should start work-output measurement on \nits most commonly used software processes to build confidence in using the COSMIC \nmethod and in the resulting productivity measurements, before moving on to measuring \nmore complex situations.Chapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "199In summary, the design of the COSMIC method is a compromise between taking into \naccount all the factors we might think of as causing work-output and the practical need \nthat measurement should be simple and not need too much effort.\n Correlation of\u00a0COSMIC Sizes with\u00a0Development \nEffort\nThe acid test of whether the COSMIC method is of real practical use is \u201cDo CFP sizes, as \nmeasurements of work-output, correlate well with measurements of development effort, \ni.e., work-input?\u201d If the correlations are good, then productivity comparisons should \nbe credible, and the results can be used for new effort estimation purposes with known \nconfidence.\nHappily, studies over several years show that under repeatable conditions (same \ntype of software, same technologies, common rules for effort recording, etc.), CFP \nsizes correlate well with effort for a variety of business and real-time software [ 4]. \nThe correlations are significantly better, according to some studies, than when using \nAlbrecht\u2019s FP sizes.\nRecent studies on agile software developments [ 5] also show that CFP sizes correlate \nwith effort far better than do story point sizes at the level of sprints or iterations. (Story \npoints may be meaningful within individual teams, but they cannot be relied upon for \nproductivity comparisons across teams, nor for higher-level effort estimation purposes.)\nFigure 17-3  shows the measurements from one such study with a Canadian supplier \nof security and surveillance software. In their agile process, tasks are allocated to \niterations lasting from three to six weeks. The effort for each task is estimated in Planning \nPoker sessions in units of story points on a Fibonacci scale, which are then converted \ndirectly to work-hours. Figure\u00a0 17-3  shows the actual effort versus the estimated effort for \n22 tasks in nine iterations that required a total of 949 work-hours.Chapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "200The sizes of the 22 tasks were subsequently measured in units of COSMIC function \npoints. Figure\u00a0 17-4  shows the actual effort for these same 22 tasks plotted against the \nCFP sizes.\ny = 2.35 x + 0.1\nR\u00b2 = 0.95\n04080120160200\n01 02 03 04 05 06 07 08 0Actual effort (work-hour s)\nSize (COSMI C Func tion Points)\nFigure 17-4.  Actual effort versus CFP sizesy = 0.502x + 15.6\nR\u00b2 = 0.36\n04080120160200\n05 0 100 1502 00Actual effort (work-hours)\nStory Points \u2192Estimated  Effort (work -hours )\nFigure 17-3.  Actual effort versus estimated effortChapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "201These two graphs show clearly the greatly improved correlation of task size versus \neffort when size is measured using COSMIC function points, rather than story points. \nAgile developers can substitute CFP sizes for story points to estimate or measure their \nwork-output without any need to change their agile processes.\nIn addition to its uses in effort estimation, studies in the domains of embedded real-  \ntime and mobile t elecoms software show that CFP sizes correlate well with the memory \nsize needed for the corresponding code.\nOrganizations using the COSMIC method are now routinely exploiting these \ncorrelations to help estimate development effort from early software requirements or \ndesigns, or in agile environments.\n Automated COSMIC Size Measurement\nCOSMIC size measurement automation is underway in three areas, in varying stages \nfrom early exploration to commercial exploitation.\n a) Automated COSMIC sizing from textual requirements using \nnatural language processing or artificial intelligence is still in the \ndevelopment stage. This step has great potential as it would allow \nearly life-cycle estimating, e.g., of approximate sizes from user stories.\n b) Automated COSMIC sizing from formal specifications or \ndesigns has reached the commercial exploitation stage in a few \norganizations. Here are two examples:\n\u2022 Automatic CFP size measurement from UML models. Several \nPolish public-sector organizations rely on the results to help \ncontrol price/performance of their software outsourcing contracts.\n\u2022 Renault, the French automotive manufacturer, has implemented \nautomatic COSMIC sizing of specifications held in the Matlab \nSimulink tool for the software embedded in its vehicle electronic \ncontrol units [ 4]. CFP sizes are used to predict the development \neffort and the hardware memory size needed for the ECUs and \nto estimate the ECU execution times. The data is then used to \ncontrol price/performance for the supply of ECUs and their \nembedded software. Other automotive manufacturers are known \nto be implementing these processes.Chapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "202 c) Automated COSMIC sizing from static and from executing Java \ncode has been achieved with some manual input \u201cseeding\u201d of the \ncode, with high accuracy.\n Conclusions\nThe ISO-standard COSMIC method has met all its design goals and is being used around \nthe world for measuring a functional size, i.e., work-output, for most types of software.\nMeasured sizes have been shown to correlate well with development effort for \nseveral types of software. The derived size/effort relationships are being used for effort \nestimation with, in some known cases of real-time software, great commercial benefits. \nThe method has been recommended by the U.S.\u00a0Government Accountability Office for \nuse in software cost estimation.\nThe method\u2019s fundamental design principles are valid for all time. The method \ndefinition [ 2] is mature and has been frozen for the foreseeable future. Automatic \nCOSMIC size measurement is already happening. As a further consequence of the \nuniversality of the method\u2019s underlying concepts, measured sizes should be easily \nunderstood and therefore acceptable to the software community whose performance is \nmeasured.\nMeasuring and understanding the productivity of software activities is a multifaceted \ntopic. The COSMIC method provides a solid basis for the many needs of work-output \nmeasurement, a key component of productivity measurement.\n Key Ideas\nHere are the key ideas from this chapter:\n\u2022 It's important for productivity measurement and estimating to have \na measure for work output that can be compared across different \ncontexts.\n\u2022 COSMIC function points are such a measure.Chapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "203 References\n [1] All C OSMIC documentation, including the references below, is \navailable for free download from www.cosmic-sizing.org . For \nan introduction to the method go to https://cosmic-sizing.\norg/publications/introduction-to-the-cosmic-method-  of-\nmeasuring-software-2/ .\n [2] \u201cThe C OSMIC Functional Size Measurement Method, Version \n4.0.2, Measurement Manual (The COSMIC Implementation Guide \nfor ISO/IEC 19761: 2017), \u201d which contains the Glossary of Terms.\n [3] \u201cGlossary of Terms for Non-Functional Requirements and \nProject Requirements used in software project performance \nmeasurement, benchmarking and estimating, \u201d Version 1.0, \nSeptember 2015, published by COSMIC and IFPUG.\n [4] \u201cMeasurement of software size: advances made by the COSMIC \ncommunity, \u201d Charles Symons, Alain Abran, Christof Ebert, Frank \nVogelezang, International Workshop on Software Measurement, \nBerlin 2016.\n [5] \u201cExperience of using COSMIC sizing in Agile projects, \u201d Charles \nSymons, Alain Abran, Onur Demirors. November 2017. https://\ncosmic-sizing.org/publications/experience-using-cosmic-\nsizing-agile-projects/Chapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "204Open Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 17  the COSMIC Meth Od fOr\u00a0Mea SurIng the\u00a0W Ork- Output C OMpOnent Of\u00a0prOduCtIvIty"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "205\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_18CHAPTER 18\nBenchmarking: Comparing \nApples to\u00a0Apples\nFrank Vogelezang, METRI, The Netherlands\nHarold van Heeringen, METRI, The Netherlands\n Introduction\nFor almost every organization, software development is becoming more and more \nimportant. The ability to develop and to release new functionality to the users and \ncustomers as fast as possible is often one of the main drivers to gain a competitive edge. \nHowever, in the software industry, there is a huge difference in productivity between the \nbest and worst performers. Productivity can be a crucial element for many organizations \n(as well as cost efficiency, speed, and quality) to bring their competitiveness in line with \ntheir most relevant competitors.\nBenchmarking is the process of comparing your organization\u2019s processes against \nindustry leaders or industry best practices (outward focus) or comparing your own \nteams (inward focus). By understanding the way the best performers do things, it \nbecomes possible to\n\u2022 Understand the competitive position of the organization\n\u2022 Understand the possibilities for process or product improvement\n\u2022 Create a point of reference, a target to aim for\nBenchmarking gives insight into best practices, with the aim to understand if \nand how one should improve to stay or become successful. Software development \nbenchmarking can be done on any scale that is comparable: a sprint, a release, a project, \nor a portfolio."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "206 The Use of\u00a0Standards\nBenchmarking is all about comparing. A well-known phrase is \u201cComparing apples to \napples and oranges to oranges. \u201d One of the key challenges in the software industry is to \nmeasure productivity of completed sprints, releases, projects, or portfolios in such a way \nthat this information can be used for processes such as estimation, project control, and \nbenchmarking. But how can we compare apples to apples  in an industry that is immature \nwhen it comes to productivity measurement?\nThe economic concept of productivity is universally defined as output/input. In \nthe context of productivity measurement in software development, input is usually \nmeasured in effort hours spent. Although it\u2019s important to define the right scope of \nactivities when benchmarking, it\u2019s just as important to measure the output of a sprint, \nrelease, or project in a meaningful way. To be able to benchmark productivity in \nan \u201capples to apples\u201d way, it\u2019s crucial that the output is measured in a standardized \nway. An important aspect of standardization is that the measurement is repeatable, \nso different measurers attribute the same number to the same object. In practice, \nmany measurement methods are being used that are not standardized. Because the \noutput is not standardized, the same number may relate to different aspects, or the \nsame object gets different ratings. This means that the productivity information is not \ncomparable and therefore not useful in benchmarking. Examples of these popular, but \nunstandardized measurement methods are lines of code (LOC) and all variants, use case \npoints, complexity points, IBRA points, and so on. Also, the story point, which is popular \nin most agile development teams, is not standardized and therefore can\u2019t be used in \nbenchmarking across teams or organizations.\nAt this moment, only the standards for functional size measurement (the main \nones being Nesma, COSMIC, and IFPUG) comply with demands for standardized \nmeasurement procedures and intermeasurer repeatability to produce measurement \nresults that can be compared across domains to benchmark productivity.\n Functional Size Measurement\nFunctional size is a measure of the amount of functionality provided by the software, \nderived by assigning numerical values to the user practices and procedures that the \nsoftware must perform to fulfill the users\u2019 needs, independent of any technical or quality \nconsiderations. The functional size is therefore a measure of what the software must do, \nnot how it should work. This general process is described in the ISO/IEC 14143 standard. Chapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "207The COSMIC method measures the occurrences of Entries, Exits, Reads, and Writes \n(Figure\u00a0 18-1 ).\nCOSMIC is a second-generation  functional size measurement method. Most \nfirst-generation  methods also assign values to data structures. This limits their use in \nsoftware that processes events. See also Chapter 17 for more extensive information about \nfunctional size measurement.\nTo benchmark productivity across projects in a comparable way, these base \nparameters are now available:\n\u2022 Output : Functional size measured in a standardized way\n\u2022 Input: Effort hours spent for agreed activities in scope\nIn practice, the productivity formula (output/input) usually results in numbers of \nfunction points per effort hour  smaller than 1. Because humans are not computers and \npeople can more easily understand and interpret numbers greater than 1, the use of the \ninverse is more commonly used in software benchmarking. This inverse is called the \nproduct delivery rat e (PDR), defined as Input/Output, or effort hours per function point  \ndelivered. This is an outcome-oriented way of assessing productivity. See Chapter 8 for \nmore details on assessing productivity.\nFigure 18-1.  The base functional components for the COSMIC method: Entry, \nExit, Read, and WriteChapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "208When the productivity is measured in a standardized way, for benchmarking purposes \nit needs to be compared to relevant peer groups in the industry. The most relevant source \nfor peer group data is the International Software Benchmarking Standards Group (ISBSG). \nThis not-for-profit organization collects data from the industry, based on standardized \nmeasures, and provides this data in an anonymized data set in easy-to-use Excel sheets. \nFor productivity benchmarking, this is the main resource available for practitioners in \nthe industry. The Development & Enhancements repository currently (February 2019) \ncontains more than 9,000 projects, releases, and sprints, most of them having a PDR in one \nof the functional size measurement methods mentioned earlier.\n Reasons for\u00a0Benchmarking\nBenchmarking is often used to understand the organization\u2019s capabilities in relation \nto industry leaders or competitors. This most common type of benchmarking has an \noutward focus. The objective is usually to find ways or approaches to reach the level \nof productivity of the industry leaders or to improve productivity in such a way that \ncompetitors can be outperformed.\nBenchmarking can also be done with an inward focus. The most common example \nof this type of benchmarking is the comparison of velocity in the last sprint to the \nvelocity in previous sprints. The objective is usually to learn from earlier sprints what \ncan be improved to reach a higher velocity. In Chapter 3, Amy J. Ko performs a thought \nexperiment to argue that we should focus on good management rather than productivity \nmeasurement. The effects that good management will have on productivity are true \nfor most successful organizations we have encountered. But the only way to prove that \ngood management brings a higher productivity is\u2026benchmarking. And benchmarking \nrequires measuring productivity.\nAnother use of benchmarking is the determination of a so-called landing zone \nby tendering organizations. A landing zone is a range of the minimum, average, and \nmaximum prices that can be expected for the scope offered for tender. These ranges are \nbased on market experience. With this use of benchmarking data, bidding companies \nare benchmarked in advance.\nExamples of a scope that is offered for tender are\n\u2022 A portfolio of applications to be maintained\n\u2022 A new b espoke software solution to be developed\n\u2022 A number of applications to be ported to a cloud platformChapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "209We have seen tenders that exclude bids that are outside the landing zone. How the \nsource data for such a landing zone can be obtained is described in the section \u201cSources \nof Benchmark Data. \u201d The objective is to determine where they expect the price offers of \nthe bidding companies will fall.\n A Standard Way of\u00a0Benchmarking\nIn 2013, the ISO published an international standard describing the industry best \npractice to carry out IT project performance benchmarking: ISO/IEC 29155 Information \ntechnology project performance benchmarking framework. The standard consists of five \nparts (Figure\u00a0 18-2 ).\nFigure 18-2.  ISO/IEC 29155 structure\nThis standard can guide organizations that want to start benchmarking their IT \nproject performance to implement an industry best practice benchmarking process in \nthe following ways:\n\u2022 By offering a standardized vocabulary of what is important in setting \nup a benchmark process\n\u2022 By defining the requirements for a good benchmarking processChapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "210\u2022 By giving guidance on reporting, before the input part is put in place\n\u2022 By giving guidance on how to collect the input data and how to \nmaintain the benchmark process\n\u2022 By defining benchmarking domains\nThe order of the parts of the standard is, as you can expect from an ISO-standard, \ndeliberate. The most important aspect is that people need to know what they are talking \nabout and need to be able to speak in the same language. The next thing is that you \ndefine up front  what to expect from a good process. Then you need to define what you \nwant to know. In the thought experiment by Amy J. Ko in Chapter 3, some nice examples \nshow what can go wrong if you do not define this in the right manner. When you have \ndone this preparation, your organization is ready to collect data and is able to make \na sensible split into different domains, where apples are compared with apples and \noranges with oranges.\n Normalizing\nBenchmarking is comparing, but more than just comparing any numbers. To really \ncompare apples with apples, the data to be compared really needs to be comparable. \nIn sizing, the size numbers of different software objects can be compared, either on \na functional level (using standardized functional size measures, for example) or on a \ntechnical level. Different hard data about the processes to build or maintain a piece of \nsoftware can be compared for measure and tracking purposes. Even soft data about \nthe software or the process can be used for assessing the differences or resemblances \nbetween different pieces of software. This can be sufficient for estimating and planning \npurposes, but is insufficient for true benchmarking. Benchmarking is useful only when \nevery aspect is the same, except for the aspect you want to benchmark. In practice, \nthis is hardly ever the case. To have a meaningful benchmark, all aspects not under \nscrutiny must be made the same. This is called normalizing . Based on mathematical \ntransformations or experience data, peer data can be normalized to reflect the \nconditions of the project that is benchmarked. Things like team size, defect density, \nand project duration can be made comparable. When a large data set of peer data is \navailable, the easiest way is to select only the peer data that is intrinsically comparable \nand can be used without mathematical transformations. When not enough peer data is \navailable, aspects can be normalized of which the effect is known.Chapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "211For instance, the effect of team size is extensively studied. When teams of different \nsizes are compared, the aspects that are impacted by the team size (such as productivity, \ndefect density, and project duration) can be normalized to reflect the size of the team \nthat you want to benchmark.\n Sources of\u00a0Benchmark Data\nThere are multiple ways to benchmark productivity against the industry. There are \nseveral international commercial organizations worldwide that provide benchmarking \nservices and that have collected a large amount of data through the years, examples of \nwhich are METRI, Premios, and QPMG.\u00a0There are also commercial estimation models \navailable that allow the users to benchmark their project estimates against industry \nknowledge bases (Galorath SEER or PRICE TruePlanning) or trendlines (QSM SLIM). \nBecause of the confidentiality of the data, these commercial parties usually won\u2019t \ndisclose the actual data that they use for their benchmarking services. Only the process \nand the results of the benchmark are usually communicated, not the actual data points \nused. External sources of benchmark data are particularly useful when not enough \ninternal data is available to benchmark internal projects on an apples to apples  basis. \nThese external sources can be tailored to reflect the situation in the organization as well \nas possible.\n ISBSG Repository\nThe only open source of productivity data is the ISBSG repository, which covers more \nthan 100 metrics on software projects. The ISBSG is an international independent and \nnot-for-profit organization based in Melbourne, Australia. Not-for-profit members of \nISBSG are software metrics organizations from all over the world. The ISBSG grows and \nexploits two repositories of software data: new development projects and enhancements \n(currently more than 9,000 projects) and maintenance and support (more than 1,100 \napplications). Data is submitted by consultants and practitioners in the industry. The \nreward for submitting data to ISBSG is a free benchmark report comparing the realized \nproductivity, quality, and speed against a few high-level industry peer groups.Chapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "212All ISBSG data is\n\u2022 Validated and rated in accordance with its quality guidelines\n\u2022 Current and representative of the industry\n\u2022 Independent and trusted\n\u2022 Captured from a range of organization sizes and industries\nAs the ISBSG data can be obtained in an Excel file, it is possible to analyze and \nto benchmark project productivity yourself. Simply select a relevant peer group and \nanalyze the data set using the most appropriate descriptive statistics, such as shown in \nthe example in the section \u201cBenchmarking in Practice. \u201d\n Internal Benchmark Data Repository\nIf the main reason for benchmarking is for internal comparison, with the objective to \nimprove, then the best source is always to have an internal benchmark repository. In \nsuch a repository, the cultural differences that have an impact on productivity (see \nChapter 3) are not present and normalizing can be done in a reliable way. When the \nprocess to build an internal repository for benchmark data is in place, ideally this \nprocess should be used to submit this data to ISBSG as well. In this way, the organization \nreceives a free benchmark on how they stand with regard to industry peers, and the \nISBSG database is strengthened with another data point.\n Benchmarking in\u00a0Practice\nTo put all the theory in practical perspective, we end this chapter with a simplified \nexample on how a benchmark is performed in practice. This example shows how \nimprovements can be found by comparing with others.\nAn insurance company has measured the productivity of ten completed Java \nprojects. The average PDR of these ten projects was ten hours per function point. To \nselect a relevant peer group in the ISBSG D&E repository, the following criteria could be \nused:\n\u2022 Data quality A or B (the best two categories in data integrity and data \ncompleteness)\n\u2022 Size measurement method: Nesma or IFPUG 4+ (comparable)Chapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "213\u2022 Industry sector = insurance\n\u2022 Primary programming language = Java\nAfter filtering the Excel file based on these criteria, the results can be shown in a \ndescriptive statistics table such as Table\u00a0 18-1 .\nAs productivity data is not normally distributed but skewed to the right (PDR \ncannot be lower than 0 but has no upper limit), it is customary to use the median \nvalue for the industry average instead of the average. In this case, the average \nproductivity of the insurance company lies between the 25th percentile and the \nmarket average (median). This may seem good, but the target may be in the best \n10 percent performance in the industry. In that case, there is still a lot of room for \nimprovement. A similar analysis can be made for other relevant metrics, such as \nquality (defects per FP), speed of delivery (FP per month) and cost (cost per FP). \nFrom these analyses it becomes clear on which aspect improvement is required. \nComparison of the underlying data with best-in-class peers or projects reveals \nthe differences between the benchmarked project and the best in class. These \ndifferences are input for improvement efforts.Table 18-1  Example Descriptive Statistics Table\nStatistic PDR\nnumber 174\nmin 3,1\n10% percentile 5,3\n25% percentile 8,2\nmedian 11,5\n75% percentile 15,2\n90% percentile 19,7\nmax 24,8Chapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "214 False Incentives\nBenchmarking, like any type of measurement, has a certain risk. People have a natural \ntendency to behave toward a better outcome of the measurement. Ill-defined measures \nwill lead to unwanted behavior, or as Amy J. Ko puts it:\nIn pursuit of productivity, however, there can be a wide range of unintended \nconsequences from trying to measure it. Moving faster can result in \ndefects. Measuring productivity can warp incentives. Keeping the pace of \ncompetitors can just lead to an arms race to the bottom of software quality.\nBenchmarking needs to be done on objects  that can be normalized to be truly \ncomparable. In software development this means a sprint, a release, a project, or a \nportfolio. You should not be benchmarking individuals. Why? The simple answer is that \nthere is no way to normalize people. More arguments against measuring productivity of \nindividual software developers can be found in Chapter 2. Although there is sufficient \nevidence that there is a 10:1 difference in productivity between programmers, they are \nalso exceedingly rare. An interesting example of what happens when you try to compare \nindividuals is in the blog \u201cYou are not a 10x software engineer. \u201d There are unmistakably \nsoftware developers who are much better than others, but this difference cannot be \nbenchmarked in a sensible way. When you compare individuals using their output per \nunit of time, then the junior team members who are building a lot of simple functions \nmight appear to be better than the brightest team member who solve the three most \ndifficult assignments while helping the juniors and reviewing the code of the other team \nmembers. This is illustrated with facts in Chapter 1.\n Summary\nBenchmarking is the process of comparing your organization\u2019s processes against \nindustry leaders or industry best practices (outward focus) or comparing your own \nteams (inward focus). By understanding the way the best performers do things, it \nbecomes possible to improve. One of the key challenges in the software industry is to \nmeasure productivity of completed sprints, releases, projects, or portfolios in an apples \nto apples  way so that this information can be used for processes such as estimation, \nproject control, and benchmarking. At this moment, only the standards for functional \nsize measurement comply with demands for standardized measurement procedures Chapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "215and intermeasurer repeatability to produce measurement results that can be compared \nacross domains to benchmark productivity. Benchmarking is useful only when \nevery aspect is the same, except for the aspect you want to benchmark. In practice, \nthis is hardly ever the case. To have a meaningful benchmark, all aspects not under \nscrutiny must be made the same. This is called normalizing . Based on mathematical \ntransformations or experience data, peer data can be normalized to reflect the \nconditions of the project that is benchmarked. There are multiple ways to benchmark \nproductivity. The best source is always to have an internal benchmark repository. In such \na repository, normalizing can be done in a reliable way. External sources of benchmark \ndata are particularly useful when not enough internal data is available to benchmark \ninternal projects on an apples-to-apples basis. These external sources can be tailored to \nreflect the situation in the organization as well as possible. Benchmarking, like any type \nof measurement, has a certain risk. People have a natural tendency to behave toward a \nbetter outcome of the measurement. Benchmarking needs to be done on objects that \ncan be normalized to be truly comparable. In software development, this means a sprint, \na release, a project, or a portfolio. You should not be benchmarking individuals.\n Key Ideas\nThe following are the key ideas from this chapter:\n\u2022 Benchmarking is necessary to compare productivity across teams \nand organizations.\n\u2022 Productivity can be compared across products, but you have to \ncompare the right thing.\n\u2022 Comparison across organization makes sense only if you do it in a \nstandardized way.Chapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "216 Further Reading\n\u2022 W ikipedia, on: Cyclomatic complexity,  \nhttp://en.wikipedia.org/wiki/Cyclomatic_complexity ,  \nLines of Code (LoC),  \nhttp://en.wikipedia.org/wiki/Source_lines_of_code , \nProductivity,  \nhttp://en.wikipedia.org/wiki/Productivity ,  \nUse Case Points,  \nhttp://en.wikipedia.org/wiki/Use_Case_Points .\n\u2022 Nesma, on IBRA points, http://nesma.org/themes/productivity/\nchallenges-productivity-measurement .\n\u2022 Scrum alliance, on Story points, http://scrumalliance.org/\ncommunity/articles/2017/January/story-point-estimations-\nin-sprints .\n\u2022 ISO, on: Information Technology project Performance Benchmarking \n(ISO/IEC 29155), http://iso.org/standard/74062.html , \nFunctional Size Measurement (ISO/IEC 14143), http://iso.org/\nstandard/38931.html .\n\u2022 ISBSG, on the source of benchmark data, http://isbsg.org/\nproject-data .\n\u2022 Amy J. Ko, on the downside of benchmarking, Chapter 3 in Caitlin \nSadowski, Thomas Zimmermann: Rethinking Productivity in \nSoftware Engineering, Apress Open, 2019.\n\u2022 Cier a Jaspan and Caitlin Sadowski, on the arguments against a single \nmetric for measuring productivity of software developers, Chapter 2 \nin Caitlin Sadowski, Thomas Zimmermann: Rethinking Productivity \nin Software Engineering, Apress Open, 2019.\n\u2022 Steve McConnell, on the underlying research of the 10x Software \nEngineer, http://construx.com/10x_Software_Development/\nOrigins_of_10X_-_How_Valid_is_the_Underlying_Research_/ .Chapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "217\u2022 Sean Cassidy, on the fact that you are most likely NOT a 10x \nSoftware Engineer, http://seancassidy.me/you-are-not-a-10x-\ndeveloper.html .\n\u2022 Yevgeniy Brikman, on the rarity of 10x Software Engineers, http://\nybrikman.com/writing/2013/09/29/the-10x-developer-is-not-\nmyth/ .\n\u2022 Lutz Prechelt, on why looking for the mythical 10x programmer is \nabout asking the wrong question, Chapter 1 in Caitlin Sadowski, \nThomas Zimmermann: Rethinking Productivity in Software \nEngineering, Apress Open, 2019.\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 18  BenChmarking: Comparing apples to\u00a0 apples"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "PART V\nBest Practices for \nProductivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "221\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_19CHAPTER 19\nRemoving Software \nDevelopment Waste \nto\u00a0Improve Productivity\nTodd Sedano, Pivotal, USA\nPaul Ralph, Dalhousie University, Canada\nC\u00e9cile P\u00e9raire, Carnegie Mellon University Silicon Valley, USA\n Introduction\nAs we have seen in previous chapters, measuring the productivity of software \nprofessionals is challenging and hazardous. However, we do not need sophisticated \nproductivity measures to recognize when time and effort are wasted. When we see \nsoftware engineers rewriting code because the previous version was hastily done, their \nproductivity is obviously suffering.\nIn project management, waste  refers to any object, property, condition, activity, or \nprocess that consumes resources without benefiting any project stakeholder. Waste in \na development process is analogous to friction in a physical process\u2014reducing waste \nimproves efficiency and productivity by definition.\nHowever, reducing waste can be challenging. Waste is often hidden by bureaucracy, \nmultitasking, poor prioritization, and invisible cognitive processes. People quickly \nacclimate to wasteful practices\u2014 that\u2019s just how we do things here . The actions necessary \nin tackling wastes are waste prevention , identification , and removal . Those actions \nrequire us to understand the kinds of waste present in software projects."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "222To better understand software development waste, we conducted an extended \nparticipant-observation grounded theory study at Pivotal Software. Pivotal is a large \nAmerican software development organization, known for using and evolving extreme \nprogramming [ 1]. Pivotal builds software products and provides agile transformation \nservices for its clients.\nGrounded theory is a research method for systematically generating scientific \nexplanations from empirical data. Participant-observation is a type of data collection \nin which the researcher takes part in the project to gain an insider\u2019s perspective. We \nobserved Pivotal teams working on agile transformation projects with engineers from \nPivotal\u2019s clients in various domains. The study involved two years and five months of \nparticipant-observation, 33 intensive open-ended interviews, and one year\u2019s worth of \nretrospection data. It is the first empirical study of waste in software development. For \nmore information about the research method, see Sedano et\u00a0al. [ 7].\n Taxonomy of\u00a0Software Development Waste\nDuring the study, we observed nine types of waste (Figure\u00a0 19-1 ). This section explains \neach waste type and associated tensions that complicate reducing the waste.\nFigure 19-1.  Types of Software Development Waste (\u00a9 Todd Sedano)Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "223 Building the\u00a0Wrong Feature or Product\nThe cost of building a feature or product that does not address user or business \nneeds.\nOne of the most serious types of waste is building features that no one wants or \nneeds. A more extreme version is building an entire product that no one wants or needs.\nFor example, on one Pivotal team, three engineers spent three years building a \nsystem without ever talking to potential users. The delivered system did not fulfill the \nusers\u2019 needs. After spending nine months trying to alter the system to meet user\u2019s needs, \nmanagement scrapped the project. Another example involved building a healthcare \nrelationship management system. During user-centered design, the team ignored user \nfeedback. After a year of trying to find people who would use the delivered system, they \nran out of money.\nWe observed two main causes of \u201cbuilding the wrong feature or product\u201d:\n\u2022 Ignoring user desiderata : This includes not doing user research, \nvalidation, or testing; ignoring user feedback; and working on \nfeatures with low user value.\n\u2022 Ignoring business desiderata : This includes not involving a business \nstakeholder, slow stakeholder feedback, and unclear product priorities.\nTechniques for avoiding or reducing this waste include:\n\u2022 Usability testing\n\u2022 Feature validation\n\u2022 Frequent releases\n\u2022 Participatory design\nBuilding the wrong features or products appears related to a specific tension: user \nversus business needs. In other words, sometimes users\u2019 needs conflict with business \nneeds. For example, for one mobile application, the marketing organization insisted on \nincluding the company news feed. Users did not want the news feed and perceived it as \nspam, lowering their opinion of the mobile application.Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "224 Mismanaging the\u00a0Backlog\nThe cost of duplicating work, expediting lower value user features, or delaying \nnecessary bug fixes.\nOne kind of prioritization problem specific to agile software development is backlog \ninversion . In principle, all of the stories are kept in a prioritized backlog such that whatever \nis on top of the backlog is what the product manager (or equivalent) wants done next. In \npractice, however, some product managers only prioritize the top n stories, after which is \na jumble of medium-priority, low-priority, and outdated stories. Backlog inversion occurs \nwhen the team gets ahead of the product manager and starts working on story n+1 .\nFor instance, on Monday, the product manager examines the backlog and  \nre- prioritizes the next seven stories. The team finishes those seven stories and begins \nworking on stories eight, nine, and ten. Since these stories have not been prioritized \nrecently, the team might unknowingly be working on low-priority stories.\nMismanaging the backlog includes all the waste associated with poor prioritization. \nWe observed numerous causes of \u201cmismanaging the backlog\u201d waste:\n\u2022 Backlog inversion\n\u2022 Working on too many features simultaneously\n\u2022 Duplicated work\n\u2022 Not enough ready stories\n\u2022 Imbalance between feature work and bug fixing\n\u2022 Delaying testing or critical bug fixing\n\u2022 Capricious thrashing (see below)\nSolutions for avoiding or reducing this waste include:\n\u2022 Prioritizing the backlog several times a week\n\u2022 Minimizing work in progress by finishing features before starting  \nnew ones\n\u2022 Updating the backlog with current work in progress\n\u2022 Writing enough stories to stay ahead of development\n\u2022 Routinely working on bug fixes while doing feature development\n\u2022 Receiving feedback from users before making changesChapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "225This waste is also related to a tension: intransigence versus capricious trashing. \nResponding to change quickly is a core tenet of agile development and often thought \nof as the opposite of refusing to change. However, responding to change is more like a \nmiddle ground between intransigence (unreasonably refusing to change) and thrashing \n(changing features too often, especially arbitrarily alternating between equally good \nalternatives). As an example of trashing, on one project, the launch was delayed while the \nbusiness fiddled with the sequence and number of steps in the user registration process.\n Rework\nThe cost of altering delivered work that should have been done correctly but was not.\nNot all rework is waste. Wasteful rework refers to the cost of altering delivered work \nthat should have been done correctly but was not . Reworking a product because of \nunforeseeable or unpredictable circumstances is not waste.\nFor example, one enterprise team had been shipping Python code while \naccumulating technical debt over time. The code became so unmanageable that they \ndecided to re-write it in Go from scratch. We see the entire rewrite as rework because \nignoring technical debt impairs the understandability and modifiability of software over \ntime, and the team could have avoided the rework by refactoring the original Python \ncode before it became unmanageable.\nWe observed the following causes of \u201crework\u201d waste:\n\u2022 Technical debt, that is, technical work delayed by taking shortcuts to \nsave time and meet deadlines.\n\u2022 Ambiguous story definition, including ambiguous acceptance criteria \nand mock-ups.\n\u2022 Rejected stories, that is, when a product manager rejects a story \nimplementation because it does not satisfy the acceptance criteria.\n\u2022 Defects, including poor testing strategy and not performing root-  \ncause analysis on defects.\nSolutions for avoiding or reducing this waste include:\n\u2022 Continuous refactoring\n\u2022 Reviewing acceptance criteria before beginning a storyChapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "226\u2022 Verifying acceptance criteria before finishing a story\n\u2022 Improving testing strategy and root-cause analysis on bugs\nRefactoring code to handle new features is not waste. A team cannot anticipate and \npredict future work to be done. Instead, we recommend teams focus on aligning their \ncode with their current understanding of the system features and code design. A team \nthat routinely refactors its code reduces onboarding developer costs and increases its \nability to deliver new functionality. Clean code has additional benefits: it is easier to \nunderstand, easier to modify, and has fewer defects. Refactoring code to support new \nfunctionality is part of the inherent cost of the new functionality. In contrast, rushing a \nfeature introduces technical debt, which leads to rework and extraneous cognitive load.\nRework waste is related to a ubiquitous tension between doing things well and doing \nthings quickly. A recent study of decision-making during programming found that this \ntension affects many developer actions, including whether to refactor problematic code and \nwhether to implement the first approach that comes to mind or research better ones [ 5].\n Unnecessarily Complicated or Complex Solutions\nThe cost of creating a more complicated solution than necessary; a missed \nopportunity to simplify features, user interface, or code.\nUnnecessary complexity is intrinsically wasteful and harmful [ 3]. The more \ncomplicated a system is, the more difficult it is to learn, use, maintain, extend, and \ndebug.\nUnnecessary feature complexity wastes users\u2019 time as they struggle to understand \nhow to use the system and achieve their objectives. For instance, one product required \nthe user to fill in form fields not related to the task at hand. Implementing and \nmaintaining those unnecessary fields is a waste of developer time and an opportunity to \nintroduce defects.\nWe observed the following causes of \u201cunnecessarily complicated or complex \nsolutions\u201d waste:\n\u2022 Unnecessary feature complexity from the user\u2019s perspective. This \nincludes overly complex user interactions and business processes.Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "227\u2022 Unnecessary technical complexity from the team\u2019s perspective. This \nincludes duplicating code, lack of interaction design reuse, and \noverly complex technical design.\nSolutions for avoiding or reducing this waste include:\n\u2022 Prefer simpler designs for user interaction\n\u2022 Prefer simpler designs for software code\n\u2022 Consider whether each proposed feature is worth the additional \ncomplexity it will introduce\nWe observed the following tension in relation to this waste: big design up-front \nversus incremental design. Up-front designs can be based on incorrect or out-of-date \nassumptions, leading to expensive rework especially in rapidly changing circumstances. \nHowever, rushing into implementation can produce ineffective emergent designs, \nalso leading to rework. Despite the emphasis on responsiveness in agile development, \ndesigners struggle to backtrack on important decisions and features [ 2].\nThe logic of avoiding rework underlies disagreement over big design up-front versus \nincremental design\u2014proponents of both approaches feel that they are reducing rework. \nHowever, on the observed projects, no amount of up-front consideration appears \nsufficient to predict user feedback and product direction. Therefore, the observed teams \npreferred to incrementally deliver functionality and delay integrating with technologies \nuntil a feature required it.\n Extraneous Cognitive Load\nThe costs of unnecessary mental effort.\nHuman beings have limited working memory and mental resources. Technically, \ncognitive load refers to how much working memory a task requires. Here, however, \nwe are using extraneous cognitive load more generally to mean the costs of making \nsomething unnecessarily mentally taxing.\nFor example, one project used five separate test suites that each worked differently. \nRunning the tests, detecting failures, and rerunning just a failed test required learning \nfive different systems. This was unnecessarily cognitively taxing in two senses: developers \nhad to learn the five systems initially, and developers had to remember how all five \nsystems worked and avoid confusing them.Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "228We observed the following causes of \u201cextraneous cognitive load\u201d waste:\n\u2022 Technical debt\n\u2022 Complex or large stories\n\u2022 Inefficient tools and problematic APIs, libraries, and frameworks\n\u2022 Unnecessary context switching\n\u2022 Inefficient development flow\n\u2022 Poorly organized code\nSolutions for avoiding or reducing this waste include:\n\u2022 Refactor code that is difficult to understand\n\u2022 Decompose large, complex stories into smaller, simpler stories\n\u2022 Replace hard-to-use libraries\n\u2022 Work on one task at a time until it is completed; avoid \u201cblocking\u201d \ntasks (i.e., putting a task on hold to work on something else)\n\u2022 Improve the development flow including better scripts and tools\n Psychological Distress\nThe costs of burdening the team with unhelpful stress.\nStress can be beneficial (\u201ceustress\u201d) or harmful (\u201cdistress\u201d). For instance, a little \npressure from knowing that the client has high expectations can motivate a team to \ndeliver a better product. Contrastingly, worrying about a sick family member, being \nyelled at by an angry client, or thinking you might lose your job can reduce performance.\nPsychological distress can be either harmful stress or just too much stress. How \nmuch stress is too much depends on the person, but everyone has a limit after which \nmore stress lowers performance. Both distress or extreme stress are distracting and \ndraining. Stress can make people feel anxious, overwhelmed, and unmotivated. \nTherefore, we see psychological distress as intrinsically wasteful.\nFor example, we observed stress resulting from snarky remarks about other teams \nor other developers on mailing lists, including \u201cWow! 22 commits with zero pull \nrequests there. \u201d Another example was a countdown to a release date written on an office Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "229whiteboard. The team felt that over-emphasizing the deadline was increasing stress and \nleading to poor technical decisions. Eventually, the countdown was erased from the \nwhiteboard.\nDifferent people find different experiences distressing. However, some common \ndistress-inducing experiences we have observed include:\n\u2022 Low team morale\n\u2022 Rush mode\n\u2022 Interpersonal or team conflict\n\u2022 Inter-team conflict\nA wealth of research investigates the nature, causes, and effects of stress. A full \ntreatment of stress in software engineering would fill a large book. The present study, in \ncontrast, supports only a few basic recommendations for detecting and reducing stress.\n\u2022 In our experience, detecting distress is not difficult\u2014simply asking \nteam members, \u201cHow are things going?\u201d is usually sufficient.\n\u2022 Stress related to deadlines can sometimes be mitigated by reducing \nscope or extending the deadline.\n\u2022 Stress related to interpersonal conflict can be mitigated by facilitated \nmediation.\n Knowledge Loss\nThe cost of re-acquiring information that the team once knew.\nA team can lose knowledge when a person with unique knowledge leaves, when \nan artifact containing unique knowledge is lost, or when the knowledge is sequestered \nwithin one person, group or system. Regardless of how the knowledge was lost, the cost \nof re-acquiring it is a type of waste.\nWe observed the following causes of \u201cknowledge loss\u201d waste:\n\u2022 Team churn (that is, staff rotating on and off a team)\n\u2022 Knowledge silos (that is, where important information is sequestered \nwithin one person, group or system)Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "230In Sedano et\u00a0al. [ 6], we propose several practices for encouraging knowledge sharing \nand continuity including continuous pair programming, overlapping pair rotation, and \nknowledge pollination (e.g., stand-up meetings). Although we have not observed it \ndirectly, code review may also help knowledge sharing and prevent knowledge loss.\nThis waste is related to the tension between sharing knowledge through interaction \nvs. documentation. One of the key insights of the agile literature is that sharing \nknowledge face-to-face is usually more effective than sharing knowledge through written \ndocuments. Indeed, often documentation quickly becomes outdated and unreliable.\n Waiting/Multitasking\nThe cost of idle time, often hidden by multitasking.\nWhen something goes wrong in a manufacturing plant, we can sometimes see \npeople waiting around. If the boxing team runs out of boxes, they might just stand idle \nuntil more boxes arrive. This is obviously waste.\nWaiting waste is less obvious among software professionals because waiting is \noften hidden by multitasking. For example, if the integration process takes an hour, \nprogrammers tend to switch to some other, lower-priority work while waiting for \nintegration.\nWe observed the following causes of \u201cwaiting/multitasking\u201d waste:\n\u2022 Slow or unreliable tests\n\u2022 Missing information, people, or equipment\n\u2022 Product managers taking too long to provide needed information\n\u2022 Context switching between tasks\nSolutions for avoiding or reducing this waste include:\n\u2022 Expose waiting time by limiting work in progress\n\u2022 For short waits, take breaks (e.g., play table tennis) instead of task \nswitching\n\u2022 For longer waits, use waiting time to work on the cause of the wait \n(e.g., shorten a long build)Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "231Multitasking introduces waste in two ways. First, multitasking involves a mental \ntransition to the new task, which can be quite time-consuming, especially if the new \ntask is cognitively demanding. Second, multitasking creates dilemmas when the original \nhigh-priority task becomes available again. Do developers finish the second lower-  \npriority task (delaying higher priority work) or immediately switch back to the original \ntask (leaving work-in-progress)?\nEngineers remaining idle for more than a few minutes is typically viewed negatively. \nThus, engineers tend to prefer context-switching over waiting despite the drawbacks \ndescribed above.\n Ineffective Communication\nThe cost of incomplete, incorrect, misleading, inefficient, or absent communication \namong project stakeholders.\nIneffective communication is intrinsically wasteful. For example, a product manager \nnotices a bug and adds it to the backlog but does not explain how to reproduce it. The \nteam ends up sleuthing\u2014either experimenting with different possible combinations \nor asking the product manager for additional details. As another example, a developer \nchanges key configuration information that affects all other developers on the team. \nInstead of telling everyone that they need to pull the latest code, the developer posts \nabout the change via asynchronous communication (e.g., Slack). Some developers do \nnot see this communication and wonder why their code stops working. They waste time \ntrying to figure out the solution when the answer was already known within the team.\nWe observed the following causes of \u201cineffective communication\u201d waste:\n\u2022 Teams that are too large.\n\u2022 Asynchronous communication, which is especially problematic \nfor distributed teams, distributed stakeholders, and when the team \ndepends on other teams or opaque processes outside the team.\n\u2022 One person or a few people dominating the conversation or not \nlistening.\n\u2022 Inefficient meetings including lack of focus during meetings, \nskipping retros, not discussing blockers each day, and meetings \nrunning over (e.g. long stand-ups).Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "232Like stress, copious research has investigated communication effectiveness, and \na complete account is beyond the scope of this chapter. However, we can make some \nsimple recommendations.\n\u2022 Synchronous (especially face-to-face) communication seems more \neffective for most people, most of the time.\n\u2022 Conversational turn-taking, where participants take turns speaking \none at a time, leads to better shared understanding.\n\u2022 More powerful participants (e.g., white male project manager) \ninterrupting less powerful participants (e.g., nonwhite female junior \ndeveloper) has a chilling effect on diversity of thought and quality of \ngroup decision-making. Other participants can mitigate interruptions \nby returning to the interrupted speaker by, for example, saying \u201cCan \nwe come back to what Alexis was saying about.... \u201d\nIneffective communication might lead to the other types of waste. For instance, \nineffective communication resulting in delays might lead to the waiting waste. Ineffective \ncommunication resulting in misunderstanding user or business needs might lead to \nbuilding the wrong feature or product, or misunderstanding the existing solution might \nlead to building an overly complex solution and extraneous cognitive load. Ineffective \ncommunication resulting in poor decision-making might lead to mismanaging the \nbacklog. Ineffective communication resulting in technical mistakes might lead to \ndefects and rework. Ineffective communication resulting in misunderstandings among \nteam members might lead to conflicts and psychological distress. These are just a \nfew examples highlighting the importance of effective communication and how poor \ncommunication can generate waste.\n Additional Wastes in\u00a0Pre-agile Projects\nSince Pivotal is lean and agile, it has already eliminated some common types of waste. \nProfessionals using waterfall, plan-driven, or other pre-agile approaches may experience \nwaste from unnecessary bureaucracy. Some bureaucracy is necessary to govern Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "233(especially large) organizations. However, much bureaucracy is simply pointless, and \nsome is actively harmful. Examples include:\n\u2022 Overplanning : This involves estimating budgets, schedules, phases, \nmilestones, or tasks at a level of detail that is not supported by the \ninformation at hand or the stability of the project environment. When \na plan requires copious guesses and assumptions, it is a fantasy, not \na plan. Overplanning not only wastes the planner\u2019s time but also \nengenders psychological distress when reality departs from the plan.\n\u2022 Overspecifying : This involves specifying requirements or design at \na level of detail that is not supported by the information at hand. \nOverspecifying is a common problem in projects with large, up-front \nrequirements and design phases. Warning signs include copious \noptional, low-priority, or low-confidence requirements; developing \nan elaborate architecture while stakeholders are still arguing about \nthe goals of the project; fleshing out features that will not be built for \nmonths, if ever. Overspecification is not only a waste of time, it can \nconstrain developers, obscure better solutions, and reduce creativity.\n\u2022 Performance metrics : Perhaps the main theme to emerge from the \nstudy of performance measurement is that measuring performance \nreduces performance. All metrics can be gamed, and gaming \nmetrics is distracting and time-consuming. Measuring people just \nmotivates them to engage in metric-optimizing theatrics, which are \nusually less efficient than what they were doing before the metrics. \nAttempts to quantify performance are therefore not just wasteful but \noften counterproductive, especially where bonuses are tied to the \nmeasurements [ 4].\n\u2022 Pointless documentation : Some documentation is necessary\u2014even \ncritical\u2014when it helps achieve a specific goal. However, some \nprojects have binders full of documentation that will not be read \nbefore growing out-of-date, if ever. Pointless documentation is a form \nof ineffective communication  waste.Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "234\u2022 Process waste : Processes can be wasteful when they generate \npointless documentation (reports, forms, formal requests), pointless \nmeetings (like large company or department-wide meetings, not \nteam meetings), pointless approvals (due to not trusting the people \nwho do the work), and handoffs.\n\u2022 Handoffs : Organizations that divide projects into phases and have \ndifferent teams involved in different phases of the same project \nexperience handoff waste. Handoff waste is the cost (in knowledge, \ntime, resources, and momentum) of passing a project from one team \nto another. Handoffs contribute to other wastes including knowledge \nloss, ineffective communication, and waiting.\nWhen following pre-agile practices, two general strategies may help reduce waste. \nFirst, hunt for slow-feedback loops, as shortening feedback loops often helps to reduce \nwaste. Second, actively remove the policies responsible for the waste. One problem with \nbureaucracy is that, once a policy is made, following the policy becomes the bureaucrat\u2019s \ngoal, regardless of the organizational goals the policy was written to support. Waste is \nthe inevitable byproduct of optimal actions for achieving organizational goals diverging \nfrom the actions prescribed by flawed or outdated policies.\n Discussion\nThe above discussion may appear to suggest that all problems are types of waste, but \nthat is not the case. This section discusses what is special about waste, and gives more \nsuggestions for removing waste.\n Not All Problems Are Wastes\nIt is tempting but incorrect to label anything that goes wrong on a project as waste. \nHuman beings make mistakes. A developer may accidentally push code before running \nthe test suite. Our knowledge is limited. A product manager may write an impractical \nuser story because he or she does not know of some particular limitation. We forget. A \ndeveloper might forget that adding a new type to the system necessitates modifying a \nconfiguration file. Whether we conceptualize these sorts of errors as waste is a matter \nof opinion, but focusing on them is unhelpful because they are often unpredictable. Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "235It is better to focus on systemic  waste: waste that affects a wide variety of projects in \nconsistent, predictable, and preventable ways.\nSimilarly, it is important to distinguish foreseeable errors from actions that only \nseem like errors in hindsight. Suppose that users clearly indicate that a particular feature \nis not desirable, but we build it anyway, and sure enough, no one uses the feature. \nObviously, this is waste. In contrast, suppose users are clamoring for a feature, so we \nbuild it, but it\u2019s quickly abandoned as users realize it does not really work for them. \nThis is not an error; it\u2019s learning. Sometimes, building a feature, prioritizing the wrong \nthing, refactoring, and communicating badly are the only ways of learning what is \nactually needed. The concept of waste should not be misused to demonize incremental \ndevelopment and learning.\n Reducing Waste\nReducing waste is often straightforward. The countdown on the whiteboard is stressing \nout the team? Erase it. Five separate test suites take forever to run? Integrate them. \nBuilding a feature no one has asked for? Stop. User interface is too complex? Simplify \nit. Not enough knowledge sharing among programmers? Pair-program. The official \napproval process is inefficient? Change it. Sometimes this is easier said than done, but \nit\u2019s not rocket science either.\nThe problem is that waste is often hidden. Rework is hidden in \u201cnew features\u201d and \n\u201cbug fixes. \u201d Building the wrong features is hidden by lack of good feedback. Knowledge \nloss is hidden by not realizing the organization used to know this information. We hide \ndistress to avoid looking weak. Bureaucracy hides waste behind an official policy. That \nis why this chapter describes all different sorts of waste\u2014waste is easier to identify if you \nknow what to look for.\nOnce we have identified some waste, there are three broad approaches for reducing \nit: prevention, incremental improvement, and \u201cgarbage day\u201d:\n\u2022 Prevention : This involves creating systems that impede waste. User \nresearch impedes \u201cbuilding the wrong feature\u201d waste. Continuous \nrefactoring impedes \u201crework\u201d waste. Pair programming, peer code \nreview, and overlapping pair rotation impede \u201cknowledge loss\u201d [ 6]. \nDaily stand-ups impede \u201cinefficient communication\u201d waste.Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "236\u2022 Incremental improvement : Waste reduction can be approached as \na continuous improvement practice, running parallel to feature \ndevelopment. Waste reduction can be discussed in retrospective \nmeetings, and one or two waste reduction tasks can be included in \nthe backlog each week. This is a good approach for most teams, since \nsuspending development for weeks to remove waste is not tenable \nin most organizations and could reduce team morale and customer \nsatisfaction.\n\u2022 Focused waste reduction: garbage day/trash pickup day : Some \ncompanies set aside special periods where employees are free to \nwork autonomously. For example, Pivotal has a \u201chack day\u201d during \nwhich employees can work on a theme or whatever they want. \nOrganizations can implement a similar set period (\u201cgarbage day\u201d) in \nwhich employees tackle some source of waste, for instance, speeding \nup the integration process, removing redundant tests, simplifying an \novercomplicated process, or just meeting with co-workers to share \nsiloed knowledge.\nA related question is, \u201cIf we have identified several different kinds of waste, what \nshould we tackle first?\u201d We observed teams prioritizing waste removal using the \nfollowing procedure:\n 1. Individually list several wastes.\n 2. Plot each waste on a graph like Figure\u00a0 19-2 .\n 3. Prioritize wastes beginning with the best ratio of easy to remove \nand high impact (e.g., W1) and working your way down to wastes \nthat are harder to remove and have less impact (e.g., W8).\n 4. Add waste reduction to the backlog (as chores) and prioritize \nthese chores as time permits.Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "237Of course, eliminating some (low impact, hard-to-remove) wastes may not be worth \nthe cost. For example, having a distributed team most often contributes to ineffective \ncommunication waste, but it might be the most practical solution when experts with \nrare skills are distributed across the globe. Eliminating waste should be and typically is a \nsecondary goal. Waste elimination should not displace the primary goal of delivering a \nquality product.\nHere, we recommend prioritizing wastes based on our best guesses as to their \nimpact. Precisely quantifying the impact of each waste is impractical. How would you \nquantify the inefficiencies of overburdening developers with unhelpful stress and the \nimpact on their health, or the impact of knowledge loss, when the team does not even \nknow what knowledge is being lost? Quantifying waste might be a good PhD project but \nis likely not worth the trouble for most professional teams.Figure 19-2.  Prioritizing waste removalChapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "238 Conclusion\nIn summary, software waste  refers to project elements (objects, properties, conditions, \nactivities, or processes) that consume resources without producing benefits. Wastes are \nlike friction in the development process. An important step in tackling this friction is \nwaste awareness and identification. During our study, we identified nine main types of \nwaste in agile software projects: building the wrong feature or product, mismanaging \nthe backlog, rework, unnecessarily complex solutions, extraneous cognitive load, \npsychological distress, waiting/multitasking, knowledge loss, and ineffective \ncommunication. For each waste type, we proposed some suggestions to reduce the \nwaste. Reducing wastes removes friction and hence improves productivity.\nSoftware professionals have become increasingly focused on productivity (or \nvelocity ), often leading to increasingly risky behavior. Moving as fast as possible is great \nuntil someone quits, gets sick, or goes on vacation and the team suddenly realizes that \nno one else knows how a large chunk of the system works or why it was built that way. \nFor many companies, stability and predictability are more important than raw speed. \nMost firms need software teams that steadily deliver value, week after week and month \nafter month, despite unexpected problems, disruptions, and challenges.\nEliminating waste is just one way to forge more resilient, disruption-proof teams. \nThis work on waste is part of a larger study of sustainability and collaboration in \nsoftware projects. In Sedano et\u00a0al. [ 6], we propose a theory of sustainable software \ndevelopment that extends and refines our understanding of extreme programming with \nnew, sustainability-focused principles, policies, and practices. The principles include \nengendering a positive attitude toward team disruption, encouraging knowledge \nsharing and continuity, and caring about code quality. The policies include team \ncode ownership, shared schedule, and avoiding technical debt. The practices include \ncontinuous pair programming, overlapping pair rotation, knowledge pollination, test-  \ndriven development, and continuous refactoring.\nBased on our experiences, none of the results presented in this chapter appears \nunique to Pivotal Software or extreme programming. However, our research method \ndoes not support statistical generalization to contexts beyond the observed teams at \nPivotal Software. Therefore, researchers and professionals should adapt our findings and \nrecommendations to their own contexts, case by case.Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "239 Key Ideas\nThe following are the key ideas from this chapter:\n\u2022 There are several different types of preventable \u201cwastes\u201d that occur \nduring software development and represent lost productivity.\n\u2022 While it may be hard to define and measure productivity, identifying/\nreducing waste is an effective way to become more productive.\n References\n [1] Kent Beck and Cynthia Andres. Extreme Programming Explained: \nEmbrace Change (2nd Edition). Addison-Wesley Professional, \n2004.\n [2] Nigel Cross. Design cognition: results from protocol and \nother empirical studies of design activity. In Design knowing \nand learning: Cognition in design education. C.\u00a0Eastman, \nW.C.\u00a0Newstetter, and M.\u00a0McCracken, eds. Elsevier Science.  \n79\u2013103. 2001.\n [3] John Maeda. The Laws of Simplicity. MIT Press. 2006.\n [4] Jerry Muller. The Tyranny of Metrics. Princeton University Press. \n2018.\n [5] Paul Ralph and Ewan Tempero. Characteristics of decision-\nmaking during coding. In Proceedings of the International \nConference on Evaluation and Assessment in Software \nEngineering, 2016.\n [6] Todd Sedano, Paul Ralph, and C\u00e9cile P\u00e9raire. Sustainable software \ndevelopment through overlapping pair rotation. In Proceedings of \nthe International Symposium on Empirical Software Engineering \nand Measurement, 2016.\n [7] Todd Sedano, Paul Ralph, and C\u00e9cile P\u00e9raire. Software \ndevelopment waste. In Proceedings of the 2017 International \nConference on Software Engineering, 2017.Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "240Open Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 19  removing Software Development waSte to\u00a0 improve proDuCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "241\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_20CHAPTER 20\nOrganizational  \nMaturity: The\u00a0Elephant \nAffecting Productivity\nBill Curtis, CAST Software, USA\nThe maturity of an organization\u2019s software development environment impacts the \nproductivity of its developers and their teams [ 5]. Consequently, organizational \nattributes should be measured and factored into estimates of cost, schedule, and \nquality. This chapter presents an evolutionary model of organizational maturity, how \nthe model can guide productivity and quality improvements, and how its practices can \nbe adapted to evolving development methods.\n Background\nWhile working on improving software development at IBM in the 1980s, Watts \nHumphrey took Phil Crosby\u2019s course on quality management that included a \nmaturity model for improving quality practices [ 1]. Crosby\u2019s model listed five stages of \nimprovement through which a collection of quality practices should progress. While \ntraveling home, Humphrey realized that Crosby\u2019s model would not work because it \nresembled approaches used for decades with little sustainable success. He realized past \nimprovement efforts died when managers and developers sacrificed improved practices \nunder the duress of unachievable development schedules. Until he fixed the primary \nproblems facing projects, productivity improvements and quality practices had little \nchance to succeed."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "242During the late 1980s, Humphrey developed an initial formulation of his Process \nMaturity Framework [ 6] in the Software Engineering Institute at Carnegie Mellon \nUniversity. In the early 1990s Mark Paulk, Charles Weber, and I transformed this \nframework into the Capability Maturity Model for Software (CMM) [ 10]. Since then the \nCMM has guided successful productivity and quality improvement programs in many \nsoftware organizations globally. An organization\u2019s maturity level is appraised in process \nassessments led by authorized lead assessors.\nAnalyzing data from CMM-based improvement programs in 14 companies, James \nHerbsleb and his colleagues [ 5] found a median annual productivity improvement of \n35 percent, ranging from 9 percent to 67 percent across companies. Accompanying this \nimprovement was a median 22 percent increase in defects found prior to testing, a median \nreduction of 39 percent in field incidents, and a median reduction in delivery time of \n19 percent. Based on cost savings during development, these improvement programs \nachieved a median return on investment of 5 to 1. How were these results achieved?\n The Process Maturity Framework\nThe Process Maturity Framework has evolved over the past 30 years while sustaining \nits basic structure. As described in Table\u00a0 20-1 , this framework consists of five maturity \nlevels, each representing a plateau of organizational capability in software development \non which more advanced practices can be built. Humphrey believed that to improve \nproductivity, impediments to sound development practices should be removed in a \nspecific order. For instance, level 1 describes organizations with inconsistent or missing \ndevelopment practices. Too often crisis-driven projects rely on heroic efforts from \ndevelopers who work nights and weekends to meet ridiculous schedules. Until project \ncommitments and baselines can be stabilized, developers are trapped into working too \nfast, making mistakes, and having little time to correct them.Chapter 20  Organizati Onal Maturity: the\u00a0elephant affeCting prOduCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "243The path to improvement begins when project managers or team leaders stabilize \nthe project environment by planning and controlling commitments, in addition to \nestablishing baseline and change controls on requirements and deliverable products. \nOnly when development schedules are achievable and product baselines stable \ncan developers work in an orderly, professional manner. Achieving level 2 does not \nforce consistent methods and practices across the organization. Rather, each project \nadopts the practices and measures needed to create achievable plans and rebalance \ncommitments when the inevitable requirements or project changes occur. When \nunachievable commitments are demanded by higher management or customers,  Table 20-1.  Process Maturity Framework\nMaturity Level Attributes\nLevel 5\u00a0\u2013 Innovating\nCMMI \u2013 Optimizing\u2022 performance gaps needing innovative improvements identified\n\u2022 innovative technologies and practices continually investigated\n\u2022 experiments conducted to evaluate innovation effectiveness\n\u2022 Successful innovations deployed as standard practices\nLevel 4\u00a0\u2013 Optimized\nCMMI\u00a0\u2013 Quantitatively\n             Managed\u2022 projects managed using in-process measures and statistics\n\u2022 Causes of variation are managed to improve predictability\n\u2022 root causes of quality problems are analyzed and eliminated\n\u2022 Standardized processes enable reuse and lean practices\nLevel 3\u00a0\u2013 Standardized\nCMMI \u2013 Defined\u2022 development processes standardized from successful practices\n\u2022 Standard processes and measures tailored to project conditions\n\u2022 project artifacts and measures are retained, and lessons shared\n\u2022 Organization-wide training is implemented\nLevel 2\u00a0\u2013 Stabilized\nCMMI \u2013 Managed\u2022 Managers balance commitments with resources and schedule\n\u2022 Changes to requirements and product baselines are managed\n\u2022 Measures are implemented for planning and managing projects\n\u2022 developers can repeat sound practices in stable environments\nLevel 1\u00a0\u2013 Inconsistent\nCMMI\u00a0\u2013 Initial\u2022 development practices are inconsistent and often missing\n\u2022 Commitments are often not balanced with resources and time\n\u2022 poor control over changes to requirements or product baselines\n\u2022 Many projects depend on unsustainable heroic effortChapter 20  Organizati Onal Maturity: the\u00a0elephant affeCting prOduCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "244level 2 managers and team leaders learn to say \u201cno\u201d or diplomatically negotiate altered \nand achievable commitments.\nOnce projects are stable, the standard development processes and measures that \ncharacterize level 3 can be synthesized across the organization from practices and \nmeasures that have proven successful on projects. Implementation guidelines are \ndeveloped from past experience to tailor practices for different project conditions. \nStandard practices transform a team/project culture at level 2 into an organizational \nculture at level 3 that enables an economy of scale. CMM lead assessors often report that \nstandard processes are most frequently defended by developers because they improved \nproductivity and quality and made transitioning between projects much easier.\nOnce standardized processes and measures have been implemented, projects can \nuse more granular in-process measures to manage the performance of development \npractices and the quality of their products across the development cycle. Process \nanalytics that characterize level 4 are used to optimize performance, reduce variation, \nenable earlier adjustments to unexpected issues, and improve prediction of project \noutcomes. Standardized development practices establish a foundation on which \nother productivity improvements such as component reuse and lean practices can be \nimplemented [ 7].\nEven when optimized to their full capability, processes may not achieve the \nproductivity and quality levels required in a competitive environment or for demanding \nrequirements. Consequently, organization must identify and evaluate innovations \nin technology, processes, workforce practices, etc., that can dramatically improve \nproductivity and quality outcomes beyond existing performance levels. At level 5, the \norganization moves into a continuous innovation loop driven by specific targets for \nimprovement that will change over time.\nThe Process Maturity Framework can be applied to individual processes\u2014the so-  \ncalled continuous approach. However, this framework is most effective when applied as \na unique guidebook for organizational change and development. If the organization does \nnot change, individual best practices typically will not survive the stress of crisis-driven \nchallenges. This approach is consistent with observations on organizational systems in \nexceptionally successful businesses described in Jim Collin\u2019s books Built to Last  and Good \nto Great .Chapter 20  Organizati Onal Maturity: the\u00a0elephant affeCting prOduCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "245 The Impact of\u00a0Maturity on\u00a0Productivity and\u00a0Quality\nOne of the earliest and best empirical studies of a maturity-based process improvement \nprogram was reported by Raytheon [ 2, 4, 8]. Raytheon\u2019s time reporting system collected \ndata in effort categories drawn from a cost of quality model designed to show how \nimprovements in product quality increased productivity and reduced costs. This model \ndivided effort into four categories:\n\u2022 Original design and development work\n\u2022 Rework to correct defects and retest the system\n\u2022 Effort devoted to first-run testing and other quality assurance \nactivities\n\u2022 Effort in training, improvement, and process assurance to prevent \nquality problems\nOver the course of their improvement program (Table\u00a0 20-2 ), Raytheon reported that \nthe percentage of original development work increased from only a third of the effort at \nlevel 1 to just over half at level 2, two-thirds at level 3, and three-quarters at level 4. At the \nsame time, rework was cut in half at level 2 and declined by a factor of almost 7 at level 4. \nAs they achieved level 4, Raytheon reported that productivity had grown by a factor of 4 \nfrom the level 1 baseline.\nTable 20-2.  Raytheon\u2019s Distribution of Work Effort by CMM Level\nYear CMM LevelPercent of total effort Productivity  \ngrowth Original work Rework First-run tests Prevention\n1988 1 34% 41% 15%   7% baseline\n1990 2 55% 18% 13% 12% 1.5 X\n1992 3 66% 11% 23% 2.5 X\n1994 4 76%   6% 18% 4.0 X\nNote 1:  Table\u00a0 20-2 was synthesized from data reported in Dion [ 2], Haley [ 4], and  \nLyndon [ 8]. Note 2:  Effort for first-run tests and prevention were collapsed into one \ncategory in 1992. Note 3:  Productivity growth is in factors compared to the 1988 baseline.Chapter 20  Organizati Onal Maturity: the\u00a0elephant affeCting prOduCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "246As evident in these data, productivity was heavily affected by the amount of rework. \nThe proportion of rework is usually high prior to initiating an improvement program, \nwith reports of 41 percent at Raytheon, 30 percent at TRW [ 14], 40 percent at NASA [ 15], \nand 33 percent at Hewlett Packard [ 3]. Stabilizing baselines and commitments enabled \ndevelopers to work in a more disciplined, professional manner, reducing mistakes \nand rework and thereby improving productivity. The amount of initial testing stayed \nthe roughly the same, while the retesting required after fixing mistakes declined. The \nextra effort devoted to the improvement program (prevention) was more than offset \nby reduced rework. Accompanying productivity growth was a 40 percent reduction in \ndevelopment costs per line of code by level 3.\nThe size of Raytheon\u2019s productivity growth in moving from level 3 to level 4 is difficult \nto explain from quantitative management practices alone. Further investigation revealed \na reuse program that reduced the effort required to develop systems. Corroborating \nresults on the productivity impact of reuse at level 4 were reported by Omron [ 11] and \nBoeing Computer Services [ 13]. Standardized processes at level 3 appear to create the \nnecessary foundation of rigorous development practices and trusted quality outcomes \nneeded to convince developers it is quicker to reuse existing components than develop \nnew ones.\n Updating Maturity Practices for\u00a0an\u00a0Agile-DevOps \nEnvironment\nIn the early 2000s the U.S.\u00a0Department of Defense and aerospace community expanded \nthe CMM to include system engineering practices. The new architecture of the \nCapability Maturity Model Integration (CMMI) dramatically increased the number of \npractices and reflected the ethos of large defense programs. In the opinion of many, \nincluding some authors of the original CMM, CMMI was bloated and required excessive \npractices for many software development environments that occasionally bordered \non bureaucracy. At the same time, the rapid iterations of agile methods were replacing \nlengthy development practices that were insufficient to handle the pace of change \naffecting most businesses.\nIn theory, agile methods solve the level 1 commitment problem by freezing the \nnumber stories to be developed at the beginning of a sprint. New stories can only be \nadded during the planning of a subsequent sprint. Consequently, it was disconcerting \nto hear developers at the Agile Alliance conferences in 2011 and 2012 complain about Chapter 20  Organizati Onal Maturity: the\u00a0elephant affeCting prOduCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "247stories being added during the middle of sprints at the request of marketing or business \nunits. These in-sprint additions created the same rework-inducing schedule pressures \nthat had plagued low maturity waterfall projects. Enforcing controls on commitments \nis a critical attribute of level 2 to protect developers from chaotic circumstances that \ndegrade the productivity and quality of their work.\nIn a session at the Agile Alliance Conference in 2012, Jeff Sutherland, one of the \ncreators of the Scrum method, commented that perhaps as many as 70 percent of the \ncompanies he visited were performing scrumbut. \u201cWe are doing Scrum, buut  we don\u2019t \ndo daily builds, buut  we don\u2019t do daily standups, buut  we don\u2019t do\u2026. \u201d As Jeff observed, \nthey clearly weren\u2019t doing Scrum. When performed rigorously across an organization\u2019s \ndevelopment teams, Scrum and other agile or DevOps methods can provide the benefits \nof standardized processes characteristic of a level 3 capability. However, when these \nmethods lack discipline, development teams are exposed to the typical level 1 problems \nof uncontrolled baselines and commitments, as well as patchy development practices \nthat sap their productivity.\nIn 2015 Fannie Mae, a provider of liquidity for mortgages in the U.S. housing \nmarket, initiated a disciplined agile-DevOps transformation across their entire IT \norganization [ 12]. The transformation involved replacing traditional waterfall processes \nwith short agile sprints and installing a DevOps tool chain with integrated analytics. \nAlthough they did not use CMMI, their improvement program mirrored a maturity \nprogression from stabilizing changes on projects (level 2) to synthesizing standard \npractices, tools, and measures across the organization (level 3). Productivity was \nmeasured using Automated Function Points [ 11] delivered per unit of time and was \ntracked to monitor progress and evaluate practices.\nAfter the transformation was deployed organization-wide, Fannie Mae found that \nthe density of defects in applications had decreased by typically 30 percent to 48 percent. \nProductivity gains attributed to the transformation had to be calculated by collating data \nacross several sprints whose combined duration and effort were comparable to previous \nwaterfall release cycles (the baseline). The initial sprints were often less productive while \nthe team adjusted to short-cycle development methods. However, when combined \nwith results from several succeeding sprints, the average productivity was found to have \nincreased by an average of 28 percent across applications compared to the waterfall \nbaseline.Chapter 20  Organizati Onal Maturity: the\u00a0elephant affeCting prOduCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "248 Summary\nImprovement programs based on the Process Maturity Framework have improved \nproductivity in software development organizations globally. Practices are implemented \nin evolutionary stages, each of which creates a foundation for more sophisticated \npractices at the next maturity level. Although development methods evolve over time, \nmany of the problems that reduce their effectiveness are similar across generations. \nThus, the maturity progression of Stabilize\u2013Standardize\u2013Optimize\u2013Innovate provides an \napproach to improving productivity that is relevant to agile-DevOps transformations.\n Key Ideas\nThe following are the key ideas from the chapter:\n\u2022 Immature, undisciplined development practices can severely \nconstrain productivity.\n\u2022 Staged evolutionary improvements in an organizations\u2019 development \npractices can dramatically increase productivity.\n\u2022 Modern development practices can suffer from weaknesses that \nhindered the productivity of earlier development methods.\n References\n [1] Crosby, P . (1979). Quality Is Free . New\u00a0York: McGraw-Hill.\n [2] Dion, R. (1993). Process improvement and the corporate balance \nsheet. IEEE Software , 10 (4), 28\u201335.\n [3] Duncker, R. (1992). Proceedings of the 25th Annual Conference of \nthe Singapore Computer Society . Singapore: November 1992.\n [4] Haley, T., Ireland, B., Wojtaszek, E., Nash, D., & Dion, R. (1995). \nRaytheon Electronic Systems Experience in Software Process \nImprovement (Tech. Rep. CMU/SEI-95-TR-017).  Pittsburgh: \nSoftware Engineering Institute, Carnegie Mellon University.Chapter 20  Organizati Onal Maturity: the\u00a0elephant affeCting prOduCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "249 [5] Herbsleb, J., Zubrow, D., Goldenson, D., Hayes, W., & Paulk, M. \n(1997). Software Quality and the Capability Maturity Model. \nCommunications of the ACM , 40 (6), 30\u201340.\n [6] Humphrey, W.\u00a0S. (1989). Managing the Software Process . Reading, \nMA: Addison-  Wesley.\n [7] Liker, J.\u00a0K. (2004). The Toyota Way: 14 Management Principles from \nthe World\u2019s Greatest Manufacturer.  New\u00a0York: McGraw-Hill.\n [8] Lydon, T. (1995). Productivity drivers: Process and capital. In \nProceedings of the 1995 SEPG Conference . Pittsburgh: Software \nEngineering Institute, Carnegie Mellon University.\n [9] Object Management Group (2014). Automated Function Points.   \nwww.omg.org/spec/AFP .\n [10] Paulk, M.\u00a0C., Weber, C.\u00a0V ., Curtis, B., & Chrissis, M.\u00a0B. (1995). The \nCapability Maturity Model: Guidelines for Improving the Software \nProcess . Reading, MA: Addison-Wesley.\n [11] Sakamoto, K., Kishida, K., & Nakakoji, K. (1996). Cultural \nadaptation of the CMM.\u00a0In Fuggetta, A. & Wolf, A. (Eds.), Software \nProcess . Chichester, UK: Wiley, 137\u2013154.\n [12] Snyder, B. & Curtis, B. (2018). Using analytics to drive \nimprovement during an Agile- DevOps transformation. IEEE \nSoftware, 35  (1), 78\u201383.\n [13] Vu. J.\u00a0D. (1996). Software process improvement: A business case. \nIn Proceedings of the European SEPG Conference . Milton Keynes, \nUK: European Software Process Improvement Foundation.\n [14] Barry W. Boehm (1987). Improving Software Productivity. IEEE \nComputer . 20(9): 43-57.\n [15] Frank McGarry (1987). Results from the Software Engineering \nLaboratory. Proceedings of the Twelfth Annual Software \nEngineering Workshop. Greenbelt, MD: NASA.Chapter 20  Organizati Onal Maturity: the\u00a0elephant affeCting prOduCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "250Open Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 20  Organizati Onal Maturity: the\u00a0elephant affeCting prOduCtivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "251\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_21CHAPTER 21\nDoes Pair Programming \nPay Off?\nFranz Zieris, Freie Universit\u00e4t Berlin, Germany\nLutz Prechelt, Freie Universit\u00e4t Berlin, Germany\n Introduction: Highly Productive Programming\nImmerse yourself in the following software development scenario: You\u2019re implementing \na new feature in a large, GUI-heavy information system. You found a close match among \nthe existing features and decided to duplicate and tweak the respective code and to \neventually refactor it to get rid of unwanted duplications. You already made the copy and \nare starting to adapt it. You feel most productive, undistracted by your surroundings, \ndeep in the zone, focused, in the flow .\nYou look at the code and read:\neditStrategy.getGeometryType()\nYou notice something odd.\nThat\u2019s wrong, no need to call a method here.\nYou understand why it feels odd.\nIt\u2019s always the same!\nYou see the parts before your inner eye, see how they fit together.\nIt\u2019s: Polygon .\nYou start typing.\n[tap tap]\nYou read the IDE\u2019s auto-completion and have second thoughts.\nOr is it  MultiPolygon?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "252You consider it. It would be the more general solution.\nCould be. That\u2019s an open question.\nThere could be many reasons in favor or against. You make a decision.\nPolygon  is fine for now.\nYou write the code.\n[tap tap]\nYou are satisfied and did all of this in just 15 seconds; life is great.\nIf you are a software developer, you know focus phases like this one. It\u2019s a great feeling \nwhen the ideas appear to be flowing directly from your brain through your fingers to \nbecome code. Who would spoil such an experience by adding another developer? At every \npoint there would be endless discussions about which way is the best; and where there is \nno disagreement, there is misunderstanding because your colleagues often just don\u2019t get it.\nWell, you are in for a surprise. The previous scenario was not a fictional inner \nmonologue of a single developer. It is in fact an actual dialogue  of two pair programmers, \nthe two taking turns with the quotes. And it did indeed finish within 15 seconds.\n Studying Pair Programming\nPair programming  (PP) means that two programmers work together closely on the same \nprogramming task on a single computer.\nAlthough super-efficient focus phases like the one described previously do happen \nduring good pair programming sessions, most of the time pair programming evolves in a \nmore pedestrian manner. So, does pair programming pay off overall?\nTo answer this, researchers have\u2014multiple times\u2014proceeded roughly like this:\n\u2022 Devise a small task, let some developers (preferably students) solve \nit alone and some others in pairs, clock their time to completion, and \ncompare the outcomes.\n\u2022 Make sure the task is isolated and requires little background \nknowledge to ensure a level playing field for everyone.\n\u2022 For greater control, assign partners randomly and set up identical \nworkspaces for all of them.\nUnfortunately, such settings do not reflect how pair programming happens in \nindustry. The students work on machines they did not configure themselves and may Chapter 21  Does pair programming pay off?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "253not even know their partner. Additionally, consider the difference between short-term \nand long-term effects. In most student PP experiments, productivity  is reduced to the \nnumber of passing (prewritten) test cases per time spent on the task. But that\u2019s not what \ncommonly matters in industrial contexts. Here, top priorities might be a short time-  \nto- market or value of implemented features, or they might be long-term goals such as \nkeeping code maintainable and avoiding information silos.\nPractitioners have by and large ignored the results of these experiments. You cannot \nexpect to learn much about how PP affects real-world productivity from a setup that so \ndrastically differs from the real world.\nIn our research, we take a different approach. We talk to tech companies and observe \npair programming as it happens in the wild. The pairs are in their normal environment \nand choose everyday development tasks and programming partners as they always \ndo. The only difference is that we record the interaction of the pair (through webcam \nand microphones) and their screen content for the duration of their session\u2014typically \nbetween one and three hours. Over the years, we have collected more than 60 such \nsession recordings from a dozen different companies.\nWe analyze this material in great detail by following a qualitative research process \nbased on grounded theory [1]. The following observations are distilled from years of \nstudying pair programming sessions of professional software developers.\n Software Development As\u00a0Knowledge Work\nLet\u2019s take a step back first, though. What makes programming highly productive? \nPsychologist Mihaly Csikszentmihalyi described a type of high-productivity mental \nstate, which is much admired (and sometimes achieved) by software developers: flow. \nHe places a flow  experience in that area between boredom  and anxiety  where difficulty \n(challenges ) and one\u2019s skills  are on par [2].\nIn software development, each task is somewhat unique with its own particular \nchallenges. Consequentially, boredom is hardly an issue for software developers. The \nchallenges while developing software, on the other hand, are not just a matter of skill. \nMany stem from a lack of understanding or knowledge . It might take many hours of \nsifting through modules to finally find the right spot to add that single new if condition \nrequired. Or to understand the unfamiliar concepts used by a new library. Or to follow \na stacktrace that leads into uncharted territories from the legacy part of the system. \nThe \u201cfluency\u201d of a developer depends on this type of understanding and familiarity Chapter 21  Does pair programming pay off?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "254with the software system at hand. The lack thereof is what mostly slows down software \ndevelopers, more or less independent of their general skill level [3].\nTo work on a given task, developers (solos and pairs alike) need to understand \nthe system  (not all of it, but at least the parts relevant for the task at hand). And last \nweek\u2019s understanding of some of these parts may already be outdated! High system \nunderstanding, let\u2019s call it system knowledge , is necessary to fix bugs and to implement \nnew features.\nOf course, general software development skills and expertise (we will call them general \nknowledge ) are also relevant. General knowledge is about language idioms, design patterns \nand principles, libraries, technology stacks and frameworks, testing and debugging \nprocedures, how to best use the editor or IDE, and the like. In contrast to the mostly product-\noriented and relatively short-lived system knowledge, general knowledge is also process-\noriented and more long-lived. (There is not necessarily a clear-cut separation between \nsystem and general knowledge\u2014some pieces of knowledge may belong to both types.)\nDevelopers build up system and general knowledge through experience, but it\u2019s \nnot the mere number of years under their belt that matters but whether they possess \napplicable system and general knowledge for the task at hand.\n What Actually Matters in\u00a0Industrial Pair Programming\nThere are different PP use cases that developers regularly employ.\n\u2022 Getting help from a colleague : One developer has been working on \nsome task for some time and either finds it hard or needs to hand \nover the results, so another joins.\n\u2022 Tackling an issue together : Two developers sit down to work on a \nproblem together from the start.\n\u2022 Ramping up newbies : A senior developer pairs with a new team \nmember to bring her up to speed.\nWe found that it\u2019s not so much the particular PP use case that characterizes the \ndynamics of a session but what the two developers know and don\u2019t know\u2014more \nprecisely, their respective level of system knowledge and general knowledge concerning \ntoday\u2019s specific task . That\u2019s because most of the work in programming consists of steps \nto get your system knowledge to what is needed to solve the task (general knowledge \nmay be helpful along the way). Once you have that, actually solving the task is usually Chapter 21  Does pair programming pay off?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "255a piece of cake\u2014the kind of thing we described in the initial scene at the beginning. \nTherefore, it is the relevant knowledge gaps  that count in programming.\nFraming PP situations in terms of the involved system and general knowledge gaps \nhelps to understand why some constellations are more beneficial than others and \nwhere pair programming actually pays off. There are three particularly interesting pair \nconstellations we will discuss here. All of the examples in this chapter are real cases we \nsaw in our data; we just left out some details and changed the developers\u2019 names.\n Constellation A: System Knowledge Advantage\nIn this setting, one developer has a more complete or more up-to-date understanding \nof the task-relevant system parts. This is normal for the \u201cgetting help\u201d use case but can \noccur in the other two as well.\nConsider the scenario of developer Hannah who has been working on some task and is \nat one point joined by Norman. Hannah already looked at the code relevant for the current \nissue and performed some changes. Norman might have a better understanding of the \nsystem in general, but this does not cover all the details relevant for this task and of course \nnot Hannah\u2019s recent code changes. Overall, Hannah has a system knowledge advantage .\nIf developers want to work as a pair, they need to address their relative system \nknowledge gap. Only if Norman understands what Hannah already found out and which \nchanges she performed can they properly discuss ideas and agree on how to proceed.\nBut some of the pairs we observed, including this one, did not address the system \nknowledge advantage. Norman takes great pride in his programming skills and assumes \nhe understands everything Hannah did. Hannah tries to explain an intricate matter \nshe encountered, but Norman doesn\u2019t pay attention. It takes almost half an hour until \nNorman realizes his misconception of the status quo, lets Hannah explain it, and, at last, \nthe pair becomes productive.\nA pair situation where one partner has a system knowledge advantage (for whatever \nreason) is challenging because the relative system knowledge gap might be hardly visible \nbut still needs to be addressed before the pair can move together at any speed. Better \npairs therefore address the matter proactively at the beginning of their session. If your \nco-developer already worked on the issue, appreciate her system knowledge advantage, \nregardless of your own (perceived) seniority, and let her explain what she already has \ndone and learned. We have heard that some developers with high system knowledge \nmay also be reluctant to share what they know, but we did not observe such behavior in \nour pairs.Chapter 21  Does pair programming pay off?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "256 Constellation B: Collective System Knowledge Gap\nWhen two developers start on a new task together (but not only then), they also usually \nboth begin with an incomplete system understanding. The pair has a collective system \nknowledge gap .\nConsider Paula and Peter who picked a new story card to work on. Both know their \nway around the system, so it doesn\u2019t take long until they find a place where to put the \nnew feature. There are still some dependencies that need to be understood, so they \nnavigate through the source code to complete their mental model. One time it\u2019s Paula \nwho sees an important detail or relationship first, and the next time it\u2019s Peter. They \nare not deliberately taking turns here; one of them just happens to have a particular \nrelevant idea first and will then explain it to the other. Sometimes Paula sees no need to \ndig deeper into the class inheritance graph, but Peter isn\u2019t as familiar with the current \nsubsystem so he prefers to keep reading. Paula cuts him some slack and lets him take his \ntime. In any case, both make sure their partner always stays on the same page so they \ncan reach a high system understanding together.\nCompared to the one-sided scenario of Hannah and Norman, Peter and Paula are \nbetter off. There are multiple strategies how they can build up the necessary system \nunderstanding as they don\u2019t depend on the knowledge flowing in one direction. \nThe developers may stay closely together for a period of time, building up system \nknowledge in what we call an episode of knowledge \u201cco-production\u201d [4]. Alternatively, \none developer may dig deeper in a self-paced manner, while the other is temporarily \nmore passive (\u201cpioneering production\u201d). Either way, the development work done in \nsuch constellations can be very effective\u2014 if the pair takes care of maintaining their \ncollaborative understanding as it grows, e.g., by explaining (\u201cpush\u201d) or getting asked \nabout (\u201cpull\u201d) what one of them just found out during his or her pioneering episode.\n Constellation C: Complementary Knowledge\nEvery time a new developer joins the team, her system knowledge will be very low. But, \ndepending on the partner\u2019s background and the nature of the current task, being low \non system knowledge can occur in every PP use case. How well a pair performs then \nis limited by the general knowledge level of the low-system-knowledge developer. At \nleast for the ramping-up use case, one would usually expect a twofold deficit, but this \nis not necessarily the case. Remember, what matters is the applicable knowledge for \nthe current task, so with the right choice of task, even a fresh team member can score Chapter 21  Does pair programming pay off?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "257high on general knowledge, perhaps higher than a given senior. We\u2019ve seen developers \non their first work day teaching their programming partner design patterns and neat \ntricks in the IDE.\u00a0Senior developers pair up in complementary constellations as well, \nsince neither system understanding nor generic software development skill is evenly \ndistributed in development teams.\nAndy and Marcus, for instance, have quite different competencies. Andy advocates \nalways writing clean, readable, and maintainable code, whereas Marcus has a pragmatic \napproach of patching things together that get the job done. A particular module that \nMarcus wrote a year ago needs an update, but since Marcus has trouble figuring out \nhow it actually works, he asks Andy for help. Their session is a complementary one: \nAndy has a general knowledge advantage but is low on system knowledge, as he knows \nnext to nothing about Marcus\u2019s module; Marcus, as the module\u2019s author, has a system \nknowledge advantage but lacks general knowledge to systematically improve its \nstructure. Their session is mutually satisfactory, as they get the job done and  Marcus \nlearns a lot about code smells and refactorings.\n So, Again: Does Pair Programming Pay Off?\nYou probably now appreciate that \u201cDoes pair programming pay off?\u201d is an entirely \ninappropriate question, because\n\u2022 It is hard to tell since too many different benefits have to be \nquantified and added up with respect to code functionality, code and \ndesign quality, and learning within the team.\n\u2022 It depends, because different knowledge and task constellations \nprovide very different opportunities for being efficient as a pair.\nThe key aspects are the knowledge gaps the developers have to deal with. To succeed \nwith the task, the pair as a whole can benefit from various pieces of pertinent-for-this-  \ntask general software development knowledge and absolutely must possess or build the \npertinent-for-this-task system knowledge. As system knowledge is more short-lived, it is \nusually the scarcer resource.\nIf the task-relevant knowledge of a pair is highly complementary, a pair \nprogramming session will probably pay for its cost multiple times. But even if it is not \nand the pair\u2019s visible work output is less than the two could have produced as two solo \nprogrammers, the PP session\u2019s midterm benefits in terms of learning provide ample Chapter 21  Does pair programming pay off?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "258opportunity for time saved in the future and mistakes not made in the future to pay off \nthe higher expense today.\nFrom an industrial perspective, an answer to the question might be this: given the \ndominant role of system knowledge for productive development, companies may not \nlike to let their top-general-knowledge developer go, but they are terrified  of losing their \nsingle top-system-knowledge developer. And frequent pair programming is an excellent \ntechnique to make sure system knowledge spreads continuously across a team.\n Key Ideas\nThe following are the key ideas from this chapter:\n\u2022 Pair programming will tend to pay off if the pair manages to have \nhigh process fluency.\n\u2022 Pair programming will pay off if the pair members\u2019 knowledge is \nnicely complementary.\n References\n [1] Stephan Salinger, Laura Plonka, Lutz Prechelt: \u201c A Coding \nScheme Development Methodology Using Grounded Theory for \nQualitative Analysis of Pair Programming, \u201d Human Technology: \nAn Interdisciplinary Journal on Humans in ICT Environments, \nVol. 4 No. 1, 2008, pp.9\u201325\n [2] Mihaly Csikszentmihalyi: \u201cFlow: The Psychology of Optimal \nExperience, \u201d Harper Perennial Modern Classics, 2008, p.74\n [3] Minghui Zhou, Audris Mockus: \u201cDeveloper Fluency: Achieving \nTrue Mastery in Software Projects, \u201d Proceedings of the 18th ACM \nSIGSOFT International Symposium on Foundations of Software \nEngineering (FSE \u201910), 2010, pp.137\u2013146\n [4] Franz Zieris, Lutz Prechelt: \u201cOn Knowledge Transfer Skill \nin Pair Programming, \u201d Proceedings of the 8th ACM/IEEE \nInternational Symposium on Empirical Software Engineering and \nMeasurement, 2014Chapter 21  Does pair programming pay off?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "259Open Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 21  Does pair programming pay off?"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "261\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_22CHAPTER 22\nFitbit for\u00a0Developers:  \nSelf-  Monitoring a t Work\nAndr\u00e9 N.  Meyer, University of Zurich, Switzerland\nThomas Fritz, University of Zurich, Switzerland\nThomas Zimmermann, Microsoft Research, USA\n Self-Monitoring to\u00a0Quantify Our Lives\nRecently, we have seen an explosion in the number of devices and apps that we can use \nto track various aspects of our lives, such as the steps we walk, the quality of our sleep, or \nthe calories we consume. People use devices such as the Fitbit activity tracker to increase \nand maintain their physical activity level by tracking their behavior, setting goals (e.g., \n10,000 steps a day), and competing with friends. Generally, the miniaturization of self-  \ntracking devices and their ubiquitousness make it possible to carry them around all the \ntime and track more and more aspects of our lives. At the same time, studies have shown \nthat these approaches can successfully encourage people to change their behavior, often \nmotivated through persuasive technologies, such as goal-setting, social encouragement, \nand sharing mechanisms [ 3].\nNotably, the interest for self-monitoring tools at the workplace is also increasing, and \napproaches to get insights into one\u2019s behavior and habits during work have emerged. \nTools, such as RescueTime, allow users to get insights into the amount of time they \nspend in different applications on their computer, or Codealike visualizes to developers \nhow they spent their time inside the IDE working in different code projects. Yet, little is \nknown about developers\u2019 expectations of, their experience with, and the experience of \nself-monitoring in the workplace."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "262 Self-Monitoring Software Developers\u2019 Work\nThere are numerous factors that impact a software developers\u2019 success and productivity \nat work: interruptions, coordinating work with the team, requirements that change, the \ninfrastructure and office environment, and many more (see Chapter 8). Developers are \noften not aware of how these factors impact both their own productivity and the work \nof others [ 1]. The success of self-monitoring approaches in other domains suggests \nthat self-monitoring can improve the awareness of developers about their work. \nDevelopers can reflect about their actions and factors that increase or decrease their \nproductivity and make informed decisions to improve their productivity. The captured \ndata about developers\u2019 work and productivity could further allow developers to compare \nthemselves to other developers with similar job profiles.\nThis idea is related to Watts Humphrey\u2019s work on the Personal Software Process (PSP)  \nthat aims to help developers better understand and improve their performance by \ntracking their estimated and actual development of code [ 2]. The research conducted to \nevaluate PSP showed promising results, including more accurate project estimations and \nhigher code quality. Today, with sensors and data trackers being more ubiquitous and \naccurate, we can give developers the ability to measure their work and behavior changes \nautomatically and provide a much broader set of insights.\nTo learn the requirements and best practices for self-monitoring systems for software \ndevelopers, we ran a mixed methods study: a literature review, a survey with more than \n400 developers, and an iterative feedback-driven approach with 5 pilot studies and a \ntotal of 20 software developers. The study revealed developers\u2019 expectations of features, \nmeasures of interest, and possible barriers toward the adoption of self-monitoring \nsystems. We then built PersonalAnalytics, a self-monitoring tool targeted to developers \nand studied its impact and use with 43 professional software developers who used it \nduring three workweeks.\nPersonalAnalytics consists of three components: the monitoring component, the self-\nreporting pop-up, and the retrospection. The monitoring component captures information \nfrom various individual aspects of software development work, including application use, \ndocuments accessed, development projects worked on, websites visited, and collaborative \nbehaviors from attending meetings, as well as using e-mail, instant messaging, and code \nreview tools. The data collection runs nonintrusively in the background, requiring no \nadditional input from the developer. In addition, PersonalAnalytics prompts developers \nto reflect on their work periodically and to-self report their perceived productivity using \na pop-up. To enable more multifaceted insights, the captured data is visualized in a daily Chapter 22  Fitbit For\u00a0Developers: selF- Monitoring at Work"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "263retrospection (see Figure\u00a0 22-1 ), which also provides a higher-level overview in a weekly \nsummary and allows users to relate various data with each other.\nIn this chapter, we share the lessons that we learned from building and evaluating \nPersonalAnalytics and the insights that users received from using the tool. We describe why \nthese insights are sometimes not enough for a behavior change. Chapter 16 further extends \nthe discussion on dashboards in software engineering, by debating about their need and risks.\nFigure 22-1.  Daily retrospection in PersonalAnalytics. (A) displays the \ndistribution of time spent in the most used programs, (B) shows a timeline of time \nspent in different activities, (C) depicts the most used programs and the amount \nof time the user self-reported feeling productive/unproductive while using them, \n(D) illustrates the user's self- reported productivity over time, (E) visualizes the \nuser input from mouse and keyboard, (F) shows a detailed breakdown of how \nmuch time was spent on different information artefacts (including web sites, files, \ne-mails, meetings, code projects, code reviews), and (G) summarizes e-mail-related \ndata such as the number of e-mails sent/received.Chapter 22  Fitbit For\u00a0Developers: selF- Monitoring at Work"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "264 Supporting Various Individual Needs \nThrough\u00a0Personalization\nIn our preliminary studies, developers expressed an interest in a large number of \ndifferent measures when it comes to the self-monitoring of their work. To support these \nindividually varying interests in work measures, we included a wide variety of measures \ninto PersonalAnalytics and allowed users to personalize their experience by selecting \nthe measures that were tracked and visualized. To capture the relevant data for these \nmeasures, PersonalAnalytics features multiple data trackers: the Programs Used tracker  \nthat logs the currently active process and window titles every time the user switches \nbetween programs or logs \u201cidle\u201d in case there was no user input for more than two \nminutes; the User Input tracker  that collects mouse clicks, movements, scrolling, and \nkeystrokes (no key logging, only time-stamp of any pressed key); and the Meetings and \nE-mail trackers  that collect data on calendar meetings and e-mails received, sent, and \nread using the Microsoft Graph API of the Office 365 Suite [ 5].\nAfter using PersonalAnalytics for several weeks, two-thirds of our users wanted to \npersonalize and better fit the retrospection to their individual needs. They also wanted \neven more data on other aspects of their work. For instance, they wanted to compare \nthemselves with their team members, get high-level measures such as their current \nfocus or progress on tasks, and correlate their data with biometric data, such as their \nheart rate, stress level, sleep, and exercise.\nThe diverse requests for extending PersonalAnalytics with additional measures \nand visualizations emphasize the importance for personalization and customization \nof the experience to increase satisfaction and long-term engagement. While it might \nseem surprising that developers requested many development-unrelated measures to \nunderstand their work, this can be explained by the relatively low amount of time they \nusually spend with development-related activities, on average just between 9 percent \nand 21 percent, versus other activities such as collaborating (45 percent) or browsing the \nWeb (17 percent) [ 4].Chapter 22  Fitbit For\u00a0Developers: selF- Monitoring at Work"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "265 Self-Reporting Increases Developers\u2019 Awareness \nAbout\u00a0Efficiency\nPersonalAnalytics asks users to answer a pop-up survey once an hour on their \ncomputer. The collected data allows us to learn more about productivity and the tasks \nthat developers work on. During the pilot studies, users expressed aversion toward the \npop-  up, as it included too many questions. After refining the pop-up to include only one \nquestion asking users to self-report productivity for the past hour, most started to like \nthe pop-up. Two-thirds of the users mentioned that the brief self-reports increased their \nawareness about work and helped them assess whether they had spent their past work \nhour effectively, whether they had spent it working on something of value, and whether \nthey had made progress on their current task:\n\u201cThe hourly interrupt helps to do a quick triage of whether you are stuck with some \ntask/problem and should consider asking for help or taking a different approach. \u201d\nPersonalAnalytics does not automatically measure productivity but rather lets users \nself-report their productivity. This was highly valued by users as many do not think an \nautomated measure can accurately capture an individual\u2019s productivity, similar to what \nis discussed in Chapters 2 and 3.\n\u201cOne thing I like about [PersonalAnalytics] a lot is that it lets me judge if my time was \nproductive or not. So just because I was in a browser or Visual Studio doesn\u2019t necessarily \nmean I was being productive or not. \u201d\nThese findings emphasize that self-reporting can be of value to users as it increases \ntheir awareness about work. It is yet to be seen how long the positive effects of self-  \nreporting last and whether users lose interest at some point.\n Retrospection About\u00a0Work Increases Developers\u2019 \nSelf-Awareness\nThe users of PersonalAnalytics liked the ability to self-reflect on work and productivity with \nthe retrospection that visualizes a personalized list of measures; 82 percent said that the  \nretrospection increased their awareness and provided novel insights. The insights \nincluded how developers spend their time collaborating or making progress on tasks, their \nproductivity over the course of a day, or the fragmentation at work. The time spent further \nrectified some misconceptions users had about their work, such as how much time they \nactually spent with e-mails and work-unrelated browsing (for example, Facebook):Chapter 22  Fitbit For\u00a0Developers: selF- Monitoring at Work"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "266\u201c[PersonalAnalytics] is awesome! It helped confirm some impression I had about my \nwork and provided some surprising and very valuable insights I wasn\u2019t aware of. I am \napparently spending most of my time in Outlook. \u201d\n\u201cI did not realize I am as productive in the afternoons. I always thought my mornings \nwere more productive but looks like I just think that because I spend more time on e-mail. \u201d\n Actionable Insights Foster Productive Behavior \nChanges\nNaturally, most users of self-monitoring tools don\u2019t just want to learn about themselves \nbut also want to improve themselves. We asked the users of PersonalAnalytics about what \nbehaviors they changed. Interestingly, this study resulted in ambivalent responses. Roughly \nhalf of the users changed some of their habits based on what they learned from reflecting \nabout their work. This includes trying to better plan their work, e.g., by taking advantage of \nmore productive afternoons, trying to optimize how they spend their time with e-mails, or \ntrying to focus better and avoid distractions, e.g., by closing the office door or listening to \nmusic when the background noise is distracting. However, the other half of our users didn\u2019t \nchange their behavior, either because they didn\u2019t want to change something or because \nthey were not sure what to change. These users reported that some of the new insights \nwere not concrete and actionable enough for knowing what or how to change:\n\u201cWhile having a retrospection on my time is a great first step, I gained interesting \ninsights and realized some bad assumptions. But ultimately, my behavior didn\u2019t change \nmuch. Neither of them have much in way of a carrot or a stick. \u201d\n\u201cIt would be nice if the tool could provide productivity tips, ideally tailored to my \nspecific habits and based on insights about when I\u2019m not productive. \u201d\nTo improve the actionability of the insights, users asked for specific \nrecommendations that encourage more focused work, e.g., to start a focused work \nblock using the Pomodoro technique, to recommend a break from work for when they \nwere stuck on the same task for too long, all the way to intervening and blocking certain \napplications or websites for a certain time:\n\u201cWarnings if time on unproductive websites exceeds some amount, and perhaps \nprovide a way for the user to block those sites (though not forced). \u201d\nBesides providing developers with personalized recommendations for \nimprovements based on their work behavior, allowing them to benchmark and compare \nthemselves with their team or other developers could lead to insights that are actionable Chapter 22  Fitbit For\u00a0Developers: selF- Monitoring at Work"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "267enough to change a behavior. For example, PersonalAnalytics could collect anonymized \nmeasures about developers\u2019 work habits, such as fragmentation, time spent on activities, \nand achievements; correlate the measures with other developers with similar job \nprofiles; and present the comparisons to the developer. Insights could reach from letting \na developer know that others spend more time reading development blogs to further \neducate themselves, all the way to informing them that they spend way more time in \nmeetings than most other developers.\n Increasing Team Awareness and\u00a0Solving Privacy \nConcerns\nOne drawback of giving developers insights only into their own productivity is that \ntheir behavior changes might have negative impact on the overall team productivity. \nAs an example, a developer who blocks out interruptions at inopportune times to focus \nbetter could be blocking a co-worker who needs to ask a question or clarify things. Also \nreceiving insights into how the team coordinates and communicates at work could help \ndevelopers make more balanced adjustments with respect to the impact their behavior \nchange might have on the team. For example, being aware of co-workers\u2019 most and least \nproductive times in a workday could help to schedule meetings during times where \neverybody is the least productive and where interrupting one\u2019s work for a meeting has \nthe least effect. Being more aware of the tasks each member of the team is currently \nworking on and how much progress they are making could also be useful for managers \nor team leads to identify problems early, e.g., a developer who is blocked on a task or \nuses communication tools inefficiently, and take appropriate action.\nHowever, these additions to a workplace self-monitoring tool would require \naggregating and analyzing the data from multiple developers, which could result in \nprivacy concerns given the possibly sensitive nature of the data. When creating tools that \ninclude data from multiple users, tool builders need to ensure privacy, e.g., by giving \nusers full control over what data is being captured and shared, by properly obfuscating \nthe data, and by being transparent about how the data is being used. If not done \nproperly, this could severely increase pressure and stress for developers.\nA recurring theme during the pilots and initial survey was the users\u2019 need to keep \nsensitive workplace data private. Some users were afraid that sharing data with their \nmanagers or team members could have severe consequences on their employment \nor increase pressure at work. To account for privacy needs at work, PersonalAnalytics, Chapter 22  Fitbit For\u00a0Developers: selF- Monitoring at Work"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "268among other precautions, stores all logged data only locally on the user\u2019s machine, \nrather than having a centralized collection on a server. This enables users to retain full \ncontrol of the captured data. While a few users were initially skeptical and had privacy \nconcerns, no privacy complaints were received during the study, and the majority even \nshared their obfuscated data with us for analyzing it. While some users mentioned that \nthey voluntarily exchanged their visualizations and insights with teammates to compare \nthemselves, others mentioned that they would start to game the tool or go as far as leave \nthe company, in case their manager would force them to run a tracking tool that would \nignore their privacy concerns.\nWe think that the chances of misuse of the data and developers\u2019 sensitivity will \ndecline if managements establish an environment where the data is used for process \nimprovements only and not for HR-related evaluations. Also, making comparisons \nacross teams with absolute data might lead to wrong conclusions since conditions \ncan differ so much between different teams, projects, and systems. Hence, the delta \nimprovements such as behavior changes and trends are important to consider. \nNonetheless, further research is required to determine how workplace data can be \nleveraged to improve team productivity, while respecting and protecting employee \nprivacy, including data protection regulations such as the GDPR [ 7]. This topic is \nexplored in more depth in Chapter 15.\n Fostering Sustainable Behaviors at Work\nOne way to foster software developers\u2019 productivity is to increase their self-awareness \nabout work and productivity through self-monitoring. We found that regular self-  \nreflection using the retrospection and minimal-intrusive self-reports allows developers \nto increase their awareness about time spent at work, their collaboration with others, \ntheir productive and unproductive work habits, and their productivity in general. You \nalso learned that developers are interested in a large and diverse set of measurements \nand correlations within the data and that the insights gained from looking at the \nvisualized data is not always concrete and actionable enough to motivate behavior \nchanges. Detailed descriptions of the studies and more findings can be found in the \ncorresponding paper [ 6]. In the future, we could imagine that self-monitoring tools \nfor developers at their workplace will be extended to include an even richer set of \nmeasures that can be correlated with each other. For example, by allowing integrations \nwith development tools (e.g., GitHub, Visual Studio, or Gerrit) and biometric sensors Chapter 22  Fitbit For\u00a0Developers: selF- Monitoring at Work"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "269(e.g., Fitbit), developers could be warned to carefully review their changes again \nbefore checking in a breaking code change after having slept badly in the night before. \nAnother possibility to foster productive behavior changes is goal-setting. Workplace \nself-monitoring tools could be extended to not only enable developers to gain rich \ninsights but also motivate them to identify meaningful goals for self-improvements and \nallow them to monitor their progress toward reaching them. Finally, anonymized or \naggregated parts of the data could be shared with the team, to increase the awareness \nwithin the team and reduce interruptions, to improve the scheduling of meetings, and to \nenhance the coordination of task assignments.\nWe open-sourced PersonalAnalytics on Github ( https://github.com/sealuzh/\nPersonalAnalytics ), opening it up to contributions and making it available for use.\n Key Ideas\nHere are the key ideas from this chapter:\n\u2022 Self-monitoring personal behavior at work can improve developers\u2019 \nperformance for a substantial proportion of developers.\n\u2022 Self-reporting productivity allows developers to briefly reflect about \ntheir efficiency and progress at work and take timely actions that \nimprove productivity.\n\u2022 Developers have a diverse interest in measures about their \nwork, ranging from development related data to data about their \ncollaboration in the team, all the way to biometric data.\n References\n [1] D ewayne E.\u00a0Perry, Nancy A.\u00a0Staudenmayer, and Lawrence \nG.\u00a0Votta. 1994. People, Organizations, and Process Improvement. \nIEEE Software 11, 4 (1994), 36\u201345.\n [2] Watts S.\u00a0Humphrey. 1995. A discipline for software engineering. \nAddison-Wesley Longman Publishing Co., Inc.Chapter 22  Fitbit For\u00a0Developers: selF- Monitoring at Work"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "270 [3] Thom as Fritz, Elaine M Huang, Gail C Murphy, and Thomas \nZimmermann. 2014. Persuasive Technology in the Real World: A \nStudy of Long-Term Use of Activity Sensing Devices for Fitness. In \nProceedings of the International Conference on Human Factors in \nComputing Systems.\n [4] Andr \u00e9 N.\u00a0Meyer, Laura E Barton, Gail C Murphy, Thomas \nZimmermann, and Thomas Fritz. 2017. The Work Life of \nDevelopers: Activities, Switches and Perceived Productivity. \nTransactions of Software Engineering (2017), 1\u201315.\n [5] Microsoft Graph API. https://graph.microsoft.io .\n [6] Andr \u00e9 N.\u00a0Meyer, Gail C Murphy, Thomas Zimmermann, and \nThomas Fritz. 2018. Design Recommendations for Self-Monitoring \nin the Workplace: Studies in Software Development. To appear at \nCSCW\u201918, 1\u201324.\n [7] European General Data Protection Regulation (GDPR). 2018. \n https://www.eugdpr.org .\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 22  Fitbit For\u00a0Developers: selF- Monitoring at Work"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "271\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_23CHAPTER 23\nReducing Interruptions \nat\u00a0Work with\u00a0FlowLight\nManuela Z\u00fcger, University of Zurich, Switzerland\nAndr\u00e9 N.  Meyer, University of Zurich, Switzerland\nThomas Fritz, University of Zurich, Switzerland\nDavid Shepherd, ABB Corporate Research, USA\n The Cost of\u00a0Interruptions at Work\nIn today\u2019s collaborative workplaces, communication is a major activity and is important \nto achieve a company\u2019s goals. Especially given the sociotechnical nature of software \ndevelopment, communication between stakeholders is important to successfully \ncomplete projects. Communication thereby takes many forms, such as e-mail and \ninstant messaging, phone calls, or talking to colleagues in person. Despite the overall \nimportance of communication, it can also impede productivity of knowledge workers \n(see Chapter 7 for a definition of knowledge work). In fact, around 13 times a day, \na knowledge worker gets interrupted and suspends his or her current activity to \nrespond to a co-worker asking a question, to read an e-mail, or to pick up a call. Each \nof these interruptions takes an average of 15 to 20 minutes and leads to an increased \nwork fragmentation. Not surprisingly, interruptions are considered one of the biggest \nimpediments to productivity, costing substantial time and money ($588 billion per year  \nin the United States) [ 1]. Additionally, interruptions have been shown to cause  \nstress and frustration for the interrupted person and lead to an increase in the errors \ncreated after resuming the interrupted task [ 2, 3]. These negative effects and costs of"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "272interruptions are particularly high when the interruptions happen at inopportune \nmoments and cannot be postponed. This is why in-person interruptions are one of the \nmost disruptive types of interruptions. Compared to other types of interruptions such \nas an e-mail notification or an instant message, it is difficult to ignore a person waiting \nnext to the desk and first finish the current task at hand. Yet, the interruption cost can \nbe reduced significantly by mediating interruptions to more opportune moments, e.g., \nmoments when the mental load is lower, when the worker might have taken a short \nbreak anyways, after just finishing a task or during work on less demanding tasks. Refer \nto Chapter 9 for more details on interruptions.\n FlowLight: A\u00a0Light to\u00a0Indicate When to\u00a0Interrupt\nThe FlowLight is an approach we developed to optimize the timing of interruptions and \nreduce the cost of external interruptions. The FlowLight is a physical desk \u201ctraffic light\u201d \nand an application that computes and indicates the current availability to co-workers \n(see Figure\u00a0 23-1 ) [4]. Similar to the colors of a traffic light and the status colors of instant \nmessaging services, the FlowLight has four states: away (yellow), available (green), busy \n(red), and do not disturb (red pulsating). The physical LED lamp is usually mounted on a \nperson\u2019s desk, cubicle separator, or office entrance to be easily visible  \nby co-workers. Depending on personal preference, the light can be places so that it \nis visible for the workers themselves, for use as a personal flow monitor, or on a less \nvisible place, to prevent distraction. After installing the FlowLight application on a user\u2019s \ncomputer, it calculates the users\u2019 \u201cflow status\u201d\u2014the availability for interruptions\u2014based \non the user\u2019s current and historical computer interaction data. A change in flow status \nresults in an update of FlowLight\u2019s LED color, as well as an update to the user\u2019s Skype \nstatus, resulting in muted notifications at times of low availability for interruptions.Chapter 23  reduCing interruptions at\u00a0Work With\u00a0Flo Wlight"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "273 Evaluation and\u00a0Benefits of\u00a0FlowLight\nWe evaluated the effects of FlowLight in a large-scale field study with 449 participants \nfrom 12 countries and 15 sites of a multinational corporation. The participants worked in \nvarious areas such as software development, other engineering, or project management \nand evaluated FlowLight while working normally for several weeks. Our goal was to \ninvestigate how knowledge workers were using it and how interactions and perceptions \nof productivity changed after introducing the FlowLights. Overall, the FlowLight reduced \nthe amount of interruptions significantly, by 46 percent, without eliminating important \ninterruptions, and participants continued using the FlowLight even long after the study \nperiod ended. Participants also stated that the FlowLight increased awareness of the \npotential harm of interruptions, that they generally paid attention to their colleagues\u2019 \nFlowLight, were more respectful of each other\u2019s work and focus, and either waited for \na more convenient time or switched to a different media to communicate with their \ncolleague when the interruption was not urgent.\n\u201cThe pilot increased the sensitivity to interruption[s]. Team members think more \nabout whether an interrupt is necessary and try to find a suitable time. \u201d\nFigure 23-1.  FlowLight in use at the officeChapter 23  reduCing interruptions at\u00a0Work With\u00a0Flo Wlight"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "274\u201cPeople ask each other if they are available, even when the light is green, even to \npeople with no light. When I see the colleague I want to ask a question (...) has a red \nlight, then I wait a while, or write an e-mail. \u201d\nThese positive effects also led to an increased feeling of productivity, on the one hand \nbecause of the increased amount of undisrupted time to work on one\u2019s own tasks, and on \nthe other hand because some participants actually liked to observe their status and felt \nmotivated when they realized that the algorithm detected that they were \u201cin flow. \u201d\n\u201cI definitely think it resulted in less interruptions both in person and via Skype. This \nresulted in more focus and ability to finish work. \u201d\n\u201cWhen I notice that my light is turning yellow, and I\u2019ll feel like, \u2018Oh yeah, I\u2019ve been \nidle\u2019 and then I do something...I think the other way, yeah, there\u2019s some effect there too. \nLike, if I see that it\u2019s red, or even flashing red, then I\u2019m like, \u2019Yeah, I\u2019ve been very active, \nor productive, I should keep that going. \u2019 At the same time, I think it\u2019s also a little bit \ndistracting too. Sometimes just because the light is there, I turn around to check it. \u201d\nFinally, most participants stated that their FlowLight\u2019s automatic state changes were \naccurate. Nonetheless, there is potential for improvement. For instance, in situations \nwhen a knowledge worker experiences a high cognitive load but is not interacting with \nthe mouse or keyboard intensely (e.g., when reading complicated text or code), the \nFlowLight will signal the user to be available for interruptions. One way to improve the \nalgorithm is to integrate more fine-grained data, such as application usage or biometric \ndata. Application usage data could, for instance, allow the algorithm to tailor to specific \ndevelopment activities, such as indicating no availability during debugging or availability \nafter code commits. Data from biometric sensors, such as heart rate variability, could \nbe used to more directly measure cognitive load or stress, which in turn influences a \nperson\u2019s availability for interruptions.\n Key Success Factors of\u00a0FlowLight\nThe iterative process of developing and evaluating FlowLight revealed many insights on \nthe factors that contributed to the FlowLight\u2019s success.\n Pay Attention to\u00a0Users\nFor the development of the FlowLight, we followed an iterative, user-driven design \nprocess. In particular, we made sure to roll out early versions of the FlowLight to receive \nuser feedback and to improve the approach iteratively. This iterative design helps Chapter 23  reduCing interruptions at\u00a0Work With\u00a0Flo Wlight"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "275to identify issues that might be small with respect to the underlying concept of the \napproach but might have a big impact on user acceptance. For instance, in the beginning \nwe set the FlowLight to busy (red) and do not disturb (red pulsating) for approximately \n19 percent of the day based on previous research. However, early users perceived the \nFlowLight to be red too often and noted that the state switched too frequently so that \nit was almost annoying. Therefore, we decreased the percentage and introduced and \nrefined a smoothing function.\nFurthermore, the early pilot studies revealed that the FlowLight needs to account \nfor specific job roles, such as managers. While software developers value time spent on \ncoding tasks without any interruptions and Skype messages muted (the \u201cdo not disturb\u201d \nmode) and sometimes wanted to increase this undisrupted time, managers want to be \navailable at all times. Therefore, we added a feature to manually set the do not disturb \nmode for longer periods as well as a feature to completely disable the do not disturb \nmode for managers.\nFinally, the user feedback also illustrated how the company culture and office layout \ncan impact the value of the approach. While the FlowLight was valuable to almost all \nteams, there were two smaller teams of people sitting very close together in the same \noffice who were generally interested in reducing interruptions but did not want to spend \nthe extra effort of looking up and checking for the FlowLight status before asking a \nquestion to a colleague. In these two teams, the FlowLight did not have any value despite \nthe teams\u2019 wish to reduce interruptions, so we uninstalled it shortly after.\n Focus on\u00a0Simplicity\nA lot of time and effort during the development of the FlowLight went into creating an \neasy and simple setup and installation process. For instance, the application can be \ninstalled by running an installer in the course of a few seconds. To set up the FlowLights \nin an office, we further had a member of the research-team visit the team, introduce \nthe functionality to the whole office site, and assist users in placing the lamps in highly \nvisible spots for the co-workers.\nWe further focused on creating an application that is intuitive and runs smoothly \nwithout user interaction. Knowledge workers have used manual strategies for indicating \navailability before, e.g., using manual busy lights or headphones, but often abandoned \nthem because of the additional effort. The automatic nature of the FlowLight for \nchanging the availability status appealed to the participants and led to the continued \nusage of the light long after the end of the study. Furthermore, the intuitive design of Chapter 23  reduCing interruptions at\u00a0Work With\u00a0Flo Wlight"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "276the FlowLight that combined the idea of a traffic light with availability states common \nin instant messaging applications made it easy for users and co-workers to pick up the \nmeaning and reason of the FlowLight and contributed to its success.\n Pay Attention to\u00a0Privacy Concerns\nProductivity is a sensitive topic in the work environment and monitoring sensitive \nwork-related data for productivity reasons can quickly result in privacy concerns. Since \nFlowLight harnesses sensitive and work-related data to calculate a person\u2019s availability \nstate, we provide transparency of the data tracking and store the collected data only \nlocally on the users\u2019 computers. We asked users to share their data with us only at the \nend of the study and at the same time gave them the opportunity to delete or obfuscate \nany data they did not want to share.\nWe further focused on tracking as little data as possible. While we considered \nleveraging application usage data from the beginning, we ended up only tracking mouse \nand keyboard interaction to reduce invasiveness and privacy concerns that users raised in \nthe beginning. Once users appreciated the FlowLight and its value, they themselves asked \nfor refining the algorithm by taking into account further data using additional tracking \nmethods. For instance, users asked us to integrate application usage data to avoid getting \ninto the do not disturb or busy state when reading social media during lunchtime or to \nmake sure they are in busy when they focus on debugging in the IDE.\u00a0By letting users drive \nthe data collection, users see a clear value from using a rich data set and privacy concerns \ncan be reduced. With productivity in the workplace, peer pressure and competition among \nteam members is another concern. Participants were concerned about being the one who \nis never \u201cbusy\u201d and therefore considered as not very focused by their peers. We designed \nthe FlowLight in a way that reduces the possibility for competition or peer pressure. In \nparticular, we set the FlowLight to be approximately the same amount of time in the \nbusy and do not disturb states for each participant and day by setting the thresholds for \nchanging the states based on historical data of each individual. We further allowed users \nto change their light manually and broadly communicated that the available state is not \nrepresentative of \u201cnot working\u201d but that it only indicates the availability for interruptions.\n Focus on\u00a0Value First, Not on\u00a0Accuracy\nWhile each study participant mentioned ways in which the FlowLight\u2019s accuracy could \nbe improved, the accuracy of our approach was good enough to lead to a large and quick Chapter 23  reduCing interruptions at\u00a0Work With\u00a0Flo Wlight"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "277adoption. We found that as long as the FlowLight provided some value to its users, was \neasy to understand by everyone, and did not require much effort, the accuracy was only \na secondary concern. Therefore, our focus on simplicity and value first paid off, and now \nthat we have a large user base and can test different options, we have time to improve the \naccuracy of the flow algorithm.\n Let Users Surprise You\nThe main intention of the FlowLight was to foster awareness of a person\u2019s availability for \ninterruptions to co-workers. However, many users found their own way of using it. For \ninstance, they used it as a personal monitor to reflect on their own productivity or also to \ncheck whether someone is in the office before going over to a colleague\u2019s desk either via \nchecking the light bulb from a distance or looking up the person\u2019s Skype status. Getting \nfeedback from users early on allowed us to identify and potentially extend such new use \ncases that were not anticipated by the creators.\n Summary\nFlowLight is a traffic-light-like LED that indicates when knowledge workers are available \nfor a chat or to answer a question. A study with 449 participants has shown that the \nFlowLight decreases interruptions, improves productivity, and promotes awareness on \nthe topic of interruptions. Overall, the FlowLight project was very successful, picked up \nby various media ( http://sealuzh.github.io/FlowTracker/ ), and study participants \ncontinue to use it. We believe that the key factors for successful adoption are to ensure \nthat the approach addresses a problem of its users in a way that is easy to install and \noperate, respects privacy concerns, and is adapted to the users\u2019 needs and use cases.\n Get Your Own FlowLight\nDo you want to get your own FlowLight? We are happy to collaborate with Embrava \n(https://embrava.com/flow ) to bring FlowLight to a wider audience. The office \nproductivity company licensed the FlowLight software and plans to offer a subscription \nfor an integration of the automatic algorithm into their own products, such as the \nBlyncLight status light or the Lumena headset with status light.Chapter 23  reduCing interruptions at\u00a0Work With\u00a0Flo Wlight"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "278 Key Ideas\nThe following are the key ideas from the chapter:\n\u2022 Interruptions, and especially in-person interruptions, are one of the \nbiggest impediments to productivity.\n\u2022 FlowLight indicates the availability for interruptions to co-workers in \nthe office with a traffic light like LED.\n\u2022 FlowLight reduced interruptions by 46 percent and increased the \nawareness on interruptions, and users felt more productive.\n\u2022 Success factors of FlowLight are its simplicity and continued \ndevelopment using a user-driven design process.\n References\n [1] Spira, Jonathan B., and Joshua B.\u00a0Feintuch. \u201cThe cost of not \npaying attention: How interruptions impact knowledge worker \nproductivity. \u201d Report from Basex (2005).\n [2] Bailey, Brian P ., and Joseph A.\u00a0Konstan. \u201cOn the need for \nattention-  aware systems: Measuring effects of interruption on task \nperformance, error rate, and affective state. \u201d Computers in human \nbehavior 22.4 (2006): 685\u2013708.\n [3] Mark, Gloria, Daniela Gudith, and Ulrich Klocke.  \n\u201cThe cost of interrupted work: more speed and stress. \u201d \nProceedings of the SIGCHI conference on Human Factors in \nComputing Systems. ACM, 2008.\n [4] Z\u00fcger, Manuela, Manuela Z\u00fcger, Christopher Corley, Andr\u00e9 \nN Meyer, Boyang Li, Thomas Fritz, David Shepherd, Vinay \nAugustine, Patrick Francis, Nicholas Kraft, and Will Snipes. \n\u201cReducing Interruptions at Work: A Large-Scale Field Study of \nFlowLight. \u201d Proceedings of the 2017 CHI Conference on Human \nFactors in Computing Systems. ACM, 2017.Chapter 23  reduCing interruptions at\u00a0Work With\u00a0Flo Wlight"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "279Open Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 23  reduCing interruptions at\u00a0Work With\u00a0Flo Wlight"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "281\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_24CHAPTER 24\nEnabling Productive \nSoftware Development \nby Improving Information \nFlow\nGail C.  Murphy, University of British Columbia, Canada\nMik Kersten, Tasktop Technologies, Canada\nRobert Elves, Tasktop Technologies, Canada\nNicole Bryan, Austin, Texas, USA\nAt its core, software development is an information-intensive knowledge generation \nand consumption activity. Information about markets and trends are analyzed to \ncreate requirements that describe what a desired software system needs to do. Those \nrequirements become information for software developers to use to produce models and \ncode that, when executed, provide the behavior desired for the system. The execution of \na system creates more information that can be analyzed as to how the software performs, \nand so on.\nWe are interested in how software tools can enable the productive development \nof software. Our hypothesis has been that software development productivity can be \nincreased by improving the access and flow of information between the humans and \ntools involved in creating software systems. In this chapter, we review an evolution of \ntechnologies that we have introduced based on this hypothesis. These technologies are \nin use by large software development organizations and have been shown to improve"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "282software developer productivity. The description of these technologies highlights how \nproductivity can be considered at the individual (the Mylyn tool), team (the Tasktop Sync \ntool), and organizational levels (the Tasktop Integration Hub).\n Mylyn: Improving Information Flow for\u00a0the \nIndividual Software Developer\nA software system cannot exist without code that executes to provide the behavior of the \nsoftware system. To produce code for a system, a software developer must deal with an \namazing amount of information, such as written requirements, documentation about \nlibraries and modules, and test suites. The result for a developer can be information \noverload. Figure\u00a0 24-1  shows a snapshot of an integrated development environment as \na software developer works on a bug fix. The developer is consulting a description of \nthe bug (A), the other hidden tabs in the main portion of the screen hold source code \nalready accessed as the developer is investigating the bug, the result of a search on a \nportion of a method name described in the stack trace is shown in the bottom part of \nthe screen (B), and the left side provides access to the many bits of code making up the \nsystem (C). Within this environment, to produce code for a new feature or a fix for a bug, \nthe developer must perform many navigation steps to access the contextual information \nneeded. The friction just to get started on a task can be significant. The more complex \nthe system, the more information a developer may need to find and cognitively maintain \nto start work on the task. If the developer worked on only one task a day, the friction \nmight be manageable. However, studies have shown that developers, on average, work \non approximately five to ten tasks per day, spending only a few minutes at any one \ntime on a particular task before switching to another task [ 3]. As a result, developers \nconstantly spend time finding, and re-finding, the bits of information they need to work \non a task, impeding their productivity.Chapter 24  enabling produ Ctive Software development by improving information flow"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "283To address these points of information flow friction for an individual software \ndeveloper, we created the Mylyn task-focused interface for integrated development \nenvironments [ 2]. Mylyn changes the paradigm with which a developer interacts with \nthe artifacts making up a software system by framing a developer\u2019s work explicitly \naround the tasks performed. With Mylyn, a developer begins work on a task by activating \na task description. A task description may be a description of a bug or a new feature \nto develop in an issue tracker. Once a task is activated, Mylyn begins tracking the \ninformation a developer accesses as part of the task, modeling the developer\u2019s degree \nof interest in information using an algorithm based on the frequency and recency with \nwhich information is accessed. For instance, if a developer accesses a particular method \ndefinition only once as part of a task, as work on the task progresses, the interest level \nof that method in the degree-of- interest model will reduce. If another method is edited \nheavily by the developer as part that task, the interest level will remain high. These \ndegree-of-interest values can be used in several ways. For example, the model can be \nused to focus the development environment on just the information that matters for a \ntask. Figure\u00a0 24-2  shows the development environment interface when focused on the \nsame bug-fixing task introduced earlier. In this view, the development environment \nprovides easy access to just the information that the developer needs for the task being \nFigure 24-1.  Information overload in integrated development environmentChapter 24  enabling produ Ctive Software development by improving information flow"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "284worked on: all other information is easily accessible but does not visibly clutter the \nscreen. As a result, the developer can see how the information accessed fits into the \nstructure of the system (A) and has easier access to the parts when needed. Behind the \nscenes, as a developer works, Mylyn is automatically modeling the information flow and \nis surfacing the most important parts of that flow in the interface for easy access. This \nmodel can then be used to flow information into other development tools. For example, \nthe active task can automatically populate commit messages for SCM systems such \nas Git. Or it can be attached to an issue to share with another developer, allowing the \ninformation accessed by one developer to another developer doing a code review for \nthat same issue.\nTo determine whether Mylyn helps improve productivity by giving developers \naccess to information when it is needed, we conducted a longitudinal field study. In this \nstudy, we recruited 99 participants who were practicing software developers using the \nEclipse integrated software development environment. For the first two weeks of the \nstudy, participants worked with the integrated development environment as normal. \nThe development environment was instrumented to collect logs of how the developer \nFigure 24-2.  Mylyn\u2019s task-focused interface active in integrated development \nenvironmentChapter 24  enabling produ Ctive Software development by improving information flow"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "285worked. Once the developer had reached a threshold of coding activity, the developer \nwas invited to install the Mylyn tool within their integrated development environment. \nFurther logs of coding activity were then collected as the developer worked using Mylyn. \nTo ensure we could reasonably compare the activities before and after the installation \nof Mylyn, we defined thresholds of coding activity for acceptance into the study. Sixteen \nparticipants met our thresholds for study acceptance. For these participants, we \ncompared their edit ratios\u2014\u2013the relative amount of edit and navigation events in their \nlogs\u2014both before and after Mylyn use. We found that the use of Mylyn improved the edit \nratio of developers, adding support that Mylyn reduces friction of accessing information \nand improves productivity when looked at through the lens of actions performed. In \nother words, developers coded more, and navigated around looking for information less, \nwhen the tool focused their coding and supported their context switching. Mylyn is an \nopen source plugin for the Eclipse integrated development environment ( www.eclipse.\norg/mylyn ) and has been use by developers around the world for more than 13 years.\n Tasktop Sync: Improving Information Flow \nfor\u00a0the\u00a0Development Team\nIn working with organizations using the open source Mylyn tool, and a commercial \nversion of Mylyn our company (Tasktop Technologies Inc.) produced called Tasktop Dev, \nwe learned about additional friction for accessing information that was occurring at the \nteam level. Increasingly, companies have been moving away from the use of one vendor\u2019s \ntools to support all development activities to the use of best-of-breed tools for each \ndevelopment activity, chosen individually by the different teams in the organization. As a \nresult, business analysts who focus on requirements gathering may be using a tool from \none vendor, the developers writing code using another vendor\u2019s tool, the testers a tool from \na third vendor, and so on. While each best-of-breed tool may enable productive work, the \ninformation flow between teams is impeded as information must be manually re-entered \ninto a tool used by another team or moved in some other form, such as via a spreadsheet \nor an e-mail. Information can also fail to flow, causing difficulties in the development, \nsuch as errors when a given team may not have access to needed information. With \nthe increasing agility and need for speed of delivery in software development, a lack of \nautomation of information flow between teams is a major impediment. A Forester  \nsurvey in 2015 identified that gaps in the process of integrating tools had become the \nnumber-one source of failure and cost overruns of efforts to modernize the software Chapter 24  enabling produ Ctive Software development by improving information flow"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "286lifecycle in organizations. The impact on the productivity of teams due to friction in the \nflow of information between teams leads to a decrease in team productivity.\nThrough our work on Mylyn and Tasktop Dev, we have gained expertise on the \nvariety of ways in which tasks\u2014a unit of work\u2014are described in the best-of-breed tools \nused by different teams in large software development organizations. We realized it \nwas possible to abstract the notion of a task across these tools and to enable automatic \nmovement of task information between tools. In 2009, we introduced a tool called \nTasktop Sync. Figure\u00a0 24-3  provides an abstraction of what Tasktop Sync supports. By \nserving as a platform, Tasktop Sync enables the flow of task information between tools \nfrom many different kinds of teams, from the project management office through to \nhandling service requests.\nTasktop Sync works in the background, synchronizing information across tools in \nnear real time. Tasktop Sync accesses information in the tools via each tool\u2019s API.\u00a0As \neach tool represents task information using a different schema and within a different \nworkflow, Tasktop Sync relies on configuration information to map and transform \ndata between the tools. For example, a task in a tool used by a business analyst may \nbe a requirement with a short-form identifier and a longer name. When synchronized \nto a developer\u2019s tool, the title of the associated task in a developer\u2019s tool may become \nFigure 24-3.  Tasktop Sync Platform viewChapter 24  enabling produ Ctive Software development by improving information flow"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "287a concatenation of the identifier and the longer name from the requirements tool. \nThe synchronization rules extend beyond simple data transformations, such as \nconcatenation. When a data value indicates workflow status, such as whether a defect \nis new or has just been reopened, the status of the information must be appropriately \nmapped to workflow in other tools. Sometimes the matching of workflow information \nmay require multiple changes of state of the data in another tool, such as requiring a task \nto move from a created state automatically into an open state.\nSynchronizing information between tools also requires the interpretation and \nmanagement of context of tasks between tools. In a business analyst\u2019s tool, a task (a \nrequirement) may exist within a hierarchy. This hierarchical context must be mapped \nappropriately to other tools. For instance, an issue tracker used by a developer may need \nthis information represented in an epic and user story structure. As tools can sometimes \nrepresent contextual information in multiple ways, including as links to information in \nother tools, maintaining context during a synchronization requires careful handling.\nAs software development is not a linear activity, to support teams appropriately, \nTasktop Sync enables bidirectional synchronization. For instance, if tasks created by \na business analyst in their tool have been synchronized to a developer\u2019s tool and the \ndeveloper subsequently starts working on the task and adds a comment requiring \nclarification on the nature of the task, the comment can be automatically synchronized \nback to the business analyst\u2019s tool. Combined, these capabilities of Tasktop Sync means \nthat a team member can work in a best-of-breed tool optimized for the work they \nperform, yet they can interact directly with other team members in near real time in their \nown best-of-breed tool choices.\nTasktop Sync has been used both within and between organizations to improve  \nthe flow of information between teams involved in a software development project.  \nA credit card processing company used Tasktop Sync to integrate the results of tests from \na testing automation tool into a tool used by the organization to chart project progress. \nA major automotive manufacturer used Tasktop Sync to synchronize change request \nand defect data between their suppliers\u2019 tools and the tools used in their organization. \nAn important factor in the automotive manufacturer\u2019s case was the ability to configure \nworkflow differences between multiple repositories in use in particular instances of a \ngiven tool by a supplier. The manufacturer reported times of less than three seconds to \nsynchronize information between a supplier and themselves, providing much needed \ntransparency between software that would be integrated into the manufacturer\u2019s \nproduct.Chapter 24  enabling produ Ctive Software development by improving information flow"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "288 Tasktop Integration Hub: Improving Information \nFlow for\u00a0a\u00a0Software Development Organization\nAs we have been working to improve the flow of information in software development, \nthere have been substantial changes in the approaches taken by organizations to \ndevelop software, largely catalyzed by the DevOps movement. Over the last ten years, the \nDevOps movement has helped organizations consider how to increase automation in \nall parts of the software life cycle and to increase the focus on simultaneously achieving \nquality in software with faster delivery times [ 1]. Thinking about the overall software \ndelivery process has led to the emergence of a consideration of the value stream of \nsoftware delivery in which the delivery process is considered as an end-to-end feedback \nloop of flowing value to customers in a way that optimizes for business value. As a simple \nexample, consider an organization with two software development delivery teams: one \nthat delivers a mobile app and another that delivers a web-based app to the company\u2019s \ninsurance business. The first team is able to deliver more customer-facing features per \nmonth than the second team. By analyzing the value stream of software delivery for \neach delivery team, it is determined that the mobile app team uses an automated testing \nprocess that speeds the creation of new features with high quality compared to the web-  \nbased app team. The organization may use this information to improve the software \ndevelopment processes across more of its teams.\nAt Tasktop, our products have continued to evolve. Our focus remains on improving \ninformation flow across the organization, and our latest product offering, Tasktop \nIntegration Hub, has replaced the Sync and Dev products. Tasktop Integration Hub \nenables visibility across an organization\u2019s value stream of software delivery. Building on \nour knowledge of synchronizing data across the tools used by different teams, Tasktop \nIntegration Hub provides insight into what information flows are occurring between \ndifferent tools for different projects. Figure\u00a0 24-4  shows a sample Tasktop Integration \nLandscape drawn automatically from the integrations various teams have set up \nbetween their tools. A landscape enables an organization to consider, and optimize, the \nsteps that are occurring in their software development process. As it executes, Tasktop \nIntegration Hub captures data about how information is flowing across tools used by the \ndevelopment teams. This data enables cross-toolchain reporting so that such aspects of \ndevelopment as the time to value from requirement being specified to being deployed \ncan be tracked. The need for Tasktop Integration Hub came from the sheer number of Chapter 24  enabling produ Ctive Software development by improving information flow"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "289teams and tools that an enterprise IT organization needs to connect in order to support \nthe flow and access of information across their software delivery value streams.\nBy supporting visibility into the software life cycle and by supporting an ability \nto track metrics as changes to the life cycle are introduced, Tasktop Integration Hub \nenables a determination of where friction is occurring in the life cycle, a precursor to \nbeing able to implement changes to reduce the friction and improve productivity at an \norganizational level.\nReturning to the example of the mobile app and web-based app delivery teams \nwithin an organization, Tasktop Integration Hub provides an explicit view of how \ninformation flows across the tools used by each delivery team and can report metrics \non how many customer-facing features are progressing through each of the tools used \nby different parts of the delivery teams. Differences between various teams in this flow \nof information through the value stream can be used to question different approaches \nFigure 24-4.  Tasktop integration landscapeChapter 24  enabling produ Ctive Software development by improving information flow"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "290being taken and to identify where there are opportunities for improving productivity \nthrough process changes, such as introducing automated testing.\n Takeaways\nDelivering high-quality software quickly is the goal of many organizations, whether their \nend goal is a software product or whether their business relies internally on the software \ndeveloped. As software is an information-intensive activity, the ability to deliver value \nis critically dependent on the flow of, and access to, information. When information \ndoes not flow appropriately, delivery is delayed, or worse, errors may occur, causing a \ndecrease in quality or a further delay in delivery. If the flow of information is supported \nand optimized, delivery times can be shortened, and productivity within an organization \ncan rise.\nIn this chapter, we have considered how information flows at different levels within \na software development organization. Individuals must access particular information \nwithin the tools they use. Teams must have access to information entered and updated \nin the tools of other teams. Organizations must consider how the activities of different \nteams combine to create a value stream of software delivery. By considering these \ndifferent flows and where friction occurs, tool support can be designed to help improve \nflow and improve productivity. We have described our journey through initial academic \nresearch, the open source Mylyn tool, and follow-on commercial application life-cycle \nintegration products built by Tasktop, which have led to productivity improvements \nat the individual, team, and organization levels. Given how much software has \npenetrated into every kind of business, improving the productivity of creating software \nmeans improving the productivity of a vast number of businesses. Further analysis of \ninformation flow may lead to additional productivity improvements in the future that \ncan have far reaching impacts into healthcare, commerce, and manufacturing domains \nto name just a few.Chapter 24  enabling produ Ctive Software development by improving information flow"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "291 Key Ideas\nThe following are the key ideas of this chapter:\n\u2022 The flow of information among software developers is directly related \nto productivity.\n\u2022 When the flow of information is adequately supported, delivery \ntimes on software can be shortened, and productivity within an \norganization can rise.\n\u2022 Individuals, teams, and organizations need different kinds of support \nfor information flow.\n\u2022 Individuals, teams, and organizations can benefit from information \nflow that respects the best-of-breed and individual tools in which \nthey can work most effectively.\n References\n [1] Humble, J.\u00a0Continuous delivery sounds great, but will it work here. \nCACM, 61 (4), pp.\u00a034\u201339.\n [2] Kersten, M. and Murphy, G.C., Using task context to improve \nprogrammer productivity. In Proc. of FSE, 2006, pp.\u00a01\u201311.\n [3] Meyer, A.N., Fritz, T., Murphy, G.C., Zimmermann, T.\u00a0Software \nDevelopers\u2019 Perceptions of Productivity. In Proc. of FSE, 2014, \npp.\u00a019\u201329.Chapter 24  enabling produ Ctive Software development by improving information flow"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "292Open Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 24  enabling produ Ctive Software development by improving information flow"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "293\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6_25CHAPTER 25\nMindfulness as\u00a0a\u00a0Potential \nTool for\u00a0Productivity\nMarieke van Vugt, University of Groningen, The Netherlands\n A Definition of\u00a0Mindfulness\nNo day passes without seeing mindfulness mentioned in popular blogs as the solution \nfor productivity. Many large companies offer mindfulness classes. Why would \nmindfulness be useful for productivity? Before discussing that question, it is important \nto first define mindfulness. Traditionally it has been defined by the originator of the \nmindfulness movement Jon Kabat-Zinn as \u201cpaying attention in a particular way, in the \npresent moment, nonjudgmentally\u201d [ 5]. A common way you could go about this is by \nbringing your attention to your breath and then gently monitoring whether it is still \nthere. Before you know it, you will realize that your attention has wandered to a different \nlocation. Once you notice your attention has wandered (which can occur after two \nminutes but also after half an hour!), you are to simply drop the thought and return to \nthe breath. This is the way in which you pay attention, and it is in the present moment \nbecause you do not linger on the past nor anticipate the future. This way of paying \nattention also has a quality of nonjudgmentalness because when you realize you have \nbeen distracted, you are not to get frustrated with yourself and blame yourself for being \na terrible mindfulness practitioner, but instead you can realize that this is the natural \nthing the mind does and then start again by paying attention to the breath. You can say \nthat you try to become friends with your mind, monitoring what it does with a sense of \nchuckle and amusement (one traditional Buddhist way of phrasing that is \u201cbe like an old \nman, watching a child play\u201d). Mindfulness tends to be practiced in sessions ranging from \nthree minutes to one hour."}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "294Mindfulness is a secular contemplative practice that was developed by Jon Kabat-  \nZinn on the basis of (mostly) Buddhist meditation techniques. It is only one of many \nmeditative techniques that vary among others in the object of the meditation (which is \nnot limited to the breath but could be anything, including code on a computer screen), \nthe width of the attentional focus, and the desired outcome [ 7]. While mindfulness is \ntypically used by people to make themselves feel better and less stressed, the traditional \ngoal of mindfulness is to make the mind more pliable such that it is less overpowered \nby the negative emotions of greed, hatred, and delusion (the three main negative \nemotions in the Buddhist context). A mindful state is thus traditionally not a goal in \nitself but rather a means to live one\u2019s life more ethically and to become a more kind and \ncompassionate human being.\n Mindfulness for\u00a0Productivity?\nMindfulness is widely used in hospitals to reduce stress and support healing. It has also \nbeen touted as a solution for employees to allow them to maintain well-being in a very \nstressful environment. The idea is that you learn to relax by bringing your attention to \nyour breath and not taking your thoughts so seriously. Some preliminary evidence for \nmindfulness\u2019 effect on stress reduction was given by a seminal study [ 3], which showed \nthat employees of a biotech firm, when given a mindfulness intervention, felt less \nstressed and showed an improved immune response.\nIn addition, it is generally thought that mindfulness helps to counteract distraction \nand mindlessness and thereby allow one to concentrate for longer periods of time \nwithout interruption. For this claim there is much less evidence, as will be discussed in \nthe next section. While the practice of mindfulness can be considered to be a training \nof attention, this is not the main point of mindfulness. Moreover, it is not clear that \nthe small amounts of attention training in mindfulness are in fact sufficient to actually \nsubstantially improve concentration. This chapter will therefore critically evaluate the \ncognitive benefits of mindfulness, discuss the benefits of mindfulness for emotional \nresilience, and then suggest how mindfulness may be specifically applied in the context \nof software engineering.Chapter 25  Mindfulness as\u00a0a\u00a0 potential tool for\u00a0 produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "295 Cognitive Benefits of\u00a0Mindfulness\nThere has been an increasing amount of laboratory research investigating the \ncognitive benefits of mindfulness. Overall the benefits are modest, as indicated by a \nmeta-  analysis [ 11]. One important reason for this is that most likely a large amount \nof practice is needed before cognitive functions are improved. Nevertheless, to \nunderstand whether and how mindfulness could potentially be beneficial for software \nproductivity, it is useful to review exactly where cognitive benefits have been observed \nwith respect to attention, distraction, and memory.\nFirst and foremost, mindfulness has been studied in the context of attention training. \nThis is logical, because attention features prominently in the definition of mindfulness \nas paying attention in a particular way, nonjudgmentally. Scientifically speaking, \nattention can be subdivided into different faculties, each measured with its own task. \nPerhaps the most convincing attentional effects have been observed in the domain of \nsustained attention: the ability to maintain attention on a stimulus for a relatively long \nduration. A seminal study of practitioners on a three-month retreat showed that while \nnormally people\u2019s attention declines over the course of a task, this effect had virtually \ngone away after 1.5 months of intense practice and stayed like that even after the retreat \nhad ended [ 8]. Of course, a three-month training is not something that is feasible for the \naverage software engineer.\nOther aspects of attention that have been reported to change with mindfulness \npractice are the ability to orient it to the desired location, the ability to engage it at the \nright time, and the ability to deal with conflicting inputs. All three aspects have been \nmeasured in a single cognitive task: the attention network task. In different meditator \npopulations, improvements in all three components have been observed, although  \nthe conflict monitoring effect is the most frequently and consistently reported [ 13].  \nA final attentional capacity is the ability to allocate it flexibly to rapidly changing stimuli. \nIt has been observed that attention becomes more flexible after an intensive three-\nmonth meditation retreat [ 12]. For this effect, it does matter what kind of meditation \nyou practice, since we found that this occurred only when practitioners engaged in \nmeditation practices that involve a general monitoring of the environment, without a \nsingle specific focus such as the breath [ 15].\nAnother aspect of attention that can be measured is the tendency to get distracted, \nwhich is quantified by asking people at random moments during a boring task whether \nthey are in fact doing the task or instead are distracted (see Chapter 14 for more details Chapter 25  Mindfulness as\u00a0a\u00a0 potential tool for\u00a0 produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "296about these tasks). Mrazek and colleagues [ 10] observed that participants in such a \ntask reported fewer attentional lapses after a short mindfulness induction compared \nto a relaxation induction. Moreover, improvements in test scores on measures such \nas working memory capacity seemed to depend on an individual\u2019s tendency to get \ndistracted. Given that mindfulness involves a constant monitoring of one\u2019s distraction, \nthis makes a lot of sense.\nA third cognitive skill is memory. Several studies have demonstrated that working \nmemory\u2014the ability to keep recent information active in mind and manipulate it\u2014is \nimproved by mindfulness [ 14]. Working memory in software engineering is crucial for \ntasks such as visualizing the impact of a particular control structure on the software \narchitecture or keeping in mind the complete design for a complex program. It is \nlikely that the mindfulness-related improvements in working memory arise from \nthe reduction in distraction that has been reported to be an effect of mindfulness. \nCompared to working memory, much less is known about the effects of mindfulness on \nlong-term memory\u2014the ability to store and retrieve information more permanently. \nThis memory skill is crucial in software engineering for being able to remember the \nrelevant commands in a programming language, for example, and to remember \nhow a software architecture changes over time. In this domain of long-  term memory \nthere have been few studies. One of those studies demonstrates an improvement in \nrecognition memory, which is the ability to remember you have seen something before, \nafter a very brief mindfulness induction [ 1].\n Mindfulness and\u00a0Emotional Intelligence\nIt has also been suggested that mindfulness can enhance emotional intelligence, which \nmay be helpful for managers or teams working together. Emotional intelligence is a fairly \nfuzzy concept. The term was coined by Peter Salavoy and John Mayer and subsequently \npopularized by Daniel Goleman. It refers to the ability to recognize, understand, and \nmanage your own and others\u2019 emotions. It is easy to see that spending some time \nwatching your thoughts and emotions when you are practicing mindfulness could help \nyou to enhance this ability. What is crucial about mindfulness is that the intention is to \ncultivate a very friendly and nonjudging attitude toward your thoughts and emotions, \nwhich is an effective way to manage these emotions. Our normal way of managing our \nemotions is to try to either suppress or enhance them, and most of the time this results \nin the emotion spinning out of control. The mindfulness practitioner learns that by Chapter 25  Mindfulness as\u00a0a\u00a0 potential tool for\u00a0 produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "297simply observing the thoughts and emotions, these emotions will simply disappear by \nthemselves when not fed by attention.\nIn the context of software productivity, a crucial emotional intelligence skill is \nresilience , the ability to deal with setbacks. Resilience relies crucially on recognizing that \nwhile your emotions may seem intense, they too are fleeting. When you are criticized, \nthis may feel like a disaster, but with the perspective of impermanence gleaned from \nmindfulness, you realize that the emotional impact is just temporary. Not being too \ncaught up in catastrophizing emotions is a crucial component of cognitive resilience, \nand is likely to benefit productivity.\nFurthermore, much of programming work these days involves significant team \ncollaboration. With team collaboration, especially in a competitive environment, comes \nsignificant potential for interpersonal friction. Although little research has been done \nin this area, a recent study showed that a brief mindfulness intervention in agile teams \nimproved the ability to listen to each other [ 4], which is crucial for preventing and \nreducing interpersonal friction. Traditionally, mindfulness is used as a natural method \nto increase compassion, thought to arise naturally when you develop a sense of kindness \nand nonjudgmentalness toward your own thoughts. In fact, one experimental study \nprovided empirical evidence for such compassion: when faced with a confederate of \nthe experimenters who was on crutches, people gave up their chair more often after a \nmindfulness intervention than a wait-list control [ 2].\n Pitfalls of\u00a0Mindfulness\nThe preceding sections demonstrated the positive effects that have been reported \nof mindfulness and meditation practices on cognitive and emotional skills that are \ncrucial for productivity. However, it is important to note that also adverse effects \nof mindfulness are starting to be reported [ 6]. These effects have not yet been \nsystematically inventorized, but a large number of interviews with meditation teachers \nand serious practitioners indicate that adverse effects of mindfulness can range from \nsleep disturbances to emotional problems to resurfacing of past trauma and many more. \nOne may think that those adverse effects will arise only after long hours of mindfulness \npractice, but in fact they have also been reported in first-time meditators taking part in \nmindfulness interventions. It is therefore important to engage in mindfulness under \nthe supervision of a well-trained teacher who can recognize signs of adverse effects \nand halt the intervention if necessary. Moreover, mindfulness interventions should Chapter 25  Mindfulness as\u00a0a\u00a0 potential tool for\u00a0 produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "298never be rolled out as a blanket intervention for a whole company because they may \nnot be suitable for every individual. Future research will ideally develop an overview of \npersonality traits for whom mindfulness is a less desirable intervention.\n Mindfulness Breaks\nNow if we want to implement a mindfulness intervention in the workflow of a software \nengineer, how could we go about this? These more practical recommendations follow \nprimarily from my own experience as a mindfulness practitioner and as a meditation \nteacher. First it should be emphasized that, given its potential adverse side effects, \nit is not advisable to force it upon software engineers. It is also important to set the \nexpectations right; as mentioned, the cognitive benefits are limited, and the first gains \nare likely to arise in emotional resilience.\nHaving established these boundary conditions, if software engineers would like \nto engage in a mindfulness practice at work, in my experience, the best approach is a \ncombination of substantial practice before the day starts and small mindfulness breaks \nduring the day itself. The longer mindfulness session (ideally at least 20 minutes) serves \nto cultivate and develop cognitive skills, while the shorter sessions serve as reminders \nand refreshers during the workday. In fact, it has been suggested that these short\u2014less \nthan three-minute\u2014sessions may be the most effective breaks (i.e., more effective \nthan, for example, browsing social media for the same amount of time). One could take \nsuch a short mindfulness break after completing a subtask such as writing a routine. \nAlternatively, it is possible to set a timer to interrupt a debugging session, which may \nhelp to give a fresh view of your program.\nFor most people, using the breath as a meditation object works well because \nit reconnects you to your body. For some, however, the breath can be a little \nclaustrophobic. In that case, focusing attention on a sound can be helpful (especially \nbecause there are probably many sounds to choose from). Focusing on sounds has the \nadded benefit that you may learn to develop a more friendly attitude toward sounds that \nyou would otherwise consider to be annoying or disturbing.\nPerhaps surprisingly, for most people, taking short mindfulness breaks during a \nworkday is not easy in practice. Even for a seasoned meditator, the thought frequently \ncreeps in: \u201cShould I not be doing something more useful?\u201d There is always more to \naccomplish, and often having more tasks makes us feel more worthwhile. Even social \nmedia can sometimes be justified as being more useful than a mindfulness break Chapter 25  Mindfulness as\u00a0a\u00a0 potential tool for\u00a0 produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "299because at least you are doing something. Nevertheless, my own experience and that of \nothers [ 9] indicates that when you muster the courage to actually take a break, you are \nable to zoom out and get a better sense of priority in your work, and you are able to build \na deeper connection with your inner kindness and therefore with your co-workers. To \nhave a productive mindfulness break, it is important to not completely close yourself off \nfrom what is going on but instead to perceive it mindfully. A mindful attitude involves \nnot only having some sense of kind attention toward it but also a sense of curiosity. \nYou can investigate your gut reactions to the current situation, or you can investigate \nyour intention. Also realize that a brief mindfulness break won\u2019t always lead to feelings \nof calm and bliss. The trick is to be present and OK with whatever shows up in these \nmoments. The goal is not to be a perfect meditator!\nA final consideration to incorporating mindfulness in work is paying attention \nto your intention. Intention is much less discussed in the popular literature on \nmindfulness than focus. Nevertheless, cultivating a good intention is a crucial \ncomponent of mindfulness [ 5]. Mindfulness practice is typically engaged with an \nintention to not just feel better oneself but to also benefit other sentient beings. In my \nown personal experience, this attitude, when reinforced at the beginning and end of a \nworking day, creates a tremendous sense of space and peace of mind. Suddenly work is \nnot primarily to get ahead oneself, but also has a larger purpose. When work is not just \ndone for yourself then also setbacks are less frustrating because you realize you are not \nworking alone.\n Conclusion\nIn conclusion, it is fair to say that mindfulness has the potential to be beneficial \nfor software engineers. Mindfulness has been associated with limited cognitive \nbenefits such as a reduction in distraction and more substantial emotional benefits, \nsuch as improved ability to manage emotions and resilience in the face of setbacks. \nNevertheless, it is important to realize that it is not a panacea. Mindfulness is not \nsomething that begets immediate results with no effort. Moreover, mindfulness may not \nbe beneficial for every individual. Incorporating mindfulness in the software engineer\u2019s \nworkflow has to be done with skill, and then it can make a large difference.Chapter 25  Mindfulness as\u00a0a\u00a0 potential tool for\u00a0 produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "300 Key Ideas\nHere are the key ideas from this chapter:\n\u2022 Mindfulness has limited benefits for cognition but may improve \nemotional intelligence.\n\u2022 Short mindfulness breaks could lead to better productivity.\n\u2022 For some people mindfulness can also have adverse effects.\n References\n [1] Br own, Kirk Warren, Robert J Goodman, Richard M Ryan, and \nBhikkhu Analayo. 2016. \u201cMindfulness Enhances Episodic Memory \nPerformance: Evidence from a Multimethod Investigation. \u201d PLoS \nONE  11 (4). Public Library of Science:e0153309.\n [2] Condon, P ., G.\u00a0Desbordes, W.\u00a0B. Miller, and D.\u00a0DeSteno. \n2013. \u201cMeditation Increases Compassionate Responses to \nSuffering. \u201d Psychological Science  24 (10):2125\u20137. https://doi.\norg/10.1177/0956797613485603 .\n [3] Davidson, R.\u00a0J., J.\u00a0Kabat-Zinn, J.\u00a0Schumacher, M.\u00a0S. Rosenkranz, \nD.\u00a0Muller, S.\u00a0F . Santorelli, F .\u00a0Urbanowski, A.\u00a0Harrington, K. Bonus, \nand J.F . Sheridan. 2003. \u201c Alteration in Brain and Immune Function \nProduced by Mindfulness Meditation. \u201d Psychosomatic Medicine  \n65:564\u201370.\n [4] Heijer, Peter den, Wibo Koole, and Christoph J Stettina. 2017. \n\u201cDon\u2019t Forget to Breathe: A Controlled Trial of Mindfulness \nPractices in Agile Project Teams. \u201d In International Conference on \nAgile Software Development , 103\u201318. Springer.\n [5] Kabat-Zinn, J. 1990. Full Catastrophe Living: The Program of the \nStress Reduction Clinic at the University of Massachusetts Medical \nCenter . Dell Publishing.Chapter 25  Mindfulness as\u00a0a\u00a0 potential tool for\u00a0 produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "301 [6] Lindahl, Jared R, Nathan E Fisher, David J Cooper, Rochelle \nK Rosen, and Willoughby B Britton. 2017. \u201cThe Varieties \nof Contemplative Experience: A Mixed-Methods Study of \nMeditation-Related Challenges in Western Buddhists. \u201d PLoS ONE  \n12 (5). Public Library of Science:e0176239.\n [7] Lutz, Antoine, Amishi P Jha, John D Dunne, and Clifford D Saron. \n2015. \u201cInvestigating the Phenomenological Matrix of Mindfulness-\nRelated Practices from a Neurocognitive Perspective. \u201d American \nPsychologist  70 (7). American Psychological Association:632.\n [8] MacLean, K.\u00a0A., E.\u00a0Ferrer, S.\u00a0R. Aichele, D.\u00a0A. Bridwell, A.\u00a0P . \nZanesco, T.\u00a0L. Jacobs, B.\u00a0G. King, et\u00a0al. 2010. \u201cIntensive Meditation \nTraining Improves Perceptual Discrimination and Sustained \nAttention. \u201d Psychological Science  21 (6):829\u201339.\n [9] Meissner, T. n.d. \u201c https://www.mindful.org/Get-Good-Pause/ .\u201d  \nAccessed 2017.\n [10]  Mrazek, M.\u00a0D., J.\u00a0Smallwood, and J.\u00a0W. Schooler. 2012. \n\u201cMindfulness and Mind-  Wandering: Finding Convergence \nThrough Opposing Constructs. \u201d Emotion  12 (3):442\u201348. https://\ndoi.org/10.1037/a0026678 .\n [11]  Sedlmeier, P ., J.\u00a0Eberth, M.\u00a0Schwarz, D.\u00a0Zimmermann, F .\u00a0Haarig, \nS.\u00a0Jaeger, and S.\u00a0Kunze. 2012. \u201cThe Psychological Effects of \nMeditation: A Meta-Analysis. \u201d Psychological Bulletin  138 (6). \nAmerican Psychological Association:1139.\n [12]  Slagter, H.\u00a0A., A.\u00a0Lutz, L.\u00a0L. Greischar, A.\u00a0D. Francis, \nS.\u00a0Nieuwenhuis, J.\u00a0M. Davis, and R.\u00a0J. Davidson. 2007. \u201cMental \nTraining Affects Distribution of Limited Brain Resources. \u201d PLoS \nBiology  5 (6):e138.\n [13]  Tang, Yi-Yuan, Britta K H\u00f6lzel, and Michael I Posner. 2015. \u201cThe \nNeuroscience of Mindfulness Meditation. \u201d Nature Reviews \nNeuroscience  16 (4). Nature Publishing Group:213\u201325.Chapter 25  Mindfulness as\u00a0a\u00a0 potential tool for\u00a0 produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "302 [14]  van Vugt, M.\u00a0K., and A.\u00a0P . Jha. 2011. \u201cInvestigating the Impact \nof Mindfulness Meditation Training on Working Memory: A \nMathematical Modeling Approach. \u201d Cognitive, Affective, & \nBehavioral Neuroscience  11 (3):344\u201353.\n [15]  van Vugt, M.\u00a0K., and H.\u00a0A. Slagter. 2013. \u201cControl over Experience? \nMagnitude of the Attentional Blink Depends on Meditative State. \u201d \nConsciousness and Cognition  23C:32.\nOpen Access  This chapter is licensed under the terms of the Creative \nCommons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits any \nnoncommercial use, sharing, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license and indicate if you modified the licensed material. \nYou do not have permission under this license to share adapted material derived from \nthis chapter or parts of it.\nThe images or other third party material in this chapter are included in the chapter\u2019s \nCreative Commons license, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the chapter\u2019s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need \nto obtain permission directly from the copyright holder.Chapter 25  Mindfulness as\u00a0a\u00a0 potential tool for\u00a0 produ Ctivity"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "303\n\u00a9 The Author(s) 2019\nC. Sadowski and T. Zimmermann (eds.), Rethinking Productivity in Software Engineering ,  \nhttps://doi.org/10.1007/978-1-4842-4221-6Index\nA\nA/B testing, 150\nAchievement method, 60\nAggregate information, 182\nAgile\nAlliance conferences, 246\ndevelopment\ncost of productivity, 129,  131\nglobal out-sourcing, 126\u2013127\nplanning, 127\u2013128\nstressful environment, 128\u2013129\nmethodology, 125\u2013126,  128,  130\nprinciples, 125\u2013127,  129\u2013131\nAgile-DevOps environment\nautomated function points, 247\nCMMI, 246\nwaterfall projects, 247\nAlbrecht\u2019s FPA method vs. cosmic \nmethod, 193\nAlbrecht\u2019s function point analysis, 192\nAtlassian tool, 183\nAutomated awareness mechanisms\ncollaborative software development, 176\ndevelopers goal, 176\nquantitative/qualitative information, 176\nAutomated methods, 175\nAwareness\naggregating information\ndevelopment life cycle, 173\ndevelopment tasks, 174expected events, 174\nnumber of issues/commits, 173\nnumbers, 173\nstatus updates, 174\ntext, 174\nunexpected events, 175\ncategories, 171\ncollaboration awareness, 171\ncontext awareness, 171\nlocation awareness, 171\nsituation awareness, 172\nsocial awareness, 171\nworkspace awareness, 172\ncollaborative software  \ndevelopment, 172\ncollaborative working, 169\ndesign, tools, 170\nhigh-level status information, 170\nB\nBalanced developers, 143\nBase population, 6\nBenchmarking\nCOSMIC method, 207\ndefinition, 205\nfalse incentives, 214\nframework, 209\ninward focus, 208\nISO-standard, 210"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "304landing zone, 208\nnormalization, 210\noutward focus, 208\nproductivity measurement, 206\nsources\ndescriptive statistics table, 213\ninternal data repository, 212\nISBSG repository, 211\nstandardized measurement, 206\nBiomarker productivity\nEEG, 161\nfMRI, 162\nMRI scanner, 162\nBiometric sensors\neye-based biosensors, 161\ngoal-directed attention, 160\ninterception system, 164\nmind-wandering, 159\noutside-the-box thinking, 159\nwebcam-based eye tracking, 160\nC\nCapability Maturity Model  \n(CMM), 242\nCapability Maturity Model Integration \n(CMMI), 246\nCloud execution, 8\nCMM-based improvement  \nprograms, 242\nCognitive models\ncharacteristics, 92\ncumulative knowledge, 91\ninterruption impact, 93\nmultitasking, 93\nperformance, 94\nswitching strategies, 93value\nerror prediction, 92\nframework model, 92\nresumption lags, 92\nCollaboration awareness, 171\nCollective system knowledge gap, 256\nCommon Software Measurement \nInternational Consortium \n(COSMIC), 192\nComparison group, 5\nComplementary knowledge, 256\nComplementary research  \nmethods, 86, 98\nConfounding factors\ncultural component, 16\nintrinsic complexity, 17\nContext\nawareness, 171\nswitching, 285\nContextual inquiry (CI), 148\nControlled experiments\naim, 87\ncompeting task, 90\ncrowdsourcing platform, 90\ndiscretionary, 90\ndisruptiveness, 88\necological validity, 89\nenforced interruptions, 90\nerrors, 89\ninterface, 87\ntask interruptions, 88, 91\nCorporate culture, 74\nCOSMIC method\nCFP sizes correlation, 199\u2013201\ncomplexity, 197\nfunctional processes, 193\u2013195\nfunctional size  \nmeasurement, 192,  202Benchmarking ( cont .)Index"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "305guideline, 196\nmeasure size, 191\u2013192\nNFRs, 196\u2013197\nparameters, 198\nsize measurement  \nautomation, 201\u2013202\nCost of interruption, 271\u2013272\nCost of productivity\nalgorithmic machine, 130\ncollaboration, 129\nrisks, 130\nCritical tasks, 10\nCrosby\u2019s model, 241\nD\nDashboards, 172\ndeveloper activity, 181\u2013182\necosystem level, 184\ngoal, 179\nperformance, 183\u2013184\nproject monitoring, 183\u2013184\nrisks, 185\u2013187\nsoftware engineering, 188\nspan of data, 180\nstrategy, 180\nteam performance\ndevelopment process, 182\ndistributed teams, 183\ntask tracking, 183\ntechnology, 188\ntype of measures, 180\ntypes of data, 180\nDevelopers perceptions\nbehaviors\nproductive, 143\nunproductive, 143\nbottom-up perspective, 138field studies, 138\ntask\noutput-related measures, 140\ntop-down perspective, 137\nDevelopment\neffort, 7\nproductive, 258\nDiscretionary self-interruptions, 93\nE\nElectroencephalography (EEG), 160\nF\nFactors\noverview, 69\nproductivity, history, 70\nsoft factors, 74\ntechnical factors, 70\nFlattening/combining metrics, 16\nFlowLight\nbenefits, 273\u2013274\nfactors\nfoster awareness, 277\nprivacy concerns, 276\nsimplicity, 275\u2013276\nuser-driven design, 274\u2013275\nvalue, 277\ninterruption, 272\u2013273\nFocused developers, 142\nFour lenses, productivity\nindividual\ncomprehending skill, 49\ndeveloper\u2019s experience, 49\ninformation, 50\nsoftware team, 49\ntraining, 50Index"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "306market\ncustomers, 52\nstakeholders, 52\nvalue propositions, 52\norganizations\ncultural and policy  \nfactors, 52\nexecutives, 52\nownership, 52\npolicies, 51\nteam\ncommunication, 51\ncoordination overhead, 51\nengineering manager, 51\nmembership, 51\nsenior developers, 51\nFramework\ncaveats, 45\u201346\nconceptualizing productivity, 39\nGQM, 42\nimpact productivity, 44\u201345\nintervention, 43\u201344\nHEART, 43\nproductivity dimensions, 40\u201342\nFunctional magnetic resonance imaging \n(fMRI), 162\nFunctional size measurement, 206\nG\nGlobal software  \ndevelopment, 126\u2013127,  129\nGoal-oriented developers, 143\nGoal-question-metric  \n(GQM), 42\nGoogle, 52\nGrounded theory, 222,  253H\nHalo effect, 60\nHandoffs, 234\nHappiness, 109\u2013121\nHewlett Packard, 246\nHigh-quality code, 131\nHomogeneity, 4\u20136\nHuman-centered methods\nA/B testing, 150\u2013151\nCI, 148\ncognitive walkthrough, 151\nevaluation of intervention\ndata mining, 152\nlog analysis, 152\nusability, 151\nexploratory lab user studies, 148\nHCI, 147,  152\nnatural-programming elicitation, 149\npaper prototypes, 149\u2013150\nRapid prototyping, 149\nusability, 151\nused methods, 153\u2013154\nHuman-computer interaction  \n(HCI), 147\nHuman resources, 75\nI, J\nInfluence of quality, 33\nInformation flow\nMylyn tool, 282\ntasktop integration hub, 288\nTasktop Sync tool, 285\nInternational Function Point Users Group \n(IFPUG), 192\nInternational Software Benchmarking \nStandards Group (ISBSG), 208\nInterruptionFour lenses, productivity ( cont .)Index"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "307benefits, 95\u201396\ncognitive models, 91, 99\ncontrolled experiments, 86, 99\ndetriments, 95\u201396\nkey insights, 98\nlags, 88\nobservational studies, 94\u201395,  97, 99\nproductivity, 96\nstrategies, 97\nstress, 96\nISBSG repository, 211\nK\nKnowledge work\ndrivers\nindividual work practices, 62\u201363\nknowledge worker, 63\nphysical environment, 62\nSmartWoW types, 62\u201363\nsocial environment, 62\nvirtual environment, 62\nhistory, 57\u201358\nmeasuring techniques\nmulti-oriented, 60\u201361\noutcome-oriented, 58\u201359\npeople-oriented, 60\nprocess-oriented, 59\nL\nLanding zone, 208\nLeading developers, 143\nLenses, productivity\ncontext, 41\nlevel, 42\nstakeholders, 41\ntime period, 42Lines of code (LOC), 30, 206\nbroad productivity, 15\u201316\ncodebase modularity, 18\nconfounding factors, 16\ndata-driven decisions, 17\ndeveloper productivity, 14\u201315\nflattening/combining metrics, 16\nROI, 18\ntracking performance, 14\nLocation awareness, 171\nLone developers, 142\nM\nMeasurement\nexperiments, 23\ngood management, 25\u201326\nlonger-term goals, 22\nproductivity goals, 24\nproductivity improvements, 25\nproductivity model, 24\u201325\nqualitative data, 24\nunintended consequences, 22\nMeasuring productivity, 53\nMeasuring rumination, 163\nMeetings and E-mail trackers, 264\nMemory for goals theory, 94\nMindfulness\nbreaks, 298\u2013299\nBuddhist meditation techniques, 294\ncognitive benefits, 295\u2013296\ncounteract distraction and \nmindlessness, 294\ndefinition, 293\neffects, 297\nemotional intelligence, 296\u2013297\nresilience, 297\nstressful environment, 294Index"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "308Mindful state, 294\nMonitoring, productivity, 23\nMultiple output productivity  \nindicator, 60\nMylyn tool\nintegrated development environment, \n282\u2013285\nN\nNext-Generation tools, 126\nNonfunctional requirements (NFRs), 196\nNormalization, 210,  215\nO\nOmniGraffle program, 149\nOrganizational level, perception\ndevelopers types, 142\npatterns, 141\nOverplanning, 233\nOverspecifying, 233\nP\nPair Programming (PP)\ndefinition, 252\nhighly productive, 251\u2013252\nknowledge work, 253\u2013254\nstudy, 252\u2013253\nsystem knowledge\nadvantage, 255\ncollective gap, 256\ncomplementary, 256\nPaying attention, 293\nPE Model, 35\nPerformance metrics, 233\nPersonalAnalytics, 262\u2013264Personal Software Process  \n(PSP), 262\nPointless documentation, 233\nPomodoro technique, 266\nPressure of productivity, 131\nProcess maturity framework, 242\nProcess waste, 234\nProduct delivery rate (PDR), 207\nProductivity\ndefinition, 9, 31\ndifferences, 10\ndimensions\nlenses ( see Lenses, productivity)\nsatisfaction, 41\nvelocity, 40\nPrograms Used tracker, 264\nProject monitoring, 183\nPsychology Experiment Building \nLanguage (PEBL), 119\nQ\nQualitative analysis, 18\nR\nRaytheon\u2019s distribution, CMM level\ncategories, 245\nwork level, 245\u2013246\nReducing waste\nfocused, 236\nincremental improvement, 236\nknowledge loss, 235\nprioritizing waste removal, 237\nprocedure, 236\nRescueTime, 261\nResumption lag, 88\u201389\nRetrospection, 265Index"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "309S\nScale of Positive and Negative Experience \n(SPANE), 110\nScripting language, 8\nScrum methodology, 126\u2013127\nSelf-Assessment Manikin (SAM), 119\nSelf-monitoring at work\nbehavior changes, 266\u2013267\ndevelopers\u2019 awareness, efficiency, 265\nfostering sustainable behaviors, 268\u2013269\npersonalization, 264\nretrospection, 265\nsoftware developers, 262\nteam awareness and solving privacy \nconcerns, 267\u2013268\nSituation awareness, 172\nSlower programmers, 7\nSmoothing function, 275\nSocial awareness, 171\nSocial developers, 142\nSoft factors\ncorporate culture, 74\nexperiences, 76\u201377\nfactors, 77\nproject, 79\nskills, 76\u201377\nteam culture, 75\u201376\nwork environment, 78\nSoftware developers vs. knowledge \nworkers, 63\nSoftware development waste\nbacklog inversion, 224\u2013225\nbuilding wrong features, 223\ncognitive load, 227\u2013228\ncomplex solutions, 226\u2013227\ndistress, 228\u2013229\ngrounded theory, 222ineffective communication, 231\u2013232\nknowledge loss, 229\nmultitasking, 230\npivotal software, 222\npre-agile approaches, 233\u2013234\nrework, 225\u2013226\ntypes, 222\nSoftware engineers, 53\naffect balance, 110\nattractors, 111\ncognitive performance, 116\nconsequences of unhappiness, 115\nflow, 116\nhappy developers, 110,  118\u2013119\nimpacts of happiness, 120\u2013121\nmotivation and withdrawal, 116\u2013117\nproductivity of developers, 117\u2013118\nproductivity-related  \nconsequences, 115\nsoftware developers, 112\u2013113\nsoftware development  \nproductivity, 121\nteam members, 111\nunhappy developers, 113\u2013114\nSoftware evolution\nCOCOMO model, 30\ncustomer value, 31\neffectiveness, 33\nefficiency, 33\nfunction points, 30\nhistory, 30\u201331\nideal quality, 34\nknowledge work, 30\nlarge-scale software systems, 29\nmutual dependencies, 30\nPE model, 35\u201336\nperformance, 33Index"}, {"source": "sources/todo/Rethinking Productivity in Software Engineering.pdf", "content": "310productivity, 32\nprofitability, 33\nSwitch contexts\nco-workers, interruptions, 139\nIDE, 139\nSystem knowledge, 254\nSystem knowledge advantage, 255\nT\nTailor process improvements, 143\nTask assignment, 128\nTasktop Integration Hub\nDevOps movement, 288\nend-to-end feedback loop, 288\nintegration landscape, 288\u2013289\nTasktop Sync tool\nbest-of-breed, 285\u2013286\nbidirectional synchronization, 287\nissue tracker, 287\nplatform view, 286\nTeam\u2019s goals, 53\nTechnical factors\narchitecture design, 73\ndevelopment environment, 73\u201374\nembedded systems, 71evolution, 73\nplatform volatility, 73\nprocess factors, 72\u201373\nproduct factors, 70\u201371\nText-entry task, 93\nTime fragmentation, 78\nTime variability data, 3\nTriple-P-model, 35\nU\nUser Input tracker, 264\nV\nVerbal-based interruptions, 95\nW, X, Y\nWaterfall method, 126,  129\u2013130\nWorkday, productive, 139\u2013140\nWorkspace awareness, 172\nWork times distribution, 4\nZ\nZendesk dashboards, 184Software evolution ( cont .)Index"}]